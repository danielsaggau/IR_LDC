{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMZiT7Vqx+Ia3jlHd1g0ie6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/model/MIMIC/mimic_log_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install sentence_transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ILp7SsvzPB1N",
        "outputId": "5dc0dd76-34ac-451d-8503-d9aedf4a676a"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing collected packages: tokenizers, sentencepiece, huggingface-hub, transformers, sentence_transformers\n",
            "Successfully installed huggingface-hub-0.11.1 sentence_transformers-2.2.2 sentencepiece-0.1.97 tokenizers-0.13.2 transformers-4.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "lq9Jk7HhOdKp"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score, f1_score, precision_score\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sentence_transformers import SentenceTransformer, InputExample, losses, models, datasets, evaluation\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from sklearn.manifold import TSNE\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "# import warnings filter\n",
        "from warnings import simplefilter\n",
        "# ignore all future warnings\n",
        "simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import random\n",
        "import torch\n",
        "\n",
        "def set_seed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/danielsaggau/IR_LDC.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KDJNPeUrOzP8",
        "outputId": "fcfb425c-6c88-41e0-f759-9ec69572f442"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'IR_LDC'...\n",
            "remote: Enumerating objects: 2644, done.\u001b[K\n",
            "remote: Counting objects: 100% (951/951), done.\u001b[K\n",
            "remote: Compressing objects: 100% (353/353), done.\u001b[K\n",
            "remote: Total 2644 (delta 651), reused 863 (delta 592), pack-reused 1693\u001b[K\n",
            "Receiving objects: 100% (2644/2644), 27.45 MiB | 24.68 MiB/s, done.\n",
            "Resolving deltas: 100% (1724/1724), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "b9wJeZ-7PaHW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "!unzip /content/drive/MyDrive/mimic.jsonl.zip -d content\n",
        "with open('content/mimic.jsonl') as f:\n",
        "    data = [json.loads(line) for line in f]"
      ],
      "metadata": {
        "id": "NewZfYk1OuLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "shutil.move(\"/content/content/mimic.jsonl\", \"/content/IR_LDC/model/MIMIC\")\n",
        "dataset = load_dataset(\"/content/IR_LDC/model/MIMIC/mimic-dataset.py\")"
      ],
      "metadata": {
        "id": "BA0urWngOx1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"/content/drive/MyDrive/bregman_mimic_FT\", use_auth_token=True, use_fast=True)"
      ],
      "metadata": {
        "id": "ANPhHiiPQD1o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#model = AutoModelForSequenceClassification.from_pretrained(\"/content/drive/MyDrive/bregman_mimic_FT\", use_auth_token=True,num_labels=19, problem_type='multi_label_classification')"
      ],
      "metadata": {
        "id": "IdiFcXhJQO9D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = dataset['train']\n",
        "eval_df = dataset['validation']\n",
        "text_col=train_df['text'] \n",
        "category_col=train_df['labels']\n",
        "x_eval = eval_df['text']\n",
        "y_eval = eval_df['labels']"
      ],
      "metadata": {
        "id": "KMbUf4lTOoML"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"/content/drive/MyDrive/bregman_mimic_FT\", use_auth_token=True)\n",
        "model"
      ],
      "metadata": {
        "id": "d9SpVeGFOnot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_noFT = model.encode(text_col)\n",
        "X_eval_noFT = model.encode(x_eval)"
      ],
      "metadata": {
        "id": "C02dghd8Q-T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sgd =  LogisticRegression(max_iter=20000)\n",
        "sgd.fit(X_train_noFT, category_col)\n",
        "y_pred_eval_sgd = sgd.predict(X_eval_noFT)"
      ],
      "metadata": {
        "id": "vq13YIJLRZCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(\"yikuan8/Clinical-Longformer\", use_auth_token=True)\n",
        "model "
      ],
      "metadata": {
        "id": "KXYW0L4kSB76"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}