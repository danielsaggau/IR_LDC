{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmZ2Q35I9hwGryUmX4LMsE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/model/projection_head_costum_loss.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/danielsaggau/IR_LDC.git"
      ],
      "metadata": {
        "id": "llJBIfKvQ32e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd IR_LDC"
      ],
      "metadata": {
        "id": "_OW6Vd3vTjcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "H9vYvyZcRBvG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch \n",
        "from torch import nn\n",
        "import logging\n",
        "from transformers import AutoConfig,AutoModelForSequenceClassification,AutoTokenizer,DataCollatorWithPadding,EvalPrediction,HfArgumentParser, TrainingArguments, set_seed, EarlyStoppingCallback, Trainer, TrainerCallback \n",
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "import transformers\n",
        "import logging\n",
        "import os\n",
        "import random\n",
        "import sys\n",
        "from dataclasses import dataclass, field\n",
        "from typing import Optional, List, Dict, Any\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import f1_score\n",
        "from scipy.special import expit\n",
        "import glob\n",
        "import shutil\n",
        "\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"lex_glue\", \"scotus\")\n",
        "\n",
        "from transformers.trainer_utils import get_last_checkpoint\n",
        "from transformers.utils import check_min_version\n",
        "from transformers.utils.versions import require_version\n",
        "from transformers.tokenization_utils_base import BatchEncoding\n",
        "\n",
        "from huggingface_hub.hf_api import HfFolder\n",
        "HfFolder.save_token('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')\n",
        "import wandb"
      ],
      "metadata": {
        "id": "izlv5tc_QxRG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.subnetworks import Model"
      ],
      "metadata": {
        "id": "WNATRCDkTzR_"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, models\n",
        "model_name = 'danielsaggau/legal_long_bert'\n",
        "word_embedding_model = models.Transformer(model_name)\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension(), 'cls') # remove this block to do mean pooling\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "metadata": {
        "id": "RWqA01F9kNgn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dense_model = models.Dense(in_features=pooling_model.get_sentence_embedding_dimension(),\n",
        "                           out_features=5120, activation_function=nn.ReLU())\n",
        "dense_model"
      ],
      "metadata": {
        "id": "cFsX4X5RzXdC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.loss import BregmanRankingLoss\n",
        "import model.loss"
      ],
      "metadata": {
        "id": "kElZpRl_3BVt"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, losses, InputExample\n",
        "from torch.utils.data import DataLoader\n",
        "train_examples = [InputExample(texts=['Anchor 1', 'Positive 1']), InputExample(texts=['Anchor 2', 'Positive 2'])]\n",
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=32)"
      ],
      "metadata": {
        "id": "iZb6TOND7TFU"
      },
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model, dense_model])\n",
        "train_loss = BregmanRankingLoss(model=model, batch_size=2,\n",
        "                                temperature=0.1, sigma=2 ,lambda1=1,  lambda2=2) \n",
        "train_loss\n",
        "#model.fit([(train_dataloader, train_loss)], show_progress_bar=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7KpqsdzK7OqF",
        "outputId": "1d5b1ca6-d935-45dd-83d0-6b62cec95c1b"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BregmanRankingLoss(\n",
              "  (model): SentenceTransformer(\n",
              "    (0): Transformer({'max_seq_length': 4096, 'do_lower_case': False}) with Transformer model: LongformerModel \n",
              "    (1): Pooling({'word_embedding_dimension': 512, 'pooling_mode_cls_token': True, 'pooling_mode_mean_tokens': False, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False})\n",
              "    (2): Dense({'in_features': 512, 'out_features': 5120, 'bias': True, 'activation_function': 'torch.nn.modules.activation.ReLU'})\n",
              "  )\n",
              "  (cross_entropy_loss): CrossEntropyLoss()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 122
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit([(train_dataloader, train_loss)], show_progress_bar=True)"
      ],
      "metadata": {
        "id": "h09At5drAUWT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Raw draft (Ignore)\n"
      ],
      "metadata": {
        "id": "IOgUnxec_Iyk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ignore \n",
        "#class LongformerSubnetworks(nn.Module):\n",
        "#    def __init__(self, config, k_subs=10, fc_dim = 512, layer_sizes=[64,1]):\n",
        "#     super().__init__()\n",
        "#     self.linear = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "#     self.activation_tanh = nn.Tanh()\n",
        "#     self.activation_relu = nn.ReLU()\n",
        "#     self.subnets = nn.ModuleList()\n",
        "#     self.dropout = nn.Dropout() #\n",
        "#\n",
        "#    def forward(self, hidden_states):\n",
        "#     output = self.linear(config.hidden_size, config.hidden_size)\n",
        "#     output = self.activation_tanh(output)\n",
        "#     output = self.dropout(output, p=dr_rate)\n",
        "#     fc_out = self.model(hidden_states)\n",
        "#     out = []\n",
        "#     for subnet in self.subnets:\n",
        " #     out.append(subnet(fc_out))\n",
        " #     out = torch.cat(out,-1)\n",
        " #        return fc_out, out \n",
        "             "
      ],
      "metadata": {
        "id": "scOx48OcsqSw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}