{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "mount_file_id": "1GeuqQEmSnwLjeysCPSKiuo9pXIyRZel8",
      "authorship_tag": "ABX9TyNW16UzMpCXKV4dg/vwquiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/model/ECTHR/WIP_ECTHR_SBERT_Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mn8QpYT0r7qD"
      },
      "outputs": [],
      "source": [
        "!pip install sentence_transformers datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"lex_glue\", \"ecthr_b\")"
      ],
      "metadata": {
        "id": "dDwulaXFsMg8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\"\n",
        "model = SentenceTransformer('/content/drive/MyDrive/SIMCSE_SCOTUS/output/train_simcse-_root_.local_share_jupyter_runtime_kernel-711f5ab8-30fd-4e18-b8df-6c94b4be8b2b.json-2022-11-03_13-54-53/64000')"
      ],
      "metadata": {
        "id": "-dJ1GAurslci"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import losses\n",
        "label_list = list(range(10))\n",
        "num_labels = len(label_list)\n",
        "train_loss = losses.SoftmaxLoss(model=model, sentence_embedding_dimension=model.get_sentence_embedding_dimension(), num_labels=num_labels)"
      ],
      "metadata": {
        "id": "GNSyWJresWom"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import EvalPrediction\n",
        "from scipy.special import expit\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def compute_metrics(p: EvalPrediction):\n",
        "        # Fix gold labels\n",
        "        y_true = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n",
        "        y_true[:, :-1] = p.label_ids\n",
        "        y_true[:, -1] = (np.sum(p.label_ids, axis=1) == 0).astype('int32')\n",
        "        # Fix predictions\n",
        "        logits = p.predictions[0] if isinstance(p.predictions, tuple) else p.predictions\n",
        "        preds = (expit(logits) > 0.5).astype('int32')\n",
        "        y_pred = np.zeros((p.label_ids.shape[0], p.label_ids.shape[1] + 1), dtype=np.int32)\n",
        "        y_pred[:, :-1] = preds\n",
        "        y_pred[:, -1] = (np.sum(preds, axis=1) == 0).astype('int32')\n",
        "        # Compute scores\n",
        "        macro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='macro', zero_division=0)\n",
        "        micro_f1 = f1_score(y_true=y_true, y_pred=y_pred, average='micro', zero_division=0)\n",
        "        return {'macro-f1': macro_f1, 'micro-f1': micro_f1}"
      ],
      "metadata": {
        "id": "M5Gq_aSSxVxU"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "XRorpBF9xt2Q"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import InputExample \n",
        "train_samples = []\n",
        "for row in dataset['test']:\n",
        "            label_id = label_list\n",
        "            train_samples.append(InputExample(texts=row['text'], label=label_id))\n",
        "train_dataloader = DataLoader(train_samples, shuffle=True, batch_size=6)"
      ],
      "metadata": {
        "id": "V1Mm6kPIw0vq"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_samples[1:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zUKe15914I9",
        "outputId": "30ea5333-65c3-4163-fc05-7a9ea74728fb"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<sentence_transformers.readers.InputExample.InputExample at 0x7fbbbad8c350>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbb3d3d150>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbb3d3d250>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbb3d3d290>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbb3d3d410>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbb3d3d210>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbb3d3d1d0>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbb3d3d310>,\n",
              " <sentence_transformers.readers.InputExample.InputExample at 0x7fbbbada7c50>]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "num_epochs = 1\n",
        "model_save_path=\"/content/drive/MyDrive/CLASSIFICATION_ECTHR/\"\n",
        "warmup_steps = math.ceil(len(train_dataloader) * num_epochs * 0.1)"
      ],
      "metadata": {
        "id": "T5R6mDMPx83o"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          epochs=num_epochs,\n",
        "          evaluation_steps=1000,\n",
        "          warmup_steps=warmup_steps,\n",
        "          output_path=\"content/drive/MyDrive/CLASSIFICATION_ECTHR/\",\n",
        "          optimizer_params={'lr': 3e-5},\n",
        "          checkpoint_path='/content/drive/MyDrive/CLASSIF_ECTHR/output',\n",
        "          show_progress_bar=True,\n",
        "          checkpoint_save_steps=8000,\n",
        "          save_best_model=True,\n",
        "          )"
      ],
      "metadata": {
        "id": "WjwEkLRByfwa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}