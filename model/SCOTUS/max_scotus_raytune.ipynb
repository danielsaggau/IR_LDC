{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/model/SCOTUS/max_scotus_raytune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/danielsaggau/IR_LDC.git"
      ],
      "metadata": {
        "id": "yhxJZHEMHPiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd IR_LDC "
      ],
      "metadata": {
        "id": "WKUKdALSHSBa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47a41663-1bd5-4975-fe2d-5fc0d62c8fd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IR_LDC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "_3RtzmARHhBs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub\n",
        "!python -c \"from huggingface_hub.hf_api import HfFolder; HfFolder.save_token('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')\""
      ],
      "metadata": {
        "id": "Tdt8zbgutdPk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "import math\n",
        "from sentence_transformers import models, losses\n",
        "from sentence_transformers import LoggingHandler, SentenceTransformer, InputExample\n",
        "import logging\n",
        "from datetime import datetime\n",
        "import gzip\n",
        "import sys\n",
        "import tqdm"
      ],
      "metadata": {
        "id": "8-cWLSElFEYP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"lex_glue\", \"scotus\")"
      ],
      "metadata": {
        "id": "XoejMce7Af_6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (\n",
        "    AutoConfig,\n",
        "    AutoModelForSequenceClassification,\n",
        "    AutoTokenizer,\n",
        "    DataCollatorWithPadding,\n",
        "    EvalPrediction,\n",
        "    HfArgumentParser,\n",
        "    TrainingArguments,\n",
        "    default_data_collator,\n",
        "    set_seed,\n",
        "    EarlyStoppingCallback,\n",
        "    Trainer\n",
        ")"
      ],
      "metadata": {
        "id": "eYLRsxXYi45u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "t63WQHQpJE3i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained('danielsaggau/scotus_max_pool', use_fast=True)\n",
        "model = AutoModelForSequenceClassification.from_pretrained('danielsaggau/scotus_max_pool', num_labels=14)"
      ],
      "metadata": {
        "id": "-mFWfRttikx8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_function(examples):\n",
        "    return tokenizer(examples[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "ao0oXGD_jBw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_data = dataset.map(preprocess_function, batched=True)"
      ],
      "metadata": {
        "id": "Vbth3n7ujFhu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import TrainerCallback \n",
        "from datasets import load_metric\n",
        "import numpy as np\n",
        "import torch as nn"
      ],
      "metadata": {
        "id": "pX11zMTKj_rZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "    metric1 = load_metric(\"f1\")\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=-1)\n",
        "    micro1 = metric1.compute(predictions=predictions, references=labels, average=\"micro\")[\"f1\"]\n",
        "    macro1 = metric1.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return { \"f1-micro\": micro1, \"f1-macro\": macro1}"
      ],
      "metadata": {
        "id": "JcKnAVl9j6JS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorWithPadding(tokenizer, pad_to_multiple_of=8) # fp16"
      ],
      "metadata": {
        "id": "-QHEHLiIj84o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "class LongformerPooler(nn.Module):\n",
        "    def __init__(self, config, pooling='max'):\n",
        "        super().__init__()\n",
        "        self.dense = nn.Linear(config.hidden_size, config.hidden_size)\n",
        "        self.pooling = pooling\n",
        "        self.activation = nn.Tanh()\n",
        "        self.max_sentence_length = 512\n",
        "\n",
        "    def forward(self, hidden_states):\n",
        "        pooled_output = torch.max(hidden_states, dim=1)[0]\n",
        "        pooled_output = self.dense(pooled_output)\n",
        "        pooled_output = self.activation(pooled_output)\n",
        "        return pooled_output"
      ],
      "metadata": {
        "id": "MjmGSkzlfK4o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.longformer.pooler = LongformerPooler(model.config)"
      ],
      "metadata": {
        "id": "cEPCeH--fV_H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir='scotus_max_linear',\n",
        "    learning_rate=3e-5,\n",
        "    per_device_train_batch_size=6,\n",
        "    per_device_eval_batch_size=6,\n",
        "    num_train_epochs=10,\n",
        "    weight_decay=0.01,\n",
        "    save_strategy=\"epoch\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    push_to_hub=True,\n",
        "    metric_for_best_model=\"f1-micro\",\n",
        "    fp16=True,\n",
        "    report_to=\"wandb\",\n",
        "    greater_is_better=True,\n",
        "    lr_scheduler_type='linear',\n",
        "    run_name=\"max\",\n",
        "    load_best_model_at_end = True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8xkVkxVk-wQ",
        "outputId": "765fda4c-93e9-4628-e44f-1f3bc8202463"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "PyTorch: setting up devices\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    compute_metrics=compute_metrics,\n",
        "    args=training_args,\n",
        "    eval_dataset=tokenized_data['test'],\n",
        "    train_dataset=tokenized_data[\"train\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,    \n",
        "    callbacks = [EarlyStoppingCallback(early_stopping_patience=5)])\n"
      ],
      "metadata": {
        "id": "W2y1EX34lEmX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = tokenized_data[\"train\"].shard(index=1, num_shards=10)"
      ],
      "metadata": {
        "id": "BG9PqL4Il1Qi"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}