{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNqP0UZLdWQ/IJTt6yqDRkl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/model/SCOTUS/Bregman_shell_command_file_scotus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naqIWr56jSUf"
      },
      "outputs": [],
      "source": [
        "!git clone https://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@github.com/danielsaggau/IR_LDC.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd IR_LDC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rw6QC9ojY5t",
        "outputId": "3a2b9450-3dec-4dd9-b59b-6179097ab7c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IR_LDC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ipRGPbTR45u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPNE-lbQex_N",
        "outputId": "b343f55e-d4f8-46a1-9a12-265a9012a75b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "!wandb login fd6f7deb3126d40be9abf77ee753bf45f00e2a9a\n",
        "wandb.init(project=\"IR_LDC\")\n",
        "%env WANDB_PROJECT=IR_LDC"
      ],
      "metadata": {
        "id": "XOCuFbIKgDss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bf37d59c-afea-4fd3-95ca-816535bfb7d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielsaggau\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/IR_LDC/wandb/run-20221208_154454-2bg72b80</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/danielsaggau/IR_LDC/runs/2bg72b80\" target=\"_blank\">graceful-surf-79</a></strong> to <a href=\"https://wandb.ai/danielsaggau/IR_LDC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_PROJECT=IR_LDC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/IR_LDC/model/SCOTUS/bregman_scotus_classification.py \\\n",
        "    --output_dir logs/output_1 \\\n",
        "    --model_name '/content/drive/MyDrive/bregman_scotus_k10_s1/50000' \\\n",
        "    --model_type 'mean' \\\n",
        "    --load_best_model_at_end \\\n",
        "    --overwrite_output_dir \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --learning_rate 3e-5 \\\n",
        "    --per_device_train_batch_size 6 \\\n",
        "    --per_device_eval_batch_size 6 \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --fp16 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --metric_for_best_model \"f1-micro\" \\\n",
        "    --greater_is_better 1 \\\n",
        "    --report_to 'wandb'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQYL6fodppBA",
        "outputId": "9f0a5dad-affb-4a34-e303-447572ebdbab"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000Â Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            " 56% 4688/8340 [1:11:19<51:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:35:57,001 >> Initializing global attention on CLS token...\n",
            " 56% 4689/8340 [1:11:20<51:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:35:57,845 >> Initializing global attention on CLS token...\n",
            " 56% 4690/8340 [1:11:21<51:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:35:58,693 >> Initializing global attention on CLS token...\n",
            " 56% 4691/8340 [1:11:22<51:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:35:59,542 >> Initializing global attention on CLS token...\n",
            " 56% 4692/8340 [1:11:23<51:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:00,384 >> Initializing global attention on CLS token...\n",
            " 56% 4693/8340 [1:11:24<51:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:01,229 >> Initializing global attention on CLS token...\n",
            " 56% 4694/8340 [1:11:25<51:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:02,073 >> Initializing global attention on CLS token...\n",
            " 56% 4695/8340 [1:11:25<51:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:02,922 >> Initializing global attention on CLS token...\n",
            " 56% 4696/8340 [1:11:26<51:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:03,763 >> Initializing global attention on CLS token...\n",
            " 56% 4697/8340 [1:11:27<51:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:04,608 >> Initializing global attention on CLS token...\n",
            " 56% 4698/8340 [1:11:28<51:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:05,453 >> Initializing global attention on CLS token...\n",
            " 56% 4699/8340 [1:11:29<51:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:06,297 >> Initializing global attention on CLS token...\n",
            " 56% 4700/8340 [1:11:30<51:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:07,143 >> Initializing global attention on CLS token...\n",
            " 56% 4701/8340 [1:11:30<51:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:07,991 >> Initializing global attention on CLS token...\n",
            " 56% 4702/8340 [1:11:31<51:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:08,834 >> Initializing global attention on CLS token...\n",
            " 56% 4703/8340 [1:11:32<51:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:09,688 >> Initializing global attention on CLS token...\n",
            " 56% 4704/8340 [1:11:33<51:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:10,534 >> Initializing global attention on CLS token...\n",
            " 56% 4705/8340 [1:11:34<51:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:11,377 >> Initializing global attention on CLS token...\n",
            " 56% 4706/8340 [1:11:35<51:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:12,224 >> Initializing global attention on CLS token...\n",
            " 56% 4707/8340 [1:11:36<51:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:13,069 >> Initializing global attention on CLS token...\n",
            " 56% 4708/8340 [1:11:36<51:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:13,914 >> Initializing global attention on CLS token...\n",
            " 56% 4709/8340 [1:11:37<51:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:14,754 >> Initializing global attention on CLS token...\n",
            " 56% 4710/8340 [1:11:38<51:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:15,602 >> Initializing global attention on CLS token...\n",
            " 56% 4711/8340 [1:11:39<51:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:16,446 >> Initializing global attention on CLS token...\n",
            " 56% 4712/8340 [1:11:40<51:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:17,291 >> Initializing global attention on CLS token...\n",
            " 57% 4713/8340 [1:11:41<50:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:18,130 >> Initializing global attention on CLS token...\n",
            " 57% 4714/8340 [1:11:41<50:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:18,973 >> Initializing global attention on CLS token...\n",
            " 57% 4715/8340 [1:11:42<50:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:19,817 >> Initializing global attention on CLS token...\n",
            " 57% 4716/8340 [1:11:43<50:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:20,662 >> Initializing global attention on CLS token...\n",
            " 57% 4717/8340 [1:11:44<50:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:21,509 >> Initializing global attention on CLS token...\n",
            " 57% 4718/8340 [1:11:45<50:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:22,352 >> Initializing global attention on CLS token...\n",
            " 57% 4719/8340 [1:11:46<50:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:23,194 >> Initializing global attention on CLS token...\n",
            " 57% 4720/8340 [1:11:46<50:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:24,040 >> Initializing global attention on CLS token...\n",
            " 57% 4721/8340 [1:11:47<50:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:24,889 >> Initializing global attention on CLS token...\n",
            " 57% 4722/8340 [1:11:48<50:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:25,733 >> Initializing global attention on CLS token...\n",
            " 57% 4723/8340 [1:11:49<50:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:26,581 >> Initializing global attention on CLS token...\n",
            " 57% 4724/8340 [1:11:50<50:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:27,428 >> Initializing global attention on CLS token...\n",
            " 57% 4725/8340 [1:11:51<51:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:28,274 >> Initializing global attention on CLS token...\n",
            " 57% 4726/8340 [1:11:52<50:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:29,117 >> Initializing global attention on CLS token...\n",
            " 57% 4727/8340 [1:11:52<50:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:29,962 >> Initializing global attention on CLS token...\n",
            " 57% 4728/8340 [1:11:53<50:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:30,809 >> Initializing global attention on CLS token...\n",
            " 57% 4729/8340 [1:11:54<50:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:31,652 >> Initializing global attention on CLS token...\n",
            " 57% 4730/8340 [1:11:55<50:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:32,501 >> Initializing global attention on CLS token...\n",
            " 57% 4731/8340 [1:11:56<50:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:33,343 >> Initializing global attention on CLS token...\n",
            " 57% 4732/8340 [1:11:57<50:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:34,192 >> Initializing global attention on CLS token...\n",
            " 57% 4733/8340 [1:11:57<50:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:35,034 >> Initializing global attention on CLS token...\n",
            " 57% 4734/8340 [1:11:58<50:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:35,879 >> Initializing global attention on CLS token...\n",
            " 57% 4735/8340 [1:11:59<50:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:36,720 >> Initializing global attention on CLS token...\n",
            " 57% 4736/8340 [1:12:00<50:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:37,568 >> Initializing global attention on CLS token...\n",
            " 57% 4737/8340 [1:12:01<50:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:38,410 >> Initializing global attention on CLS token...\n",
            " 57% 4738/8340 [1:12:02<50:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:39,256 >> Initializing global attention on CLS token...\n",
            " 57% 4739/8340 [1:12:03<50:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:40,105 >> Initializing global attention on CLS token...\n",
            " 57% 4740/8340 [1:12:03<50:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:40,948 >> Initializing global attention on CLS token...\n",
            " 57% 4741/8340 [1:12:04<50:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:41,789 >> Initializing global attention on CLS token...\n",
            " 57% 4742/8340 [1:12:05<50:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:42,634 >> Initializing global attention on CLS token...\n",
            " 57% 4743/8340 [1:12:06<50:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:43,479 >> Initializing global attention on CLS token...\n",
            " 57% 4744/8340 [1:12:07<50:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:44,326 >> Initializing global attention on CLS token...\n",
            " 57% 4745/8340 [1:12:08<50:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:45,172 >> Initializing global attention on CLS token...\n",
            " 57% 4746/8340 [1:12:08<50:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:46,015 >> Initializing global attention on CLS token...\n",
            " 57% 4747/8340 [1:12:09<50:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:46,872 >> Initializing global attention on CLS token...\n",
            " 57% 4748/8340 [1:12:10<50:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:47,718 >> Initializing global attention on CLS token...\n",
            " 57% 4749/8340 [1:12:11<50:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:48,560 >> Initializing global attention on CLS token...\n",
            " 57% 4750/8340 [1:12:12<50:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:49,408 >> Initializing global attention on CLS token...\n",
            " 57% 4751/8340 [1:12:13<50:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:50,253 >> Initializing global attention on CLS token...\n",
            " 57% 4752/8340 [1:12:14<50:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:51,103 >> Initializing global attention on CLS token...\n",
            " 57% 4753/8340 [1:12:14<50:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:51,948 >> Initializing global attention on CLS token...\n",
            " 57% 4754/8340 [1:12:15<50:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:52,795 >> Initializing global attention on CLS token...\n",
            " 57% 4755/8340 [1:12:16<50:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:53,651 >> Initializing global attention on CLS token...\n",
            " 57% 4756/8340 [1:12:17<50:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:54,498 >> Initializing global attention on CLS token...\n",
            " 57% 4757/8340 [1:12:18<50:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:55,336 >> Initializing global attention on CLS token...\n",
            " 57% 4758/8340 [1:12:19<50:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:56,185 >> Initializing global attention on CLS token...\n",
            " 57% 4759/8340 [1:12:19<50:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:57,025 >> Initializing global attention on CLS token...\n",
            " 57% 4760/8340 [1:12:20<50:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:57,873 >> Initializing global attention on CLS token...\n",
            " 57% 4761/8340 [1:12:21<50:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:58,717 >> Initializing global attention on CLS token...\n",
            " 57% 4762/8340 [1:12:22<50:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:36:59,571 >> Initializing global attention on CLS token...\n",
            " 57% 4763/8340 [1:12:23<50:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:00,420 >> Initializing global attention on CLS token...\n",
            " 57% 4764/8340 [1:12:24<50:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:01,263 >> Initializing global attention on CLS token...\n",
            " 57% 4765/8340 [1:12:25<50:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:02,110 >> Initializing global attention on CLS token...\n",
            " 57% 4766/8340 [1:12:25<50:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:02,949 >> Initializing global attention on CLS token...\n",
            " 57% 4767/8340 [1:12:26<50:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:03,796 >> Initializing global attention on CLS token...\n",
            " 57% 4768/8340 [1:12:27<50:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:04,641 >> Initializing global attention on CLS token...\n",
            " 57% 4769/8340 [1:12:28<50:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:05,486 >> Initializing global attention on CLS token...\n",
            " 57% 4770/8340 [1:12:29<50:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:06,331 >> Initializing global attention on CLS token...\n",
            " 57% 4771/8340 [1:12:30<50:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:07,180 >> Initializing global attention on CLS token...\n",
            " 57% 4772/8340 [1:12:30<50:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:08,022 >> Initializing global attention on CLS token...\n",
            " 57% 4773/8340 [1:12:31<50:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:08,871 >> Initializing global attention on CLS token...\n",
            " 57% 4774/8340 [1:12:32<50:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:09,717 >> Initializing global attention on CLS token...\n",
            " 57% 4775/8340 [1:12:33<50:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:10,563 >> Initializing global attention on CLS token...\n",
            " 57% 4776/8340 [1:12:34<50:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:11,403 >> Initializing global attention on CLS token...\n",
            " 57% 4777/8340 [1:12:35<50:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:12,244 >> Initializing global attention on CLS token...\n",
            " 57% 4778/8340 [1:12:36<50:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:13,085 >> Initializing global attention on CLS token...\n",
            " 57% 4779/8340 [1:12:36<50:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:13,929 >> Initializing global attention on CLS token...\n",
            " 57% 4780/8340 [1:12:37<50:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:14,773 >> Initializing global attention on CLS token...\n",
            " 57% 4781/8340 [1:12:38<49:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:15,614 >> Initializing global attention on CLS token...\n",
            " 57% 4782/8340 [1:12:39<49:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:16,456 >> Initializing global attention on CLS token...\n",
            " 57% 4783/8340 [1:12:40<49:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:17,301 >> Initializing global attention on CLS token...\n",
            " 57% 4784/8340 [1:12:41<49:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:18,142 >> Initializing global attention on CLS token...\n",
            " 57% 4785/8340 [1:12:41<50:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:19,006 >> Initializing global attention on CLS token...\n",
            " 57% 4786/8340 [1:12:42<50:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:19,877 >> Initializing global attention on CLS token...\n",
            " 57% 4787/8340 [1:12:43<50:48,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:20,754 >> Initializing global attention on CLS token...\n",
            " 57% 4788/8340 [1:12:44<51:03,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:21,629 >> Initializing global attention on CLS token...\n",
            " 57% 4789/8340 [1:12:45<51:15,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:22,491 >> Initializing global attention on CLS token...\n",
            " 57% 4790/8340 [1:12:46<51:17,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:23,349 >> Initializing global attention on CLS token...\n",
            " 57% 4791/8340 [1:12:47<50:56,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:24,193 >> Initializing global attention on CLS token...\n",
            " 57% 4792/8340 [1:12:47<50:37,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:25,037 >> Initializing global attention on CLS token...\n",
            " 57% 4793/8340 [1:12:48<50:20,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:25,880 >> Initializing global attention on CLS token...\n",
            " 57% 4794/8340 [1:12:49<50:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:26,725 >> Initializing global attention on CLS token...\n",
            " 57% 4795/8340 [1:12:50<50:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:27,570 >> Initializing global attention on CLS token...\n",
            " 58% 4796/8340 [1:12:51<50:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:28,413 >> Initializing global attention on CLS token...\n",
            " 58% 4797/8340 [1:12:52<49:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:29,259 >> Initializing global attention on CLS token...\n",
            " 58% 4798/8340 [1:12:53<49:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:30,101 >> Initializing global attention on CLS token...\n",
            " 58% 4799/8340 [1:12:53<49:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:30,947 >> Initializing global attention on CLS token...\n",
            " 58% 4800/8340 [1:12:54<49:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:31,791 >> Initializing global attention on CLS token...\n",
            " 58% 4801/8340 [1:12:55<49:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:32,638 >> Initializing global attention on CLS token...\n",
            " 58% 4802/8340 [1:12:56<49:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:33,478 >> Initializing global attention on CLS token...\n",
            " 58% 4803/8340 [1:12:57<49:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:34,326 >> Initializing global attention on CLS token...\n",
            " 58% 4804/8340 [1:12:58<49:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:35,166 >> Initializing global attention on CLS token...\n",
            " 58% 4805/8340 [1:12:58<49:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:36,015 >> Initializing global attention on CLS token...\n",
            " 58% 4806/8340 [1:12:59<49:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:36,857 >> Initializing global attention on CLS token...\n",
            " 58% 4807/8340 [1:13:00<49:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:37,699 >> Initializing global attention on CLS token...\n",
            " 58% 4808/8340 [1:13:01<49:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:38,541 >> Initializing global attention on CLS token...\n",
            " 58% 4809/8340 [1:13:02<49:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:39,384 >> Initializing global attention on CLS token...\n",
            " 58% 4810/8340 [1:13:03<49:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:40,226 >> Initializing global attention on CLS token...\n",
            " 58% 4811/8340 [1:13:04<49:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:41,075 >> Initializing global attention on CLS token...\n",
            " 58% 4812/8340 [1:13:04<49:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:41,915 >> Initializing global attention on CLS token...\n",
            " 58% 4813/8340 [1:13:05<49:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:42,764 >> Initializing global attention on CLS token...\n",
            " 58% 4814/8340 [1:13:06<49:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:43,606 >> Initializing global attention on CLS token...\n",
            " 58% 4815/8340 [1:13:07<49:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:44,452 >> Initializing global attention on CLS token...\n",
            " 58% 4816/8340 [1:13:08<49:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:45,296 >> Initializing global attention on CLS token...\n",
            " 58% 4817/8340 [1:13:09<49:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:46,139 >> Initializing global attention on CLS token...\n",
            " 58% 4818/8340 [1:13:09<49:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:46,982 >> Initializing global attention on CLS token...\n",
            " 58% 4819/8340 [1:13:10<49:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:47,826 >> Initializing global attention on CLS token...\n",
            " 58% 4820/8340 [1:13:11<49:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:48,677 >> Initializing global attention on CLS token...\n",
            " 58% 4821/8340 [1:13:12<49:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:49,524 >> Initializing global attention on CLS token...\n",
            " 58% 4822/8340 [1:13:13<49:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:50,371 >> Initializing global attention on CLS token...\n",
            " 58% 4823/8340 [1:13:14<49:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:51,211 >> Initializing global attention on CLS token...\n",
            " 58% 4824/8340 [1:13:15<49:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:52,053 >> Initializing global attention on CLS token...\n",
            " 58% 4825/8340 [1:13:15<49:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:52,894 >> Initializing global attention on CLS token...\n",
            " 58% 4826/8340 [1:13:16<49:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:53,744 >> Initializing global attention on CLS token...\n",
            " 58% 4827/8340 [1:13:17<49:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:54,588 >> Initializing global attention on CLS token...\n",
            " 58% 4828/8340 [1:13:18<49:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:55,438 >> Initializing global attention on CLS token...\n",
            " 58% 4829/8340 [1:13:19<49:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:56,286 >> Initializing global attention on CLS token...\n",
            " 58% 4830/8340 [1:13:20<49:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:57,126 >> Initializing global attention on CLS token...\n",
            " 58% 4831/8340 [1:13:20<49:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:57,974 >> Initializing global attention on CLS token...\n",
            " 58% 4832/8340 [1:13:21<49:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:58,815 >> Initializing global attention on CLS token...\n",
            " 58% 4833/8340 [1:13:22<49:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:37:59,660 >> Initializing global attention on CLS token...\n",
            " 58% 4834/8340 [1:13:23<49:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:00,503 >> Initializing global attention on CLS token...\n",
            " 58% 4835/8340 [1:13:24<49:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:01,358 >> Initializing global attention on CLS token...\n",
            " 58% 4836/8340 [1:13:25<49:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:02,200 >> Initializing global attention on CLS token...\n",
            " 58% 4837/8340 [1:13:26<49:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:03,042 >> Initializing global attention on CLS token...\n",
            " 58% 4838/8340 [1:13:26<49:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:03,888 >> Initializing global attention on CLS token...\n",
            " 58% 4839/8340 [1:13:27<49:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:04,735 >> Initializing global attention on CLS token...\n",
            " 58% 4840/8340 [1:13:28<49:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:05,589 >> Initializing global attention on CLS token...\n",
            " 58% 4841/8340 [1:13:29<49:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:06,435 >> Initializing global attention on CLS token...\n",
            " 58% 4842/8340 [1:13:30<49:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:07,279 >> Initializing global attention on CLS token...\n",
            " 58% 4843/8340 [1:13:31<49:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:08,121 >> Initializing global attention on CLS token...\n",
            " 58% 4844/8340 [1:13:31<49:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:08,960 >> Initializing global attention on CLS token...\n",
            " 58% 4845/8340 [1:13:32<49:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:09,809 >> Initializing global attention on CLS token...\n",
            " 58% 4846/8340 [1:13:33<49:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:10,653 >> Initializing global attention on CLS token...\n",
            " 58% 4847/8340 [1:13:34<49:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:11,494 >> Initializing global attention on CLS token...\n",
            " 58% 4848/8340 [1:13:35<49:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:12,339 >> Initializing global attention on CLS token...\n",
            " 58% 4849/8340 [1:13:36<49:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:13,187 >> Initializing global attention on CLS token...\n",
            " 58% 4850/8340 [1:13:36<49:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:14,032 >> Initializing global attention on CLS token...\n",
            " 58% 4851/8340 [1:13:37<49:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:14,875 >> Initializing global attention on CLS token...\n",
            " 58% 4852/8340 [1:13:38<49:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:15,731 >> Initializing global attention on CLS token...\n",
            " 58% 4853/8340 [1:13:39<49:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:16,573 >> Initializing global attention on CLS token...\n",
            " 58% 4854/8340 [1:13:40<49:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:17,420 >> Initializing global attention on CLS token...\n",
            " 58% 4855/8340 [1:13:41<49:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:18,264 >> Initializing global attention on CLS token...\n",
            " 58% 4856/8340 [1:13:42<49:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:19,108 >> Initializing global attention on CLS token...\n",
            " 58% 4857/8340 [1:13:42<49:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:19,950 >> Initializing global attention on CLS token...\n",
            " 58% 4858/8340 [1:13:43<49:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:20,797 >> Initializing global attention on CLS token...\n",
            " 58% 4859/8340 [1:13:44<49:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:21,640 >> Initializing global attention on CLS token...\n",
            " 58% 4860/8340 [1:13:45<48:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:22,483 >> Initializing global attention on CLS token...\n",
            " 58% 4861/8340 [1:13:46<48:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:23,326 >> Initializing global attention on CLS token...\n",
            " 58% 4862/8340 [1:13:47<48:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:24,168 >> Initializing global attention on CLS token...\n",
            " 58% 4863/8340 [1:13:47<48:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:25,014 >> Initializing global attention on CLS token...\n",
            " 58% 4864/8340 [1:13:48<48:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:25,858 >> Initializing global attention on CLS token...\n",
            " 58% 4865/8340 [1:13:49<48:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:26,711 >> Initializing global attention on CLS token...\n",
            " 58% 4866/8340 [1:13:50<49:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:27,561 >> Initializing global attention on CLS token...\n",
            " 58% 4867/8340 [1:13:51<49:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:28,404 >> Initializing global attention on CLS token...\n",
            " 58% 4868/8340 [1:13:52<48:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:29,248 >> Initializing global attention on CLS token...\n",
            " 58% 4869/8340 [1:13:53<48:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:30,093 >> Initializing global attention on CLS token...\n",
            " 58% 4870/8340 [1:13:53<48:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:30,936 >> Initializing global attention on CLS token...\n",
            " 58% 4871/8340 [1:13:54<48:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:31,780 >> Initializing global attention on CLS token...\n",
            " 58% 4872/8340 [1:13:55<48:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:32,625 >> Initializing global attention on CLS token...\n",
            " 58% 4873/8340 [1:13:56<48:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:33,468 >> Initializing global attention on CLS token...\n",
            " 58% 4874/8340 [1:13:57<48:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:34,318 >> Initializing global attention on CLS token...\n",
            " 58% 4875/8340 [1:13:58<48:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:35,165 >> Initializing global attention on CLS token...\n",
            " 58% 4876/8340 [1:13:58<48:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:36,010 >> Initializing global attention on CLS token...\n",
            " 58% 4877/8340 [1:13:59<48:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:36,852 >> Initializing global attention on CLS token...\n",
            " 58% 4878/8340 [1:14:00<48:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:37,698 >> Initializing global attention on CLS token...\n",
            " 59% 4879/8340 [1:14:01<48:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:38,545 >> Initializing global attention on CLS token...\n",
            " 59% 4880/8340 [1:14:02<48:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:39,390 >> Initializing global attention on CLS token...\n",
            " 59% 4881/8340 [1:14:03<48:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:40,231 >> Initializing global attention on CLS token...\n",
            " 59% 4882/8340 [1:14:04<48:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:41,075 >> Initializing global attention on CLS token...\n",
            " 59% 4883/8340 [1:14:04<48:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:41,917 >> Initializing global attention on CLS token...\n",
            " 59% 4884/8340 [1:14:05<48:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:42,763 >> Initializing global attention on CLS token...\n",
            " 59% 4885/8340 [1:14:06<48:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:43,604 >> Initializing global attention on CLS token...\n",
            " 59% 4886/8340 [1:14:07<48:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:44,450 >> Initializing global attention on CLS token...\n",
            " 59% 4887/8340 [1:14:08<48:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:45,292 >> Initializing global attention on CLS token...\n",
            " 59% 4888/8340 [1:14:09<48:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:46,137 >> Initializing global attention on CLS token...\n",
            " 59% 4889/8340 [1:14:09<48:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:46,980 >> Initializing global attention on CLS token...\n",
            " 59% 4890/8340 [1:14:10<48:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:47,827 >> Initializing global attention on CLS token...\n",
            " 59% 4891/8340 [1:14:11<48:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:48,667 >> Initializing global attention on CLS token...\n",
            " 59% 4892/8340 [1:14:12<48:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:49,516 >> Initializing global attention on CLS token...\n",
            " 59% 4893/8340 [1:14:13<48:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:50,357 >> Initializing global attention on CLS token...\n",
            " 59% 4894/8340 [1:14:14<48:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:51,205 >> Initializing global attention on CLS token...\n",
            " 59% 4895/8340 [1:14:15<48:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:52,045 >> Initializing global attention on CLS token...\n",
            " 59% 4896/8340 [1:14:15<48:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:52,890 >> Initializing global attention on CLS token...\n",
            " 59% 4897/8340 [1:14:16<48:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:53,737 >> Initializing global attention on CLS token...\n",
            " 59% 4898/8340 [1:14:17<48:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:54,586 >> Initializing global attention on CLS token...\n",
            " 59% 4899/8340 [1:14:18<48:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:55,434 >> Initializing global attention on CLS token...\n",
            " 59% 4900/8340 [1:14:19<48:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:56,273 >> Initializing global attention on CLS token...\n",
            " 59% 4901/8340 [1:14:20<48:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:57,117 >> Initializing global attention on CLS token...\n",
            " 59% 4902/8340 [1:14:20<48:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:57,961 >> Initializing global attention on CLS token...\n",
            " 59% 4903/8340 [1:14:21<48:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:58,801 >> Initializing global attention on CLS token...\n",
            " 59% 4904/8340 [1:14:22<48:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:38:59,651 >> Initializing global attention on CLS token...\n",
            " 59% 4905/8340 [1:14:23<48:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:00,498 >> Initializing global attention on CLS token...\n",
            " 59% 4906/8340 [1:14:24<48:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:01,341 >> Initializing global attention on CLS token...\n",
            " 59% 4907/8340 [1:14:25<48:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:02,185 >> Initializing global attention on CLS token...\n",
            " 59% 4908/8340 [1:14:25<48:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:03,027 >> Initializing global attention on CLS token...\n",
            " 59% 4909/8340 [1:14:26<48:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:03,866 >> Initializing global attention on CLS token...\n",
            " 59% 4910/8340 [1:14:27<48:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:04,713 >> Initializing global attention on CLS token...\n",
            " 59% 4911/8340 [1:14:28<48:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:05,554 >> Initializing global attention on CLS token...\n",
            " 59% 4912/8340 [1:14:29<48:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:06,399 >> Initializing global attention on CLS token...\n",
            " 59% 4913/8340 [1:14:30<48:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:07,241 >> Initializing global attention on CLS token...\n",
            " 59% 4914/8340 [1:14:31<48:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:08,092 >> Initializing global attention on CLS token...\n",
            " 59% 4915/8340 [1:14:31<48:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:08,939 >> Initializing global attention on CLS token...\n",
            " 59% 4916/8340 [1:14:32<48:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:09,792 >> Initializing global attention on CLS token...\n",
            " 59% 4917/8340 [1:14:33<48:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:10,644 >> Initializing global attention on CLS token...\n",
            " 59% 4918/8340 [1:14:34<48:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:11,496 >> Initializing global attention on CLS token...\n",
            " 59% 4919/8340 [1:14:35<48:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:12,346 >> Initializing global attention on CLS token...\n",
            " 59% 4920/8340 [1:14:36<48:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:13,191 >> Initializing global attention on CLS token...\n",
            " 59% 4921/8340 [1:14:36<48:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:14,028 >> Initializing global attention on CLS token...\n",
            " 59% 4922/8340 [1:14:37<48:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:14,872 >> Initializing global attention on CLS token...\n",
            " 59% 4923/8340 [1:14:38<48:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:15,714 >> Initializing global attention on CLS token...\n",
            " 59% 4924/8340 [1:14:39<48:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:16,559 >> Initializing global attention on CLS token...\n",
            " 59% 4925/8340 [1:14:40<48:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:17,403 >> Initializing global attention on CLS token...\n",
            " 59% 4926/8340 [1:14:41<48:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:18,248 >> Initializing global attention on CLS token...\n",
            " 59% 4927/8340 [1:14:42<48:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:19,092 >> Initializing global attention on CLS token...\n",
            " 59% 4928/8340 [1:14:42<47:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:19,930 >> Initializing global attention on CLS token...\n",
            " 59% 4929/8340 [1:14:43<47:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:20,771 >> Initializing global attention on CLS token...\n",
            " 59% 4930/8340 [1:14:44<47:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:21,617 >> Initializing global attention on CLS token...\n",
            " 59% 4931/8340 [1:14:45<47:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:22,462 >> Initializing global attention on CLS token...\n",
            " 59% 4932/8340 [1:14:46<47:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:23,311 >> Initializing global attention on CLS token...\n",
            " 59% 4933/8340 [1:14:47<47:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:24,153 >> Initializing global attention on CLS token...\n",
            " 59% 4934/8340 [1:14:47<47:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:25,000 >> Initializing global attention on CLS token...\n",
            " 59% 4935/8340 [1:14:48<47:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:25,843 >> Initializing global attention on CLS token...\n",
            " 59% 4936/8340 [1:14:49<47:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:26,689 >> Initializing global attention on CLS token...\n",
            " 59% 4937/8340 [1:14:50<47:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:27,536 >> Initializing global attention on CLS token...\n",
            " 59% 4938/8340 [1:14:51<47:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:28,379 >> Initializing global attention on CLS token...\n",
            " 59% 4939/8340 [1:14:52<47:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:29,220 >> Initializing global attention on CLS token...\n",
            " 59% 4940/8340 [1:14:53<47:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:30,063 >> Initializing global attention on CLS token...\n",
            " 59% 4941/8340 [1:14:53<47:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:30,905 >> Initializing global attention on CLS token...\n",
            " 59% 4942/8340 [1:14:54<47:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:31,752 >> Initializing global attention on CLS token...\n",
            " 59% 4943/8340 [1:14:55<47:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:32,599 >> Initializing global attention on CLS token...\n",
            " 59% 4944/8340 [1:14:56<47:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:33,440 >> Initializing global attention on CLS token...\n",
            " 59% 4945/8340 [1:14:57<47:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:34,285 >> Initializing global attention on CLS token...\n",
            " 59% 4946/8340 [1:14:58<47:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:35,130 >> Initializing global attention on CLS token...\n",
            " 59% 4947/8340 [1:14:58<47:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:35,973 >> Initializing global attention on CLS token...\n",
            " 59% 4948/8340 [1:14:59<47:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:36,815 >> Initializing global attention on CLS token...\n",
            " 59% 4949/8340 [1:15:00<47:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:37,662 >> Initializing global attention on CLS token...\n",
            " 59% 4950/8340 [1:15:01<47:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:38,504 >> Initializing global attention on CLS token...\n",
            " 59% 4951/8340 [1:15:02<47:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:39,351 >> Initializing global attention on CLS token...\n",
            " 59% 4952/8340 [1:15:03<47:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:40,193 >> Initializing global attention on CLS token...\n",
            " 59% 4953/8340 [1:15:03<47:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:41,036 >> Initializing global attention on CLS token...\n",
            " 59% 4954/8340 [1:15:04<47:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:41,877 >> Initializing global attention on CLS token...\n",
            " 59% 4955/8340 [1:15:05<47:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:42,718 >> Initializing global attention on CLS token...\n",
            " 59% 4956/8340 [1:15:06<47:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:43,563 >> Initializing global attention on CLS token...\n",
            " 59% 4957/8340 [1:15:07<47:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:44,407 >> Initializing global attention on CLS token...\n",
            " 59% 4958/8340 [1:15:08<47:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:45,263 >> Initializing global attention on CLS token...\n",
            " 59% 4959/8340 [1:15:09<47:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:46,108 >> Initializing global attention on CLS token...\n",
            " 59% 4960/8340 [1:15:09<47:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:46,950 >> Initializing global attention on CLS token...\n",
            " 59% 4961/8340 [1:15:10<47:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:47,794 >> Initializing global attention on CLS token...\n",
            " 59% 4962/8340 [1:15:11<47:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:48,637 >> Initializing global attention on CLS token...\n",
            " 60% 4963/8340 [1:15:12<47:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:49,483 >> Initializing global attention on CLS token...\n",
            " 60% 4964/8340 [1:15:13<47:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:50,326 >> Initializing global attention on CLS token...\n",
            " 60% 4965/8340 [1:15:14<47:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:51,168 >> Initializing global attention on CLS token...\n",
            " 60% 4966/8340 [1:15:14<47:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:52,010 >> Initializing global attention on CLS token...\n",
            " 60% 4967/8340 [1:15:15<47:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:52,856 >> Initializing global attention on CLS token...\n",
            " 60% 4968/8340 [1:15:16<47:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:53,698 >> Initializing global attention on CLS token...\n",
            " 60% 4969/8340 [1:15:17<47:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:54,547 >> Initializing global attention on CLS token...\n",
            " 60% 4970/8340 [1:15:18<47:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:55,388 >> Initializing global attention on CLS token...\n",
            " 60% 4971/8340 [1:15:19<47:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:56,241 >> Initializing global attention on CLS token...\n",
            " 60% 4972/8340 [1:15:20<47:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:57,089 >> Initializing global attention on CLS token...\n",
            " 60% 4973/8340 [1:15:20<47:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:57,936 >> Initializing global attention on CLS token...\n",
            " 60% 4974/8340 [1:15:21<47:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:58,776 >> Initializing global attention on CLS token...\n",
            " 60% 4975/8340 [1:15:22<47:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:39:59,618 >> Initializing global attention on CLS token...\n",
            " 60% 4976/8340 [1:15:23<47:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:00,461 >> Initializing global attention on CLS token...\n",
            " 60% 4977/8340 [1:15:24<47:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:01,307 >> Initializing global attention on CLS token...\n",
            " 60% 4978/8340 [1:15:25<47:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:02,157 >> Initializing global attention on CLS token...\n",
            " 60% 4979/8340 [1:15:25<47:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:03,004 >> Initializing global attention on CLS token...\n",
            " 60% 4980/8340 [1:15:26<47:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:03,847 >> Initializing global attention on CLS token...\n",
            " 60% 4981/8340 [1:15:27<47:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:04,696 >> Initializing global attention on CLS token...\n",
            " 60% 4982/8340 [1:15:28<47:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:05,538 >> Initializing global attention on CLS token...\n",
            " 60% 4983/8340 [1:15:29<47:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:06,396 >> Initializing global attention on CLS token...\n",
            " 60% 4984/8340 [1:15:30<47:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:07,244 >> Initializing global attention on CLS token...\n",
            " 60% 4985/8340 [1:15:31<47:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:08,084 >> Initializing global attention on CLS token...\n",
            " 60% 4986/8340 [1:15:31<47:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:08,930 >> Initializing global attention on CLS token...\n",
            " 60% 4987/8340 [1:15:32<47:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:09,772 >> Initializing global attention on CLS token...\n",
            " 60% 4988/8340 [1:15:33<47:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:10,615 >> Initializing global attention on CLS token...\n",
            " 60% 4989/8340 [1:15:34<47:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:11,455 >> Initializing global attention on CLS token...\n",
            " 60% 4990/8340 [1:15:35<47:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:12,302 >> Initializing global attention on CLS token...\n",
            " 60% 4991/8340 [1:15:36<47:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:13,143 >> Initializing global attention on CLS token...\n",
            " 60% 4992/8340 [1:15:36<47:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:13,991 >> Initializing global attention on CLS token...\n",
            " 60% 4993/8340 [1:15:37<47:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:14,832 >> Initializing global attention on CLS token...\n",
            " 60% 4994/8340 [1:15:38<47:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:15,678 >> Initializing global attention on CLS token...\n",
            " 60% 4995/8340 [1:15:39<47:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:16,519 >> Initializing global attention on CLS token...\n",
            " 60% 4996/8340 [1:15:40<47:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:17,366 >> Initializing global attention on CLS token...\n",
            " 60% 4997/8340 [1:15:41<46:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:18,208 >> Initializing global attention on CLS token...\n",
            " 60% 4998/8340 [1:15:42<46:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:19,052 >> Initializing global attention on CLS token...\n",
            " 60% 4999/8340 [1:15:42<47:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:19,897 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.146, 'learning_rate': 1.2028776978417266e-05, 'epoch': 6.0}\n",
            " 60% 5000/8340 [1:15:43<49:36,  1.12it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:20,908 >> Initializing global attention on CLS token...\n",
            " 60% 5001/8340 [1:15:44<48:55,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:21,748 >> Initializing global attention on CLS token...\n",
            " 60% 5002/8340 [1:15:45<48:19,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:22,596 >> Initializing global attention on CLS token...\n",
            " 60% 5003/8340 [1:15:46<47:52,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:40:23,416 >> Initializing global attention on CLS token...\n",
            " 60% 5004/8340 [1:15:46<38:45,  1.43it/s][INFO|trainer.py:725] 2022-12-09 23:40:23,721 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-09 23:40:23,723 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-09 23:40:23,723 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-09 23:40:23,723 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:23,754 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:24,012 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:30,  7.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:24,279 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:43,  5.35it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:24,538 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:48,  4.69it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:24,796 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:52,  4.38it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:25,052 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:54,  4.19it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:25,311 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:55,  4.08it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:25,570 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:56,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:25,826 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:56,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:26,083 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:56,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:26,338 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:56,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:26,596 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:56,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:26,854 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:56,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:27,116 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:56,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:27,376 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:56,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:27,633 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:56,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:27,894 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:56,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:28,150 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:55,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:28,414 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:55,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:28,673 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:55,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:28,934 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:55,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:29,198 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:55,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:29,457 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:54,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:29,717 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:54,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:29,977 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:54,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:30,235 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:53,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:30,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:53,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:30,748 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:53,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:31,018 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:53,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:31,275 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:52,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:31,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:53,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:31,805 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:08<00:52,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:32,065 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:52,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:32,326 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:52,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:32,585 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:51,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:32,840 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:09<00:51,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:33,109 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:51,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:33,389 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:52,  3.76it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:33,659 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:52,  3.73it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:33,924 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:10<00:51,  3.74it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:34,185 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:51,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:34,452 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:51,  3.75it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:34,717 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:50,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:34,975 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:11<00:49,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:35,233 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:49,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:35,496 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:49,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:35,763 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:12<00:49,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:36,028 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:12<00:49,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:36,294 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:48,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:36,557 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:48,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:36,818 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:13<00:48,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:37,085 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:48,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:37,342 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:47,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:37,607 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:47,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:37,861 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:14<00:46,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:38,123 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:46,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:38,389 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:46,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:38,645 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:45,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:38,914 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:15<00:46,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:39,170 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:45,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:39,425 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:39,686 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:44,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:39,945 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:16<00:44,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:40,206 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:40,461 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:43,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:40,724 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:43,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:40,978 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:17<00:43,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:41,239 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:43,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:41,495 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:42,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:41,757 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:18<00:42,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:42,016 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:18<00:42,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:42,275 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:42,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:42,535 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:41,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:42,797 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:19<00:41,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:43,055 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:19<00:41,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:43,317 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:41,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:43,582 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:41,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:43,846 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:20<00:40,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:44,102 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:20<00:40,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:44,359 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:39,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:44,613 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:39,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:44,880 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:21<00:39,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:45,134 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:21<00:39,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:45,395 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:45,662 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:39,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:45,918 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:22<00:38,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:46,178 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:22<00:38,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:46,436 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:46,696 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:37,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:46,957 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:23<00:37,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:47,212 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:23<00:36,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:47,470 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:47,728 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:36,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:47,989 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:24<00:36,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:48,246 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:35,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:48,507 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:48,763 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:25<00:35,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:49,023 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:25<00:35,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:49,284 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:49,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:49,809 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:26<00:34,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:50,064 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:26<00:34,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:50,327 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:34,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:50,586 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:33,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:50,843 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:27<00:33,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:51,102 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:27<00:33,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:51,362 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:32,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:51,628 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:32,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:51,884 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:28<00:32,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:52,145 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:28<00:32,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:52,401 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:31,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:52,660 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:31,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:52,929 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:29<00:31,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:53,187 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:29<00:31,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:53,446 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:30,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:53,701 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:29<00:30,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:53,958 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:30<00:30,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:54,215 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:30<00:29,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:54,468 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:29,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:54,728 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:30<00:29,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:54,985 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:31<00:29,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:55,249 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:31<00:29,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:55,505 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:28,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:55,770 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:32<00:28,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:56,030 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:32<00:28,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:56,288 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:32<00:28,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:56,549 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:56,807 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:33<00:27,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:57,068 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:33<00:27,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:57,326 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:33<00:26,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:57,583 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:26,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:57,839 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:34<00:26,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:58,097 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:34<00:25,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:58,355 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:34<00:25,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:58,616 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:58,876 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:35<00:25,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:59,136 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:35<00:25,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:59,396 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:35<00:24,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:59,650 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:35<00:24,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:40:59,911 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:36<00:24,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:00,169 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:36<00:24,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:00,430 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:36<00:23,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:00,687 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:36<00:23,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:00,953 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:37<00:23,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:01,219 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:37<00:23,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:01,475 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:01,741 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:37<00:22,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:01,996 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:38<00:22,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:02,253 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:38<00:22,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:02,517 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:02,777 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:39<00:21,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:03,048 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:39<00:21,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:03,310 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:39<00:21,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:03,571 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:21,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:03,829 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:40<00:20,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:04,088 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:40<00:20,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:04,365 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:40<00:20,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:04,626 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:20,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:04,889 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:41<00:19,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:05,147 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:41<00:19,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:05,403 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:41<00:18,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:05,659 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:05,917 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:42<00:18,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:06,174 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:42<00:18,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:06,434 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:42<00:17,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:06,694 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:06,952 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:43<00:17,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:07,214 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:43<00:17,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:07,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:43<00:17,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:07,737 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:43<00:16,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:07,996 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:44<00:16,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:08,254 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:44<00:16,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:08,519 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:44<00:15,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:08,787 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:45<00:15,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:09,042 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:45<00:15,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:09,305 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:45<00:15,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:09,567 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:45<00:14,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:09,826 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:46<00:14,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:10,087 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:46<00:14,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:10,343 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:46<00:14,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:10,608 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:46<00:13,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:10,867 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:47<00:13,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:11,126 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:47<00:13,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:11,383 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:47<00:12,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:11,642 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:47<00:12,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:11,901 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:48<00:12,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:12,159 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:48<00:12,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:12,414 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:48<00:11,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:12,671 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:48<00:11,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:12,936 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:49<00:11,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:13,190 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:49<00:11,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:13,453 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:49<00:10,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:13,713 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:49<00:10,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:13,970 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:50<00:10,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:14,234 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:50<00:10,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:14,490 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:50<00:09,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:14,754 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:51<00:09,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:15,012 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:51<00:09,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:15,276 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:51<00:09,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:15,537 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:51<00:08,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:15,794 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:52<00:08,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:16,050 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:52<00:08,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:16,309 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:52<00:08,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:16,572 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:52<00:07,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:16,842 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:53<00:07,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:17,099 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:53<00:07,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:17,357 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:53<00:07,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:17,613 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:53<00:06,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:17,870 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:54<00:06,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:18,121 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:54<00:06,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:18,381 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:54<00:05,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:18,638 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:54<00:05,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:18,894 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:55<00:05,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:19,152 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:55<00:05,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:19,406 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:55<00:04,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:19,673 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:55<00:04,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:19,928 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:56<00:04,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:20,189 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:56<00:04,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:20,444 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:56<00:03,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:20,713 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:56<00:03,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:20,969 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:57<00:03,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:21,231 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:57<00:03,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:21,499 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:57<00:02,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:21,758 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:58<00:02,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:22,036 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:58<00:02,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:22,297 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:58<00:02,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:22,552 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:58<00:01,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:22,827 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:59<00:01,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:23,093 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:59<00:01,  3.75it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:23,371 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:59<00:01,  3.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:23,627 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:59<00:00,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:23,882 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [01:00<00:00,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:24,139 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [01:00<00:00,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:24,378 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.3870692253112793, 'eval_f1-micro': 0.7714285714285715, 'eval_f1-macro': 0.6871046676274961, 'eval_runtime': 61.0242, 'eval_samples_per_second': 22.942, 'eval_steps_per_second': 3.835, 'epoch': 6.0}\n",
            " 60% 5004/8340 [1:16:47<38:45,  1.43it/s]\n",
            "100% 234/234 [01:00<00:00,  3.83it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-09 23:41:24,750 >> Saving model checkpoint to logs/output_1/checkpoint-5004\n",
            "[INFO|configuration_utils.py:447] 2022-12-09 23:41:24,751 >> Configuration saved in logs/output_1/checkpoint-5004/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-09 23:41:25,190 >> Model weights saved in logs/output_1/checkpoint-5004/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-09 23:41:25,191 >> tokenizer config file saved in logs/output_1/checkpoint-5004/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-09 23:41:25,192 >> Special tokens file saved in logs/output_1/checkpoint-5004/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-09 23:41:26,015 >> Initializing global attention on CLS token...\n",
            " 60% 5005/8340 [1:16:49<17:59:24, 19.42s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:26,857 >> Initializing global attention on CLS token...\n",
            " 60% 5006/8340 [1:16:50<12:49:30, 13.85s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:27,706 >> Initializing global attention on CLS token...\n",
            " 60% 5007/8340 [1:16:51<9:12:30,  9.95s/it] [INFO|modeling_longformer.py:1932] 2022-12-09 23:41:28,547 >> Initializing global attention on CLS token...\n",
            " 60% 5008/8340 [1:16:52<6:40:44,  7.22s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:29,392 >> Initializing global attention on CLS token...\n",
            " 60% 5009/8340 [1:16:53<4:54:26,  5.30s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:30,235 >> Initializing global attention on CLS token...\n",
            " 60% 5010/8340 [1:16:54<3:40:08,  3.97s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:31,080 >> Initializing global attention on CLS token...\n",
            " 60% 5011/8340 [1:16:54<2:48:06,  3.03s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:31,927 >> Initializing global attention on CLS token...\n",
            " 60% 5012/8340 [1:16:55<2:11:41,  2.37s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:32,769 >> Initializing global attention on CLS token...\n",
            " 60% 5013/8340 [1:16:56<1:46:10,  1.91s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:33,612 >> Initializing global attention on CLS token...\n",
            " 60% 5014/8340 [1:16:57<1:28:18,  1.59s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:34,455 >> Initializing global attention on CLS token...\n",
            " 60% 5015/8340 [1:16:58<1:15:49,  1.37s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:35,298 >> Initializing global attention on CLS token...\n",
            " 60% 5016/8340 [1:16:59<1:07:02,  1.21s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:36,140 >> Initializing global attention on CLS token...\n",
            " 60% 5017/8340 [1:16:59<1:00:54,  1.10s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:36,984 >> Initializing global attention on CLS token...\n",
            " 60% 5018/8340 [1:17:00<56:37,  1.02s/it]  [INFO|modeling_longformer.py:1932] 2022-12-09 23:41:37,825 >> Initializing global attention on CLS token...\n",
            " 60% 5019/8340 [1:17:01<53:40,  1.03it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:38,672 >> Initializing global attention on CLS token...\n",
            " 60% 5020/8340 [1:17:02<51:33,  1.07it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:39,515 >> Initializing global attention on CLS token...\n",
            " 60% 5021/8340 [1:17:03<50:09,  1.10it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:40,370 >> Initializing global attention on CLS token...\n",
            " 60% 5022/8340 [1:17:04<49:18,  1.12it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:41,218 >> Initializing global attention on CLS token...\n",
            " 60% 5023/8340 [1:17:05<48:24,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:42,058 >> Initializing global attention on CLS token...\n",
            " 60% 5024/8340 [1:17:05<47:53,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:42,905 >> Initializing global attention on CLS token...\n",
            " 60% 5025/8340 [1:17:06<47:32,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:43,748 >> Initializing global attention on CLS token...\n",
            " 60% 5026/8340 [1:17:07<47:12,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:44,589 >> Initializing global attention on CLS token...\n",
            " 60% 5027/8340 [1:17:08<47:01,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:45,433 >> Initializing global attention on CLS token...\n",
            " 60% 5028/8340 [1:17:09<46:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:46,276 >> Initializing global attention on CLS token...\n",
            " 60% 5029/8340 [1:17:10<46:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:47,121 >> Initializing global attention on CLS token...\n",
            " 60% 5030/8340 [1:17:10<46:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:47,968 >> Initializing global attention on CLS token...\n",
            " 60% 5031/8340 [1:17:11<46:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:48,817 >> Initializing global attention on CLS token...\n",
            " 60% 5032/8340 [1:17:12<46:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:49,666 >> Initializing global attention on CLS token...\n",
            " 60% 5033/8340 [1:17:13<46:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:50,507 >> Initializing global attention on CLS token...\n",
            " 60% 5034/8340 [1:17:14<46:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:51,347 >> Initializing global attention on CLS token...\n",
            " 60% 5035/8340 [1:17:15<46:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:52,192 >> Initializing global attention on CLS token...\n",
            " 60% 5036/8340 [1:17:15<46:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:53,031 >> Initializing global attention on CLS token...\n",
            " 60% 5037/8340 [1:17:16<46:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:53,870 >> Initializing global attention on CLS token...\n",
            " 60% 5038/8340 [1:17:17<46:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:54,717 >> Initializing global attention on CLS token...\n",
            " 60% 5039/8340 [1:17:18<46:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:55,558 >> Initializing global attention on CLS token...\n",
            " 60% 5040/8340 [1:17:19<46:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:56,404 >> Initializing global attention on CLS token...\n",
            " 60% 5041/8340 [1:17:20<46:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:57,248 >> Initializing global attention on CLS token...\n",
            " 60% 5042/8340 [1:17:21<46:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:58,092 >> Initializing global attention on CLS token...\n",
            " 60% 5043/8340 [1:17:21<46:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:58,935 >> Initializing global attention on CLS token...\n",
            " 60% 5044/8340 [1:17:22<46:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:41:59,788 >> Initializing global attention on CLS token...\n",
            " 60% 5045/8340 [1:17:23<46:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:00,639 >> Initializing global attention on CLS token...\n",
            " 61% 5046/8340 [1:17:24<46:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:01,486 >> Initializing global attention on CLS token...\n",
            " 61% 5047/8340 [1:17:25<46:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:02,331 >> Initializing global attention on CLS token...\n",
            " 61% 5048/8340 [1:17:26<46:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:03,176 >> Initializing global attention on CLS token...\n",
            " 61% 5049/8340 [1:17:26<46:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:04,019 >> Initializing global attention on CLS token...\n",
            " 61% 5050/8340 [1:17:27<46:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:04,866 >> Initializing global attention on CLS token...\n",
            " 61% 5051/8340 [1:17:28<46:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:05,710 >> Initializing global attention on CLS token...\n",
            " 61% 5052/8340 [1:17:29<46:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:06,557 >> Initializing global attention on CLS token...\n",
            " 61% 5053/8340 [1:17:30<46:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:07,397 >> Initializing global attention on CLS token...\n",
            " 61% 5054/8340 [1:17:31<46:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:08,244 >> Initializing global attention on CLS token...\n",
            " 61% 5055/8340 [1:17:32<46:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:09,083 >> Initializing global attention on CLS token...\n",
            " 61% 5056/8340 [1:17:32<46:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:09,929 >> Initializing global attention on CLS token...\n",
            " 61% 5057/8340 [1:17:33<46:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:10,772 >> Initializing global attention on CLS token...\n",
            " 61% 5058/8340 [1:17:34<46:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:11,617 >> Initializing global attention on CLS token...\n",
            " 61% 5059/8340 [1:17:35<46:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:12,459 >> Initializing global attention on CLS token...\n",
            " 61% 5060/8340 [1:17:36<46:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:13,301 >> Initializing global attention on CLS token...\n",
            " 61% 5061/8340 [1:17:37<46:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:14,147 >> Initializing global attention on CLS token...\n",
            " 61% 5062/8340 [1:17:37<46:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:14,996 >> Initializing global attention on CLS token...\n",
            " 61% 5063/8340 [1:17:38<46:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:15,838 >> Initializing global attention on CLS token...\n",
            " 61% 5064/8340 [1:17:39<46:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:16,688 >> Initializing global attention on CLS token...\n",
            " 61% 5065/8340 [1:17:40<46:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:17,532 >> Initializing global attention on CLS token...\n",
            " 61% 5066/8340 [1:17:41<46:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:18,376 >> Initializing global attention on CLS token...\n",
            " 61% 5067/8340 [1:17:42<46:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:19,225 >> Initializing global attention on CLS token...\n",
            " 61% 5068/8340 [1:17:43<46:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:20,065 >> Initializing global attention on CLS token...\n",
            " 61% 5069/8340 [1:17:43<46:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:20,912 >> Initializing global attention on CLS token...\n",
            " 61% 5070/8340 [1:17:44<45:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:21,752 >> Initializing global attention on CLS token...\n",
            " 61% 5071/8340 [1:17:45<45:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:22,598 >> Initializing global attention on CLS token...\n",
            " 61% 5072/8340 [1:17:46<45:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:23,441 >> Initializing global attention on CLS token...\n",
            " 61% 5073/8340 [1:17:47<46:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:24,296 >> Initializing global attention on CLS token...\n",
            " 61% 5074/8340 [1:17:48<46:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:25,140 >> Initializing global attention on CLS token...\n",
            " 61% 5075/8340 [1:17:48<46:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:25,982 >> Initializing global attention on CLS token...\n",
            " 61% 5076/8340 [1:17:49<45:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:26,825 >> Initializing global attention on CLS token...\n",
            " 61% 5077/8340 [1:17:50<45:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:27,663 >> Initializing global attention on CLS token...\n",
            " 61% 5078/8340 [1:17:51<45:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:28,506 >> Initializing global attention on CLS token...\n",
            " 61% 5079/8340 [1:17:52<45:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:29,356 >> Initializing global attention on CLS token...\n",
            " 61% 5080/8340 [1:17:53<45:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:30,205 >> Initializing global attention on CLS token...\n",
            " 61% 5081/8340 [1:17:54<45:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:31,047 >> Initializing global attention on CLS token...\n",
            " 61% 5082/8340 [1:17:54<45:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:31,890 >> Initializing global attention on CLS token...\n",
            " 61% 5083/8340 [1:17:55<45:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:32,735 >> Initializing global attention on CLS token...\n",
            " 61% 5084/8340 [1:17:56<45:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:33,585 >> Initializing global attention on CLS token...\n",
            " 61% 5085/8340 [1:17:57<45:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:34,429 >> Initializing global attention on CLS token...\n",
            " 61% 5086/8340 [1:17:58<45:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:35,270 >> Initializing global attention on CLS token...\n",
            " 61% 5087/8340 [1:17:59<45:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:36,115 >> Initializing global attention on CLS token...\n",
            " 61% 5088/8340 [1:17:59<45:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:36,966 >> Initializing global attention on CLS token...\n",
            " 61% 5089/8340 [1:18:00<45:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:37,813 >> Initializing global attention on CLS token...\n",
            " 61% 5090/8340 [1:18:01<45:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:38,654 >> Initializing global attention on CLS token...\n",
            " 61% 5091/8340 [1:18:02<45:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:39,493 >> Initializing global attention on CLS token...\n",
            " 61% 5092/8340 [1:18:03<45:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:40,340 >> Initializing global attention on CLS token...\n",
            " 61% 5093/8340 [1:18:04<45:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:41,183 >> Initializing global attention on CLS token...\n",
            " 61% 5094/8340 [1:18:04<45:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:42,028 >> Initializing global attention on CLS token...\n",
            " 61% 5095/8340 [1:18:05<45:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:42,876 >> Initializing global attention on CLS token...\n",
            " 61% 5096/8340 [1:18:06<45:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:43,724 >> Initializing global attention on CLS token...\n",
            " 61% 5097/8340 [1:18:07<45:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:44,568 >> Initializing global attention on CLS token...\n",
            " 61% 5098/8340 [1:18:08<45:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:45,415 >> Initializing global attention on CLS token...\n",
            " 61% 5099/8340 [1:18:09<45:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:46,256 >> Initializing global attention on CLS token...\n",
            " 61% 5100/8340 [1:18:10<45:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:47,104 >> Initializing global attention on CLS token...\n",
            " 61% 5101/8340 [1:18:10<45:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:47,946 >> Initializing global attention on CLS token...\n",
            " 61% 5102/8340 [1:18:11<45:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:48,794 >> Initializing global attention on CLS token...\n",
            " 61% 5103/8340 [1:18:12<45:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:49,641 >> Initializing global attention on CLS token...\n",
            " 61% 5104/8340 [1:18:13<45:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:50,488 >> Initializing global attention on CLS token...\n",
            " 61% 5105/8340 [1:18:14<45:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:51,332 >> Initializing global attention on CLS token...\n",
            " 61% 5106/8340 [1:18:15<45:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:52,178 >> Initializing global attention on CLS token...\n",
            " 61% 5107/8340 [1:18:15<45:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:53,022 >> Initializing global attention on CLS token...\n",
            " 61% 5108/8340 [1:18:16<45:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:53,869 >> Initializing global attention on CLS token...\n",
            " 61% 5109/8340 [1:18:17<45:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:54,710 >> Initializing global attention on CLS token...\n",
            " 61% 5110/8340 [1:18:18<45:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:55,553 >> Initializing global attention on CLS token...\n",
            " 61% 5111/8340 [1:18:19<45:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:56,398 >> Initializing global attention on CLS token...\n",
            " 61% 5112/8340 [1:18:20<45:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:57,238 >> Initializing global attention on CLS token...\n",
            " 61% 5113/8340 [1:18:21<45:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:58,087 >> Initializing global attention on CLS token...\n",
            " 61% 5114/8340 [1:18:21<45:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:58,933 >> Initializing global attention on CLS token...\n",
            " 61% 5115/8340 [1:18:22<45:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:42:59,776 >> Initializing global attention on CLS token...\n",
            " 61% 5116/8340 [1:18:23<45:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:00,619 >> Initializing global attention on CLS token...\n",
            " 61% 5117/8340 [1:18:24<45:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:01,462 >> Initializing global attention on CLS token...\n",
            " 61% 5118/8340 [1:18:25<45:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:02,302 >> Initializing global attention on CLS token...\n",
            " 61% 5119/8340 [1:18:26<45:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:03,146 >> Initializing global attention on CLS token...\n",
            " 61% 5120/8340 [1:18:26<45:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:03,993 >> Initializing global attention on CLS token...\n",
            " 61% 5121/8340 [1:18:27<45:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:04,835 >> Initializing global attention on CLS token...\n",
            " 61% 5122/8340 [1:18:28<45:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:05,679 >> Initializing global attention on CLS token...\n",
            " 61% 5123/8340 [1:18:29<45:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:06,523 >> Initializing global attention on CLS token...\n",
            " 61% 5124/8340 [1:18:30<45:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:07,365 >> Initializing global attention on CLS token...\n",
            " 61% 5125/8340 [1:18:31<45:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:08,209 >> Initializing global attention on CLS token...\n",
            " 61% 5126/8340 [1:18:32<45:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:09,055 >> Initializing global attention on CLS token...\n",
            " 61% 5127/8340 [1:18:32<45:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:09,899 >> Initializing global attention on CLS token...\n",
            " 61% 5128/8340 [1:18:33<45:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:10,747 >> Initializing global attention on CLS token...\n",
            " 61% 5129/8340 [1:18:34<45:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:11,585 >> Initializing global attention on CLS token...\n",
            " 62% 5130/8340 [1:18:35<45:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:12,430 >> Initializing global attention on CLS token...\n",
            " 62% 5131/8340 [1:18:36<45:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:13,271 >> Initializing global attention on CLS token...\n",
            " 62% 5132/8340 [1:18:37<45:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:14,114 >> Initializing global attention on CLS token...\n",
            " 62% 5133/8340 [1:18:37<45:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:14,956 >> Initializing global attention on CLS token...\n",
            " 62% 5134/8340 [1:18:38<45:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:15,798 >> Initializing global attention on CLS token...\n",
            " 62% 5135/8340 [1:18:39<45:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:16,643 >> Initializing global attention on CLS token...\n",
            " 62% 5136/8340 [1:18:40<44:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:17,484 >> Initializing global attention on CLS token...\n",
            " 62% 5137/8340 [1:18:41<44:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:18,324 >> Initializing global attention on CLS token...\n",
            " 62% 5138/8340 [1:18:42<44:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:19,163 >> Initializing global attention on CLS token...\n",
            " 62% 5139/8340 [1:18:42<44:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:20,005 >> Initializing global attention on CLS token...\n",
            " 62% 5140/8340 [1:18:43<44:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:20,849 >> Initializing global attention on CLS token...\n",
            " 62% 5141/8340 [1:18:44<44:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:21,696 >> Initializing global attention on CLS token...\n",
            " 62% 5142/8340 [1:18:45<44:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:22,538 >> Initializing global attention on CLS token...\n",
            " 62% 5143/8340 [1:18:46<44:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:23,381 >> Initializing global attention on CLS token...\n",
            " 62% 5144/8340 [1:18:47<44:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:24,227 >> Initializing global attention on CLS token...\n",
            " 62% 5145/8340 [1:18:48<44:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:25,069 >> Initializing global attention on CLS token...\n",
            " 62% 5146/8340 [1:18:48<44:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:25,913 >> Initializing global attention on CLS token...\n",
            " 62% 5147/8340 [1:18:49<44:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:26,758 >> Initializing global attention on CLS token...\n",
            " 62% 5148/8340 [1:18:50<44:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:27,603 >> Initializing global attention on CLS token...\n",
            " 62% 5149/8340 [1:18:51<44:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:28,444 >> Initializing global attention on CLS token...\n",
            " 62% 5150/8340 [1:18:52<44:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:29,285 >> Initializing global attention on CLS token...\n",
            " 62% 5151/8340 [1:18:53<44:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:30,133 >> Initializing global attention on CLS token...\n",
            " 62% 5152/8340 [1:18:53<44:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:30,976 >> Initializing global attention on CLS token...\n",
            " 62% 5153/8340 [1:18:54<44:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:31,822 >> Initializing global attention on CLS token...\n",
            " 62% 5154/8340 [1:18:55<44:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:32,660 >> Initializing global attention on CLS token...\n",
            " 62% 5155/8340 [1:18:56<44:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:33,502 >> Initializing global attention on CLS token...\n",
            " 62% 5156/8340 [1:18:57<44:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:34,355 >> Initializing global attention on CLS token...\n",
            " 62% 5157/8340 [1:18:58<44:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:35,199 >> Initializing global attention on CLS token...\n",
            " 62% 5158/8340 [1:18:59<44:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:36,043 >> Initializing global attention on CLS token...\n",
            " 62% 5159/8340 [1:18:59<44:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:36,887 >> Initializing global attention on CLS token...\n",
            " 62% 5160/8340 [1:19:00<44:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:37,731 >> Initializing global attention on CLS token...\n",
            " 62% 5161/8340 [1:19:01<44:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:38,578 >> Initializing global attention on CLS token...\n",
            " 62% 5162/8340 [1:19:02<44:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:39,419 >> Initializing global attention on CLS token...\n",
            " 62% 5163/8340 [1:19:03<44:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:40,270 >> Initializing global attention on CLS token...\n",
            " 62% 5164/8340 [1:19:04<44:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:41,121 >> Initializing global attention on CLS token...\n",
            " 62% 5165/8340 [1:19:04<44:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:41,970 >> Initializing global attention on CLS token...\n",
            " 62% 5166/8340 [1:19:05<44:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:42,809 >> Initializing global attention on CLS token...\n",
            " 62% 5167/8340 [1:19:06<44:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:43,655 >> Initializing global attention on CLS token...\n",
            " 62% 5168/8340 [1:19:07<44:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:44,495 >> Initializing global attention on CLS token...\n",
            " 62% 5169/8340 [1:19:08<44:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:45,345 >> Initializing global attention on CLS token...\n",
            " 62% 5170/8340 [1:19:09<44:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:46,187 >> Initializing global attention on CLS token...\n",
            " 62% 5171/8340 [1:19:09<44:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:47,035 >> Initializing global attention on CLS token...\n",
            " 62% 5172/8340 [1:19:10<44:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:47,873 >> Initializing global attention on CLS token...\n",
            " 62% 5173/8340 [1:19:11<44:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:48,714 >> Initializing global attention on CLS token...\n",
            " 62% 5174/8340 [1:19:12<44:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:49,557 >> Initializing global attention on CLS token...\n",
            " 62% 5175/8340 [1:19:13<44:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:50,401 >> Initializing global attention on CLS token...\n",
            " 62% 5176/8340 [1:19:14<44:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:51,245 >> Initializing global attention on CLS token...\n",
            " 62% 5177/8340 [1:19:15<44:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:52,090 >> Initializing global attention on CLS token...\n",
            " 62% 5178/8340 [1:19:15<44:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:52,933 >> Initializing global attention on CLS token...\n",
            " 62% 5179/8340 [1:19:16<44:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:53,774 >> Initializing global attention on CLS token...\n",
            " 62% 5180/8340 [1:19:17<44:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:54,616 >> Initializing global attention on CLS token...\n",
            " 62% 5181/8340 [1:19:18<44:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:55,461 >> Initializing global attention on CLS token...\n",
            " 62% 5182/8340 [1:19:19<44:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:56,306 >> Initializing global attention on CLS token...\n",
            " 62% 5183/8340 [1:19:20<44:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:57,165 >> Initializing global attention on CLS token...\n",
            " 62% 5184/8340 [1:19:20<44:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:58,010 >> Initializing global attention on CLS token...\n",
            " 62% 5185/8340 [1:19:21<44:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:58,856 >> Initializing global attention on CLS token...\n",
            " 62% 5186/8340 [1:19:22<44:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:43:59,705 >> Initializing global attention on CLS token...\n",
            " 62% 5187/8340 [1:19:23<44:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:00,552 >> Initializing global attention on CLS token...\n",
            " 62% 5188/8340 [1:19:24<44:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:01,393 >> Initializing global attention on CLS token...\n",
            " 62% 5189/8340 [1:19:25<44:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:02,235 >> Initializing global attention on CLS token...\n",
            " 62% 5190/8340 [1:19:26<44:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:03,081 >> Initializing global attention on CLS token...\n",
            " 62% 5191/8340 [1:19:26<44:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:03,922 >> Initializing global attention on CLS token...\n",
            " 62% 5192/8340 [1:19:27<44:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:04,772 >> Initializing global attention on CLS token...\n",
            " 62% 5193/8340 [1:19:28<44:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:05,612 >> Initializing global attention on CLS token...\n",
            " 62% 5194/8340 [1:19:29<44:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:06,461 >> Initializing global attention on CLS token...\n",
            " 62% 5195/8340 [1:19:30<44:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:07,301 >> Initializing global attention on CLS token...\n",
            " 62% 5196/8340 [1:19:31<44:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:08,147 >> Initializing global attention on CLS token...\n",
            " 62% 5197/8340 [1:19:31<44:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:08,996 >> Initializing global attention on CLS token...\n",
            " 62% 5198/8340 [1:19:32<44:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:09,840 >> Initializing global attention on CLS token...\n",
            " 62% 5199/8340 [1:19:33<44:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:10,680 >> Initializing global attention on CLS token...\n",
            " 62% 5200/8340 [1:19:34<44:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:11,524 >> Initializing global attention on CLS token...\n",
            " 62% 5201/8340 [1:19:35<44:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:12,366 >> Initializing global attention on CLS token...\n",
            " 62% 5202/8340 [1:19:36<44:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:13,210 >> Initializing global attention on CLS token...\n",
            " 62% 5203/8340 [1:19:37<44:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:14,053 >> Initializing global attention on CLS token...\n",
            " 62% 5204/8340 [1:19:37<44:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:14,899 >> Initializing global attention on CLS token...\n",
            " 62% 5205/8340 [1:19:38<44:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:15,739 >> Initializing global attention on CLS token...\n",
            " 62% 5206/8340 [1:19:39<43:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:16,577 >> Initializing global attention on CLS token...\n",
            " 62% 5207/8340 [1:19:40<43:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:17,422 >> Initializing global attention on CLS token...\n",
            " 62% 5208/8340 [1:19:41<43:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:18,262 >> Initializing global attention on CLS token...\n",
            " 62% 5209/8340 [1:19:42<43:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:19,100 >> Initializing global attention on CLS token...\n",
            " 62% 5210/8340 [1:19:42<43:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:19,943 >> Initializing global attention on CLS token...\n",
            " 62% 5211/8340 [1:19:43<43:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:20,787 >> Initializing global attention on CLS token...\n",
            " 62% 5212/8340 [1:19:44<43:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:21,630 >> Initializing global attention on CLS token...\n",
            " 63% 5213/8340 [1:19:45<43:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:22,474 >> Initializing global attention on CLS token...\n",
            " 63% 5214/8340 [1:19:46<43:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:23,315 >> Initializing global attention on CLS token...\n",
            " 63% 5215/8340 [1:19:47<43:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:24,165 >> Initializing global attention on CLS token...\n",
            " 63% 5216/8340 [1:19:47<43:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:25,010 >> Initializing global attention on CLS token...\n",
            " 63% 5217/8340 [1:19:48<43:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:25,853 >> Initializing global attention on CLS token...\n",
            " 63% 5218/8340 [1:19:49<43:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:26,698 >> Initializing global attention on CLS token...\n",
            " 63% 5219/8340 [1:19:50<43:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:27,539 >> Initializing global attention on CLS token...\n",
            " 63% 5220/8340 [1:19:51<43:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:28,386 >> Initializing global attention on CLS token...\n",
            " 63% 5221/8340 [1:19:52<43:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:29,227 >> Initializing global attention on CLS token...\n",
            " 63% 5222/8340 [1:19:53<43:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:30,073 >> Initializing global attention on CLS token...\n",
            " 63% 5223/8340 [1:19:53<43:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:30,913 >> Initializing global attention on CLS token...\n",
            " 63% 5224/8340 [1:19:54<43:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:31,757 >> Initializing global attention on CLS token...\n",
            " 63% 5225/8340 [1:19:55<43:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:32,599 >> Initializing global attention on CLS token...\n",
            " 63% 5226/8340 [1:19:56<43:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:33,442 >> Initializing global attention on CLS token...\n",
            " 63% 5227/8340 [1:19:57<43:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:34,285 >> Initializing global attention on CLS token...\n",
            " 63% 5228/8340 [1:19:58<43:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:35,134 >> Initializing global attention on CLS token...\n",
            " 63% 5229/8340 [1:19:58<43:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:35,980 >> Initializing global attention on CLS token...\n",
            " 63% 5230/8340 [1:19:59<43:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:36,822 >> Initializing global attention on CLS token...\n",
            " 63% 5231/8340 [1:20:00<43:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:37,665 >> Initializing global attention on CLS token...\n",
            " 63% 5232/8340 [1:20:01<43:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:38,505 >> Initializing global attention on CLS token...\n",
            " 63% 5233/8340 [1:20:02<43:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:39,347 >> Initializing global attention on CLS token...\n",
            " 63% 5234/8340 [1:20:03<43:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:40,195 >> Initializing global attention on CLS token...\n",
            " 63% 5235/8340 [1:20:03<43:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:41,039 >> Initializing global attention on CLS token...\n",
            " 63% 5236/8340 [1:20:04<43:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:41,879 >> Initializing global attention on CLS token...\n",
            " 63% 5237/8340 [1:20:05<43:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:42,722 >> Initializing global attention on CLS token...\n",
            " 63% 5238/8340 [1:20:06<43:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:43,567 >> Initializing global attention on CLS token...\n",
            " 63% 5239/8340 [1:20:07<43:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:44,415 >> Initializing global attention on CLS token...\n",
            " 63% 5240/8340 [1:20:08<43:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:45,262 >> Initializing global attention on CLS token...\n",
            " 63% 5241/8340 [1:20:09<43:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:46,105 >> Initializing global attention on CLS token...\n",
            " 63% 5242/8340 [1:20:09<43:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:46,951 >> Initializing global attention on CLS token...\n",
            " 63% 5243/8340 [1:20:10<43:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:47,797 >> Initializing global attention on CLS token...\n",
            " 63% 5244/8340 [1:20:11<43:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:48,650 >> Initializing global attention on CLS token...\n",
            " 63% 5245/8340 [1:20:12<43:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:49,494 >> Initializing global attention on CLS token...\n",
            " 63% 5246/8340 [1:20:13<43:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:50,336 >> Initializing global attention on CLS token...\n",
            " 63% 5247/8340 [1:20:14<43:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:51,179 >> Initializing global attention on CLS token...\n",
            " 63% 5248/8340 [1:20:14<43:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:52,022 >> Initializing global attention on CLS token...\n",
            " 63% 5249/8340 [1:20:15<43:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:52,871 >> Initializing global attention on CLS token...\n",
            " 63% 5250/8340 [1:20:16<43:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:53,710 >> Initializing global attention on CLS token...\n",
            " 63% 5251/8340 [1:20:17<43:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:54,551 >> Initializing global attention on CLS token...\n",
            " 63% 5252/8340 [1:20:18<43:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:55,394 >> Initializing global attention on CLS token...\n",
            " 63% 5253/8340 [1:20:19<43:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:56,239 >> Initializing global attention on CLS token...\n",
            " 63% 5254/8340 [1:20:20<43:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:57,085 >> Initializing global attention on CLS token...\n",
            " 63% 5255/8340 [1:20:20<43:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:57,930 >> Initializing global attention on CLS token...\n",
            " 63% 5256/8340 [1:20:21<43:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:58,774 >> Initializing global attention on CLS token...\n",
            " 63% 5257/8340 [1:20:22<43:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:44:59,615 >> Initializing global attention on CLS token...\n",
            " 63% 5258/8340 [1:20:23<43:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:00,459 >> Initializing global attention on CLS token...\n",
            " 63% 5259/8340 [1:20:24<43:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:01,308 >> Initializing global attention on CLS token...\n",
            " 63% 5260/8340 [1:20:25<43:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:02,150 >> Initializing global attention on CLS token...\n",
            " 63% 5261/8340 [1:20:25<43:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:02,997 >> Initializing global attention on CLS token...\n",
            " 63% 5262/8340 [1:20:26<43:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:03,839 >> Initializing global attention on CLS token...\n",
            " 63% 5263/8340 [1:20:27<43:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:04,690 >> Initializing global attention on CLS token...\n",
            " 63% 5264/8340 [1:20:28<43:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:05,535 >> Initializing global attention on CLS token...\n",
            " 63% 5265/8340 [1:20:29<43:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:06,383 >> Initializing global attention on CLS token...\n",
            " 63% 5266/8340 [1:20:30<43:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:07,228 >> Initializing global attention on CLS token...\n",
            " 63% 5267/8340 [1:20:31<43:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:08,079 >> Initializing global attention on CLS token...\n",
            " 63% 5268/8340 [1:20:31<43:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:08,924 >> Initializing global attention on CLS token...\n",
            " 63% 5269/8340 [1:20:32<43:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:09,764 >> Initializing global attention on CLS token...\n",
            " 63% 5270/8340 [1:20:33<43:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:10,605 >> Initializing global attention on CLS token...\n",
            " 63% 5271/8340 [1:20:34<43:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:11,452 >> Initializing global attention on CLS token...\n",
            " 63% 5272/8340 [1:20:35<43:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:12,292 >> Initializing global attention on CLS token...\n",
            " 63% 5273/8340 [1:20:36<43:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:13,144 >> Initializing global attention on CLS token...\n",
            " 63% 5274/8340 [1:20:36<43:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:13,988 >> Initializing global attention on CLS token...\n",
            " 63% 5275/8340 [1:20:37<43:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:14,830 >> Initializing global attention on CLS token...\n",
            " 63% 5276/8340 [1:20:38<43:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:15,672 >> Initializing global attention on CLS token...\n",
            " 63% 5277/8340 [1:20:39<43:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:16,515 >> Initializing global attention on CLS token...\n",
            " 63% 5278/8340 [1:20:40<43:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:17,358 >> Initializing global attention on CLS token...\n",
            " 63% 5279/8340 [1:20:41<43:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:18,203 >> Initializing global attention on CLS token...\n",
            " 63% 5280/8340 [1:20:42<42:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:19,044 >> Initializing global attention on CLS token...\n",
            " 63% 5281/8340 [1:20:42<42:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:19,886 >> Initializing global attention on CLS token...\n",
            " 63% 5282/8340 [1:20:43<42:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:20,730 >> Initializing global attention on CLS token...\n",
            " 63% 5283/8340 [1:20:44<42:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:21,574 >> Initializing global attention on CLS token...\n",
            " 63% 5284/8340 [1:20:45<42:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:22,417 >> Initializing global attention on CLS token...\n",
            " 63% 5285/8340 [1:20:46<42:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:23,261 >> Initializing global attention on CLS token...\n",
            " 63% 5286/8340 [1:20:47<42:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:24,108 >> Initializing global attention on CLS token...\n",
            " 63% 5287/8340 [1:20:47<43:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:24,956 >> Initializing global attention on CLS token...\n",
            " 63% 5288/8340 [1:20:48<42:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:25,796 >> Initializing global attention on CLS token...\n",
            " 63% 5289/8340 [1:20:49<42:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:26,644 >> Initializing global attention on CLS token...\n",
            " 63% 5290/8340 [1:20:50<42:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:27,485 >> Initializing global attention on CLS token...\n",
            " 63% 5291/8340 [1:20:51<42:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:28,327 >> Initializing global attention on CLS token...\n",
            " 63% 5292/8340 [1:20:52<42:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:29,170 >> Initializing global attention on CLS token...\n",
            " 63% 5293/8340 [1:20:52<42:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:30,016 >> Initializing global attention on CLS token...\n",
            " 63% 5294/8340 [1:20:53<42:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:30,857 >> Initializing global attention on CLS token...\n",
            " 63% 5295/8340 [1:20:54<42:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:31,703 >> Initializing global attention on CLS token...\n",
            " 64% 5296/8340 [1:20:55<42:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:32,547 >> Initializing global attention on CLS token...\n",
            " 64% 5297/8340 [1:20:56<42:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:33,392 >> Initializing global attention on CLS token...\n",
            " 64% 5298/8340 [1:20:57<42:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:34,234 >> Initializing global attention on CLS token...\n",
            " 64% 5299/8340 [1:20:58<42:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:35,075 >> Initializing global attention on CLS token...\n",
            " 64% 5300/8340 [1:20:58<42:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:35,918 >> Initializing global attention on CLS token...\n",
            " 64% 5301/8340 [1:20:59<42:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:36,764 >> Initializing global attention on CLS token...\n",
            " 64% 5302/8340 [1:21:00<42:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:37,608 >> Initializing global attention on CLS token...\n",
            " 64% 5303/8340 [1:21:01<42:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:38,455 >> Initializing global attention on CLS token...\n",
            " 64% 5304/8340 [1:21:02<42:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:39,295 >> Initializing global attention on CLS token...\n",
            " 64% 5305/8340 [1:21:03<42:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:40,146 >> Initializing global attention on CLS token...\n",
            " 64% 5306/8340 [1:21:03<42:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:40,988 >> Initializing global attention on CLS token...\n",
            " 64% 5307/8340 [1:21:04<42:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:41,831 >> Initializing global attention on CLS token...\n",
            " 64% 5308/8340 [1:21:05<42:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:42,671 >> Initializing global attention on CLS token...\n",
            " 64% 5309/8340 [1:21:06<42:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:43,515 >> Initializing global attention on CLS token...\n",
            " 64% 5310/8340 [1:21:07<42:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:44,357 >> Initializing global attention on CLS token...\n",
            " 64% 5311/8340 [1:21:08<42:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:45,205 >> Initializing global attention on CLS token...\n",
            " 64% 5312/8340 [1:21:09<42:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:46,048 >> Initializing global attention on CLS token...\n",
            " 64% 5313/8340 [1:21:09<42:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:46,897 >> Initializing global attention on CLS token...\n",
            " 64% 5314/8340 [1:21:10<42:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:47,739 >> Initializing global attention on CLS token...\n",
            " 64% 5315/8340 [1:21:11<42:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:48,586 >> Initializing global attention on CLS token...\n",
            " 64% 5316/8340 [1:21:12<42:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:49,428 >> Initializing global attention on CLS token...\n",
            " 64% 5317/8340 [1:21:13<42:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:50,275 >> Initializing global attention on CLS token...\n",
            " 64% 5318/8340 [1:21:14<42:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:51,114 >> Initializing global attention on CLS token...\n",
            " 64% 5319/8340 [1:21:14<42:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:51,962 >> Initializing global attention on CLS token...\n",
            " 64% 5320/8340 [1:21:15<42:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:52,802 >> Initializing global attention on CLS token...\n",
            " 64% 5321/8340 [1:21:16<42:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:53,647 >> Initializing global attention on CLS token...\n",
            " 64% 5322/8340 [1:21:17<42:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:54,492 >> Initializing global attention on CLS token...\n",
            " 64% 5323/8340 [1:21:18<42:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:55,339 >> Initializing global attention on CLS token...\n",
            " 64% 5324/8340 [1:21:19<42:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:56,191 >> Initializing global attention on CLS token...\n",
            " 64% 5325/8340 [1:21:19<42:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:57,036 >> Initializing global attention on CLS token...\n",
            " 64% 5326/8340 [1:21:20<42:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:57,886 >> Initializing global attention on CLS token...\n",
            " 64% 5327/8340 [1:21:21<42:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:58,730 >> Initializing global attention on CLS token...\n",
            " 64% 5328/8340 [1:21:22<42:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:45:59,571 >> Initializing global attention on CLS token...\n",
            " 64% 5329/8340 [1:21:23<42:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:00,416 >> Initializing global attention on CLS token...\n",
            " 64% 5330/8340 [1:21:24<42:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:01,257 >> Initializing global attention on CLS token...\n",
            " 64% 5331/8340 [1:21:25<42:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:02,098 >> Initializing global attention on CLS token...\n",
            " 64% 5332/8340 [1:21:25<42:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:02,947 >> Initializing global attention on CLS token...\n",
            " 64% 5333/8340 [1:21:26<42:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:03,792 >> Initializing global attention on CLS token...\n",
            " 64% 5334/8340 [1:21:27<42:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:04,639 >> Initializing global attention on CLS token...\n",
            " 64% 5335/8340 [1:21:28<42:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:05,482 >> Initializing global attention on CLS token...\n",
            " 64% 5336/8340 [1:21:29<42:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:06,327 >> Initializing global attention on CLS token...\n",
            " 64% 5337/8340 [1:21:30<42:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:07,168 >> Initializing global attention on CLS token...\n",
            " 64% 5338/8340 [1:21:30<42:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:08,016 >> Initializing global attention on CLS token...\n",
            " 64% 5339/8340 [1:21:31<42:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:08,860 >> Initializing global attention on CLS token...\n",
            " 64% 5340/8340 [1:21:32<42:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:09,704 >> Initializing global attention on CLS token...\n",
            " 64% 5341/8340 [1:21:33<42:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:10,548 >> Initializing global attention on CLS token...\n",
            " 64% 5342/8340 [1:21:34<42:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:11,390 >> Initializing global attention on CLS token...\n",
            " 64% 5343/8340 [1:21:35<42:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:12,234 >> Initializing global attention on CLS token...\n",
            " 64% 5344/8340 [1:21:36<42:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:13,079 >> Initializing global attention on CLS token...\n",
            " 64% 5345/8340 [1:21:36<42:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:13,928 >> Initializing global attention on CLS token...\n",
            " 64% 5346/8340 [1:21:37<42:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:14,778 >> Initializing global attention on CLS token...\n",
            " 64% 5347/8340 [1:21:38<42:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:15,624 >> Initializing global attention on CLS token...\n",
            " 64% 5348/8340 [1:21:39<42:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:16,477 >> Initializing global attention on CLS token...\n",
            " 64% 5349/8340 [1:21:40<42:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:17,331 >> Initializing global attention on CLS token...\n",
            " 64% 5350/8340 [1:21:41<42:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:18,177 >> Initializing global attention on CLS token...\n",
            " 64% 5351/8340 [1:21:41<42:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:19,024 >> Initializing global attention on CLS token...\n",
            " 64% 5352/8340 [1:21:42<42:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:19,873 >> Initializing global attention on CLS token...\n",
            " 64% 5353/8340 [1:21:43<42:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:20,712 >> Initializing global attention on CLS token...\n",
            " 64% 5354/8340 [1:21:44<42:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:21,559 >> Initializing global attention on CLS token...\n",
            " 64% 5355/8340 [1:21:45<42:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:22,400 >> Initializing global attention on CLS token...\n",
            " 64% 5356/8340 [1:21:46<42:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:23,244 >> Initializing global attention on CLS token...\n",
            " 64% 5357/8340 [1:21:47<41:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:24,087 >> Initializing global attention on CLS token...\n",
            " 64% 5358/8340 [1:21:47<41:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:24,934 >> Initializing global attention on CLS token...\n",
            " 64% 5359/8340 [1:21:48<41:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:25,775 >> Initializing global attention on CLS token...\n",
            " 64% 5360/8340 [1:21:49<41:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:26,620 >> Initializing global attention on CLS token...\n",
            " 64% 5361/8340 [1:21:50<41:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:27,470 >> Initializing global attention on CLS token...\n",
            " 64% 5362/8340 [1:21:51<42:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:28,316 >> Initializing global attention on CLS token...\n",
            " 64% 5363/8340 [1:21:52<41:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:29,161 >> Initializing global attention on CLS token...\n",
            " 64% 5364/8340 [1:21:52<41:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:30,006 >> Initializing global attention on CLS token...\n",
            " 64% 5365/8340 [1:21:53<41:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:30,852 >> Initializing global attention on CLS token...\n",
            " 64% 5366/8340 [1:21:54<41:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:31,691 >> Initializing global attention on CLS token...\n",
            " 64% 5367/8340 [1:21:55<41:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:32,538 >> Initializing global attention on CLS token...\n",
            " 64% 5368/8340 [1:21:56<41:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:33,381 >> Initializing global attention on CLS token...\n",
            " 64% 5369/8340 [1:21:57<41:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:34,226 >> Initializing global attention on CLS token...\n",
            " 64% 5370/8340 [1:21:58<41:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:35,070 >> Initializing global attention on CLS token...\n",
            " 64% 5371/8340 [1:21:58<41:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:35,919 >> Initializing global attention on CLS token...\n",
            " 64% 5372/8340 [1:21:59<41:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:36,765 >> Initializing global attention on CLS token...\n",
            " 64% 5373/8340 [1:22:00<41:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:37,609 >> Initializing global attention on CLS token...\n",
            " 64% 5374/8340 [1:22:01<41:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:38,455 >> Initializing global attention on CLS token...\n",
            " 64% 5375/8340 [1:22:02<41:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:39,299 >> Initializing global attention on CLS token...\n",
            " 64% 5376/8340 [1:22:03<41:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:40,143 >> Initializing global attention on CLS token...\n",
            " 64% 5377/8340 [1:22:03<41:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:40,985 >> Initializing global attention on CLS token...\n",
            " 64% 5378/8340 [1:22:04<41:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:41,829 >> Initializing global attention on CLS token...\n",
            " 64% 5379/8340 [1:22:05<41:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:42,674 >> Initializing global attention on CLS token...\n",
            " 65% 5380/8340 [1:22:06<41:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:43,519 >> Initializing global attention on CLS token...\n",
            " 65% 5381/8340 [1:22:07<41:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:44,361 >> Initializing global attention on CLS token...\n",
            " 65% 5382/8340 [1:22:08<41:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:45,206 >> Initializing global attention on CLS token...\n",
            " 65% 5383/8340 [1:22:09<41:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:46,052 >> Initializing global attention on CLS token...\n",
            " 65% 5384/8340 [1:22:09<41:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:46,893 >> Initializing global attention on CLS token...\n",
            " 65% 5385/8340 [1:22:10<41:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:47,737 >> Initializing global attention on CLS token...\n",
            " 65% 5386/8340 [1:22:11<41:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:48,584 >> Initializing global attention on CLS token...\n",
            " 65% 5387/8340 [1:22:12<41:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:49,425 >> Initializing global attention on CLS token...\n",
            " 65% 5388/8340 [1:22:13<41:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:50,267 >> Initializing global attention on CLS token...\n",
            " 65% 5389/8340 [1:22:14<41:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:51,108 >> Initializing global attention on CLS token...\n",
            " 65% 5390/8340 [1:22:14<41:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:51,950 >> Initializing global attention on CLS token...\n",
            " 65% 5391/8340 [1:22:15<41:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:52,787 >> Initializing global attention on CLS token...\n",
            " 65% 5392/8340 [1:22:16<41:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:53,632 >> Initializing global attention on CLS token...\n",
            " 65% 5393/8340 [1:22:17<41:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:54,474 >> Initializing global attention on CLS token...\n",
            " 65% 5394/8340 [1:22:18<41:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:55,315 >> Initializing global attention on CLS token...\n",
            " 65% 5395/8340 [1:22:19<41:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:56,154 >> Initializing global attention on CLS token...\n",
            " 65% 5396/8340 [1:22:19<41:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:56,997 >> Initializing global attention on CLS token...\n",
            " 65% 5397/8340 [1:22:20<41:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:57,839 >> Initializing global attention on CLS token...\n",
            " 65% 5398/8340 [1:22:21<41:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:58,690 >> Initializing global attention on CLS token...\n",
            " 65% 5399/8340 [1:22:22<41:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:46:59,530 >> Initializing global attention on CLS token...\n",
            " 65% 5400/8340 [1:22:23<41:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:00,379 >> Initializing global attention on CLS token...\n",
            " 65% 5401/8340 [1:22:24<41:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:01,220 >> Initializing global attention on CLS token...\n",
            " 65% 5402/8340 [1:22:25<41:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:02,066 >> Initializing global attention on CLS token...\n",
            " 65% 5403/8340 [1:22:25<41:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:02,906 >> Initializing global attention on CLS token...\n",
            " 65% 5404/8340 [1:22:26<41:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:03,754 >> Initializing global attention on CLS token...\n",
            " 65% 5405/8340 [1:22:27<41:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:04,595 >> Initializing global attention on CLS token...\n",
            " 65% 5406/8340 [1:22:28<41:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:05,440 >> Initializing global attention on CLS token...\n",
            " 65% 5407/8340 [1:22:29<41:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:06,281 >> Initializing global attention on CLS token...\n",
            " 65% 5408/8340 [1:22:30<41:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:07,119 >> Initializing global attention on CLS token...\n",
            " 65% 5409/8340 [1:22:30<41:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:07,963 >> Initializing global attention on CLS token...\n",
            " 65% 5410/8340 [1:22:31<41:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:08,808 >> Initializing global attention on CLS token...\n",
            " 65% 5411/8340 [1:22:32<41:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:09,652 >> Initializing global attention on CLS token...\n",
            " 65% 5412/8340 [1:22:33<41:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:10,497 >> Initializing global attention on CLS token...\n",
            " 65% 5413/8340 [1:22:34<41:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:11,341 >> Initializing global attention on CLS token...\n",
            " 65% 5414/8340 [1:22:35<41:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:12,184 >> Initializing global attention on CLS token...\n",
            " 65% 5415/8340 [1:22:35<41:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:13,026 >> Initializing global attention on CLS token...\n",
            " 65% 5416/8340 [1:22:36<41:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:13,872 >> Initializing global attention on CLS token...\n",
            " 65% 5417/8340 [1:22:37<41:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:14,713 >> Initializing global attention on CLS token...\n",
            " 65% 5418/8340 [1:22:38<41:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:15,557 >> Initializing global attention on CLS token...\n",
            " 65% 5419/8340 [1:22:39<41:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:16,403 >> Initializing global attention on CLS token...\n",
            " 65% 5420/8340 [1:22:40<41:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:17,250 >> Initializing global attention on CLS token...\n",
            " 65% 5421/8340 [1:22:41<41:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:18,092 >> Initializing global attention on CLS token...\n",
            " 65% 5422/8340 [1:22:41<41:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:18,949 >> Initializing global attention on CLS token...\n",
            " 65% 5423/8340 [1:22:42<41:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:19,797 >> Initializing global attention on CLS token...\n",
            " 65% 5424/8340 [1:22:43<41:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:20,640 >> Initializing global attention on CLS token...\n",
            " 65% 5425/8340 [1:22:44<41:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:21,478 >> Initializing global attention on CLS token...\n",
            " 65% 5426/8340 [1:22:45<41:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:22,327 >> Initializing global attention on CLS token...\n",
            " 65% 5427/8340 [1:22:46<40:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:23,168 >> Initializing global attention on CLS token...\n",
            " 65% 5428/8340 [1:22:46<41:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:24,014 >> Initializing global attention on CLS token...\n",
            " 65% 5429/8340 [1:22:47<40:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:24,858 >> Initializing global attention on CLS token...\n",
            " 65% 5430/8340 [1:22:48<40:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:25,701 >> Initializing global attention on CLS token...\n",
            " 65% 5431/8340 [1:22:49<40:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:26,545 >> Initializing global attention on CLS token...\n",
            " 65% 5432/8340 [1:22:50<40:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:27,387 >> Initializing global attention on CLS token...\n",
            " 65% 5433/8340 [1:22:51<40:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:28,235 >> Initializing global attention on CLS token...\n",
            " 65% 5434/8340 [1:22:52<40:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:29,086 >> Initializing global attention on CLS token...\n",
            " 65% 5435/8340 [1:22:52<41:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:29,939 >> Initializing global attention on CLS token...\n",
            " 65% 5436/8340 [1:22:53<41:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:30,789 >> Initializing global attention on CLS token...\n",
            " 65% 5437/8340 [1:22:54<41:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:31,635 >> Initializing global attention on CLS token...\n",
            " 65% 5438/8340 [1:22:55<41:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:32,485 >> Initializing global attention on CLS token...\n",
            " 65% 5439/8340 [1:22:56<40:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:33,325 >> Initializing global attention on CLS token...\n",
            " 65% 5440/8340 [1:22:57<40:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:34,169 >> Initializing global attention on CLS token...\n",
            " 65% 5441/8340 [1:22:57<40:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:35,012 >> Initializing global attention on CLS token...\n",
            " 65% 5442/8340 [1:22:58<40:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:35,861 >> Initializing global attention on CLS token...\n",
            " 65% 5443/8340 [1:22:59<40:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:36,705 >> Initializing global attention on CLS token...\n",
            " 65% 5444/8340 [1:23:00<40:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:37,551 >> Initializing global attention on CLS token...\n",
            " 65% 5445/8340 [1:23:01<40:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:38,396 >> Initializing global attention on CLS token...\n",
            " 65% 5446/8340 [1:23:02<40:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:39,237 >> Initializing global attention on CLS token...\n",
            " 65% 5447/8340 [1:23:03<40:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:40,081 >> Initializing global attention on CLS token...\n",
            " 65% 5448/8340 [1:23:03<40:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:40,925 >> Initializing global attention on CLS token...\n",
            " 65% 5449/8340 [1:23:04<40:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:41,766 >> Initializing global attention on CLS token...\n",
            " 65% 5450/8340 [1:23:05<40:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:42,614 >> Initializing global attention on CLS token...\n",
            " 65% 5451/8340 [1:23:06<40:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:43,461 >> Initializing global attention on CLS token...\n",
            " 65% 5452/8340 [1:23:07<40:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:44,304 >> Initializing global attention on CLS token...\n",
            " 65% 5453/8340 [1:23:08<40:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:45,155 >> Initializing global attention on CLS token...\n",
            " 65% 5454/8340 [1:23:08<40:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:45,998 >> Initializing global attention on CLS token...\n",
            " 65% 5455/8340 [1:23:09<40:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:46,846 >> Initializing global attention on CLS token...\n",
            " 65% 5456/8340 [1:23:10<40:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:47,692 >> Initializing global attention on CLS token...\n",
            " 65% 5457/8340 [1:23:11<40:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:48,531 >> Initializing global attention on CLS token...\n",
            " 65% 5458/8340 [1:23:12<40:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:49,385 >> Initializing global attention on CLS token...\n",
            " 65% 5459/8340 [1:23:13<40:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:50,224 >> Initializing global attention on CLS token...\n",
            " 65% 5460/8340 [1:23:14<40:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:51,068 >> Initializing global attention on CLS token...\n",
            " 65% 5461/8340 [1:23:14<40:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:51,911 >> Initializing global attention on CLS token...\n",
            " 65% 5462/8340 [1:23:15<40:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:52,752 >> Initializing global attention on CLS token...\n",
            " 66% 5463/8340 [1:23:16<40:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:53,598 >> Initializing global attention on CLS token...\n",
            " 66% 5464/8340 [1:23:17<40:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:54,441 >> Initializing global attention on CLS token...\n",
            " 66% 5465/8340 [1:23:18<40:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:55,284 >> Initializing global attention on CLS token...\n",
            " 66% 5466/8340 [1:23:19<40:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:56,132 >> Initializing global attention on CLS token...\n",
            " 66% 5467/8340 [1:23:19<40:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:56,973 >> Initializing global attention on CLS token...\n",
            " 66% 5468/8340 [1:23:20<40:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:57,817 >> Initializing global attention on CLS token...\n",
            " 66% 5469/8340 [1:23:21<40:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:58,664 >> Initializing global attention on CLS token...\n",
            " 66% 5470/8340 [1:23:22<40:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:47:59,513 >> Initializing global attention on CLS token...\n",
            " 66% 5471/8340 [1:23:23<40:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:00,353 >> Initializing global attention on CLS token...\n",
            " 66% 5472/8340 [1:23:24<40:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:01,198 >> Initializing global attention on CLS token...\n",
            " 66% 5473/8340 [1:23:25<40:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:02,042 >> Initializing global attention on CLS token...\n",
            " 66% 5474/8340 [1:23:25<40:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:02,885 >> Initializing global attention on CLS token...\n",
            " 66% 5475/8340 [1:23:26<40:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:03,729 >> Initializing global attention on CLS token...\n",
            " 66% 5476/8340 [1:23:27<40:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:04,577 >> Initializing global attention on CLS token...\n",
            " 66% 5477/8340 [1:23:28<40:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:05,426 >> Initializing global attention on CLS token...\n",
            " 66% 5478/8340 [1:23:29<40:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:06,274 >> Initializing global attention on CLS token...\n",
            " 66% 5479/8340 [1:23:30<40:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:07,117 >> Initializing global attention on CLS token...\n",
            " 66% 5480/8340 [1:23:30<40:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:07,959 >> Initializing global attention on CLS token...\n",
            " 66% 5481/8340 [1:23:31<40:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:08,808 >> Initializing global attention on CLS token...\n",
            " 66% 5482/8340 [1:23:32<40:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:09,653 >> Initializing global attention on CLS token...\n",
            " 66% 5483/8340 [1:23:33<40:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:10,505 >> Initializing global attention on CLS token...\n",
            " 66% 5484/8340 [1:23:34<40:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:11,355 >> Initializing global attention on CLS token...\n",
            " 66% 5485/8340 [1:23:35<40:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:12,202 >> Initializing global attention on CLS token...\n",
            " 66% 5486/8340 [1:23:36<40:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:13,045 >> Initializing global attention on CLS token...\n",
            " 66% 5487/8340 [1:23:36<40:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:13,893 >> Initializing global attention on CLS token...\n",
            " 66% 5488/8340 [1:23:37<40:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:14,741 >> Initializing global attention on CLS token...\n",
            " 66% 5489/8340 [1:23:38<40:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:15,588 >> Initializing global attention on CLS token...\n",
            " 66% 5490/8340 [1:23:39<40:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:16,434 >> Initializing global attention on CLS token...\n",
            " 66% 5491/8340 [1:23:40<40:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:17,277 >> Initializing global attention on CLS token...\n",
            " 66% 5492/8340 [1:23:41<40:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:18,126 >> Initializing global attention on CLS token...\n",
            " 66% 5493/8340 [1:23:41<40:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:18,967 >> Initializing global attention on CLS token...\n",
            " 66% 5494/8340 [1:23:42<40:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:19,809 >> Initializing global attention on CLS token...\n",
            " 66% 5495/8340 [1:23:43<40:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:20,657 >> Initializing global attention on CLS token...\n",
            " 66% 5496/8340 [1:23:44<40:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:21,499 >> Initializing global attention on CLS token...\n",
            " 66% 5497/8340 [1:23:45<39:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:22,342 >> Initializing global attention on CLS token...\n",
            " 66% 5498/8340 [1:23:46<39:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:23,185 >> Initializing global attention on CLS token...\n",
            " 66% 5499/8340 [1:23:46<39:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:24,027 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0852, 'learning_rate': 1.0230215827338129e-05, 'epoch': 6.59}\n",
            " 66% 5500/8340 [1:23:47<41:57,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:25,023 >> Initializing global attention on CLS token...\n",
            " 66% 5501/8340 [1:23:48<41:27,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:25,867 >> Initializing global attention on CLS token...\n",
            " 66% 5502/8340 [1:23:49<41:01,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:26,713 >> Initializing global attention on CLS token...\n",
            " 66% 5503/8340 [1:23:50<40:36,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:27,552 >> Initializing global attention on CLS token...\n",
            " 66% 5504/8340 [1:23:51<40:21,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:28,395 >> Initializing global attention on CLS token...\n",
            " 66% 5505/8340 [1:23:52<40:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:29,228 >> Initializing global attention on CLS token...\n",
            " 66% 5506/8340 [1:23:53<40:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:30,075 >> Initializing global attention on CLS token...\n",
            " 66% 5507/8340 [1:23:53<39:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:30,924 >> Initializing global attention on CLS token...\n",
            " 66% 5508/8340 [1:23:54<39:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:31,770 >> Initializing global attention on CLS token...\n",
            " 66% 5509/8340 [1:23:55<39:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:32,614 >> Initializing global attention on CLS token...\n",
            " 66% 5510/8340 [1:23:56<39:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:33,459 >> Initializing global attention on CLS token...\n",
            " 66% 5511/8340 [1:23:57<39:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:34,301 >> Initializing global attention on CLS token...\n",
            " 66% 5512/8340 [1:23:58<39:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:35,152 >> Initializing global attention on CLS token...\n",
            " 66% 5513/8340 [1:23:58<39:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:35,991 >> Initializing global attention on CLS token...\n",
            " 66% 5514/8340 [1:23:59<39:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:36,836 >> Initializing global attention on CLS token...\n",
            " 66% 5515/8340 [1:24:00<39:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:37,678 >> Initializing global attention on CLS token...\n",
            " 66% 5516/8340 [1:24:01<39:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:38,523 >> Initializing global attention on CLS token...\n",
            " 66% 5517/8340 [1:24:02<39:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:39,365 >> Initializing global attention on CLS token...\n",
            " 66% 5518/8340 [1:24:03<39:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:40,211 >> Initializing global attention on CLS token...\n",
            " 66% 5519/8340 [1:24:04<39:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:41,050 >> Initializing global attention on CLS token...\n",
            " 66% 5520/8340 [1:24:04<39:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:41,895 >> Initializing global attention on CLS token...\n",
            " 66% 5521/8340 [1:24:05<39:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:42,736 >> Initializing global attention on CLS token...\n",
            " 66% 5522/8340 [1:24:06<39:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:43,577 >> Initializing global attention on CLS token...\n",
            " 66% 5523/8340 [1:24:07<39:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:44,429 >> Initializing global attention on CLS token...\n",
            " 66% 5524/8340 [1:24:08<39:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:45,275 >> Initializing global attention on CLS token...\n",
            " 66% 5525/8340 [1:24:09<39:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:46,117 >> Initializing global attention on CLS token...\n",
            " 66% 5526/8340 [1:24:09<39:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:46,966 >> Initializing global attention on CLS token...\n",
            " 66% 5527/8340 [1:24:10<39:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:47,812 >> Initializing global attention on CLS token...\n",
            " 66% 5528/8340 [1:24:11<39:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:48,657 >> Initializing global attention on CLS token...\n",
            " 66% 5529/8340 [1:24:12<39:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:49,502 >> Initializing global attention on CLS token...\n",
            " 66% 5530/8340 [1:24:13<39:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:50,348 >> Initializing global attention on CLS token...\n",
            " 66% 5531/8340 [1:24:14<39:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:51,200 >> Initializing global attention on CLS token...\n",
            " 66% 5532/8340 [1:24:15<39:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:52,042 >> Initializing global attention on CLS token...\n",
            " 66% 5533/8340 [1:24:15<39:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:52,884 >> Initializing global attention on CLS token...\n",
            " 66% 5534/8340 [1:24:16<39:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:53,726 >> Initializing global attention on CLS token...\n",
            " 66% 5535/8340 [1:24:17<39:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:54,573 >> Initializing global attention on CLS token...\n",
            " 66% 5536/8340 [1:24:18<39:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:55,415 >> Initializing global attention on CLS token...\n",
            " 66% 5537/8340 [1:24:19<39:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:56,260 >> Initializing global attention on CLS token...\n",
            " 66% 5538/8340 [1:24:20<39:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:57,099 >> Initializing global attention on CLS token...\n",
            " 66% 5539/8340 [1:24:20<39:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:57,940 >> Initializing global attention on CLS token...\n",
            " 66% 5540/8340 [1:24:21<39:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:58,787 >> Initializing global attention on CLS token...\n",
            " 66% 5541/8340 [1:24:22<39:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:48:59,636 >> Initializing global attention on CLS token...\n",
            " 66% 5542/8340 [1:24:23<39:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:00,476 >> Initializing global attention on CLS token...\n",
            " 66% 5543/8340 [1:24:24<39:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:01,322 >> Initializing global attention on CLS token...\n",
            " 66% 5544/8340 [1:24:25<39:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:02,166 >> Initializing global attention on CLS token...\n",
            " 66% 5545/8340 [1:24:25<39:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:03,017 >> Initializing global attention on CLS token...\n",
            " 66% 5546/8340 [1:24:26<39:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:03,869 >> Initializing global attention on CLS token...\n",
            " 67% 5547/8340 [1:24:27<39:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:04,712 >> Initializing global attention on CLS token...\n",
            " 67% 5548/8340 [1:24:28<39:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:05,557 >> Initializing global attention on CLS token...\n",
            " 67% 5549/8340 [1:24:29<39:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:06,398 >> Initializing global attention on CLS token...\n",
            " 67% 5550/8340 [1:24:30<39:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:07,243 >> Initializing global attention on CLS token...\n",
            " 67% 5551/8340 [1:24:31<39:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:08,085 >> Initializing global attention on CLS token...\n",
            " 67% 5552/8340 [1:24:31<39:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:08,928 >> Initializing global attention on CLS token...\n",
            " 67% 5553/8340 [1:24:32<39:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:09,770 >> Initializing global attention on CLS token...\n",
            " 67% 5554/8340 [1:24:33<39:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:10,616 >> Initializing global attention on CLS token...\n",
            " 67% 5555/8340 [1:24:34<39:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:11,459 >> Initializing global attention on CLS token...\n",
            " 67% 5556/8340 [1:24:35<39:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:12,304 >> Initializing global attention on CLS token...\n",
            " 67% 5557/8340 [1:24:36<39:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:13,147 >> Initializing global attention on CLS token...\n",
            " 67% 5558/8340 [1:24:36<39:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:13,989 >> Initializing global attention on CLS token...\n",
            " 67% 5559/8340 [1:24:37<39:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:14,831 >> Initializing global attention on CLS token...\n",
            " 67% 5560/8340 [1:24:38<39:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:15,679 >> Initializing global attention on CLS token...\n",
            " 67% 5561/8340 [1:24:39<39:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:16,521 >> Initializing global attention on CLS token...\n",
            " 67% 5562/8340 [1:24:40<39:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:17,364 >> Initializing global attention on CLS token...\n",
            " 67% 5563/8340 [1:24:41<39:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:18,208 >> Initializing global attention on CLS token...\n",
            " 67% 5564/8340 [1:24:42<39:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:19,054 >> Initializing global attention on CLS token...\n",
            " 67% 5565/8340 [1:24:42<39:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:19,896 >> Initializing global attention on CLS token...\n",
            " 67% 5566/8340 [1:24:43<39:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:20,742 >> Initializing global attention on CLS token...\n",
            " 67% 5567/8340 [1:24:44<38:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:21,581 >> Initializing global attention on CLS token...\n",
            " 67% 5568/8340 [1:24:45<38:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:22,419 >> Initializing global attention on CLS token...\n",
            " 67% 5569/8340 [1:24:46<38:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:23,264 >> Initializing global attention on CLS token...\n",
            " 67% 5570/8340 [1:24:47<38:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:24,106 >> Initializing global attention on CLS token...\n",
            " 67% 5571/8340 [1:24:47<38:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:24,952 >> Initializing global attention on CLS token...\n",
            " 67% 5572/8340 [1:24:48<38:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:25,795 >> Initializing global attention on CLS token...\n",
            " 67% 5573/8340 [1:24:49<38:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:26,640 >> Initializing global attention on CLS token...\n",
            " 67% 5574/8340 [1:24:50<38:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:27,486 >> Initializing global attention on CLS token...\n",
            " 67% 5575/8340 [1:24:51<38:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:28,326 >> Initializing global attention on CLS token...\n",
            " 67% 5576/8340 [1:24:52<38:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:29,172 >> Initializing global attention on CLS token...\n",
            " 67% 5577/8340 [1:24:52<38:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:30,014 >> Initializing global attention on CLS token...\n",
            " 67% 5578/8340 [1:24:53<38:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:30,851 >> Initializing global attention on CLS token...\n",
            " 67% 5579/8340 [1:24:54<38:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:31,701 >> Initializing global attention on CLS token...\n",
            " 67% 5580/8340 [1:24:55<38:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:32,543 >> Initializing global attention on CLS token...\n",
            " 67% 5581/8340 [1:24:56<38:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:33,389 >> Initializing global attention on CLS token...\n",
            " 67% 5582/8340 [1:24:57<38:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:34,232 >> Initializing global attention on CLS token...\n",
            " 67% 5583/8340 [1:24:58<38:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:35,079 >> Initializing global attention on CLS token...\n",
            " 67% 5584/8340 [1:24:58<38:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:35,924 >> Initializing global attention on CLS token...\n",
            " 67% 5585/8340 [1:24:59<38:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:36,774 >> Initializing global attention on CLS token...\n",
            " 67% 5586/8340 [1:25:00<38:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:37,614 >> Initializing global attention on CLS token...\n",
            " 67% 5587/8340 [1:25:01<38:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:38,452 >> Initializing global attention on CLS token...\n",
            " 67% 5588/8340 [1:25:02<38:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:39,300 >> Initializing global attention on CLS token...\n",
            " 67% 5589/8340 [1:25:03<38:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:40,142 >> Initializing global attention on CLS token...\n",
            " 67% 5590/8340 [1:25:03<38:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:40,991 >> Initializing global attention on CLS token...\n",
            " 67% 5591/8340 [1:25:04<38:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:41,833 >> Initializing global attention on CLS token...\n",
            " 67% 5592/8340 [1:25:05<38:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:42,677 >> Initializing global attention on CLS token...\n",
            " 67% 5593/8340 [1:25:06<38:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:43,526 >> Initializing global attention on CLS token...\n",
            " 67% 5594/8340 [1:25:07<38:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:44,374 >> Initializing global attention on CLS token...\n",
            " 67% 5595/8340 [1:25:08<38:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:45,224 >> Initializing global attention on CLS token...\n",
            " 67% 5596/8340 [1:25:09<38:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:46,070 >> Initializing global attention on CLS token...\n",
            " 67% 5597/8340 [1:25:09<38:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:46,913 >> Initializing global attention on CLS token...\n",
            " 67% 5598/8340 [1:25:10<38:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:47,760 >> Initializing global attention on CLS token...\n",
            " 67% 5599/8340 [1:25:11<38:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:48,602 >> Initializing global attention on CLS token...\n",
            " 67% 5600/8340 [1:25:12<38:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:49,451 >> Initializing global attention on CLS token...\n",
            " 67% 5601/8340 [1:25:13<38:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:50,299 >> Initializing global attention on CLS token...\n",
            " 67% 5602/8340 [1:25:14<38:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:51,148 >> Initializing global attention on CLS token...\n",
            " 67% 5603/8340 [1:25:14<38:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:51,992 >> Initializing global attention on CLS token...\n",
            " 67% 5604/8340 [1:25:15<38:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:52,831 >> Initializing global attention on CLS token...\n",
            " 67% 5605/8340 [1:25:16<38:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:53,677 >> Initializing global attention on CLS token...\n",
            " 67% 5606/8340 [1:25:17<38:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:54,521 >> Initializing global attention on CLS token...\n",
            " 67% 5607/8340 [1:25:18<38:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:55,365 >> Initializing global attention on CLS token...\n",
            " 67% 5608/8340 [1:25:19<38:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:56,207 >> Initializing global attention on CLS token...\n",
            " 67% 5609/8340 [1:25:20<38:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:57,052 >> Initializing global attention on CLS token...\n",
            " 67% 5610/8340 [1:25:20<38:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:57,897 >> Initializing global attention on CLS token...\n",
            " 67% 5611/8340 [1:25:21<38:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:58,742 >> Initializing global attention on CLS token...\n",
            " 67% 5612/8340 [1:25:22<38:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:49:59,588 >> Initializing global attention on CLS token...\n",
            " 67% 5613/8340 [1:25:23<38:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:00,435 >> Initializing global attention on CLS token...\n",
            " 67% 5614/8340 [1:25:24<38:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:01,284 >> Initializing global attention on CLS token...\n",
            " 67% 5615/8340 [1:25:25<38:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:02,126 >> Initializing global attention on CLS token...\n",
            " 67% 5616/8340 [1:25:25<38:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:02,970 >> Initializing global attention on CLS token...\n",
            " 67% 5617/8340 [1:25:26<38:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:03,813 >> Initializing global attention on CLS token...\n",
            " 67% 5618/8340 [1:25:27<38:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:04,657 >> Initializing global attention on CLS token...\n",
            " 67% 5619/8340 [1:25:28<38:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:05,494 >> Initializing global attention on CLS token...\n",
            " 67% 5620/8340 [1:25:29<38:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:06,336 >> Initializing global attention on CLS token...\n",
            " 67% 5621/8340 [1:25:30<38:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:07,182 >> Initializing global attention on CLS token...\n",
            " 67% 5622/8340 [1:25:30<38:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:08,022 >> Initializing global attention on CLS token...\n",
            " 67% 5623/8340 [1:25:31<38:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:08,870 >> Initializing global attention on CLS token...\n",
            " 67% 5624/8340 [1:25:32<38:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:09,715 >> Initializing global attention on CLS token...\n",
            " 67% 5625/8340 [1:25:33<38:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:10,559 >> Initializing global attention on CLS token...\n",
            " 67% 5626/8340 [1:25:34<38:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:11,406 >> Initializing global attention on CLS token...\n",
            " 67% 5627/8340 [1:25:35<38:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:12,246 >> Initializing global attention on CLS token...\n",
            " 67% 5628/8340 [1:25:36<38:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:13,089 >> Initializing global attention on CLS token...\n",
            " 67% 5629/8340 [1:25:36<38:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:13,933 >> Initializing global attention on CLS token...\n",
            " 68% 5630/8340 [1:25:37<38:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:14,775 >> Initializing global attention on CLS token...\n",
            " 68% 5631/8340 [1:25:38<38:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:15,619 >> Initializing global attention on CLS token...\n",
            " 68% 5632/8340 [1:25:39<38:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:16,464 >> Initializing global attention on CLS token...\n",
            " 68% 5633/8340 [1:25:40<38:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:17,312 >> Initializing global attention on CLS token...\n",
            " 68% 5634/8340 [1:25:41<38:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:18,153 >> Initializing global attention on CLS token...\n",
            " 68% 5635/8340 [1:25:41<38:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:19,001 >> Initializing global attention on CLS token...\n",
            " 68% 5636/8340 [1:25:42<38:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:19,841 >> Initializing global attention on CLS token...\n",
            " 68% 5637/8340 [1:25:43<38:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:20,691 >> Initializing global attention on CLS token...\n",
            " 68% 5638/8340 [1:25:44<38:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:21,534 >> Initializing global attention on CLS token...\n",
            " 68% 5639/8340 [1:25:45<37:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:22,376 >> Initializing global attention on CLS token...\n",
            " 68% 5640/8340 [1:25:46<37:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:23,219 >> Initializing global attention on CLS token...\n",
            " 68% 5641/8340 [1:25:47<37:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:24,066 >> Initializing global attention on CLS token...\n",
            " 68% 5642/8340 [1:25:47<37:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:24,907 >> Initializing global attention on CLS token...\n",
            " 68% 5643/8340 [1:25:48<37:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:25,752 >> Initializing global attention on CLS token...\n",
            " 68% 5644/8340 [1:25:49<37:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:26,596 >> Initializing global attention on CLS token...\n",
            " 68% 5645/8340 [1:25:50<37:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:27,442 >> Initializing global attention on CLS token...\n",
            " 68% 5646/8340 [1:25:51<37:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:28,283 >> Initializing global attention on CLS token...\n",
            " 68% 5647/8340 [1:25:52<37:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:29,135 >> Initializing global attention on CLS token...\n",
            " 68% 5648/8340 [1:25:52<37:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:29,983 >> Initializing global attention on CLS token...\n",
            " 68% 5649/8340 [1:25:53<37:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:30,824 >> Initializing global attention on CLS token...\n",
            " 68% 5650/8340 [1:25:54<37:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:31,676 >> Initializing global attention on CLS token...\n",
            " 68% 5651/8340 [1:25:55<37:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:32,523 >> Initializing global attention on CLS token...\n",
            " 68% 5652/8340 [1:25:56<37:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:33,369 >> Initializing global attention on CLS token...\n",
            " 68% 5653/8340 [1:25:57<37:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:34,214 >> Initializing global attention on CLS token...\n",
            " 68% 5654/8340 [1:25:58<37:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:35,059 >> Initializing global attention on CLS token...\n",
            " 68% 5655/8340 [1:25:58<37:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:35,903 >> Initializing global attention on CLS token...\n",
            " 68% 5656/8340 [1:25:59<37:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:36,747 >> Initializing global attention on CLS token...\n",
            " 68% 5657/8340 [1:26:00<37:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:37,593 >> Initializing global attention on CLS token...\n",
            " 68% 5658/8340 [1:26:01<37:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:38,436 >> Initializing global attention on CLS token...\n",
            " 68% 5659/8340 [1:26:02<37:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:39,282 >> Initializing global attention on CLS token...\n",
            " 68% 5660/8340 [1:26:03<37:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:40,123 >> Initializing global attention on CLS token...\n",
            " 68% 5661/8340 [1:26:03<37:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:40,963 >> Initializing global attention on CLS token...\n",
            " 68% 5662/8340 [1:26:04<37:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:41,807 >> Initializing global attention on CLS token...\n",
            " 68% 5663/8340 [1:26:05<37:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:42,652 >> Initializing global attention on CLS token...\n",
            " 68% 5664/8340 [1:26:06<37:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:43,498 >> Initializing global attention on CLS token...\n",
            " 68% 5665/8340 [1:26:07<37:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:44,342 >> Initializing global attention on CLS token...\n",
            " 68% 5666/8340 [1:26:08<37:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:45,195 >> Initializing global attention on CLS token...\n",
            " 68% 5667/8340 [1:26:09<37:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:46,050 >> Initializing global attention on CLS token...\n",
            " 68% 5668/8340 [1:26:09<37:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:46,901 >> Initializing global attention on CLS token...\n",
            " 68% 5669/8340 [1:26:10<37:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:47,758 >> Initializing global attention on CLS token...\n",
            " 68% 5670/8340 [1:26:11<37:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:48,610 >> Initializing global attention on CLS token...\n",
            " 68% 5671/8340 [1:26:12<37:52,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:49,457 >> Initializing global attention on CLS token...\n",
            " 68% 5672/8340 [1:26:13<37:51,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:50,304 >> Initializing global attention on CLS token...\n",
            " 68% 5673/8340 [1:26:14<37:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:51,144 >> Initializing global attention on CLS token...\n",
            " 68% 5674/8340 [1:26:14<37:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:51,990 >> Initializing global attention on CLS token...\n",
            " 68% 5675/8340 [1:26:15<37:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:52,830 >> Initializing global attention on CLS token...\n",
            " 68% 5676/8340 [1:26:16<37:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:53,681 >> Initializing global attention on CLS token...\n",
            " 68% 5677/8340 [1:26:17<37:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:54,517 >> Initializing global attention on CLS token...\n",
            " 68% 5678/8340 [1:26:18<37:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:55,365 >> Initializing global attention on CLS token...\n",
            " 68% 5679/8340 [1:26:19<37:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:56,207 >> Initializing global attention on CLS token...\n",
            " 68% 5680/8340 [1:26:20<37:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:57,054 >> Initializing global attention on CLS token...\n",
            " 68% 5681/8340 [1:26:20<37:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:57,895 >> Initializing global attention on CLS token...\n",
            " 68% 5682/8340 [1:26:21<37:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:58,736 >> Initializing global attention on CLS token...\n",
            " 68% 5683/8340 [1:26:22<37:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:50:59,581 >> Initializing global attention on CLS token...\n",
            " 68% 5684/8340 [1:26:23<37:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:00,419 >> Initializing global attention on CLS token...\n",
            " 68% 5685/8340 [1:26:24<37:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:01,262 >> Initializing global attention on CLS token...\n",
            " 68% 5686/8340 [1:26:25<37:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:02,105 >> Initializing global attention on CLS token...\n",
            " 68% 5687/8340 [1:26:25<37:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:02,950 >> Initializing global attention on CLS token...\n",
            " 68% 5688/8340 [1:26:26<37:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:03,794 >> Initializing global attention on CLS token...\n",
            " 68% 5689/8340 [1:26:27<37:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:04,640 >> Initializing global attention on CLS token...\n",
            " 68% 5690/8340 [1:26:28<37:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:05,485 >> Initializing global attention on CLS token...\n",
            " 68% 5691/8340 [1:26:29<37:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:06,329 >> Initializing global attention on CLS token...\n",
            " 68% 5692/8340 [1:26:30<37:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:07,175 >> Initializing global attention on CLS token...\n",
            " 68% 5693/8340 [1:26:30<37:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:08,025 >> Initializing global attention on CLS token...\n",
            " 68% 5694/8340 [1:26:31<37:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:08,877 >> Initializing global attention on CLS token...\n",
            " 68% 5695/8340 [1:26:32<37:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:09,726 >> Initializing global attention on CLS token...\n",
            " 68% 5696/8340 [1:26:33<37:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:10,566 >> Initializing global attention on CLS token...\n",
            " 68% 5697/8340 [1:26:34<37:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:11,414 >> Initializing global attention on CLS token...\n",
            " 68% 5698/8340 [1:26:35<37:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:12,258 >> Initializing global attention on CLS token...\n",
            " 68% 5699/8340 [1:26:36<37:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:13,103 >> Initializing global attention on CLS token...\n",
            " 68% 5700/8340 [1:26:36<37:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:13,943 >> Initializing global attention on CLS token...\n",
            " 68% 5701/8340 [1:26:37<37:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:14,797 >> Initializing global attention on CLS token...\n",
            " 68% 5702/8340 [1:26:38<37:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:15,645 >> Initializing global attention on CLS token...\n",
            " 68% 5703/8340 [1:26:39<37:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:16,488 >> Initializing global attention on CLS token...\n",
            " 68% 5704/8340 [1:26:40<37:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:17,332 >> Initializing global attention on CLS token...\n",
            " 68% 5705/8340 [1:26:41<37:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:18,178 >> Initializing global attention on CLS token...\n",
            " 68% 5706/8340 [1:26:41<37:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:19,021 >> Initializing global attention on CLS token...\n",
            " 68% 5707/8340 [1:26:42<37:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:19,863 >> Initializing global attention on CLS token...\n",
            " 68% 5708/8340 [1:26:43<37:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:20,707 >> Initializing global attention on CLS token...\n",
            " 68% 5709/8340 [1:26:44<36:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:21,549 >> Initializing global attention on CLS token...\n",
            " 68% 5710/8340 [1:26:45<36:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:22,395 >> Initializing global attention on CLS token...\n",
            " 68% 5711/8340 [1:26:46<36:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:23,236 >> Initializing global attention on CLS token...\n",
            " 68% 5712/8340 [1:26:47<36:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:24,081 >> Initializing global attention on CLS token...\n",
            " 69% 5713/8340 [1:26:47<36:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:24,923 >> Initializing global attention on CLS token...\n",
            " 69% 5714/8340 [1:26:48<36:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:25,766 >> Initializing global attention on CLS token...\n",
            " 69% 5715/8340 [1:26:49<36:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:26,607 >> Initializing global attention on CLS token...\n",
            " 69% 5716/8340 [1:26:50<36:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:27,448 >> Initializing global attention on CLS token...\n",
            " 69% 5717/8340 [1:26:51<36:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:28,294 >> Initializing global attention on CLS token...\n",
            " 69% 5718/8340 [1:26:52<36:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:29,136 >> Initializing global attention on CLS token...\n",
            " 69% 5719/8340 [1:26:52<36:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:29,979 >> Initializing global attention on CLS token...\n",
            " 69% 5720/8340 [1:26:53<36:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:30,820 >> Initializing global attention on CLS token...\n",
            " 69% 5721/8340 [1:26:54<36:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:31,668 >> Initializing global attention on CLS token...\n",
            " 69% 5722/8340 [1:26:55<36:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:32,510 >> Initializing global attention on CLS token...\n",
            " 69% 5723/8340 [1:26:56<36:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:33,363 >> Initializing global attention on CLS token...\n",
            " 69% 5724/8340 [1:26:57<36:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:34,204 >> Initializing global attention on CLS token...\n",
            " 69% 5725/8340 [1:26:58<36:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:35,052 >> Initializing global attention on CLS token...\n",
            " 69% 5726/8340 [1:26:58<36:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:35,897 >> Initializing global attention on CLS token...\n",
            " 69% 5727/8340 [1:26:59<36:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:36,739 >> Initializing global attention on CLS token...\n",
            " 69% 5728/8340 [1:27:00<36:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:37,585 >> Initializing global attention on CLS token...\n",
            " 69% 5729/8340 [1:27:01<36:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:38,427 >> Initializing global attention on CLS token...\n",
            " 69% 5730/8340 [1:27:02<36:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:39,272 >> Initializing global attention on CLS token...\n",
            " 69% 5731/8340 [1:27:03<36:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:40,114 >> Initializing global attention on CLS token...\n",
            " 69% 5732/8340 [1:27:03<36:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:40,967 >> Initializing global attention on CLS token...\n",
            " 69% 5733/8340 [1:27:04<36:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:41,809 >> Initializing global attention on CLS token...\n",
            " 69% 5734/8340 [1:27:05<36:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:42,653 >> Initializing global attention on CLS token...\n",
            " 69% 5735/8340 [1:27:06<36:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:43,497 >> Initializing global attention on CLS token...\n",
            " 69% 5736/8340 [1:27:07<36:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:44,343 >> Initializing global attention on CLS token...\n",
            " 69% 5737/8340 [1:27:08<36:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:45,189 >> Initializing global attention on CLS token...\n",
            " 69% 5738/8340 [1:27:08<36:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:46,031 >> Initializing global attention on CLS token...\n",
            " 69% 5739/8340 [1:27:09<36:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:46,877 >> Initializing global attention on CLS token...\n",
            " 69% 5740/8340 [1:27:10<36:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:47,718 >> Initializing global attention on CLS token...\n",
            " 69% 5741/8340 [1:27:11<36:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:48,563 >> Initializing global attention on CLS token...\n",
            " 69% 5742/8340 [1:27:12<36:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:49,408 >> Initializing global attention on CLS token...\n",
            " 69% 5743/8340 [1:27:13<36:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:50,254 >> Initializing global attention on CLS token...\n",
            " 69% 5744/8340 [1:27:14<36:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:51,096 >> Initializing global attention on CLS token...\n",
            " 69% 5745/8340 [1:27:14<36:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:51,942 >> Initializing global attention on CLS token...\n",
            " 69% 5746/8340 [1:27:15<36:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:52,779 >> Initializing global attention on CLS token...\n",
            " 69% 5747/8340 [1:27:16<36:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:53,632 >> Initializing global attention on CLS token...\n",
            " 69% 5748/8340 [1:27:17<36:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:54,479 >> Initializing global attention on CLS token...\n",
            " 69% 5749/8340 [1:27:18<36:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:55,325 >> Initializing global attention on CLS token...\n",
            " 69% 5750/8340 [1:27:19<36:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:56,164 >> Initializing global attention on CLS token...\n",
            " 69% 5751/8340 [1:27:19<36:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:57,004 >> Initializing global attention on CLS token...\n",
            " 69% 5752/8340 [1:27:20<36:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:57,852 >> Initializing global attention on CLS token...\n",
            " 69% 5753/8340 [1:27:21<36:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:58,697 >> Initializing global attention on CLS token...\n",
            " 69% 5754/8340 [1:27:22<36:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:51:59,542 >> Initializing global attention on CLS token...\n",
            " 69% 5755/8340 [1:27:23<36:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:00,385 >> Initializing global attention on CLS token...\n",
            " 69% 5756/8340 [1:27:24<36:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:01,228 >> Initializing global attention on CLS token...\n",
            " 69% 5757/8340 [1:27:25<36:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:02,071 >> Initializing global attention on CLS token...\n",
            " 69% 5758/8340 [1:27:25<36:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:02,913 >> Initializing global attention on CLS token...\n",
            " 69% 5759/8340 [1:27:26<36:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:03,756 >> Initializing global attention on CLS token...\n",
            " 69% 5760/8340 [1:27:27<36:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:04,596 >> Initializing global attention on CLS token...\n",
            " 69% 5761/8340 [1:27:28<36:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:05,438 >> Initializing global attention on CLS token...\n",
            " 69% 5762/8340 [1:27:29<36:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:06,284 >> Initializing global attention on CLS token...\n",
            " 69% 5763/8340 [1:27:30<36:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:07,133 >> Initializing global attention on CLS token...\n",
            " 69% 5764/8340 [1:27:30<36:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:07,978 >> Initializing global attention on CLS token...\n",
            " 69% 5765/8340 [1:27:31<36:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:08,821 >> Initializing global attention on CLS token...\n",
            " 69% 5766/8340 [1:27:32<36:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:09,668 >> Initializing global attention on CLS token...\n",
            " 69% 5767/8340 [1:27:33<36:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:10,513 >> Initializing global attention on CLS token...\n",
            " 69% 5768/8340 [1:27:34<36:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:11,363 >> Initializing global attention on CLS token...\n",
            " 69% 5769/8340 [1:27:35<36:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:12,210 >> Initializing global attention on CLS token...\n",
            " 69% 5770/8340 [1:27:36<36:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:13,050 >> Initializing global attention on CLS token...\n",
            " 69% 5771/8340 [1:27:36<36:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:13,894 >> Initializing global attention on CLS token...\n",
            " 69% 5772/8340 [1:27:37<36:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:14,739 >> Initializing global attention on CLS token...\n",
            " 69% 5773/8340 [1:27:38<36:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:15,586 >> Initializing global attention on CLS token...\n",
            " 69% 5774/8340 [1:27:39<36:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:16,429 >> Initializing global attention on CLS token...\n",
            " 69% 5775/8340 [1:27:40<36:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:17,273 >> Initializing global attention on CLS token...\n",
            " 69% 5776/8340 [1:27:41<36:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:18,116 >> Initializing global attention on CLS token...\n",
            " 69% 5777/8340 [1:27:41<36:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:18,971 >> Initializing global attention on CLS token...\n",
            " 69% 5778/8340 [1:27:42<36:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:19,813 >> Initializing global attention on CLS token...\n",
            " 69% 5779/8340 [1:27:43<36:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:20,657 >> Initializing global attention on CLS token...\n",
            " 69% 5780/8340 [1:27:44<36:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:21,500 >> Initializing global attention on CLS token...\n",
            " 69% 5781/8340 [1:27:45<36:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:22,347 >> Initializing global attention on CLS token...\n",
            " 69% 5782/8340 [1:27:46<36:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:23,190 >> Initializing global attention on CLS token...\n",
            " 69% 5783/8340 [1:27:46<35:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:24,032 >> Initializing global attention on CLS token...\n",
            " 69% 5784/8340 [1:27:47<35:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:24,880 >> Initializing global attention on CLS token...\n",
            " 69% 5785/8340 [1:27:48<35:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:25,724 >> Initializing global attention on CLS token...\n",
            " 69% 5786/8340 [1:27:49<35:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:26,572 >> Initializing global attention on CLS token...\n",
            " 69% 5787/8340 [1:27:50<35:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:27,412 >> Initializing global attention on CLS token...\n",
            " 69% 5788/8340 [1:27:51<35:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:28,255 >> Initializing global attention on CLS token...\n",
            " 69% 5789/8340 [1:27:52<35:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:29,095 >> Initializing global attention on CLS token...\n",
            " 69% 5790/8340 [1:27:52<35:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:29,936 >> Initializing global attention on CLS token...\n",
            " 69% 5791/8340 [1:27:53<35:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:30,780 >> Initializing global attention on CLS token...\n",
            " 69% 5792/8340 [1:27:54<35:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:31,623 >> Initializing global attention on CLS token...\n",
            " 69% 5793/8340 [1:27:55<35:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:32,468 >> Initializing global attention on CLS token...\n",
            " 69% 5794/8340 [1:27:56<35:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:33,310 >> Initializing global attention on CLS token...\n",
            " 69% 5795/8340 [1:27:57<35:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:34,148 >> Initializing global attention on CLS token...\n",
            " 69% 5796/8340 [1:27:57<35:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:34,990 >> Initializing global attention on CLS token...\n",
            " 70% 5797/8340 [1:27:58<35:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:35,834 >> Initializing global attention on CLS token...\n",
            " 70% 5798/8340 [1:27:59<35:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:36,681 >> Initializing global attention on CLS token...\n",
            " 70% 5799/8340 [1:28:00<35:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:37,523 >> Initializing global attention on CLS token...\n",
            " 70% 5800/8340 [1:28:01<35:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:38,373 >> Initializing global attention on CLS token...\n",
            " 70% 5801/8340 [1:28:02<35:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:39,213 >> Initializing global attention on CLS token...\n",
            " 70% 5802/8340 [1:28:03<35:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:40,054 >> Initializing global attention on CLS token...\n",
            " 70% 5803/8340 [1:28:03<35:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:40,897 >> Initializing global attention on CLS token...\n",
            " 70% 5804/8340 [1:28:04<35:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:41,738 >> Initializing global attention on CLS token...\n",
            " 70% 5805/8340 [1:28:05<35:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:42,583 >> Initializing global attention on CLS token...\n",
            " 70% 5806/8340 [1:28:06<35:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:43,421 >> Initializing global attention on CLS token...\n",
            " 70% 5807/8340 [1:28:07<35:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:44,265 >> Initializing global attention on CLS token...\n",
            " 70% 5808/8340 [1:28:08<35:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:45,107 >> Initializing global attention on CLS token...\n",
            " 70% 5809/8340 [1:28:08<35:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:45,954 >> Initializing global attention on CLS token...\n",
            " 70% 5810/8340 [1:28:09<35:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:46,796 >> Initializing global attention on CLS token...\n",
            " 70% 5811/8340 [1:28:10<35:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:47,642 >> Initializing global attention on CLS token...\n",
            " 70% 5812/8340 [1:28:11<35:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:48,485 >> Initializing global attention on CLS token...\n",
            " 70% 5813/8340 [1:28:12<35:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:49,332 >> Initializing global attention on CLS token...\n",
            " 70% 5814/8340 [1:28:13<35:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:50,174 >> Initializing global attention on CLS token...\n",
            " 70% 5815/8340 [1:28:13<35:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:51,018 >> Initializing global attention on CLS token...\n",
            " 70% 5816/8340 [1:28:14<35:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:51,859 >> Initializing global attention on CLS token...\n",
            " 70% 5817/8340 [1:28:15<35:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:52,699 >> Initializing global attention on CLS token...\n",
            " 70% 5818/8340 [1:28:16<35:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:53,537 >> Initializing global attention on CLS token...\n",
            " 70% 5819/8340 [1:28:17<35:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:54,382 >> Initializing global attention on CLS token...\n",
            " 70% 5820/8340 [1:28:18<35:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:55,225 >> Initializing global attention on CLS token...\n",
            " 70% 5821/8340 [1:28:19<35:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:56,071 >> Initializing global attention on CLS token...\n",
            " 70% 5822/8340 [1:28:19<35:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:56,916 >> Initializing global attention on CLS token...\n",
            " 70% 5823/8340 [1:28:20<35:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:57,761 >> Initializing global attention on CLS token...\n",
            " 70% 5824/8340 [1:28:21<35:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:58,598 >> Initializing global attention on CLS token...\n",
            " 70% 5825/8340 [1:28:22<35:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:52:59,440 >> Initializing global attention on CLS token...\n",
            " 70% 5826/8340 [1:28:23<35:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:00,285 >> Initializing global attention on CLS token...\n",
            " 70% 5827/8340 [1:28:24<35:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:01,127 >> Initializing global attention on CLS token...\n",
            " 70% 5828/8340 [1:28:24<35:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:01,966 >> Initializing global attention on CLS token...\n",
            " 70% 5829/8340 [1:28:25<35:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:02,809 >> Initializing global attention on CLS token...\n",
            " 70% 5830/8340 [1:28:26<35:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:03,655 >> Initializing global attention on CLS token...\n",
            " 70% 5831/8340 [1:28:27<35:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:04,497 >> Initializing global attention on CLS token...\n",
            " 70% 5832/8340 [1:28:28<35:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:05,342 >> Initializing global attention on CLS token...\n",
            " 70% 5833/8340 [1:28:29<35:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:06,185 >> Initializing global attention on CLS token...\n",
            " 70% 5834/8340 [1:28:29<35:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:07,031 >> Initializing global attention on CLS token...\n",
            " 70% 5835/8340 [1:28:30<35:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:07,874 >> Initializing global attention on CLS token...\n",
            " 70% 5836/8340 [1:28:31<35:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:08,716 >> Initializing global attention on CLS token...\n",
            " 70% 5837/8340 [1:28:32<35:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:53:09,538 >> Initializing global attention on CLS token...\n",
            " 70% 5838/8340 [1:28:32<28:34,  1.46it/s][INFO|trainer.py:725] 2022-12-09 23:53:09,844 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-09 23:53:09,846 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-09 23:53:09,846 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-09 23:53:09,847 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:09,877 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:10,146 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:31,  7.44it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:10,405 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:43,  5.36it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:10,662 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:49,  4.68it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:10,921 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:52,  4.36it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:11,183 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:54,  4.17it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:11,440 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:55,  4.08it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:11,699 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:56,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:11,955 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:56,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:12,212 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:56,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:12,467 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:56,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:12,736 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:57,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:12,994 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:57,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:13,256 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:57,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:13,517 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:56,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:13,776 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:56,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:14,038 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:56,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:14,295 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:56,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:14,574 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:56,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:14,833 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:56,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:15,108 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:56,  3.74it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:15,387 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:57,  3.70it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:15,653 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:56,  3.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:15,910 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:06<00:55,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:16,181 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:55,  3.74it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:16,442 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:55,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:16,698 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:54,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:16,977 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:07<00:55,  3.73it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:17,239 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:54,  3.75it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:17,515 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:54,  3.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:17,781 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:54,  3.74it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:18,036 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:08<00:53,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:18,293 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:52,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:18,548 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:52,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:18,812 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:51,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:19,069 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:09<00:51,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:19,326 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:51,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:19,593 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:50,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:19,850 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:50,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:20,115 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:10<00:50,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:20,376 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:50,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:20,642 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:50,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:20,923 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:11<00:51,  3.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:21,195 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:11<00:51,  3.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:21,472 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:51,  3.68it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:21,755 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:51,  3.63it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:22,034 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:12<00:51,  3.63it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:22,294 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:12<00:50,  3.69it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:22,553 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:49,  3.73it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:22,822 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:49,  3.74it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:23,080 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:13<00:48,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:23,359 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:48,  3.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:23,629 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:48,  3.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:23,883 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:14<00:47,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:24,136 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:14<00:46,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:24,391 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:46,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:24,645 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:24,902 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:15<00:45,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:25,160 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:15<00:44,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:25,415 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:44,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:25,675 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:25,933 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:16<00:44,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:26,188 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:16<00:43,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:26,447 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:26,701 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:43,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:26,953 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:17<00:42,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:27,203 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:17<00:42,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:27,460 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:42,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:27,716 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:42,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:27,985 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:18<00:42,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:28,240 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:18<00:42,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:28,496 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:41,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:28,757 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:41,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:29,011 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:19<00:41,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:29,274 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:19<00:41,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:29,530 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:40,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:29,795 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:40,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:30,051 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:20<00:40,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:30,320 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:20<00:40,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:30,578 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:40,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:30,835 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:39,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:31,107 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:21<00:39,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:31,359 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:21<00:39,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:31,618 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:31,876 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:22<00:38,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:32,135 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:22<00:38,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:32,395 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:22<00:38,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:32,652 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:32,911 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:23<00:37,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:33,167 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:23<00:37,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:33,432 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:23<00:37,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:33,692 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:33,946 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:24<00:36,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:34,210 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:24<00:36,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:34,473 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:36,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:34,733 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:34,989 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:25<00:35,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:35,247 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:25<00:35,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:35,504 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:35,767 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:36,026 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:26<00:34,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:36,292 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:26<00:34,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:36,548 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:34,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:36,804 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:33,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:37,060 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:27<00:33,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:37,317 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:27<00:33,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:37,583 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:33,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:37,844 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:32,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:38,101 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:28<00:32,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:38,358 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:28<00:31,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:38,612 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:31,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:38,876 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:31,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:39,131 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:29<00:31,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:39,404 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:29<00:31,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:39,664 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:31,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:39,923 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:30<00:30,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:40,183 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:30<00:30,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:40,437 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:30<00:29,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:40,690 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:29,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:40,949 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:31<00:29,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:41,210 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:31<00:29,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:41,468 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:31<00:28,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:41,726 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:28,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:41,984 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:32<00:28,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:42,244 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:32<00:28,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:42,498 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:32<00:27,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:42,753 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:43,020 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:33<00:27,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:43,283 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:33<00:27,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:43,546 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:33<00:27,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:43,812 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:27,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:44,069 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:34<00:26,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:44,333 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:34<00:26,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:44,591 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:34<00:26,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:44,853 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:45,118 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:35<00:25,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:45,376 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:35<00:25,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:45,649 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:35<00:25,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:45,906 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:36<00:24,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:46,163 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:36<00:24,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:46,418 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:36<00:24,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:46,676 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:36<00:23,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:46,932 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:37<00:23,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:47,186 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:37<00:23,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:47,440 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:37<00:22,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:47,697 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:47,953 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:38<00:22,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:48,205 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:38<00:22,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:48,470 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:38<00:21,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:48,730 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:48,992 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:39<00:21,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:49,248 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:39<00:21,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:49,505 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:39<00:20,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:49,769 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:20,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:50,029 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:40<00:20,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:50,288 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:40<00:20,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:50,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:40<00:19,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:50,810 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:19,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:51,069 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:41<00:19,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:51,324 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:41<00:19,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:51,580 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:41<00:18,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:51,838 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:52,090 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:42<00:18,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:52,346 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:42<00:17,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:52,607 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:42<00:17,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:52,870 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:53,127 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:43<00:17,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:53,405 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:43<00:17,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:53,661 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:43<00:16,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:53,916 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:44<00:16,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:54,178 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:44<00:16,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:54,443 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:44<00:16,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:54,710 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:44<00:16,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:54,964 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:45<00:15,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:55,221 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:45<00:15,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:55,476 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:45<00:14,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:55,735 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:45<00:14,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:55,991 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:46<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:56,250 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:46<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:56,512 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:46<00:14,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:56,768 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:46<00:13,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:57,023 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:47<00:13,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:57,280 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:47<00:13,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:57,539 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:47<00:12,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:57,798 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:47<00:12,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:58,057 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:48<00:12,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:58,312 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:48<00:12,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:58,571 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:48<00:11,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:58,841 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:48<00:11,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:59,101 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:49<00:11,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:59,355 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:49<00:11,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:59,614 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:49<00:10,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:53:59,892 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:50<00:10,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:00,147 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:50<00:10,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:00,403 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:50<00:10,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:00,664 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:50<00:09,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:00,919 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:51<00:09,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:01,178 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:51<00:09,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:01,432 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:51<00:09,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:01,694 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:51<00:08,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:01,952 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:52<00:08,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:02,211 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:52<00:08,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:02,485 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:52<00:08,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:02,740 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:52<00:07,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:02,999 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:53<00:07,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:03,257 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:53<00:07,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:03,515 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:53<00:06,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:03,781 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:53<00:06,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:04,034 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:54<00:06,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:04,292 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:54<00:06,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:04,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:54<00:05,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:04,805 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:54<00:05,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:05,068 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:55<00:05,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:05,322 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:55<00:05,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:05,587 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:55<00:04,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:05,845 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:55<00:04,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:06,104 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:56<00:04,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:06,359 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:56<00:04,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:06,622 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:56<00:03,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:06,882 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:57<00:03,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:07,136 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:57<00:03,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:07,401 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:57<00:03,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:07,658 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:57<00:02,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:07,935 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:58<00:02,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:08,192 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:58<00:02,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:08,450 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:58<00:02,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:08,709 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:58<00:01,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:08,981 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:59<00:01,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:09,245 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:59<00:01,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:09,502 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:59<00:01,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:09,758 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:59<00:00,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:10,018 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [01:00<00:00,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:10,276 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [01:00<00:00,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:10,513 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.5322692394256592, 'eval_f1-micro': 0.7714285714285715, 'eval_f1-macro': 0.6875646526692225, 'eval_runtime': 61.0444, 'eval_samples_per_second': 22.934, 'eval_steps_per_second': 3.833, 'epoch': 7.0}\n",
            " 70% 5838/8340 [1:29:33<28:34,  1.46it/s]\n",
            "100% 234/234 [01:00<00:00,  3.85it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-09 23:54:10,893 >> Saving model checkpoint to logs/output_1/checkpoint-5838\n",
            "[INFO|configuration_utils.py:447] 2022-12-09 23:54:10,894 >> Configuration saved in logs/output_1/checkpoint-5838/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-09 23:54:11,284 >> Model weights saved in logs/output_1/checkpoint-5838/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-09 23:54:11,285 >> tokenizer config file saved in logs/output_1/checkpoint-5838/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-09 23:54:11,285 >> Special tokens file saved in logs/output_1/checkpoint-5838/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-09 23:54:12,369 >> Initializing global attention on CLS token...\n",
            " 70% 5839/8340 [1:29:36<13:32:02, 19.48s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:13,213 >> Initializing global attention on CLS token...\n",
            " 70% 5840/8340 [1:29:37<9:38:44, 13.89s/it] [INFO|modeling_longformer.py:1932] 2022-12-09 23:54:14,058 >> Initializing global attention on CLS token...\n",
            " 70% 5841/8340 [1:29:37<6:55:29,  9.98s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:14,900 >> Initializing global attention on CLS token...\n",
            " 70% 5842/8340 [1:29:38<5:01:16,  7.24s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:15,745 >> Initializing global attention on CLS token...\n",
            " 70% 5843/8340 [1:29:39<3:41:19,  5.32s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:16,587 >> Initializing global attention on CLS token...\n",
            " 70% 5844/8340 [1:29:40<2:45:24,  3.98s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:17,431 >> Initializing global attention on CLS token...\n",
            " 70% 5845/8340 [1:29:41<2:06:14,  3.04s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:18,273 >> Initializing global attention on CLS token...\n",
            " 70% 5846/8340 [1:29:42<1:38:52,  2.38s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:19,123 >> Initializing global attention on CLS token...\n",
            " 70% 5847/8340 [1:29:42<1:19:41,  1.92s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:19,964 >> Initializing global attention on CLS token...\n",
            " 70% 5848/8340 [1:29:43<1:06:18,  1.60s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:20,812 >> Initializing global attention on CLS token...\n",
            " 70% 5849/8340 [1:29:44<56:54,  1.37s/it]  [INFO|modeling_longformer.py:1932] 2022-12-09 23:54:21,653 >> Initializing global attention on CLS token...\n",
            " 70% 5850/8340 [1:29:45<50:19,  1.21s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:22,499 >> Initializing global attention on CLS token...\n",
            " 70% 5851/8340 [1:29:46<45:42,  1.10s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:23,342 >> Initializing global attention on CLS token...\n",
            " 70% 5852/8340 [1:29:47<42:30,  1.02s/it][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:24,186 >> Initializing global attention on CLS token...\n",
            " 70% 5853/8340 [1:29:47<40:13,  1.03it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:25,034 >> Initializing global attention on CLS token...\n",
            " 70% 5854/8340 [1:29:48<38:41,  1.07it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:25,875 >> Initializing global attention on CLS token...\n",
            " 70% 5855/8340 [1:29:49<37:28,  1.10it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:26,715 >> Initializing global attention on CLS token...\n",
            " 70% 5856/8340 [1:29:50<36:44,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:27,564 >> Initializing global attention on CLS token...\n",
            " 70% 5857/8340 [1:29:51<36:09,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:28,403 >> Initializing global attention on CLS token...\n",
            " 70% 5858/8340 [1:29:52<35:46,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:29,247 >> Initializing global attention on CLS token...\n",
            " 70% 5859/8340 [1:29:53<35:29,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:30,089 >> Initializing global attention on CLS token...\n",
            " 70% 5860/8340 [1:29:53<35:16,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:30,934 >> Initializing global attention on CLS token...\n",
            " 70% 5861/8340 [1:29:54<35:10,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:31,780 >> Initializing global attention on CLS token...\n",
            " 70% 5862/8340 [1:29:55<35:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:32,621 >> Initializing global attention on CLS token...\n",
            " 70% 5863/8340 [1:29:56<34:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:33,465 >> Initializing global attention on CLS token...\n",
            " 70% 5864/8340 [1:29:57<34:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:34,310 >> Initializing global attention on CLS token...\n",
            " 70% 5865/8340 [1:29:58<34:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:35,154 >> Initializing global attention on CLS token...\n",
            " 70% 5866/8340 [1:29:58<34:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:35,999 >> Initializing global attention on CLS token...\n",
            " 70% 5867/8340 [1:29:59<34:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:36,839 >> Initializing global attention on CLS token...\n",
            " 70% 5868/8340 [1:30:00<34:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:37,684 >> Initializing global attention on CLS token...\n",
            " 70% 5869/8340 [1:30:01<34:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:38,527 >> Initializing global attention on CLS token...\n",
            " 70% 5870/8340 [1:30:02<34:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:39,367 >> Initializing global attention on CLS token...\n",
            " 70% 5871/8340 [1:30:03<34:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:40,215 >> Initializing global attention on CLS token...\n",
            " 70% 5872/8340 [1:30:04<34:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:41,059 >> Initializing global attention on CLS token...\n",
            " 70% 5873/8340 [1:30:04<34:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:41,903 >> Initializing global attention on CLS token...\n",
            " 70% 5874/8340 [1:30:05<34:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:42,742 >> Initializing global attention on CLS token...\n",
            " 70% 5875/8340 [1:30:06<34:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:43,590 >> Initializing global attention on CLS token...\n",
            " 70% 5876/8340 [1:30:07<34:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:44,433 >> Initializing global attention on CLS token...\n",
            " 70% 5877/8340 [1:30:08<34:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:45,283 >> Initializing global attention on CLS token...\n",
            " 70% 5878/8340 [1:30:09<34:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:46,122 >> Initializing global attention on CLS token...\n",
            " 70% 5879/8340 [1:30:09<34:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:46,967 >> Initializing global attention on CLS token...\n",
            " 71% 5880/8340 [1:30:10<34:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:47,809 >> Initializing global attention on CLS token...\n",
            " 71% 5881/8340 [1:30:11<34:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:48,656 >> Initializing global attention on CLS token...\n",
            " 71% 5882/8340 [1:30:12<34:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:49,500 >> Initializing global attention on CLS token...\n",
            " 71% 5883/8340 [1:30:13<34:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:50,341 >> Initializing global attention on CLS token...\n",
            " 71% 5884/8340 [1:30:14<34:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:51,182 >> Initializing global attention on CLS token...\n",
            " 71% 5885/8340 [1:30:14<34:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:52,027 >> Initializing global attention on CLS token...\n",
            " 71% 5886/8340 [1:30:15<34:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:52,872 >> Initializing global attention on CLS token...\n",
            " 71% 5887/8340 [1:30:16<34:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:53,716 >> Initializing global attention on CLS token...\n",
            " 71% 5888/8340 [1:30:17<34:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:54,557 >> Initializing global attention on CLS token...\n",
            " 71% 5889/8340 [1:30:18<34:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:55,404 >> Initializing global attention on CLS token...\n",
            " 71% 5890/8340 [1:30:19<34:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:56,245 >> Initializing global attention on CLS token...\n",
            " 71% 5891/8340 [1:30:20<34:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:57,089 >> Initializing global attention on CLS token...\n",
            " 71% 5892/8340 [1:30:20<34:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:57,931 >> Initializing global attention on CLS token...\n",
            " 71% 5893/8340 [1:30:21<34:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:58,776 >> Initializing global attention on CLS token...\n",
            " 71% 5894/8340 [1:30:22<34:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:54:59,620 >> Initializing global attention on CLS token...\n",
            " 71% 5895/8340 [1:30:23<34:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:00,466 >> Initializing global attention on CLS token...\n",
            " 71% 5896/8340 [1:30:24<34:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:01,308 >> Initializing global attention on CLS token...\n",
            " 71% 5897/8340 [1:30:25<34:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:02,150 >> Initializing global attention on CLS token...\n",
            " 71% 5898/8340 [1:30:25<34:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:02,991 >> Initializing global attention on CLS token...\n",
            " 71% 5899/8340 [1:30:26<34:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:03,840 >> Initializing global attention on CLS token...\n",
            " 71% 5900/8340 [1:30:27<34:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:04,684 >> Initializing global attention on CLS token...\n",
            " 71% 5901/8340 [1:30:28<34:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:05,525 >> Initializing global attention on CLS token...\n",
            " 71% 5902/8340 [1:30:29<34:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:06,371 >> Initializing global attention on CLS token...\n",
            " 71% 5903/8340 [1:30:30<34:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:07,211 >> Initializing global attention on CLS token...\n",
            " 71% 5904/8340 [1:30:31<34:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:08,059 >> Initializing global attention on CLS token...\n",
            " 71% 5905/8340 [1:30:31<34:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:08,896 >> Initializing global attention on CLS token...\n",
            " 71% 5906/8340 [1:30:32<34:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:09,737 >> Initializing global attention on CLS token...\n",
            " 71% 5907/8340 [1:30:33<34:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:10,575 >> Initializing global attention on CLS token...\n",
            " 71% 5908/8340 [1:30:34<34:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:11,423 >> Initializing global attention on CLS token...\n",
            " 71% 5909/8340 [1:30:35<34:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:12,265 >> Initializing global attention on CLS token...\n",
            " 71% 5910/8340 [1:30:36<34:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:13,108 >> Initializing global attention on CLS token...\n",
            " 71% 5911/8340 [1:30:36<34:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:13,954 >> Initializing global attention on CLS token...\n",
            " 71% 5912/8340 [1:30:37<34:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:14,793 >> Initializing global attention on CLS token...\n",
            " 71% 5913/8340 [1:30:38<34:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:15,639 >> Initializing global attention on CLS token...\n",
            " 71% 5914/8340 [1:30:39<34:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:16,481 >> Initializing global attention on CLS token...\n",
            " 71% 5915/8340 [1:30:40<34:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:17,326 >> Initializing global attention on CLS token...\n",
            " 71% 5916/8340 [1:30:41<34:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:18,170 >> Initializing global attention on CLS token...\n",
            " 71% 5917/8340 [1:30:41<34:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:19,014 >> Initializing global attention on CLS token...\n",
            " 71% 5918/8340 [1:30:42<34:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:19,861 >> Initializing global attention on CLS token...\n",
            " 71% 5919/8340 [1:30:43<34:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:20,701 >> Initializing global attention on CLS token...\n",
            " 71% 5920/8340 [1:30:44<34:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:21,547 >> Initializing global attention on CLS token...\n",
            " 71% 5921/8340 [1:30:45<34:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:22,391 >> Initializing global attention on CLS token...\n",
            " 71% 5922/8340 [1:30:46<34:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:23,232 >> Initializing global attention on CLS token...\n",
            " 71% 5923/8340 [1:30:47<33:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:24,069 >> Initializing global attention on CLS token...\n",
            " 71% 5924/8340 [1:30:47<33:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:24,909 >> Initializing global attention on CLS token...\n",
            " 71% 5925/8340 [1:30:48<33:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:25,749 >> Initializing global attention on CLS token...\n",
            " 71% 5926/8340 [1:30:49<33:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:26,592 >> Initializing global attention on CLS token...\n",
            " 71% 5927/8340 [1:30:50<33:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:27,435 >> Initializing global attention on CLS token...\n",
            " 71% 5928/8340 [1:30:51<33:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:28,276 >> Initializing global attention on CLS token...\n",
            " 71% 5929/8340 [1:30:52<33:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:29,119 >> Initializing global attention on CLS token...\n",
            " 71% 5930/8340 [1:30:52<33:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:29,963 >> Initializing global attention on CLS token...\n",
            " 71% 5931/8340 [1:30:53<33:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:30,806 >> Initializing global attention on CLS token...\n",
            " 71% 5932/8340 [1:30:54<33:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:31,647 >> Initializing global attention on CLS token...\n",
            " 71% 5933/8340 [1:30:55<33:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:32,488 >> Initializing global attention on CLS token...\n",
            " 71% 5934/8340 [1:30:56<33:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:33,328 >> Initializing global attention on CLS token...\n",
            " 71% 5935/8340 [1:30:57<33:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:34,166 >> Initializing global attention on CLS token...\n",
            " 71% 5936/8340 [1:30:57<33:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:35,013 >> Initializing global attention on CLS token...\n",
            " 71% 5937/8340 [1:30:58<33:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:35,853 >> Initializing global attention on CLS token...\n",
            " 71% 5938/8340 [1:30:59<33:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:36,702 >> Initializing global attention on CLS token...\n",
            " 71% 5939/8340 [1:31:00<33:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:37,541 >> Initializing global attention on CLS token...\n",
            " 71% 5940/8340 [1:31:01<33:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:38,387 >> Initializing global attention on CLS token...\n",
            " 71% 5941/8340 [1:31:02<33:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:39,232 >> Initializing global attention on CLS token...\n",
            " 71% 5942/8340 [1:31:03<33:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:40,081 >> Initializing global attention on CLS token...\n",
            " 71% 5943/8340 [1:31:03<33:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:40,934 >> Initializing global attention on CLS token...\n",
            " 71% 5944/8340 [1:31:04<33:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:41,783 >> Initializing global attention on CLS token...\n",
            " 71% 5945/8340 [1:31:05<33:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:42,627 >> Initializing global attention on CLS token...\n",
            " 71% 5946/8340 [1:31:06<33:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:43,476 >> Initializing global attention on CLS token...\n",
            " 71% 5947/8340 [1:31:07<33:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:44,333 >> Initializing global attention on CLS token...\n",
            " 71% 5948/8340 [1:31:08<33:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:45,177 >> Initializing global attention on CLS token...\n",
            " 71% 5949/8340 [1:31:08<33:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:46,019 >> Initializing global attention on CLS token...\n",
            " 71% 5950/8340 [1:31:09<33:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:46,859 >> Initializing global attention on CLS token...\n",
            " 71% 5951/8340 [1:31:10<33:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:47,702 >> Initializing global attention on CLS token...\n",
            " 71% 5952/8340 [1:31:11<33:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:48,546 >> Initializing global attention on CLS token...\n",
            " 71% 5953/8340 [1:31:12<33:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:49,390 >> Initializing global attention on CLS token...\n",
            " 71% 5954/8340 [1:31:13<33:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:50,231 >> Initializing global attention on CLS token...\n",
            " 71% 5955/8340 [1:31:14<33:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:51,076 >> Initializing global attention on CLS token...\n",
            " 71% 5956/8340 [1:31:14<33:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:51,917 >> Initializing global attention on CLS token...\n",
            " 71% 5957/8340 [1:31:15<33:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:52,761 >> Initializing global attention on CLS token...\n",
            " 71% 5958/8340 [1:31:16<33:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:53,604 >> Initializing global attention on CLS token...\n",
            " 71% 5959/8340 [1:31:17<33:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:54,446 >> Initializing global attention on CLS token...\n",
            " 71% 5960/8340 [1:31:18<33:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:55,290 >> Initializing global attention on CLS token...\n",
            " 71% 5961/8340 [1:31:19<33:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:56,127 >> Initializing global attention on CLS token...\n",
            " 71% 5962/8340 [1:31:19<33:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:56,974 >> Initializing global attention on CLS token...\n",
            " 71% 5963/8340 [1:31:20<33:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:57,814 >> Initializing global attention on CLS token...\n",
            " 72% 5964/8340 [1:31:21<33:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:58,656 >> Initializing global attention on CLS token...\n",
            " 72% 5965/8340 [1:31:22<33:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:55:59,495 >> Initializing global attention on CLS token...\n",
            " 72% 5966/8340 [1:31:23<33:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:00,335 >> Initializing global attention on CLS token...\n",
            " 72% 5967/8340 [1:31:24<33:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:01,175 >> Initializing global attention on CLS token...\n",
            " 72% 5968/8340 [1:31:24<33:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:02,015 >> Initializing global attention on CLS token...\n",
            " 72% 5969/8340 [1:31:25<33:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:02,853 >> Initializing global attention on CLS token...\n",
            " 72% 5970/8340 [1:31:26<33:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:03,701 >> Initializing global attention on CLS token...\n",
            " 72% 5971/8340 [1:31:27<33:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:04,544 >> Initializing global attention on CLS token...\n",
            " 72% 5972/8340 [1:31:28<33:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:05,390 >> Initializing global attention on CLS token...\n",
            " 72% 5973/8340 [1:31:29<33:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:06,225 >> Initializing global attention on CLS token...\n",
            " 72% 5974/8340 [1:31:30<33:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:07,066 >> Initializing global attention on CLS token...\n",
            " 72% 5975/8340 [1:31:30<33:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:07,910 >> Initializing global attention on CLS token...\n",
            " 72% 5976/8340 [1:31:31<33:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:08,754 >> Initializing global attention on CLS token...\n",
            " 72% 5977/8340 [1:31:32<33:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:09,593 >> Initializing global attention on CLS token...\n",
            " 72% 5978/8340 [1:31:33<33:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:10,437 >> Initializing global attention on CLS token...\n",
            " 72% 5979/8340 [1:31:34<33:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:11,280 >> Initializing global attention on CLS token...\n",
            " 72% 5980/8340 [1:31:35<33:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:12,122 >> Initializing global attention on CLS token...\n",
            " 72% 5981/8340 [1:31:35<33:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:12,964 >> Initializing global attention on CLS token...\n",
            " 72% 5982/8340 [1:31:36<33:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:13,805 >> Initializing global attention on CLS token...\n",
            " 72% 5983/8340 [1:31:37<33:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:14,646 >> Initializing global attention on CLS token...\n",
            " 72% 5984/8340 [1:31:38<32:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:15,484 >> Initializing global attention on CLS token...\n",
            " 72% 5985/8340 [1:31:39<33:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:16,327 >> Initializing global attention on CLS token...\n",
            " 72% 5986/8340 [1:31:40<33:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:17,172 >> Initializing global attention on CLS token...\n",
            " 72% 5987/8340 [1:31:40<33:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:18,014 >> Initializing global attention on CLS token...\n",
            " 72% 5988/8340 [1:31:41<32:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:18,854 >> Initializing global attention on CLS token...\n",
            " 72% 5989/8340 [1:31:42<32:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:19,696 >> Initializing global attention on CLS token...\n",
            " 72% 5990/8340 [1:31:43<33:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:20,541 >> Initializing global attention on CLS token...\n",
            " 72% 5991/8340 [1:31:44<33:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:21,387 >> Initializing global attention on CLS token...\n",
            " 72% 5992/8340 [1:31:45<32:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:22,225 >> Initializing global attention on CLS token...\n",
            " 72% 5993/8340 [1:31:46<32:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:23,065 >> Initializing global attention on CLS token...\n",
            " 72% 5994/8340 [1:31:46<32:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:23,907 >> Initializing global attention on CLS token...\n",
            " 72% 5995/8340 [1:31:47<32:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:24,746 >> Initializing global attention on CLS token...\n",
            " 72% 5996/8340 [1:31:48<32:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:25,584 >> Initializing global attention on CLS token...\n",
            " 72% 5997/8340 [1:31:49<32:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:26,435 >> Initializing global attention on CLS token...\n",
            " 72% 5998/8340 [1:31:50<32:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:27,276 >> Initializing global attention on CLS token...\n",
            " 72% 5999/8340 [1:31:51<32:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:28,120 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0919, 'learning_rate': 8.435251798561151e-06, 'epoch': 7.19}\n",
            " 72% 6000/8340 [1:31:52<34:32,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:29,105 >> Initializing global attention on CLS token...\n",
            " 72% 6001/8340 [1:31:52<34:01,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:29,948 >> Initializing global attention on CLS token...\n",
            " 72% 6002/8340 [1:31:53<33:40,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:30,793 >> Initializing global attention on CLS token...\n",
            " 72% 6003/8340 [1:31:54<33:24,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:31,635 >> Initializing global attention on CLS token...\n",
            " 72% 6004/8340 [1:31:55<33:15,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:32,479 >> Initializing global attention on CLS token...\n",
            " 72% 6005/8340 [1:31:56<33:07,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:33,325 >> Initializing global attention on CLS token...\n",
            " 72% 6006/8340 [1:31:57<33:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:34,175 >> Initializing global attention on CLS token...\n",
            " 72% 6007/8340 [1:31:57<33:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:35,026 >> Initializing global attention on CLS token...\n",
            " 72% 6008/8340 [1:31:58<33:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:35,875 >> Initializing global attention on CLS token...\n",
            " 72% 6009/8340 [1:31:59<33:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:36,721 >> Initializing global attention on CLS token...\n",
            " 72% 6010/8340 [1:32:00<32:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:37,567 >> Initializing global attention on CLS token...\n",
            " 72% 6011/8340 [1:32:01<32:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:38,410 >> Initializing global attention on CLS token...\n",
            " 72% 6012/8340 [1:32:02<32:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:39,250 >> Initializing global attention on CLS token...\n",
            " 72% 6013/8340 [1:32:03<32:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:40,092 >> Initializing global attention on CLS token...\n",
            " 72% 6014/8340 [1:32:03<32:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:40,936 >> Initializing global attention on CLS token...\n",
            " 72% 6015/8340 [1:32:04<32:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:41,778 >> Initializing global attention on CLS token...\n",
            " 72% 6016/8340 [1:32:05<32:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:42,621 >> Initializing global attention on CLS token...\n",
            " 72% 6017/8340 [1:32:06<32:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:43,461 >> Initializing global attention on CLS token...\n",
            " 72% 6018/8340 [1:32:07<32:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:44,305 >> Initializing global attention on CLS token...\n",
            " 72% 6019/8340 [1:32:08<32:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:45,147 >> Initializing global attention on CLS token...\n",
            " 72% 6020/8340 [1:32:08<32:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:45,991 >> Initializing global attention on CLS token...\n",
            " 72% 6021/8340 [1:32:09<32:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:46,833 >> Initializing global attention on CLS token...\n",
            " 72% 6022/8340 [1:32:10<32:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:47,679 >> Initializing global attention on CLS token...\n",
            " 72% 6023/8340 [1:32:11<32:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:48,519 >> Initializing global attention on CLS token...\n",
            " 72% 6024/8340 [1:32:12<32:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:49,370 >> Initializing global attention on CLS token...\n",
            " 72% 6025/8340 [1:32:13<32:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:50,211 >> Initializing global attention on CLS token...\n",
            " 72% 6026/8340 [1:32:14<32:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:51,060 >> Initializing global attention on CLS token...\n",
            " 72% 6027/8340 [1:32:14<32:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:51,907 >> Initializing global attention on CLS token...\n",
            " 72% 6028/8340 [1:32:15<32:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:52,751 >> Initializing global attention on CLS token...\n",
            " 72% 6029/8340 [1:32:16<32:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:53,595 >> Initializing global attention on CLS token...\n",
            " 72% 6030/8340 [1:32:17<32:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:54,439 >> Initializing global attention on CLS token...\n",
            " 72% 6031/8340 [1:32:18<32:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:55,278 >> Initializing global attention on CLS token...\n",
            " 72% 6032/8340 [1:32:19<32:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:56,122 >> Initializing global attention on CLS token...\n",
            " 72% 6033/8340 [1:32:19<32:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:56,973 >> Initializing global attention on CLS token...\n",
            " 72% 6034/8340 [1:32:20<32:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:57,812 >> Initializing global attention on CLS token...\n",
            " 72% 6035/8340 [1:32:21<32:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:58,655 >> Initializing global attention on CLS token...\n",
            " 72% 6036/8340 [1:32:22<32:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:56:59,497 >> Initializing global attention on CLS token...\n",
            " 72% 6037/8340 [1:32:23<32:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:00,337 >> Initializing global attention on CLS token...\n",
            " 72% 6038/8340 [1:32:24<32:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:01,182 >> Initializing global attention on CLS token...\n",
            " 72% 6039/8340 [1:32:24<32:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:02,023 >> Initializing global attention on CLS token...\n",
            " 72% 6040/8340 [1:32:25<32:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:02,862 >> Initializing global attention on CLS token...\n",
            " 72% 6041/8340 [1:32:26<32:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:03,704 >> Initializing global attention on CLS token...\n",
            " 72% 6042/8340 [1:32:27<32:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:04,544 >> Initializing global attention on CLS token...\n",
            " 72% 6043/8340 [1:32:28<32:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:05,384 >> Initializing global attention on CLS token...\n",
            " 72% 6044/8340 [1:32:29<32:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:06,229 >> Initializing global attention on CLS token...\n",
            " 72% 6045/8340 [1:32:30<32:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:07,072 >> Initializing global attention on CLS token...\n",
            " 72% 6046/8340 [1:32:30<32:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:07,917 >> Initializing global attention on CLS token...\n",
            " 73% 6047/8340 [1:32:31<32:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:08,759 >> Initializing global attention on CLS token...\n",
            " 73% 6048/8340 [1:32:32<32:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:09,601 >> Initializing global attention on CLS token...\n",
            " 73% 6049/8340 [1:32:33<32:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:10,443 >> Initializing global attention on CLS token...\n",
            " 73% 6050/8340 [1:32:34<32:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:11,287 >> Initializing global attention on CLS token...\n",
            " 73% 6051/8340 [1:32:35<32:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:12,132 >> Initializing global attention on CLS token...\n",
            " 73% 6052/8340 [1:32:35<32:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:12,979 >> Initializing global attention on CLS token...\n",
            " 73% 6053/8340 [1:32:36<32:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:13,821 >> Initializing global attention on CLS token...\n",
            " 73% 6054/8340 [1:32:37<32:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:14,658 >> Initializing global attention on CLS token...\n",
            " 73% 6055/8340 [1:32:38<32:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:15,505 >> Initializing global attention on CLS token...\n",
            " 73% 6056/8340 [1:32:39<32:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:16,348 >> Initializing global attention on CLS token...\n",
            " 73% 6057/8340 [1:32:40<32:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:17,192 >> Initializing global attention on CLS token...\n",
            " 73% 6058/8340 [1:32:40<32:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:18,032 >> Initializing global attention on CLS token...\n",
            " 73% 6059/8340 [1:32:41<32:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:18,877 >> Initializing global attention on CLS token...\n",
            " 73% 6060/8340 [1:32:42<32:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:19,719 >> Initializing global attention on CLS token...\n",
            " 73% 6061/8340 [1:32:43<31:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:20,557 >> Initializing global attention on CLS token...\n",
            " 73% 6062/8340 [1:32:44<31:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:21,399 >> Initializing global attention on CLS token...\n",
            " 73% 6063/8340 [1:32:45<31:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:22,245 >> Initializing global attention on CLS token...\n",
            " 73% 6064/8340 [1:32:46<31:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:23,087 >> Initializing global attention on CLS token...\n",
            " 73% 6065/8340 [1:32:46<31:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:23,928 >> Initializing global attention on CLS token...\n",
            " 73% 6066/8340 [1:32:47<31:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:24,766 >> Initializing global attention on CLS token...\n",
            " 73% 6067/8340 [1:32:48<31:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:25,610 >> Initializing global attention on CLS token...\n",
            " 73% 6068/8340 [1:32:49<31:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:26,456 >> Initializing global attention on CLS token...\n",
            " 73% 6069/8340 [1:32:50<31:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:27,298 >> Initializing global attention on CLS token...\n",
            " 73% 6070/8340 [1:32:51<31:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:28,141 >> Initializing global attention on CLS token...\n",
            " 73% 6071/8340 [1:32:51<31:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:28,982 >> Initializing global attention on CLS token...\n",
            " 73% 6072/8340 [1:32:52<31:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:29,822 >> Initializing global attention on CLS token...\n",
            " 73% 6073/8340 [1:32:53<31:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:30,662 >> Initializing global attention on CLS token...\n",
            " 73% 6074/8340 [1:32:54<31:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:31,507 >> Initializing global attention on CLS token...\n",
            " 73% 6075/8340 [1:32:55<31:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:32,346 >> Initializing global attention on CLS token...\n",
            " 73% 6076/8340 [1:32:56<31:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:33,188 >> Initializing global attention on CLS token...\n",
            " 73% 6077/8340 [1:32:56<31:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:34,035 >> Initializing global attention on CLS token...\n",
            " 73% 6078/8340 [1:32:57<31:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:34,876 >> Initializing global attention on CLS token...\n",
            " 73% 6079/8340 [1:32:58<31:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:35,715 >> Initializing global attention on CLS token...\n",
            " 73% 6080/8340 [1:32:59<31:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:36,557 >> Initializing global attention on CLS token...\n",
            " 73% 6081/8340 [1:33:00<31:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:37,402 >> Initializing global attention on CLS token...\n",
            " 73% 6082/8340 [1:33:01<31:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:38,241 >> Initializing global attention on CLS token...\n",
            " 73% 6083/8340 [1:33:02<31:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:39,086 >> Initializing global attention on CLS token...\n",
            " 73% 6084/8340 [1:33:02<31:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:39,925 >> Initializing global attention on CLS token...\n",
            " 73% 6085/8340 [1:33:03<31:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:40,769 >> Initializing global attention on CLS token...\n",
            " 73% 6086/8340 [1:33:04<31:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:41,612 >> Initializing global attention on CLS token...\n",
            " 73% 6087/8340 [1:33:05<31:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:42,458 >> Initializing global attention on CLS token...\n",
            " 73% 6088/8340 [1:33:06<31:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:43,300 >> Initializing global attention on CLS token...\n",
            " 73% 6089/8340 [1:33:07<31:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:44,143 >> Initializing global attention on CLS token...\n",
            " 73% 6090/8340 [1:33:07<31:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:44,996 >> Initializing global attention on CLS token...\n",
            " 73% 6091/8340 [1:33:08<31:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:45,841 >> Initializing global attention on CLS token...\n",
            " 73% 6092/8340 [1:33:09<31:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:46,680 >> Initializing global attention on CLS token...\n",
            " 73% 6093/8340 [1:33:10<31:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:47,522 >> Initializing global attention on CLS token...\n",
            " 73% 6094/8340 [1:33:11<31:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:48,364 >> Initializing global attention on CLS token...\n",
            " 73% 6095/8340 [1:33:12<31:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:49,213 >> Initializing global attention on CLS token...\n",
            " 73% 6096/8340 [1:33:13<31:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:50,053 >> Initializing global attention on CLS token...\n",
            " 73% 6097/8340 [1:33:13<31:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:50,899 >> Initializing global attention on CLS token...\n",
            " 73% 6098/8340 [1:33:14<31:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:51,743 >> Initializing global attention on CLS token...\n",
            " 73% 6099/8340 [1:33:15<31:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:52,583 >> Initializing global attention on CLS token...\n",
            " 73% 6100/8340 [1:33:16<31:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:53,426 >> Initializing global attention on CLS token...\n",
            " 73% 6101/8340 [1:33:17<31:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:54,266 >> Initializing global attention on CLS token...\n",
            " 73% 6102/8340 [1:33:18<31:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:55,112 >> Initializing global attention on CLS token...\n",
            " 73% 6103/8340 [1:33:18<31:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:55,964 >> Initializing global attention on CLS token...\n",
            " 73% 6104/8340 [1:33:19<31:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:56,807 >> Initializing global attention on CLS token...\n",
            " 73% 6105/8340 [1:33:20<31:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:57,653 >> Initializing global attention on CLS token...\n",
            " 73% 6106/8340 [1:33:21<31:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:58,494 >> Initializing global attention on CLS token...\n",
            " 73% 6107/8340 [1:33:22<31:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:57:59,339 >> Initializing global attention on CLS token...\n",
            " 73% 6108/8340 [1:33:23<31:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:00,183 >> Initializing global attention on CLS token...\n",
            " 73% 6109/8340 [1:33:23<31:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:01,029 >> Initializing global attention on CLS token...\n",
            " 73% 6110/8340 [1:33:24<31:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:01,870 >> Initializing global attention on CLS token...\n",
            " 73% 6111/8340 [1:33:25<31:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:02,716 >> Initializing global attention on CLS token...\n",
            " 73% 6112/8340 [1:33:26<31:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:03,557 >> Initializing global attention on CLS token...\n",
            " 73% 6113/8340 [1:33:27<31:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:04,396 >> Initializing global attention on CLS token...\n",
            " 73% 6114/8340 [1:33:28<31:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:05,239 >> Initializing global attention on CLS token...\n",
            " 73% 6115/8340 [1:33:29<31:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:06,082 >> Initializing global attention on CLS token...\n",
            " 73% 6116/8340 [1:33:29<31:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:06,921 >> Initializing global attention on CLS token...\n",
            " 73% 6117/8340 [1:33:30<31:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:07,769 >> Initializing global attention on CLS token...\n",
            " 73% 6118/8340 [1:33:31<31:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:08,609 >> Initializing global attention on CLS token...\n",
            " 73% 6119/8340 [1:33:32<31:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:09,454 >> Initializing global attention on CLS token...\n",
            " 73% 6120/8340 [1:33:33<31:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:10,295 >> Initializing global attention on CLS token...\n",
            " 73% 6121/8340 [1:33:34<31:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:11,139 >> Initializing global attention on CLS token...\n",
            " 73% 6122/8340 [1:33:34<31:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:11,981 >> Initializing global attention on CLS token...\n",
            " 73% 6123/8340 [1:33:35<31:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:12,824 >> Initializing global attention on CLS token...\n",
            " 73% 6124/8340 [1:33:36<31:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:13,674 >> Initializing global attention on CLS token...\n",
            " 73% 6125/8340 [1:33:37<31:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:14,519 >> Initializing global attention on CLS token...\n",
            " 73% 6126/8340 [1:33:38<31:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:15,361 >> Initializing global attention on CLS token...\n",
            " 73% 6127/8340 [1:33:39<31:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:16,213 >> Initializing global attention on CLS token...\n",
            " 73% 6128/8340 [1:33:40<31:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:17,062 >> Initializing global attention on CLS token...\n",
            " 73% 6129/8340 [1:33:40<31:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:17,906 >> Initializing global attention on CLS token...\n",
            " 74% 6130/8340 [1:33:41<31:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:18,748 >> Initializing global attention on CLS token...\n",
            " 74% 6131/8340 [1:33:42<31:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:19,586 >> Initializing global attention on CLS token...\n",
            " 74% 6132/8340 [1:33:43<31:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:20,430 >> Initializing global attention on CLS token...\n",
            " 74% 6133/8340 [1:33:44<31:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:21,275 >> Initializing global attention on CLS token...\n",
            " 74% 6134/8340 [1:33:45<31:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:22,117 >> Initializing global attention on CLS token...\n",
            " 74% 6135/8340 [1:33:45<31:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:22,962 >> Initializing global attention on CLS token...\n",
            " 74% 6136/8340 [1:33:46<31:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:23,808 >> Initializing global attention on CLS token...\n",
            " 74% 6137/8340 [1:33:47<30:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:24,656 >> Initializing global attention on CLS token...\n",
            " 74% 6138/8340 [1:33:48<31:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:25,500 >> Initializing global attention on CLS token...\n",
            " 74% 6139/8340 [1:33:49<30:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:26,346 >> Initializing global attention on CLS token...\n",
            " 74% 6140/8340 [1:33:50<30:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:27,191 >> Initializing global attention on CLS token...\n",
            " 74% 6141/8340 [1:33:50<30:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:28,035 >> Initializing global attention on CLS token...\n",
            " 74% 6142/8340 [1:33:51<30:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:28,879 >> Initializing global attention on CLS token...\n",
            " 74% 6143/8340 [1:33:52<30:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:29,724 >> Initializing global attention on CLS token...\n",
            " 74% 6144/8340 [1:33:53<30:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:30,565 >> Initializing global attention on CLS token...\n",
            " 74% 6145/8340 [1:33:54<30:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:31,413 >> Initializing global attention on CLS token...\n",
            " 74% 6146/8340 [1:33:55<30:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:32,257 >> Initializing global attention on CLS token...\n",
            " 74% 6147/8340 [1:33:56<30:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:33,104 >> Initializing global attention on CLS token...\n",
            " 74% 6148/8340 [1:33:56<30:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:33,948 >> Initializing global attention on CLS token...\n",
            " 74% 6149/8340 [1:33:57<30:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:34,791 >> Initializing global attention on CLS token...\n",
            " 74% 6150/8340 [1:33:58<30:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:35,634 >> Initializing global attention on CLS token...\n",
            " 74% 6151/8340 [1:33:59<30:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:36,474 >> Initializing global attention on CLS token...\n",
            " 74% 6152/8340 [1:34:00<30:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:37,315 >> Initializing global attention on CLS token...\n",
            " 74% 6153/8340 [1:34:01<30:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:38,155 >> Initializing global attention on CLS token...\n",
            " 74% 6154/8340 [1:34:01<30:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:38,999 >> Initializing global attention on CLS token...\n",
            " 74% 6155/8340 [1:34:02<30:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:39,839 >> Initializing global attention on CLS token...\n",
            " 74% 6156/8340 [1:34:03<30:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:40,684 >> Initializing global attention on CLS token...\n",
            " 74% 6157/8340 [1:34:04<30:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:41,530 >> Initializing global attention on CLS token...\n",
            " 74% 6158/8340 [1:34:05<30:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:42,371 >> Initializing global attention on CLS token...\n",
            " 74% 6159/8340 [1:34:06<30:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:43,218 >> Initializing global attention on CLS token...\n",
            " 74% 6160/8340 [1:34:07<30:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:44,059 >> Initializing global attention on CLS token...\n",
            " 74% 6161/8340 [1:34:07<30:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:44,898 >> Initializing global attention on CLS token...\n",
            " 74% 6162/8340 [1:34:08<30:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:45,741 >> Initializing global attention on CLS token...\n",
            " 74% 6163/8340 [1:34:09<30:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:46,580 >> Initializing global attention on CLS token...\n",
            " 74% 6164/8340 [1:34:10<30:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:47,418 >> Initializing global attention on CLS token...\n",
            " 74% 6165/8340 [1:34:11<30:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:48,265 >> Initializing global attention on CLS token...\n",
            " 74% 6166/8340 [1:34:12<30:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:49,109 >> Initializing global attention on CLS token...\n",
            " 74% 6167/8340 [1:34:12<30:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:49,954 >> Initializing global attention on CLS token...\n",
            " 74% 6168/8340 [1:34:13<30:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:50,795 >> Initializing global attention on CLS token...\n",
            " 74% 6169/8340 [1:34:14<30:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:51,644 >> Initializing global attention on CLS token...\n",
            " 74% 6170/8340 [1:34:15<30:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:52,486 >> Initializing global attention on CLS token...\n",
            " 74% 6171/8340 [1:34:16<30:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:53,329 >> Initializing global attention on CLS token...\n",
            " 74% 6172/8340 [1:34:17<30:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:54,173 >> Initializing global attention on CLS token...\n",
            " 74% 6173/8340 [1:34:17<30:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:55,016 >> Initializing global attention on CLS token...\n",
            " 74% 6174/8340 [1:34:18<30:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:55,862 >> Initializing global attention on CLS token...\n",
            " 74% 6175/8340 [1:34:19<30:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:56,714 >> Initializing global attention on CLS token...\n",
            " 74% 6176/8340 [1:34:20<30:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:57,560 >> Initializing global attention on CLS token...\n",
            " 74% 6177/8340 [1:34:21<30:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:58,406 >> Initializing global attention on CLS token...\n",
            " 74% 6178/8340 [1:34:22<30:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:58:59,258 >> Initializing global attention on CLS token...\n",
            " 74% 6179/8340 [1:34:23<30:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:00,102 >> Initializing global attention on CLS token...\n",
            " 74% 6180/8340 [1:34:23<30:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:00,943 >> Initializing global attention on CLS token...\n",
            " 74% 6181/8340 [1:34:24<30:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:01,785 >> Initializing global attention on CLS token...\n",
            " 74% 6182/8340 [1:34:25<30:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:02,627 >> Initializing global attention on CLS token...\n",
            " 74% 6183/8340 [1:34:26<30:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:03,469 >> Initializing global attention on CLS token...\n",
            " 74% 6184/8340 [1:34:27<30:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:04,315 >> Initializing global attention on CLS token...\n",
            " 74% 6185/8340 [1:34:28<30:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:05,158 >> Initializing global attention on CLS token...\n",
            " 74% 6186/8340 [1:34:28<30:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:06,001 >> Initializing global attention on CLS token...\n",
            " 74% 6187/8340 [1:34:29<30:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:06,840 >> Initializing global attention on CLS token...\n",
            " 74% 6188/8340 [1:34:30<30:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:07,686 >> Initializing global attention on CLS token...\n",
            " 74% 6189/8340 [1:34:31<30:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:08,526 >> Initializing global attention on CLS token...\n",
            " 74% 6190/8340 [1:34:32<30:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:09,370 >> Initializing global attention on CLS token...\n",
            " 74% 6191/8340 [1:34:33<30:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:10,210 >> Initializing global attention on CLS token...\n",
            " 74% 6192/8340 [1:34:34<30:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:11,050 >> Initializing global attention on CLS token...\n",
            " 74% 6193/8340 [1:34:34<30:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:11,895 >> Initializing global attention on CLS token...\n",
            " 74% 6194/8340 [1:34:35<30:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:12,735 >> Initializing global attention on CLS token...\n",
            " 74% 6195/8340 [1:34:36<30:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:13,575 >> Initializing global attention on CLS token...\n",
            " 74% 6196/8340 [1:34:37<30:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:14,420 >> Initializing global attention on CLS token...\n",
            " 74% 6197/8340 [1:34:38<30:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:15,260 >> Initializing global attention on CLS token...\n",
            " 74% 6198/8340 [1:34:39<30:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:16,098 >> Initializing global attention on CLS token...\n",
            " 74% 6199/8340 [1:34:39<30:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:16,950 >> Initializing global attention on CLS token...\n",
            " 74% 6200/8340 [1:34:40<30:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:17,793 >> Initializing global attention on CLS token...\n",
            " 74% 6201/8340 [1:34:41<30:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:18,633 >> Initializing global attention on CLS token...\n",
            " 74% 6202/8340 [1:34:42<29:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:19,472 >> Initializing global attention on CLS token...\n",
            " 74% 6203/8340 [1:34:43<29:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:20,316 >> Initializing global attention on CLS token...\n",
            " 74% 6204/8340 [1:34:44<30:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:21,159 >> Initializing global attention on CLS token...\n",
            " 74% 6205/8340 [1:34:44<30:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:22,007 >> Initializing global attention on CLS token...\n",
            " 74% 6206/8340 [1:34:45<30:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:22,849 >> Initializing global attention on CLS token...\n",
            " 74% 6207/8340 [1:34:46<30:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:23,699 >> Initializing global attention on CLS token...\n",
            " 74% 6208/8340 [1:34:47<30:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:24,544 >> Initializing global attention on CLS token...\n",
            " 74% 6209/8340 [1:34:48<29:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:25,380 >> Initializing global attention on CLS token...\n",
            " 74% 6210/8340 [1:34:49<29:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:26,222 >> Initializing global attention on CLS token...\n",
            " 74% 6211/8340 [1:34:50<29:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:27,068 >> Initializing global attention on CLS token...\n",
            " 74% 6212/8340 [1:34:50<29:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:27,910 >> Initializing global attention on CLS token...\n",
            " 74% 6213/8340 [1:34:51<29:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:28,753 >> Initializing global attention on CLS token...\n",
            " 75% 6214/8340 [1:34:52<29:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:29,594 >> Initializing global attention on CLS token...\n",
            " 75% 6215/8340 [1:34:53<29:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:30,440 >> Initializing global attention on CLS token...\n",
            " 75% 6216/8340 [1:34:54<29:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:31,276 >> Initializing global attention on CLS token...\n",
            " 75% 6217/8340 [1:34:55<29:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:32,116 >> Initializing global attention on CLS token...\n",
            " 75% 6218/8340 [1:34:55<29:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:32,962 >> Initializing global attention on CLS token...\n",
            " 75% 6219/8340 [1:34:56<29:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:33,797 >> Initializing global attention on CLS token...\n",
            " 75% 6220/8340 [1:34:57<29:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:34,646 >> Initializing global attention on CLS token...\n",
            " 75% 6221/8340 [1:34:58<29:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:35,494 >> Initializing global attention on CLS token...\n",
            " 75% 6222/8340 [1:34:59<29:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:36,334 >> Initializing global attention on CLS token...\n",
            " 75% 6223/8340 [1:35:00<29:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:37,178 >> Initializing global attention on CLS token...\n",
            " 75% 6224/8340 [1:35:00<29:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:38,026 >> Initializing global attention on CLS token...\n",
            " 75% 6225/8340 [1:35:01<29:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:38,870 >> Initializing global attention on CLS token...\n",
            " 75% 6226/8340 [1:35:02<29:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:39,715 >> Initializing global attention on CLS token...\n",
            " 75% 6227/8340 [1:35:03<29:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:40,562 >> Initializing global attention on CLS token...\n",
            " 75% 6228/8340 [1:35:04<29:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:41,405 >> Initializing global attention on CLS token...\n",
            " 75% 6229/8340 [1:35:05<29:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:42,251 >> Initializing global attention on CLS token...\n",
            " 75% 6230/8340 [1:35:06<29:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:43,097 >> Initializing global attention on CLS token...\n",
            " 75% 6231/8340 [1:35:06<29:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:43,938 >> Initializing global attention on CLS token...\n",
            " 75% 6232/8340 [1:35:07<29:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:44,783 >> Initializing global attention on CLS token...\n",
            " 75% 6233/8340 [1:35:08<29:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:45,626 >> Initializing global attention on CLS token...\n",
            " 75% 6234/8340 [1:35:09<29:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:46,467 >> Initializing global attention on CLS token...\n",
            " 75% 6235/8340 [1:35:10<29:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:47,310 >> Initializing global attention on CLS token...\n",
            " 75% 6236/8340 [1:35:11<29:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:48,155 >> Initializing global attention on CLS token...\n",
            " 75% 6237/8340 [1:35:11<29:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:48,999 >> Initializing global attention on CLS token...\n",
            " 75% 6238/8340 [1:35:12<29:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:49,845 >> Initializing global attention on CLS token...\n",
            " 75% 6239/8340 [1:35:13<29:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:50,688 >> Initializing global attention on CLS token...\n",
            " 75% 6240/8340 [1:35:14<29:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:51,535 >> Initializing global attention on CLS token...\n",
            " 75% 6241/8340 [1:35:15<29:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:52,377 >> Initializing global attention on CLS token...\n",
            " 75% 6242/8340 [1:35:16<29:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:53,221 >> Initializing global attention on CLS token...\n",
            " 75% 6243/8340 [1:35:17<29:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:54,064 >> Initializing global attention on CLS token...\n",
            " 75% 6244/8340 [1:35:17<29:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:54,909 >> Initializing global attention on CLS token...\n",
            " 75% 6245/8340 [1:35:18<29:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:55,750 >> Initializing global attention on CLS token...\n",
            " 75% 6246/8340 [1:35:19<29:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:56,589 >> Initializing global attention on CLS token...\n",
            " 75% 6247/8340 [1:35:20<29:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:57,435 >> Initializing global attention on CLS token...\n",
            " 75% 6248/8340 [1:35:21<29:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:58,276 >> Initializing global attention on CLS token...\n",
            " 75% 6249/8340 [1:35:22<29:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:59,117 >> Initializing global attention on CLS token...\n",
            " 75% 6250/8340 [1:35:22<29:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-09 23:59:59,968 >> Initializing global attention on CLS token...\n",
            " 75% 6251/8340 [1:35:23<29:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:00,807 >> Initializing global attention on CLS token...\n",
            " 75% 6252/8340 [1:35:24<29:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:01,651 >> Initializing global attention on CLS token...\n",
            " 75% 6253/8340 [1:35:25<29:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:02,495 >> Initializing global attention on CLS token...\n",
            " 75% 6254/8340 [1:35:26<29:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:03,338 >> Initializing global attention on CLS token...\n",
            " 75% 6255/8340 [1:35:27<29:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:04,185 >> Initializing global attention on CLS token...\n",
            " 75% 6256/8340 [1:35:27<29:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:05,027 >> Initializing global attention on CLS token...\n",
            " 75% 6257/8340 [1:35:28<29:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:05,872 >> Initializing global attention on CLS token...\n",
            " 75% 6258/8340 [1:35:29<29:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:06,713 >> Initializing global attention on CLS token...\n",
            " 75% 6259/8340 [1:35:30<29:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:07,560 >> Initializing global attention on CLS token...\n",
            " 75% 6260/8340 [1:35:31<29:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:08,401 >> Initializing global attention on CLS token...\n",
            " 75% 6261/8340 [1:35:32<29:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:09,246 >> Initializing global attention on CLS token...\n",
            " 75% 6262/8340 [1:35:33<29:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:10,088 >> Initializing global attention on CLS token...\n",
            " 75% 6263/8340 [1:35:33<29:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:10,929 >> Initializing global attention on CLS token...\n",
            " 75% 6264/8340 [1:35:34<29:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:11,774 >> Initializing global attention on CLS token...\n",
            " 75% 6265/8340 [1:35:35<29:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:12,613 >> Initializing global attention on CLS token...\n",
            " 75% 6266/8340 [1:35:36<29:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:13,457 >> Initializing global attention on CLS token...\n",
            " 75% 6267/8340 [1:35:37<29:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:14,302 >> Initializing global attention on CLS token...\n",
            " 75% 6268/8340 [1:35:38<29:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:15,142 >> Initializing global attention on CLS token...\n",
            " 75% 6269/8340 [1:35:38<29:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:15,981 >> Initializing global attention on CLS token...\n",
            " 75% 6270/8340 [1:35:39<29:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:16,822 >> Initializing global attention on CLS token...\n",
            " 75% 6271/8340 [1:35:40<29:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:17,665 >> Initializing global attention on CLS token...\n",
            " 75% 6272/8340 [1:35:41<29:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:18,507 >> Initializing global attention on CLS token...\n",
            " 75% 6273/8340 [1:35:42<29:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:19,353 >> Initializing global attention on CLS token...\n",
            " 75% 6274/8340 [1:35:43<29:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:20,195 >> Initializing global attention on CLS token...\n",
            " 75% 6275/8340 [1:35:43<28:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:21,035 >> Initializing global attention on CLS token...\n",
            " 75% 6276/8340 [1:35:44<28:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:21,877 >> Initializing global attention on CLS token...\n",
            " 75% 6277/8340 [1:35:45<28:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:22,721 >> Initializing global attention on CLS token...\n",
            " 75% 6278/8340 [1:35:46<28:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:23,566 >> Initializing global attention on CLS token...\n",
            " 75% 6279/8340 [1:35:47<28:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:24,405 >> Initializing global attention on CLS token...\n",
            " 75% 6280/8340 [1:35:48<28:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:25,242 >> Initializing global attention on CLS token...\n",
            " 75% 6281/8340 [1:35:49<28:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:26,083 >> Initializing global attention on CLS token...\n",
            " 75% 6282/8340 [1:35:49<28:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:26,927 >> Initializing global attention on CLS token...\n",
            " 75% 6283/8340 [1:35:50<28:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:27,767 >> Initializing global attention on CLS token...\n",
            " 75% 6284/8340 [1:35:51<28:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:28,612 >> Initializing global attention on CLS token...\n",
            " 75% 6285/8340 [1:35:52<28:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:29,453 >> Initializing global attention on CLS token...\n",
            " 75% 6286/8340 [1:35:53<28:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:30,298 >> Initializing global attention on CLS token...\n",
            " 75% 6287/8340 [1:35:54<28:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:31,138 >> Initializing global attention on CLS token...\n",
            " 75% 6288/8340 [1:35:54<28:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:31,980 >> Initializing global attention on CLS token...\n",
            " 75% 6289/8340 [1:35:55<28:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:32,829 >> Initializing global attention on CLS token...\n",
            " 75% 6290/8340 [1:35:56<28:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:33,671 >> Initializing global attention on CLS token...\n",
            " 75% 6291/8340 [1:35:57<28:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:34,515 >> Initializing global attention on CLS token...\n",
            " 75% 6292/8340 [1:35:58<28:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:35,366 >> Initializing global attention on CLS token...\n",
            " 75% 6293/8340 [1:35:59<28:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:36,213 >> Initializing global attention on CLS token...\n",
            " 75% 6294/8340 [1:36:00<28:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:37,053 >> Initializing global attention on CLS token...\n",
            " 75% 6295/8340 [1:36:00<28:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:37,893 >> Initializing global attention on CLS token...\n",
            " 75% 6296/8340 [1:36:01<28:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:38,737 >> Initializing global attention on CLS token...\n",
            " 76% 6297/8340 [1:36:02<28:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:39,579 >> Initializing global attention on CLS token...\n",
            " 76% 6298/8340 [1:36:03<28:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:40,422 >> Initializing global attention on CLS token...\n",
            " 76% 6299/8340 [1:36:04<28:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:41,268 >> Initializing global attention on CLS token...\n",
            " 76% 6300/8340 [1:36:05<28:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:42,110 >> Initializing global attention on CLS token...\n",
            " 76% 6301/8340 [1:36:05<28:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:42,952 >> Initializing global attention on CLS token...\n",
            " 76% 6302/8340 [1:36:06<28:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:43,806 >> Initializing global attention on CLS token...\n",
            " 76% 6303/8340 [1:36:07<28:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:44,653 >> Initializing global attention on CLS token...\n",
            " 76% 6304/8340 [1:36:08<28:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:45,496 >> Initializing global attention on CLS token...\n",
            " 76% 6305/8340 [1:36:09<28:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:46,350 >> Initializing global attention on CLS token...\n",
            " 76% 6306/8340 [1:36:10<28:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:47,195 >> Initializing global attention on CLS token...\n",
            " 76% 6307/8340 [1:36:10<28:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:48,038 >> Initializing global attention on CLS token...\n",
            " 76% 6308/8340 [1:36:11<28:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:48,882 >> Initializing global attention on CLS token...\n",
            " 76% 6309/8340 [1:36:12<28:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:49,721 >> Initializing global attention on CLS token...\n",
            " 76% 6310/8340 [1:36:13<28:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:50,565 >> Initializing global attention on CLS token...\n",
            " 76% 6311/8340 [1:36:14<28:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:51,405 >> Initializing global attention on CLS token...\n",
            " 76% 6312/8340 [1:36:15<28:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:52,250 >> Initializing global attention on CLS token...\n",
            " 76% 6313/8340 [1:36:16<28:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:53,089 >> Initializing global attention on CLS token...\n",
            " 76% 6314/8340 [1:36:16<28:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:53,936 >> Initializing global attention on CLS token...\n",
            " 76% 6315/8340 [1:36:17<28:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:54,780 >> Initializing global attention on CLS token...\n",
            " 76% 6316/8340 [1:36:18<28:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:55,628 >> Initializing global attention on CLS token...\n",
            " 76% 6317/8340 [1:36:19<28:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:56,472 >> Initializing global attention on CLS token...\n",
            " 76% 6318/8340 [1:36:20<28:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:57,316 >> Initializing global attention on CLS token...\n",
            " 76% 6319/8340 [1:36:21<28:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:58,161 >> Initializing global attention on CLS token...\n",
            " 76% 6320/8340 [1:36:21<28:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:58,999 >> Initializing global attention on CLS token...\n",
            " 76% 6321/8340 [1:36:22<28:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:00:59,839 >> Initializing global attention on CLS token...\n",
            " 76% 6322/8340 [1:36:23<28:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:00,689 >> Initializing global attention on CLS token...\n",
            " 76% 6323/8340 [1:36:24<28:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:01,529 >> Initializing global attention on CLS token...\n",
            " 76% 6324/8340 [1:36:25<28:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:02,373 >> Initializing global attention on CLS token...\n",
            " 76% 6325/8340 [1:36:26<28:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:03,215 >> Initializing global attention on CLS token...\n",
            " 76% 6326/8340 [1:36:27<28:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:04,059 >> Initializing global attention on CLS token...\n",
            " 76% 6327/8340 [1:36:27<28:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:04,901 >> Initializing global attention on CLS token...\n",
            " 76% 6328/8340 [1:36:28<28:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:05,741 >> Initializing global attention on CLS token...\n",
            " 76% 6329/8340 [1:36:29<28:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:06,583 >> Initializing global attention on CLS token...\n",
            " 76% 6330/8340 [1:36:30<28:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:07,423 >> Initializing global attention on CLS token...\n",
            " 76% 6331/8340 [1:36:31<28:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:08,263 >> Initializing global attention on CLS token...\n",
            " 76% 6332/8340 [1:36:32<28:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:09,107 >> Initializing global attention on CLS token...\n",
            " 76% 6333/8340 [1:36:32<28:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:09,951 >> Initializing global attention on CLS token...\n",
            " 76% 6334/8340 [1:36:33<28:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:10,796 >> Initializing global attention on CLS token...\n",
            " 76% 6335/8340 [1:36:34<28:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:11,642 >> Initializing global attention on CLS token...\n",
            " 76% 6336/8340 [1:36:35<28:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:12,490 >> Initializing global attention on CLS token...\n",
            " 76% 6337/8340 [1:36:36<28:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:13,335 >> Initializing global attention on CLS token...\n",
            " 76% 6338/8340 [1:36:37<28:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:14,181 >> Initializing global attention on CLS token...\n",
            " 76% 6339/8340 [1:36:37<28:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:15,027 >> Initializing global attention on CLS token...\n",
            " 76% 6340/8340 [1:36:38<28:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:15,874 >> Initializing global attention on CLS token...\n",
            " 76% 6341/8340 [1:36:39<28:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:16,718 >> Initializing global attention on CLS token...\n",
            " 76% 6342/8340 [1:36:40<28:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:17,560 >> Initializing global attention on CLS token...\n",
            " 76% 6343/8340 [1:36:41<28:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:18,405 >> Initializing global attention on CLS token...\n",
            " 76% 6344/8340 [1:36:42<28:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:19,254 >> Initializing global attention on CLS token...\n",
            " 76% 6345/8340 [1:36:43<28:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:20,093 >> Initializing global attention on CLS token...\n",
            " 76% 6346/8340 [1:36:43<28:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:20,936 >> Initializing global attention on CLS token...\n",
            " 76% 6347/8340 [1:36:44<27:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:21,776 >> Initializing global attention on CLS token...\n",
            " 76% 6348/8340 [1:36:45<27:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:22,616 >> Initializing global attention on CLS token...\n",
            " 76% 6349/8340 [1:36:46<27:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:23,463 >> Initializing global attention on CLS token...\n",
            " 76% 6350/8340 [1:36:47<27:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:24,308 >> Initializing global attention on CLS token...\n",
            " 76% 6351/8340 [1:36:48<27:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:25,151 >> Initializing global attention on CLS token...\n",
            " 76% 6352/8340 [1:36:48<27:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:25,990 >> Initializing global attention on CLS token...\n",
            " 76% 6353/8340 [1:36:49<27:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:26,832 >> Initializing global attention on CLS token...\n",
            " 76% 6354/8340 [1:36:50<27:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:27,674 >> Initializing global attention on CLS token...\n",
            " 76% 6355/8340 [1:36:51<27:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:28,517 >> Initializing global attention on CLS token...\n",
            " 76% 6356/8340 [1:36:52<27:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:29,361 >> Initializing global attention on CLS token...\n",
            " 76% 6357/8340 [1:36:53<27:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:30,204 >> Initializing global attention on CLS token...\n",
            " 76% 6358/8340 [1:36:54<27:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:31,048 >> Initializing global attention on CLS token...\n",
            " 76% 6359/8340 [1:36:54<27:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:31,889 >> Initializing global attention on CLS token...\n",
            " 76% 6360/8340 [1:36:55<27:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:32,736 >> Initializing global attention on CLS token...\n",
            " 76% 6361/8340 [1:36:56<27:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:33,578 >> Initializing global attention on CLS token...\n",
            " 76% 6362/8340 [1:36:57<27:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:34,423 >> Initializing global attention on CLS token...\n",
            " 76% 6363/8340 [1:36:58<27:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:35,268 >> Initializing global attention on CLS token...\n",
            " 76% 6364/8340 [1:36:59<27:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:36,113 >> Initializing global attention on CLS token...\n",
            " 76% 6365/8340 [1:36:59<27:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:36,953 >> Initializing global attention on CLS token...\n",
            " 76% 6366/8340 [1:37:00<27:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:37,792 >> Initializing global attention on CLS token...\n",
            " 76% 6367/8340 [1:37:01<27:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:38,628 >> Initializing global attention on CLS token...\n",
            " 76% 6368/8340 [1:37:02<27:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:39,475 >> Initializing global attention on CLS token...\n",
            " 76% 6369/8340 [1:37:03<27:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:40,315 >> Initializing global attention on CLS token...\n",
            " 76% 6370/8340 [1:37:04<27:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:41,157 >> Initializing global attention on CLS token...\n",
            " 76% 6371/8340 [1:37:04<27:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:42,002 >> Initializing global attention on CLS token...\n",
            " 76% 6372/8340 [1:37:05<27:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:42,851 >> Initializing global attention on CLS token...\n",
            " 76% 6373/8340 [1:37:06<27:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:43,694 >> Initializing global attention on CLS token...\n",
            " 76% 6374/8340 [1:37:07<27:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:44,541 >> Initializing global attention on CLS token...\n",
            " 76% 6375/8340 [1:37:08<27:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:45,384 >> Initializing global attention on CLS token...\n",
            " 76% 6376/8340 [1:37:09<27:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:46,226 >> Initializing global attention on CLS token...\n",
            " 76% 6377/8340 [1:37:10<27:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:47,068 >> Initializing global attention on CLS token...\n",
            " 76% 6378/8340 [1:37:10<27:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:47,916 >> Initializing global attention on CLS token...\n",
            " 76% 6379/8340 [1:37:11<27:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:48,763 >> Initializing global attention on CLS token...\n",
            " 76% 6380/8340 [1:37:12<27:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:49,602 >> Initializing global attention on CLS token...\n",
            " 77% 6381/8340 [1:37:13<27:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:50,443 >> Initializing global attention on CLS token...\n",
            " 77% 6382/8340 [1:37:14<27:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:51,286 >> Initializing global attention on CLS token...\n",
            " 77% 6383/8340 [1:37:15<27:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:52,126 >> Initializing global attention on CLS token...\n",
            " 77% 6384/8340 [1:37:15<27:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:52,971 >> Initializing global attention on CLS token...\n",
            " 77% 6385/8340 [1:37:16<27:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:53,809 >> Initializing global attention on CLS token...\n",
            " 77% 6386/8340 [1:37:17<27:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:54,652 >> Initializing global attention on CLS token...\n",
            " 77% 6387/8340 [1:37:18<27:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:55,500 >> Initializing global attention on CLS token...\n",
            " 77% 6388/8340 [1:37:19<27:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:56,340 >> Initializing global attention on CLS token...\n",
            " 77% 6389/8340 [1:37:20<27:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:57,180 >> Initializing global attention on CLS token...\n",
            " 77% 6390/8340 [1:37:20<27:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:58,024 >> Initializing global attention on CLS token...\n",
            " 77% 6391/8340 [1:37:21<27:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:58,869 >> Initializing global attention on CLS token...\n",
            " 77% 6392/8340 [1:37:22<27:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:01:59,708 >> Initializing global attention on CLS token...\n",
            " 77% 6393/8340 [1:37:23<27:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:00,550 >> Initializing global attention on CLS token...\n",
            " 77% 6394/8340 [1:37:24<27:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:01,387 >> Initializing global attention on CLS token...\n",
            " 77% 6395/8340 [1:37:25<27:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:02,229 >> Initializing global attention on CLS token...\n",
            " 77% 6396/8340 [1:37:26<27:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:03,073 >> Initializing global attention on CLS token...\n",
            " 77% 6397/8340 [1:37:26<27:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:03,915 >> Initializing global attention on CLS token...\n",
            " 77% 6398/8340 [1:37:27<27:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:04,755 >> Initializing global attention on CLS token...\n",
            " 77% 6399/8340 [1:37:28<27:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:05,599 >> Initializing global attention on CLS token...\n",
            " 77% 6400/8340 [1:37:29<27:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:06,440 >> Initializing global attention on CLS token...\n",
            " 77% 6401/8340 [1:37:30<27:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:07,280 >> Initializing global attention on CLS token...\n",
            " 77% 6402/8340 [1:37:31<27:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:08,124 >> Initializing global attention on CLS token...\n",
            " 77% 6403/8340 [1:37:31<27:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:08,965 >> Initializing global attention on CLS token...\n",
            " 77% 6404/8340 [1:37:32<27:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:09,805 >> Initializing global attention on CLS token...\n",
            " 77% 6405/8340 [1:37:33<27:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:10,651 >> Initializing global attention on CLS token...\n",
            " 77% 6406/8340 [1:37:34<27:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:11,490 >> Initializing global attention on CLS token...\n",
            " 77% 6407/8340 [1:37:35<27:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:12,336 >> Initializing global attention on CLS token...\n",
            " 77% 6408/8340 [1:37:36<27:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:13,179 >> Initializing global attention on CLS token...\n",
            " 77% 6409/8340 [1:37:36<27:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:14,023 >> Initializing global attention on CLS token...\n",
            " 77% 6410/8340 [1:37:37<27:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:14,866 >> Initializing global attention on CLS token...\n",
            " 77% 6411/8340 [1:37:38<27:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:15,715 >> Initializing global attention on CLS token...\n",
            " 77% 6412/8340 [1:37:39<27:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:16,559 >> Initializing global attention on CLS token...\n",
            " 77% 6413/8340 [1:37:40<27:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:17,398 >> Initializing global attention on CLS token...\n",
            " 77% 6414/8340 [1:37:41<27:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:18,237 >> Initializing global attention on CLS token...\n",
            " 77% 6415/8340 [1:37:42<27:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:19,081 >> Initializing global attention on CLS token...\n",
            " 77% 6416/8340 [1:37:42<27:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:19,932 >> Initializing global attention on CLS token...\n",
            " 77% 6417/8340 [1:37:43<27:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:20,771 >> Initializing global attention on CLS token...\n",
            " 77% 6418/8340 [1:37:44<27:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:21,615 >> Initializing global attention on CLS token...\n",
            " 77% 6419/8340 [1:37:45<26:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:22,455 >> Initializing global attention on CLS token...\n",
            " 77% 6420/8340 [1:37:46<26:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:23,294 >> Initializing global attention on CLS token...\n",
            " 77% 6421/8340 [1:37:47<26:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:24,136 >> Initializing global attention on CLS token...\n",
            " 77% 6422/8340 [1:37:47<26:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:24,984 >> Initializing global attention on CLS token...\n",
            " 77% 6423/8340 [1:37:48<26:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:25,828 >> Initializing global attention on CLS token...\n",
            " 77% 6424/8340 [1:37:49<26:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:26,668 >> Initializing global attention on CLS token...\n",
            " 77% 6425/8340 [1:37:50<26:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:27,512 >> Initializing global attention on CLS token...\n",
            " 77% 6426/8340 [1:37:51<26:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:28,355 >> Initializing global attention on CLS token...\n",
            " 77% 6427/8340 [1:37:52<26:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:29,199 >> Initializing global attention on CLS token...\n",
            " 77% 6428/8340 [1:37:53<26:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:30,041 >> Initializing global attention on CLS token...\n",
            " 77% 6429/8340 [1:37:53<26:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:30,881 >> Initializing global attention on CLS token...\n",
            " 77% 6430/8340 [1:37:54<26:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:31,725 >> Initializing global attention on CLS token...\n",
            " 77% 6431/8340 [1:37:55<26:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:32,572 >> Initializing global attention on CLS token...\n",
            " 77% 6432/8340 [1:37:56<26:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:33,415 >> Initializing global attention on CLS token...\n",
            " 77% 6433/8340 [1:37:57<26:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:34,257 >> Initializing global attention on CLS token...\n",
            " 77% 6434/8340 [1:37:58<26:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:35,101 >> Initializing global attention on CLS token...\n",
            " 77% 6435/8340 [1:37:58<26:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:35,940 >> Initializing global attention on CLS token...\n",
            " 77% 6436/8340 [1:37:59<26:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:36,780 >> Initializing global attention on CLS token...\n",
            " 77% 6437/8340 [1:38:00<26:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:37,619 >> Initializing global attention on CLS token...\n",
            " 77% 6438/8340 [1:38:01<26:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:38,464 >> Initializing global attention on CLS token...\n",
            " 77% 6439/8340 [1:38:02<26:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:39,303 >> Initializing global attention on CLS token...\n",
            " 77% 6440/8340 [1:38:03<26:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:40,141 >> Initializing global attention on CLS token...\n",
            " 77% 6441/8340 [1:38:03<26:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:40,984 >> Initializing global attention on CLS token...\n",
            " 77% 6442/8340 [1:38:04<26:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:41,825 >> Initializing global attention on CLS token...\n",
            " 77% 6443/8340 [1:38:05<26:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:42,669 >> Initializing global attention on CLS token...\n",
            " 77% 6444/8340 [1:38:06<26:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:43,510 >> Initializing global attention on CLS token...\n",
            " 77% 6445/8340 [1:38:07<26:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:44,353 >> Initializing global attention on CLS token...\n",
            " 77% 6446/8340 [1:38:08<26:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:45,197 >> Initializing global attention on CLS token...\n",
            " 77% 6447/8340 [1:38:08<26:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:46,037 >> Initializing global attention on CLS token...\n",
            " 77% 6448/8340 [1:38:09<26:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:46,880 >> Initializing global attention on CLS token...\n",
            " 77% 6449/8340 [1:38:10<26:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:47,715 >> Initializing global attention on CLS token...\n",
            " 77% 6450/8340 [1:38:11<26:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:48,557 >> Initializing global attention on CLS token...\n",
            " 77% 6451/8340 [1:38:12<26:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:49,395 >> Initializing global attention on CLS token...\n",
            " 77% 6452/8340 [1:38:13<26:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:50,233 >> Initializing global attention on CLS token...\n",
            " 77% 6453/8340 [1:38:14<26:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:51,087 >> Initializing global attention on CLS token...\n",
            " 77% 6454/8340 [1:38:14<26:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:51,931 >> Initializing global attention on CLS token...\n",
            " 77% 6455/8340 [1:38:15<26:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:52,774 >> Initializing global attention on CLS token...\n",
            " 77% 6456/8340 [1:38:16<26:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:53,617 >> Initializing global attention on CLS token...\n",
            " 77% 6457/8340 [1:38:17<26:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:54,462 >> Initializing global attention on CLS token...\n",
            " 77% 6458/8340 [1:38:18<26:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:55,303 >> Initializing global attention on CLS token...\n",
            " 77% 6459/8340 [1:38:19<26:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:56,144 >> Initializing global attention on CLS token...\n",
            " 77% 6460/8340 [1:38:19<26:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:56,996 >> Initializing global attention on CLS token...\n",
            " 77% 6461/8340 [1:38:20<26:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:57,841 >> Initializing global attention on CLS token...\n",
            " 77% 6462/8340 [1:38:21<26:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:58,685 >> Initializing global attention on CLS token...\n",
            " 77% 6463/8340 [1:38:22<26:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:02:59,536 >> Initializing global attention on CLS token...\n",
            " 78% 6464/8340 [1:38:23<26:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:00,376 >> Initializing global attention on CLS token...\n",
            " 78% 6465/8340 [1:38:24<26:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:01,217 >> Initializing global attention on CLS token...\n",
            " 78% 6466/8340 [1:38:25<26:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:02,060 >> Initializing global attention on CLS token...\n",
            " 78% 6467/8340 [1:38:25<26:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:02,903 >> Initializing global attention on CLS token...\n",
            " 78% 6468/8340 [1:38:26<26:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:03,747 >> Initializing global attention on CLS token...\n",
            " 78% 6469/8340 [1:38:27<26:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:04,610 >> Initializing global attention on CLS token...\n",
            " 78% 6470/8340 [1:38:28<26:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:05,466 >> Initializing global attention on CLS token...\n",
            " 78% 6471/8340 [1:38:29<26:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:06,317 >> Initializing global attention on CLS token...\n",
            " 78% 6472/8340 [1:38:30<26:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:07,159 >> Initializing global attention on CLS token...\n",
            " 78% 6473/8340 [1:38:30<26:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:08,000 >> Initializing global attention on CLS token...\n",
            " 78% 6474/8340 [1:38:31<26:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:08,845 >> Initializing global attention on CLS token...\n",
            " 78% 6475/8340 [1:38:32<26:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:09,683 >> Initializing global attention on CLS token...\n",
            " 78% 6476/8340 [1:38:33<26:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:10,524 >> Initializing global attention on CLS token...\n",
            " 78% 6477/8340 [1:38:34<26:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:11,364 >> Initializing global attention on CLS token...\n",
            " 78% 6478/8340 [1:38:35<26:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:12,208 >> Initializing global attention on CLS token...\n",
            " 78% 6479/8340 [1:38:36<26:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:13,052 >> Initializing global attention on CLS token...\n",
            " 78% 6480/8340 [1:38:36<26:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:13,895 >> Initializing global attention on CLS token...\n",
            " 78% 6481/8340 [1:38:37<26:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:14,738 >> Initializing global attention on CLS token...\n",
            " 78% 6482/8340 [1:38:38<26:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:15,579 >> Initializing global attention on CLS token...\n",
            " 78% 6483/8340 [1:38:39<26:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:16,428 >> Initializing global attention on CLS token...\n",
            " 78% 6484/8340 [1:38:40<26:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:17,268 >> Initializing global attention on CLS token...\n",
            " 78% 6485/8340 [1:38:41<26:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:18,112 >> Initializing global attention on CLS token...\n",
            " 78% 6486/8340 [1:38:41<26:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:18,952 >> Initializing global attention on CLS token...\n",
            " 78% 6487/8340 [1:38:42<26:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:19,797 >> Initializing global attention on CLS token...\n",
            " 78% 6488/8340 [1:38:43<26:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:20,638 >> Initializing global attention on CLS token...\n",
            " 78% 6489/8340 [1:38:44<26:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:21,481 >> Initializing global attention on CLS token...\n",
            " 78% 6490/8340 [1:38:45<25:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:22,330 >> Initializing global attention on CLS token...\n",
            " 78% 6491/8340 [1:38:46<26:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:23,171 >> Initializing global attention on CLS token...\n",
            " 78% 6492/8340 [1:38:46<25:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:24,015 >> Initializing global attention on CLS token...\n",
            " 78% 6493/8340 [1:38:47<25:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:24,859 >> Initializing global attention on CLS token...\n",
            " 78% 6494/8340 [1:38:48<25:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:25,699 >> Initializing global attention on CLS token...\n",
            " 78% 6495/8340 [1:38:49<25:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:26,536 >> Initializing global attention on CLS token...\n",
            " 78% 6496/8340 [1:38:50<25:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:27,379 >> Initializing global attention on CLS token...\n",
            " 78% 6497/8340 [1:38:51<25:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:28,222 >> Initializing global attention on CLS token...\n",
            " 78% 6498/8340 [1:38:52<25:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:29,069 >> Initializing global attention on CLS token...\n",
            " 78% 6499/8340 [1:38:52<25:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:29,917 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0634, 'learning_rate': 6.636690647482015e-06, 'epoch': 7.79}\n",
            " 78% 6500/8340 [1:38:53<27:23,  1.12it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:30,923 >> Initializing global attention on CLS token...\n",
            " 78% 6501/8340 [1:38:54<26:57,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:31,774 >> Initializing global attention on CLS token...\n",
            " 78% 6502/8340 [1:38:55<26:37,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:32,618 >> Initializing global attention on CLS token...\n",
            " 78% 6503/8340 [1:38:56<26:26,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:33,465 >> Initializing global attention on CLS token...\n",
            " 78% 6504/8340 [1:38:57<26:15,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:34,312 >> Initializing global attention on CLS token...\n",
            " 78% 6505/8340 [1:38:58<26:06,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:35,153 >> Initializing global attention on CLS token...\n",
            " 78% 6506/8340 [1:38:58<26:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:35,998 >> Initializing global attention on CLS token...\n",
            " 78% 6507/8340 [1:38:59<25:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:36,847 >> Initializing global attention on CLS token...\n",
            " 78% 6508/8340 [1:39:00<25:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:37,688 >> Initializing global attention on CLS token...\n",
            " 78% 6509/8340 [1:39:01<25:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:38,529 >> Initializing global attention on CLS token...\n",
            " 78% 6510/8340 [1:39:02<25:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:39,375 >> Initializing global attention on CLS token...\n",
            " 78% 6511/8340 [1:39:03<25:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:40,213 >> Initializing global attention on CLS token...\n",
            " 78% 6512/8340 [1:39:04<25:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:41,055 >> Initializing global attention on CLS token...\n",
            " 78% 6513/8340 [1:39:04<25:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:41,896 >> Initializing global attention on CLS token...\n",
            " 78% 6514/8340 [1:39:05<25:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:42,743 >> Initializing global attention on CLS token...\n",
            " 78% 6515/8340 [1:39:06<25:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:43,588 >> Initializing global attention on CLS token...\n",
            " 78% 6516/8340 [1:39:07<25:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:44,426 >> Initializing global attention on CLS token...\n",
            " 78% 6517/8340 [1:39:08<25:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:45,269 >> Initializing global attention on CLS token...\n",
            " 78% 6518/8340 [1:39:09<25:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:46,108 >> Initializing global attention on CLS token...\n",
            " 78% 6519/8340 [1:39:09<25:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:46,948 >> Initializing global attention on CLS token...\n",
            " 78% 6520/8340 [1:39:10<25:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:47,792 >> Initializing global attention on CLS token...\n",
            " 78% 6521/8340 [1:39:11<25:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:48,635 >> Initializing global attention on CLS token...\n",
            " 78% 6522/8340 [1:39:12<25:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:49,475 >> Initializing global attention on CLS token...\n",
            " 78% 6523/8340 [1:39:13<25:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:50,318 >> Initializing global attention on CLS token...\n",
            " 78% 6524/8340 [1:39:14<25:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:51,158 >> Initializing global attention on CLS token...\n",
            " 78% 6525/8340 [1:39:14<25:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:51,997 >> Initializing global attention on CLS token...\n",
            " 78% 6526/8340 [1:39:15<25:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:52,840 >> Initializing global attention on CLS token...\n",
            " 78% 6527/8340 [1:39:16<25:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:53,690 >> Initializing global attention on CLS token...\n",
            " 78% 6528/8340 [1:39:17<25:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:54,532 >> Initializing global attention on CLS token...\n",
            " 78% 6529/8340 [1:39:18<25:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:55,375 >> Initializing global attention on CLS token...\n",
            " 78% 6530/8340 [1:39:19<25:28,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:56,220 >> Initializing global attention on CLS token...\n",
            " 78% 6531/8340 [1:39:20<25:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:57,062 >> Initializing global attention on CLS token...\n",
            " 78% 6532/8340 [1:39:20<25:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:57,902 >> Initializing global attention on CLS token...\n",
            " 78% 6533/8340 [1:39:21<25:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:58,743 >> Initializing global attention on CLS token...\n",
            " 78% 6534/8340 [1:39:22<25:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:03:59,582 >> Initializing global attention on CLS token...\n",
            " 78% 6535/8340 [1:39:23<25:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:00,426 >> Initializing global attention on CLS token...\n",
            " 78% 6536/8340 [1:39:24<25:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:01,268 >> Initializing global attention on CLS token...\n",
            " 78% 6537/8340 [1:39:25<25:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:02,114 >> Initializing global attention on CLS token...\n",
            " 78% 6538/8340 [1:39:25<25:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:02,956 >> Initializing global attention on CLS token...\n",
            " 78% 6539/8340 [1:39:26<25:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:03,802 >> Initializing global attention on CLS token...\n",
            " 78% 6540/8340 [1:39:27<25:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:04,650 >> Initializing global attention on CLS token...\n",
            " 78% 6541/8340 [1:39:28<25:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:05,500 >> Initializing global attention on CLS token...\n",
            " 78% 6542/8340 [1:39:29<25:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:06,348 >> Initializing global attention on CLS token...\n",
            " 78% 6543/8340 [1:39:30<25:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:07,198 >> Initializing global attention on CLS token...\n",
            " 78% 6544/8340 [1:39:30<25:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:08,039 >> Initializing global attention on CLS token...\n",
            " 78% 6545/8340 [1:39:31<25:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:08,877 >> Initializing global attention on CLS token...\n",
            " 78% 6546/8340 [1:39:32<25:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:09,717 >> Initializing global attention on CLS token...\n",
            " 79% 6547/8340 [1:39:33<25:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:10,561 >> Initializing global attention on CLS token...\n",
            " 79% 6548/8340 [1:39:34<25:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:11,401 >> Initializing global attention on CLS token...\n",
            " 79% 6549/8340 [1:39:35<25:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:12,241 >> Initializing global attention on CLS token...\n",
            " 79% 6550/8340 [1:39:36<25:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:13,081 >> Initializing global attention on CLS token...\n",
            " 79% 6551/8340 [1:39:36<25:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:13,924 >> Initializing global attention on CLS token...\n",
            " 79% 6552/8340 [1:39:37<25:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:14,766 >> Initializing global attention on CLS token...\n",
            " 79% 6553/8340 [1:39:38<25:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:15,606 >> Initializing global attention on CLS token...\n",
            " 79% 6554/8340 [1:39:39<25:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:16,451 >> Initializing global attention on CLS token...\n",
            " 79% 6555/8340 [1:39:40<25:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:17,293 >> Initializing global attention on CLS token...\n",
            " 79% 6556/8340 [1:39:41<25:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:18,135 >> Initializing global attention on CLS token...\n",
            " 79% 6557/8340 [1:39:41<25:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:18,981 >> Initializing global attention on CLS token...\n",
            " 79% 6558/8340 [1:39:42<25:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:19,819 >> Initializing global attention on CLS token...\n",
            " 79% 6559/8340 [1:39:43<24:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:20,660 >> Initializing global attention on CLS token...\n",
            " 79% 6560/8340 [1:39:44<25:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:21,507 >> Initializing global attention on CLS token...\n",
            " 79% 6561/8340 [1:39:45<25:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:22,350 >> Initializing global attention on CLS token...\n",
            " 79% 6562/8340 [1:39:46<24:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:23,190 >> Initializing global attention on CLS token...\n",
            " 79% 6563/8340 [1:39:46<24:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:24,034 >> Initializing global attention on CLS token...\n",
            " 79% 6564/8340 [1:39:47<24:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:24,877 >> Initializing global attention on CLS token...\n",
            " 79% 6565/8340 [1:39:48<24:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:25,720 >> Initializing global attention on CLS token...\n",
            " 79% 6566/8340 [1:39:49<24:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:26,559 >> Initializing global attention on CLS token...\n",
            " 79% 6567/8340 [1:39:50<24:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:27,399 >> Initializing global attention on CLS token...\n",
            " 79% 6568/8340 [1:39:51<24:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:28,240 >> Initializing global attention on CLS token...\n",
            " 79% 6569/8340 [1:39:52<24:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:29,086 >> Initializing global attention on CLS token...\n",
            " 79% 6570/8340 [1:39:52<24:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:29,934 >> Initializing global attention on CLS token...\n",
            " 79% 6571/8340 [1:39:53<24:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:30,777 >> Initializing global attention on CLS token...\n",
            " 79% 6572/8340 [1:39:54<24:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:31,619 >> Initializing global attention on CLS token...\n",
            " 79% 6573/8340 [1:39:55<24:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:32,459 >> Initializing global attention on CLS token...\n",
            " 79% 6574/8340 [1:39:56<24:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:33,305 >> Initializing global attention on CLS token...\n",
            " 79% 6575/8340 [1:39:57<24:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:34,144 >> Initializing global attention on CLS token...\n",
            " 79% 6576/8340 [1:39:57<24:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:34,989 >> Initializing global attention on CLS token...\n",
            " 79% 6577/8340 [1:39:58<24:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:35,830 >> Initializing global attention on CLS token...\n",
            " 79% 6578/8340 [1:39:59<24:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:36,675 >> Initializing global attention on CLS token...\n",
            " 79% 6579/8340 [1:40:00<24:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:37,518 >> Initializing global attention on CLS token...\n",
            " 79% 6580/8340 [1:40:01<24:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:38,361 >> Initializing global attention on CLS token...\n",
            " 79% 6581/8340 [1:40:02<24:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:39,202 >> Initializing global attention on CLS token...\n",
            " 79% 6582/8340 [1:40:02<24:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:40,041 >> Initializing global attention on CLS token...\n",
            " 79% 6583/8340 [1:40:03<24:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:40,884 >> Initializing global attention on CLS token...\n",
            " 79% 6584/8340 [1:40:04<24:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:41,725 >> Initializing global attention on CLS token...\n",
            " 79% 6585/8340 [1:40:05<24:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:42,565 >> Initializing global attention on CLS token...\n",
            " 79% 6586/8340 [1:40:06<24:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:43,408 >> Initializing global attention on CLS token...\n",
            " 79% 6587/8340 [1:40:07<24:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:44,249 >> Initializing global attention on CLS token...\n",
            " 79% 6588/8340 [1:40:08<24:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:45,091 >> Initializing global attention on CLS token...\n",
            " 79% 6589/8340 [1:40:08<24:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:45,936 >> Initializing global attention on CLS token...\n",
            " 79% 6590/8340 [1:40:09<24:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:46,773 >> Initializing global attention on CLS token...\n",
            " 79% 6591/8340 [1:40:10<24:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:47,616 >> Initializing global attention on CLS token...\n",
            " 79% 6592/8340 [1:40:11<24:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:48,461 >> Initializing global attention on CLS token...\n",
            " 79% 6593/8340 [1:40:12<24:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:49,304 >> Initializing global attention on CLS token...\n",
            " 79% 6594/8340 [1:40:13<24:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:50,150 >> Initializing global attention on CLS token...\n",
            " 79% 6595/8340 [1:40:13<24:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:51,000 >> Initializing global attention on CLS token...\n",
            " 79% 6596/8340 [1:40:14<24:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:51,852 >> Initializing global attention on CLS token...\n",
            " 79% 6597/8340 [1:40:15<24:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:52,694 >> Initializing global attention on CLS token...\n",
            " 79% 6598/8340 [1:40:16<24:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:53,538 >> Initializing global attention on CLS token...\n",
            " 79% 6599/8340 [1:40:17<24:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:54,383 >> Initializing global attention on CLS token...\n",
            " 79% 6600/8340 [1:40:18<24:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:55,229 >> Initializing global attention on CLS token...\n",
            " 79% 6601/8340 [1:40:19<24:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:56,067 >> Initializing global attention on CLS token...\n",
            " 79% 6602/8340 [1:40:19<24:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:56,912 >> Initializing global attention on CLS token...\n",
            " 79% 6603/8340 [1:40:20<24:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:57,752 >> Initializing global attention on CLS token...\n",
            " 79% 6604/8340 [1:40:21<24:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:58,594 >> Initializing global attention on CLS token...\n",
            " 79% 6605/8340 [1:40:22<24:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:04:59,438 >> Initializing global attention on CLS token...\n",
            " 79% 6606/8340 [1:40:23<24:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:00,282 >> Initializing global attention on CLS token...\n",
            " 79% 6607/8340 [1:40:24<24:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:01,119 >> Initializing global attention on CLS token...\n",
            " 79% 6608/8340 [1:40:24<24:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:01,960 >> Initializing global attention on CLS token...\n",
            " 79% 6609/8340 [1:40:25<24:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:02,810 >> Initializing global attention on CLS token...\n",
            " 79% 6610/8340 [1:40:26<24:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:03,648 >> Initializing global attention on CLS token...\n",
            " 79% 6611/8340 [1:40:27<24:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:04,486 >> Initializing global attention on CLS token...\n",
            " 79% 6612/8340 [1:40:28<24:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:05,330 >> Initializing global attention on CLS token...\n",
            " 79% 6613/8340 [1:40:29<24:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:06,174 >> Initializing global attention on CLS token...\n",
            " 79% 6614/8340 [1:40:29<24:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:07,018 >> Initializing global attention on CLS token...\n",
            " 79% 6615/8340 [1:40:30<24:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:07,858 >> Initializing global attention on CLS token...\n",
            " 79% 6616/8340 [1:40:31<24:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:08,704 >> Initializing global attention on CLS token...\n",
            " 79% 6617/8340 [1:40:32<24:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:09,547 >> Initializing global attention on CLS token...\n",
            " 79% 6618/8340 [1:40:33<24:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:10,383 >> Initializing global attention on CLS token...\n",
            " 79% 6619/8340 [1:40:34<24:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:11,229 >> Initializing global attention on CLS token...\n",
            " 79% 6620/8340 [1:40:35<24:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:12,079 >> Initializing global attention on CLS token...\n",
            " 79% 6621/8340 [1:40:35<24:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:12,921 >> Initializing global attention on CLS token...\n",
            " 79% 6622/8340 [1:40:36<24:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:13,767 >> Initializing global attention on CLS token...\n",
            " 79% 6623/8340 [1:40:37<24:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:14,611 >> Initializing global attention on CLS token...\n",
            " 79% 6624/8340 [1:40:38<24:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:15,456 >> Initializing global attention on CLS token...\n",
            " 79% 6625/8340 [1:40:39<24:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:16,298 >> Initializing global attention on CLS token...\n",
            " 79% 6626/8340 [1:40:40<24:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:17,138 >> Initializing global attention on CLS token...\n",
            " 79% 6627/8340 [1:40:40<24:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:17,982 >> Initializing global attention on CLS token...\n",
            " 79% 6628/8340 [1:40:41<24:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:18,829 >> Initializing global attention on CLS token...\n",
            " 79% 6629/8340 [1:40:42<24:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:19,675 >> Initializing global attention on CLS token...\n",
            " 79% 6630/8340 [1:40:43<24:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:20,517 >> Initializing global attention on CLS token...\n",
            " 80% 6631/8340 [1:40:44<24:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:21,356 >> Initializing global attention on CLS token...\n",
            " 80% 6632/8340 [1:40:45<24:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:22,207 >> Initializing global attention on CLS token...\n",
            " 80% 6633/8340 [1:40:46<23:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:23,048 >> Initializing global attention on CLS token...\n",
            " 80% 6634/8340 [1:40:46<24:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:23,893 >> Initializing global attention on CLS token...\n",
            " 80% 6635/8340 [1:40:47<24:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:24,741 >> Initializing global attention on CLS token...\n",
            " 80% 6636/8340 [1:40:48<24:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:25,587 >> Initializing global attention on CLS token...\n",
            " 80% 6637/8340 [1:40:49<24:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:26,431 >> Initializing global attention on CLS token...\n",
            " 80% 6638/8340 [1:40:50<23:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:27,274 >> Initializing global attention on CLS token...\n",
            " 80% 6639/8340 [1:40:51<23:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:28,116 >> Initializing global attention on CLS token...\n",
            " 80% 6640/8340 [1:40:51<23:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:28,961 >> Initializing global attention on CLS token...\n",
            " 80% 6641/8340 [1:40:52<23:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:29,801 >> Initializing global attention on CLS token...\n",
            " 80% 6642/8340 [1:40:53<23:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:30,643 >> Initializing global attention on CLS token...\n",
            " 80% 6643/8340 [1:40:54<23:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:31,491 >> Initializing global attention on CLS token...\n",
            " 80% 6644/8340 [1:40:55<23:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:32,335 >> Initializing global attention on CLS token...\n",
            " 80% 6645/8340 [1:40:56<23:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:33,182 >> Initializing global attention on CLS token...\n",
            " 80% 6646/8340 [1:40:56<23:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:34,031 >> Initializing global attention on CLS token...\n",
            " 80% 6647/8340 [1:40:57<23:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:34,874 >> Initializing global attention on CLS token...\n",
            " 80% 6648/8340 [1:40:58<23:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:35,721 >> Initializing global attention on CLS token...\n",
            " 80% 6649/8340 [1:40:59<23:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:36,561 >> Initializing global attention on CLS token...\n",
            " 80% 6650/8340 [1:41:00<23:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:37,409 >> Initializing global attention on CLS token...\n",
            " 80% 6651/8340 [1:41:01<23:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:38,250 >> Initializing global attention on CLS token...\n",
            " 80% 6652/8340 [1:41:02<23:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:39,093 >> Initializing global attention on CLS token...\n",
            " 80% 6653/8340 [1:41:02<23:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:39,930 >> Initializing global attention on CLS token...\n",
            " 80% 6654/8340 [1:41:03<23:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:40,773 >> Initializing global attention on CLS token...\n",
            " 80% 6655/8340 [1:41:04<23:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:41,614 >> Initializing global attention on CLS token...\n",
            " 80% 6656/8340 [1:41:05<23:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:42,458 >> Initializing global attention on CLS token...\n",
            " 80% 6657/8340 [1:41:06<23:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:43,298 >> Initializing global attention on CLS token...\n",
            " 80% 6658/8340 [1:41:07<23:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:44,141 >> Initializing global attention on CLS token...\n",
            " 80% 6659/8340 [1:41:07<23:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:44,982 >> Initializing global attention on CLS token...\n",
            " 80% 6660/8340 [1:41:08<23:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:45,824 >> Initializing global attention on CLS token...\n",
            " 80% 6661/8340 [1:41:09<23:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:46,670 >> Initializing global attention on CLS token...\n",
            " 80% 6662/8340 [1:41:10<23:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:47,517 >> Initializing global attention on CLS token...\n",
            " 80% 6663/8340 [1:41:11<23:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:48,355 >> Initializing global attention on CLS token...\n",
            " 80% 6664/8340 [1:41:12<23:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:49,202 >> Initializing global attention on CLS token...\n",
            " 80% 6665/8340 [1:41:13<23:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:50,045 >> Initializing global attention on CLS token...\n",
            " 80% 6666/8340 [1:41:13<23:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:50,889 >> Initializing global attention on CLS token...\n",
            " 80% 6667/8340 [1:41:14<23:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:51,727 >> Initializing global attention on CLS token...\n",
            " 80% 6668/8340 [1:41:15<23:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:52,569 >> Initializing global attention on CLS token...\n",
            " 80% 6669/8340 [1:41:16<23:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:53,409 >> Initializing global attention on CLS token...\n",
            " 80% 6670/8340 [1:41:17<23:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:54,253 >> Initializing global attention on CLS token...\n",
            " 80% 6671/8340 [1:41:18<23:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:05:55,080 >> Initializing global attention on CLS token...\n",
            " 80% 6672/8340 [1:41:18<19:03,  1.46it/s][INFO|trainer.py:725] 2022-12-10 00:05:55,385 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 00:05:55,387 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 00:05:55,388 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 00:05:55,388 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:55,418 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:55,676 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:29,  7.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:55,928 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:41,  5.52it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:56,189 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:48,  4.74it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:56,451 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:52,  4.39it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:56,707 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:54,  4.22it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:56,960 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:54,  4.13it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:57,213 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:55,  4.07it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:57,468 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:55,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:57,722 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:55,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:57,977 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:56,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:58,229 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:55,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:58,483 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:55,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:58,740 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:55,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:58,998 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:55,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:59,261 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:56,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:59,519 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:55,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:05:59,773 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:55,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:00,027 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:55,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:00,290 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:55,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:00,546 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:54,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:00,800 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:54,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:01,054 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:53,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:01,312 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:53,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:01,574 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:53,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:01,831 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:53,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:02,091 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:53,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:02,344 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:52,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:02,603 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:52,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:02,855 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:52,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:03,110 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:51,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:03,361 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:51,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:03,640 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:52,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:03,893 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:51,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:04,152 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:51,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:04,405 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:50,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:04,663 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:50,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:04,921 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:50,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:05,173 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:49,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:05,434 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:10<00:50,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:05,690 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:49,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:05,945 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:49,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:06,199 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:48,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:06,460 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:11<00:48,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:06,715 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:48,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:06,973 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:48,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:07,232 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:48,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:07,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:12<00:48,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:07,745 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:47,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:08,000 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:47,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:08,255 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:46,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:08,511 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:46,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:08,771 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:46,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:09,026 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:46,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:09,278 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:45,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:09,534 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:45,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:09,788 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:10,044 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:44,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:10,297 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:44,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:10,562 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:44,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:10,818 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:11,072 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:11,324 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:11,592 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:11,843 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:43,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:12,098 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:42,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:12,353 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:42,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:12,604 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:42,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:12,856 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:42,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:13,116 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:42,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:13,373 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:41,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:13,631 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:41,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:13,886 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:41,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:14,141 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:40,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:14,400 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:40,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:14,654 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:40,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:14,909 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:40,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:15,163 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:39,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:15,419 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:20<00:39,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:15,673 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:39,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:15,925 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:38,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:16,178 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:38,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:16,437 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:21<00:38,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:16,695 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:16,951 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:38,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:17,204 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:37,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:17,462 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:22<00:37,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:17,726 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:17,981 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:37,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:18,234 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:36,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:18,486 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:23<00:36,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:18,742 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:18,994 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:35,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:19,256 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:35,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:19,510 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:35,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:19,774 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:20,031 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:35,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:20,290 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:35,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:20,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:20,802 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:21,058 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:34,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:21,311 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:33,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:21,597 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:34,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:21,860 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:34,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:22,113 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:33,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:22,368 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:33,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:22,627 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:33,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:22,894 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:32,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:23,151 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:32,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:23,411 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:32,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:23,671 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:32,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:23,926 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:31,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:24,190 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:31,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:24,454 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:29<00:31,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:24,708 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:30,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:24,968 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:29<00:30,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:25,228 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:30,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:25,483 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:30<00:29,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:25,735 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:29,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:25,991 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:30<00:29,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:26,247 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:28,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:26,510 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:31<00:28,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:26,764 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:28,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:27,035 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:31<00:28,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:27,291 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:31<00:28,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:27,546 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:32<00:27,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:27,808 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:28,062 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:32<00:27,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:28,320 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:32<00:27,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:28,574 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:33<00:26,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:28,832 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:26,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:29,085 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:33<00:26,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:29,348 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:33<00:26,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:29,602 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:34<00:25,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:29,872 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:30,141 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:34<00:25,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:30,396 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:34<00:25,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:30,647 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:35<00:24,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:30,903 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:35<00:24,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:31,160 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:35<00:24,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:31,413 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:35<00:23,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:31,678 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:36<00:23,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:31,936 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:36<00:23,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:32,194 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:36<00:23,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:32,455 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:37<00:23,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:32,710 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:32,969 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:37<00:22,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:33,222 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:37<00:22,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:33,476 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:38<00:21,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:33,731 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:33,990 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:38<00:21,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:34,247 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:38<00:21,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:34,504 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:39<00:20,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:34,768 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:20,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:35,033 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:39<00:20,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:35,289 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:39<00:20,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:35,543 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:40<00:19,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:35,795 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:19,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:36,054 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:40<00:19,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:36,310 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:40<00:19,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:36,569 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:41<00:18,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:36,824 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:37,080 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:41<00:18,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:37,336 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:41<00:17,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:37,599 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:42<00:17,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:37,850 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:38,108 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:42<00:17,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:38,360 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:42<00:16,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:38,629 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:43<00:16,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:38,888 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:43<00:16,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:39,144 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:43<00:16,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:39,406 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:43<00:16,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:39,659 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:44<00:15,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:39,913 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:44<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:40,169 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:44<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:40,423 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:45<00:14,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:40,676 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:45<00:14,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:40,937 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:45<00:14,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:41,193 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:45<00:14,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:41,448 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:46<00:13,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:41,702 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:46<00:13,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:41,958 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:46<00:13,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:42,216 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:46<00:13,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:42,472 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:47<00:12,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:42,727 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:47<00:12,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:42,985 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:47<00:12,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:43,238 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:47<00:12,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:43,495 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:48<00:11,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:43,752 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:48<00:11,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:44,007 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:48<00:11,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:44,262 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:48<00:10,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:44,514 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:49<00:10,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:44,778 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:49<00:10,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:45,034 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:49<00:10,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:45,291 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:49<00:10,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:45,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:50<00:09,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:45,803 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:50<00:09,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:46,061 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:50<00:09,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:46,317 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:50<00:08,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:46,591 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:51<00:08,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:46,843 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:51<00:08,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:47,098 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:51<00:08,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:47,355 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:51<00:07,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:47,609 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:52<00:07,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:47,873 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:52<00:07,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:48,129 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:52<00:07,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:48,383 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:52<00:06,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:48,636 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:53<00:06,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:48,889 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:53<00:06,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:49,139 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:53<00:06,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:49,394 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:53<00:05,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:49,650 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:54<00:05,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:49,903 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:54<00:05,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:50,159 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:54<00:05,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:50,425 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:55<00:04,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:50,687 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:55<00:04,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:50,948 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:55<00:04,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:51,224 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:55<00:04,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:51,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:56<00:03,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:51,746 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:56<00:03,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:52,002 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:56<00:03,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:52,259 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:56<00:03,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:52,520 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:57<00:02,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:52,778 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:57<00:02,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:53,039 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:57<00:02,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:53,294 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:57<00:02,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:53,560 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:58<00:01,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:53,829 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:58<00:01,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:54,085 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:58<00:01,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:54,343 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:58<00:01,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:54,600 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:59<00:00,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:54,870 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:59<00:00,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:55,125 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:59<00:00,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:55,371 >> Initializing global attention on CLS token...\n",
            "\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.5420656204223633, 'eval_f1-micro': 0.78, 'eval_f1-macro': 0.6958588432168603, 'eval_runtime': 60.3475, 'eval_samples_per_second': 23.199, 'eval_steps_per_second': 3.878, 'epoch': 8.0}\n",
            " 80% 6672/8340 [1:42:18<19:03,  1.46it/s]\n",
            "100% 234/234 [01:00<00:00,  4.70it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-10 00:06:55,737 >> Saving model checkpoint to logs/output_1/checkpoint-6672\n",
            "[INFO|configuration_utils.py:447] 2022-12-10 00:06:55,739 >> Configuration saved in logs/output_1/checkpoint-6672/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-10 00:06:56,136 >> Model weights saved in logs/output_1/checkpoint-6672/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-10 00:06:56,137 >> tokenizer config file saved in logs/output_1/checkpoint-6672/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-10 00:06:56,138 >> Special tokens file saved in logs/output_1/checkpoint-6672/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 00:06:57,038 >> Initializing global attention on CLS token...\n",
            " 80% 6673/8340 [1:42:20<8:54:01, 19.22s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:06:57,887 >> Initializing global attention on CLS token...\n",
            " 80% 6674/8340 [1:42:21<6:20:34, 13.71s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:06:58,725 >> Initializing global attention on CLS token...\n",
            " 80% 6675/8340 [1:42:22<4:33:16,  9.85s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:06:59,575 >> Initializing global attention on CLS token...\n",
            " 80% 6676/8340 [1:42:23<3:18:12,  7.15s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:00,416 >> Initializing global attention on CLS token...\n",
            " 80% 6677/8340 [1:42:24<2:25:43,  5.26s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:01,265 >> Initializing global attention on CLS token...\n",
            " 80% 6678/8340 [1:42:25<1:48:57,  3.93s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:02,109 >> Initializing global attention on CLS token...\n",
            " 80% 6679/8340 [1:42:25<1:23:16,  3.01s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:02,957 >> Initializing global attention on CLS token...\n",
            " 80% 6680/8340 [1:42:26<1:05:14,  2.36s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:03,799 >> Initializing global attention on CLS token...\n",
            " 80% 6681/8340 [1:42:27<52:37,  1.90s/it]  [INFO|modeling_longformer.py:1932] 2022-12-10 00:07:04,648 >> Initializing global attention on CLS token...\n",
            " 80% 6682/8340 [1:42:28<43:52,  1.59s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:05,500 >> Initializing global attention on CLS token...\n",
            " 80% 6683/8340 [1:42:29<37:44,  1.37s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:06,347 >> Initializing global attention on CLS token...\n",
            " 80% 6684/8340 [1:42:30<33:24,  1.21s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:07,199 >> Initializing global attention on CLS token...\n",
            " 80% 6685/8340 [1:42:30<30:23,  1.10s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:08,038 >> Initializing global attention on CLS token...\n",
            " 80% 6686/8340 [1:42:31<28:11,  1.02s/it][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:08,875 >> Initializing global attention on CLS token...\n",
            " 80% 6687/8340 [1:42:32<26:41,  1.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:09,720 >> Initializing global attention on CLS token...\n",
            " 80% 6688/8340 [1:42:33<25:37,  1.07it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:10,562 >> Initializing global attention on CLS token...\n",
            " 80% 6689/8340 [1:42:34<24:53,  1.11it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:11,405 >> Initializing global attention on CLS token...\n",
            " 80% 6690/8340 [1:42:35<24:21,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:12,247 >> Initializing global attention on CLS token...\n",
            " 80% 6691/8340 [1:42:36<23:58,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:13,087 >> Initializing global attention on CLS token...\n",
            " 80% 6692/8340 [1:42:36<23:44,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:13,935 >> Initializing global attention on CLS token...\n",
            " 80% 6693/8340 [1:42:37<23:32,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:14,777 >> Initializing global attention on CLS token...\n",
            " 80% 6694/8340 [1:42:38<23:24,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:15,622 >> Initializing global attention on CLS token...\n",
            " 80% 6695/8340 [1:42:39<23:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:16,461 >> Initializing global attention on CLS token...\n",
            " 80% 6696/8340 [1:42:40<23:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:17,307 >> Initializing global attention on CLS token...\n",
            " 80% 6697/8340 [1:42:41<23:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:18,148 >> Initializing global attention on CLS token...\n",
            " 80% 6698/8340 [1:42:41<23:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:19,000 >> Initializing global attention on CLS token...\n",
            " 80% 6699/8340 [1:42:42<23:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:19,848 >> Initializing global attention on CLS token...\n",
            " 80% 6700/8340 [1:42:43<23:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:20,690 >> Initializing global attention on CLS token...\n",
            " 80% 6701/8340 [1:42:44<23:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:21,535 >> Initializing global attention on CLS token...\n",
            " 80% 6702/8340 [1:42:45<23:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:22,379 >> Initializing global attention on CLS token...\n",
            " 80% 6703/8340 [1:42:46<23:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:23,229 >> Initializing global attention on CLS token...\n",
            " 80% 6704/8340 [1:42:47<23:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:24,075 >> Initializing global attention on CLS token...\n",
            " 80% 6705/8340 [1:42:47<23:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:24,921 >> Initializing global attention on CLS token...\n",
            " 80% 6706/8340 [1:42:48<23:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:25,764 >> Initializing global attention on CLS token...\n",
            " 80% 6707/8340 [1:42:49<22:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:26,606 >> Initializing global attention on CLS token...\n",
            " 80% 6708/8340 [1:42:50<22:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:27,452 >> Initializing global attention on CLS token...\n",
            " 80% 6709/8340 [1:42:51<22:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:28,294 >> Initializing global attention on CLS token...\n",
            " 80% 6710/8340 [1:42:52<22:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:29,141 >> Initializing global attention on CLS token...\n",
            " 80% 6711/8340 [1:42:52<22:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:29,982 >> Initializing global attention on CLS token...\n",
            " 80% 6712/8340 [1:42:53<22:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:30,823 >> Initializing global attention on CLS token...\n",
            " 80% 6713/8340 [1:42:54<22:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:31,665 >> Initializing global attention on CLS token...\n",
            " 81% 6714/8340 [1:42:55<22:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:32,505 >> Initializing global attention on CLS token...\n",
            " 81% 6715/8340 [1:42:56<22:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:33,358 >> Initializing global attention on CLS token...\n",
            " 81% 6716/8340 [1:42:57<22:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:34,203 >> Initializing global attention on CLS token...\n",
            " 81% 6717/8340 [1:42:58<22:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:35,051 >> Initializing global attention on CLS token...\n",
            " 81% 6718/8340 [1:42:58<22:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:35,902 >> Initializing global attention on CLS token...\n",
            " 81% 6719/8340 [1:42:59<22:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:36,747 >> Initializing global attention on CLS token...\n",
            " 81% 6720/8340 [1:43:00<22:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:37,590 >> Initializing global attention on CLS token...\n",
            " 81% 6721/8340 [1:43:01<22:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:38,428 >> Initializing global attention on CLS token...\n",
            " 81% 6722/8340 [1:43:02<22:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:39,277 >> Initializing global attention on CLS token...\n",
            " 81% 6723/8340 [1:43:03<22:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:40,120 >> Initializing global attention on CLS token...\n",
            " 81% 6724/8340 [1:43:03<22:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:40,965 >> Initializing global attention on CLS token...\n",
            " 81% 6725/8340 [1:43:04<22:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:41,812 >> Initializing global attention on CLS token...\n",
            " 81% 6726/8340 [1:43:05<22:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:42,651 >> Initializing global attention on CLS token...\n",
            " 81% 6727/8340 [1:43:06<22:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:43,498 >> Initializing global attention on CLS token...\n",
            " 81% 6728/8340 [1:43:07<22:41,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:44,349 >> Initializing global attention on CLS token...\n",
            " 81% 6729/8340 [1:43:08<22:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:45,196 >> Initializing global attention on CLS token...\n",
            " 81% 6730/8340 [1:43:08<22:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:46,035 >> Initializing global attention on CLS token...\n",
            " 81% 6731/8340 [1:43:09<22:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:46,882 >> Initializing global attention on CLS token...\n",
            " 81% 6732/8340 [1:43:10<22:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:47,727 >> Initializing global attention on CLS token...\n",
            " 81% 6733/8340 [1:43:11<22:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:48,576 >> Initializing global attention on CLS token...\n",
            " 81% 6734/8340 [1:43:12<22:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:49,415 >> Initializing global attention on CLS token...\n",
            " 81% 6735/8340 [1:43:13<22:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:50,258 >> Initializing global attention on CLS token...\n",
            " 81% 6736/8340 [1:43:14<22:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:51,100 >> Initializing global attention on CLS token...\n",
            " 81% 6737/8340 [1:43:14<22:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:51,945 >> Initializing global attention on CLS token...\n",
            " 81% 6738/8340 [1:43:15<22:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:52,790 >> Initializing global attention on CLS token...\n",
            " 81% 6739/8340 [1:43:16<22:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:53,634 >> Initializing global attention on CLS token...\n",
            " 81% 6740/8340 [1:43:17<22:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:54,473 >> Initializing global attention on CLS token...\n",
            " 81% 6741/8340 [1:43:18<22:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:55,312 >> Initializing global attention on CLS token...\n",
            " 81% 6742/8340 [1:43:19<22:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:56,157 >> Initializing global attention on CLS token...\n",
            " 81% 6743/8340 [1:43:19<22:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:57,000 >> Initializing global attention on CLS token...\n",
            " 81% 6744/8340 [1:43:20<22:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:57,845 >> Initializing global attention on CLS token...\n",
            " 81% 6745/8340 [1:43:21<22:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:58,682 >> Initializing global attention on CLS token...\n",
            " 81% 6746/8340 [1:43:22<22:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:07:59,521 >> Initializing global attention on CLS token...\n",
            " 81% 6747/8340 [1:43:23<22:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:00,363 >> Initializing global attention on CLS token...\n",
            " 81% 6748/8340 [1:43:24<22:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:01,206 >> Initializing global attention on CLS token...\n",
            " 81% 6749/8340 [1:43:25<22:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:02,044 >> Initializing global attention on CLS token...\n",
            " 81% 6750/8340 [1:43:25<22:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:02,886 >> Initializing global attention on CLS token...\n",
            " 81% 6751/8340 [1:43:26<22:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:03,730 >> Initializing global attention on CLS token...\n",
            " 81% 6752/8340 [1:43:27<22:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:04,577 >> Initializing global attention on CLS token...\n",
            " 81% 6753/8340 [1:43:28<22:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:05,419 >> Initializing global attention on CLS token...\n",
            " 81% 6754/8340 [1:43:29<22:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:06,265 >> Initializing global attention on CLS token...\n",
            " 81% 6755/8340 [1:43:30<22:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:07,119 >> Initializing global attention on CLS token...\n",
            " 81% 6756/8340 [1:43:30<22:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:07,964 >> Initializing global attention on CLS token...\n",
            " 81% 6757/8340 [1:43:31<22:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:08,804 >> Initializing global attention on CLS token...\n",
            " 81% 6758/8340 [1:43:32<22:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:09,644 >> Initializing global attention on CLS token...\n",
            " 81% 6759/8340 [1:43:33<22:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:10,496 >> Initializing global attention on CLS token...\n",
            " 81% 6760/8340 [1:43:34<22:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:11,336 >> Initializing global attention on CLS token...\n",
            " 81% 6761/8340 [1:43:35<22:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:12,180 >> Initializing global attention on CLS token...\n",
            " 81% 6762/8340 [1:43:35<22:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:13,023 >> Initializing global attention on CLS token...\n",
            " 81% 6763/8340 [1:43:36<22:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:13,868 >> Initializing global attention on CLS token...\n",
            " 81% 6764/8340 [1:43:37<22:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:14,707 >> Initializing global attention on CLS token...\n",
            " 81% 6765/8340 [1:43:38<22:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:15,550 >> Initializing global attention on CLS token...\n",
            " 81% 6766/8340 [1:43:39<22:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:16,389 >> Initializing global attention on CLS token...\n",
            " 81% 6767/8340 [1:43:40<22:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:17,235 >> Initializing global attention on CLS token...\n",
            " 81% 6768/8340 [1:43:41<22:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:18,077 >> Initializing global attention on CLS token...\n",
            " 81% 6769/8340 [1:43:41<22:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:18,918 >> Initializing global attention on CLS token...\n",
            " 81% 6770/8340 [1:43:42<22:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:19,757 >> Initializing global attention on CLS token...\n",
            " 81% 6771/8340 [1:43:43<21:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:20,598 >> Initializing global attention on CLS token...\n",
            " 81% 6772/8340 [1:43:44<22:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:21,446 >> Initializing global attention on CLS token...\n",
            " 81% 6773/8340 [1:43:45<22:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:22,288 >> Initializing global attention on CLS token...\n",
            " 81% 6774/8340 [1:43:46<22:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:23,132 >> Initializing global attention on CLS token...\n",
            " 81% 6775/8340 [1:43:46<21:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:23,975 >> Initializing global attention on CLS token...\n",
            " 81% 6776/8340 [1:43:47<21:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:24,812 >> Initializing global attention on CLS token...\n",
            " 81% 6777/8340 [1:43:48<21:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:25,653 >> Initializing global attention on CLS token...\n",
            " 81% 6778/8340 [1:43:49<21:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:26,492 >> Initializing global attention on CLS token...\n",
            " 81% 6779/8340 [1:43:50<21:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:27,334 >> Initializing global attention on CLS token...\n",
            " 81% 6780/8340 [1:43:51<21:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:28,178 >> Initializing global attention on CLS token...\n",
            " 81% 6781/8340 [1:43:51<21:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:29,023 >> Initializing global attention on CLS token...\n",
            " 81% 6782/8340 [1:43:52<21:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:29,867 >> Initializing global attention on CLS token...\n",
            " 81% 6783/8340 [1:43:53<21:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:30,712 >> Initializing global attention on CLS token...\n",
            " 81% 6784/8340 [1:43:54<21:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:31,555 >> Initializing global attention on CLS token...\n",
            " 81% 6785/8340 [1:43:55<21:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:32,402 >> Initializing global attention on CLS token...\n",
            " 81% 6786/8340 [1:43:56<21:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:33,242 >> Initializing global attention on CLS token...\n",
            " 81% 6787/8340 [1:43:57<21:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:34,080 >> Initializing global attention on CLS token...\n",
            " 81% 6788/8340 [1:43:57<21:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:34,924 >> Initializing global attention on CLS token...\n",
            " 81% 6789/8340 [1:43:58<21:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:35,765 >> Initializing global attention on CLS token...\n",
            " 81% 6790/8340 [1:43:59<21:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:36,605 >> Initializing global attention on CLS token...\n",
            " 81% 6791/8340 [1:44:00<21:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:37,449 >> Initializing global attention on CLS token...\n",
            " 81% 6792/8340 [1:44:01<21:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:38,292 >> Initializing global attention on CLS token...\n",
            " 81% 6793/8340 [1:44:02<21:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:39,130 >> Initializing global attention on CLS token...\n",
            " 81% 6794/8340 [1:44:02<21:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:39,971 >> Initializing global attention on CLS token...\n",
            " 81% 6795/8340 [1:44:03<21:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:40,809 >> Initializing global attention on CLS token...\n",
            " 81% 6796/8340 [1:44:04<21:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:41,648 >> Initializing global attention on CLS token...\n",
            " 81% 6797/8340 [1:44:05<21:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:42,490 >> Initializing global attention on CLS token...\n",
            " 82% 6798/8340 [1:44:06<21:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:43,340 >> Initializing global attention on CLS token...\n",
            " 82% 6799/8340 [1:44:07<21:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:44,180 >> Initializing global attention on CLS token...\n",
            " 82% 6800/8340 [1:44:07<21:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:45,026 >> Initializing global attention on CLS token...\n",
            " 82% 6801/8340 [1:44:08<21:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:45,867 >> Initializing global attention on CLS token...\n",
            " 82% 6802/8340 [1:44:09<21:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:46,708 >> Initializing global attention on CLS token...\n",
            " 82% 6803/8340 [1:44:10<21:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:47,549 >> Initializing global attention on CLS token...\n",
            " 82% 6804/8340 [1:44:11<21:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:48,395 >> Initializing global attention on CLS token...\n",
            " 82% 6805/8340 [1:44:12<21:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:49,239 >> Initializing global attention on CLS token...\n",
            " 82% 6806/8340 [1:44:13<21:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:50,078 >> Initializing global attention on CLS token...\n",
            " 82% 6807/8340 [1:44:13<21:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:50,920 >> Initializing global attention on CLS token...\n",
            " 82% 6808/8340 [1:44:14<21:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:51,765 >> Initializing global attention on CLS token...\n",
            " 82% 6809/8340 [1:44:15<21:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:52,606 >> Initializing global attention on CLS token...\n",
            " 82% 6810/8340 [1:44:16<21:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:53,446 >> Initializing global attention on CLS token...\n",
            " 82% 6811/8340 [1:44:17<21:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:54,290 >> Initializing global attention on CLS token...\n",
            " 82% 6812/8340 [1:44:18<21:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:55,130 >> Initializing global attention on CLS token...\n",
            " 82% 6813/8340 [1:44:18<21:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:55,972 >> Initializing global attention on CLS token...\n",
            " 82% 6814/8340 [1:44:19<21:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:56,818 >> Initializing global attention on CLS token...\n",
            " 82% 6815/8340 [1:44:20<21:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:57,659 >> Initializing global attention on CLS token...\n",
            " 82% 6816/8340 [1:44:21<21:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:58,503 >> Initializing global attention on CLS token...\n",
            " 82% 6817/8340 [1:44:22<21:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:08:59,346 >> Initializing global attention on CLS token...\n",
            " 82% 6818/8340 [1:44:23<21:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:00,195 >> Initializing global attention on CLS token...\n",
            " 82% 6819/8340 [1:44:23<21:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:01,034 >> Initializing global attention on CLS token...\n",
            " 82% 6820/8340 [1:44:24<21:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:01,877 >> Initializing global attention on CLS token...\n",
            " 82% 6821/8340 [1:44:25<21:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:02,716 >> Initializing global attention on CLS token...\n",
            " 82% 6822/8340 [1:44:26<21:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:03,555 >> Initializing global attention on CLS token...\n",
            " 82% 6823/8340 [1:44:27<21:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:04,397 >> Initializing global attention on CLS token...\n",
            " 82% 6824/8340 [1:44:28<21:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:05,247 >> Initializing global attention on CLS token...\n",
            " 82% 6825/8340 [1:44:29<21:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:06,092 >> Initializing global attention on CLS token...\n",
            " 82% 6826/8340 [1:44:29<21:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:06,940 >> Initializing global attention on CLS token...\n",
            " 82% 6827/8340 [1:44:30<21:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:07,785 >> Initializing global attention on CLS token...\n",
            " 82% 6828/8340 [1:44:31<21:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:08,631 >> Initializing global attention on CLS token...\n",
            " 82% 6829/8340 [1:44:32<21:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:09,468 >> Initializing global attention on CLS token...\n",
            " 82% 6830/8340 [1:44:33<21:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:10,312 >> Initializing global attention on CLS token...\n",
            " 82% 6831/8340 [1:44:34<21:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:11,154 >> Initializing global attention on CLS token...\n",
            " 82% 6832/8340 [1:44:34<21:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:11,996 >> Initializing global attention on CLS token...\n",
            " 82% 6833/8340 [1:44:35<21:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:12,835 >> Initializing global attention on CLS token...\n",
            " 82% 6834/8340 [1:44:36<21:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:13,679 >> Initializing global attention on CLS token...\n",
            " 82% 6835/8340 [1:44:37<21:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:14,522 >> Initializing global attention on CLS token...\n",
            " 82% 6836/8340 [1:44:38<21:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:15,366 >> Initializing global attention on CLS token...\n",
            " 82% 6837/8340 [1:44:39<21:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:16,203 >> Initializing global attention on CLS token...\n",
            " 82% 6838/8340 [1:44:40<21:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:17,046 >> Initializing global attention on CLS token...\n",
            " 82% 6839/8340 [1:44:40<21:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:17,894 >> Initializing global attention on CLS token...\n",
            " 82% 6840/8340 [1:44:41<21:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:18,739 >> Initializing global attention on CLS token...\n",
            " 82% 6841/8340 [1:44:42<21:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:19,589 >> Initializing global attention on CLS token...\n",
            " 82% 6842/8340 [1:44:43<21:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:20,434 >> Initializing global attention on CLS token...\n",
            " 82% 6843/8340 [1:44:44<21:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:21,276 >> Initializing global attention on CLS token...\n",
            " 82% 6844/8340 [1:44:45<21:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:22,118 >> Initializing global attention on CLS token...\n",
            " 82% 6845/8340 [1:44:45<21:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:22,961 >> Initializing global attention on CLS token...\n",
            " 82% 6846/8340 [1:44:46<20:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:23,798 >> Initializing global attention on CLS token...\n",
            " 82% 6847/8340 [1:44:47<20:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:24,645 >> Initializing global attention on CLS token...\n",
            " 82% 6848/8340 [1:44:48<20:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:25,485 >> Initializing global attention on CLS token...\n",
            " 82% 6849/8340 [1:44:49<20:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:26,331 >> Initializing global attention on CLS token...\n",
            " 82% 6850/8340 [1:44:50<20:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:27,171 >> Initializing global attention on CLS token...\n",
            " 82% 6851/8340 [1:44:50<20:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:28,014 >> Initializing global attention on CLS token...\n",
            " 82% 6852/8340 [1:44:51<20:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:28,855 >> Initializing global attention on CLS token...\n",
            " 82% 6853/8340 [1:44:52<20:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:29,697 >> Initializing global attention on CLS token...\n",
            " 82% 6854/8340 [1:44:53<20:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:30,545 >> Initializing global attention on CLS token...\n",
            " 82% 6855/8340 [1:44:54<20:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:31,387 >> Initializing global attention on CLS token...\n",
            " 82% 6856/8340 [1:44:55<20:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:32,228 >> Initializing global attention on CLS token...\n",
            " 82% 6857/8340 [1:44:56<20:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:33,070 >> Initializing global attention on CLS token...\n",
            " 82% 6858/8340 [1:44:56<20:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:33,915 >> Initializing global attention on CLS token...\n",
            " 82% 6859/8340 [1:44:57<20:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:34,754 >> Initializing global attention on CLS token...\n",
            " 82% 6860/8340 [1:44:58<20:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:35,598 >> Initializing global attention on CLS token...\n",
            " 82% 6861/8340 [1:44:59<20:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:36,440 >> Initializing global attention on CLS token...\n",
            " 82% 6862/8340 [1:45:00<20:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:37,284 >> Initializing global attention on CLS token...\n",
            " 82% 6863/8340 [1:45:01<20:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:38,125 >> Initializing global attention on CLS token...\n",
            " 82% 6864/8340 [1:45:01<20:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:38,962 >> Initializing global attention on CLS token...\n",
            " 82% 6865/8340 [1:45:02<20:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:39,806 >> Initializing global attention on CLS token...\n",
            " 82% 6866/8340 [1:45:03<20:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:40,650 >> Initializing global attention on CLS token...\n",
            " 82% 6867/8340 [1:45:04<20:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:41,491 >> Initializing global attention on CLS token...\n",
            " 82% 6868/8340 [1:45:05<20:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:42,335 >> Initializing global attention on CLS token...\n",
            " 82% 6869/8340 [1:45:06<20:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:43,173 >> Initializing global attention on CLS token...\n",
            " 82% 6870/8340 [1:45:06<20:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:44,014 >> Initializing global attention on CLS token...\n",
            " 82% 6871/8340 [1:45:07<20:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:44,855 >> Initializing global attention on CLS token...\n",
            " 82% 6872/8340 [1:45:08<20:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:45,696 >> Initializing global attention on CLS token...\n",
            " 82% 6873/8340 [1:45:09<20:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:46,536 >> Initializing global attention on CLS token...\n",
            " 82% 6874/8340 [1:45:10<20:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:47,379 >> Initializing global attention on CLS token...\n",
            " 82% 6875/8340 [1:45:11<20:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:48,222 >> Initializing global attention on CLS token...\n",
            " 82% 6876/8340 [1:45:12<20:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:49,062 >> Initializing global attention on CLS token...\n",
            " 82% 6877/8340 [1:45:12<20:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:49,905 >> Initializing global attention on CLS token...\n",
            " 82% 6878/8340 [1:45:13<20:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:50,748 >> Initializing global attention on CLS token...\n",
            " 82% 6879/8340 [1:45:14<20:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:51,588 >> Initializing global attention on CLS token...\n",
            " 82% 6880/8340 [1:45:15<20:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:52,429 >> Initializing global attention on CLS token...\n",
            " 83% 6881/8340 [1:45:16<20:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:53,274 >> Initializing global attention on CLS token...\n",
            " 83% 6882/8340 [1:45:17<20:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:54,116 >> Initializing global attention on CLS token...\n",
            " 83% 6883/8340 [1:45:17<20:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:54,972 >> Initializing global attention on CLS token...\n",
            " 83% 6884/8340 [1:45:18<20:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:55,822 >> Initializing global attention on CLS token...\n",
            " 83% 6885/8340 [1:45:19<20:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:56,664 >> Initializing global attention on CLS token...\n",
            " 83% 6886/8340 [1:45:20<20:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:57,510 >> Initializing global attention on CLS token...\n",
            " 83% 6887/8340 [1:45:21<20:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:58,349 >> Initializing global attention on CLS token...\n",
            " 83% 6888/8340 [1:45:22<20:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:09:59,194 >> Initializing global attention on CLS token...\n",
            " 83% 6889/8340 [1:45:22<20:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:00,040 >> Initializing global attention on CLS token...\n",
            " 83% 6890/8340 [1:45:23<20:25,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:00,886 >> Initializing global attention on CLS token...\n",
            " 83% 6891/8340 [1:45:24<20:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:01,727 >> Initializing global attention on CLS token...\n",
            " 83% 6892/8340 [1:45:25<20:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:02,564 >> Initializing global attention on CLS token...\n",
            " 83% 6893/8340 [1:45:26<20:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:03,406 >> Initializing global attention on CLS token...\n",
            " 83% 6894/8340 [1:45:27<20:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:04,249 >> Initializing global attention on CLS token...\n",
            " 83% 6895/8340 [1:45:28<20:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:05,094 >> Initializing global attention on CLS token...\n",
            " 83% 6896/8340 [1:45:28<20:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:05,943 >> Initializing global attention on CLS token...\n",
            " 83% 6897/8340 [1:45:29<20:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:06,795 >> Initializing global attention on CLS token...\n",
            " 83% 6898/8340 [1:45:30<20:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:07,637 >> Initializing global attention on CLS token...\n",
            " 83% 6899/8340 [1:45:31<20:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:08,489 >> Initializing global attention on CLS token...\n",
            " 83% 6900/8340 [1:45:32<20:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:09,340 >> Initializing global attention on CLS token...\n",
            " 83% 6901/8340 [1:45:33<20:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:10,188 >> Initializing global attention on CLS token...\n",
            " 83% 6902/8340 [1:45:33<20:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:11,033 >> Initializing global attention on CLS token...\n",
            " 83% 6903/8340 [1:45:34<20:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:11,873 >> Initializing global attention on CLS token...\n",
            " 83% 6904/8340 [1:45:35<20:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:12,722 >> Initializing global attention on CLS token...\n",
            " 83% 6905/8340 [1:45:36<20:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:13,563 >> Initializing global attention on CLS token...\n",
            " 83% 6906/8340 [1:45:37<20:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:14,403 >> Initializing global attention on CLS token...\n",
            " 83% 6907/8340 [1:45:38<20:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:15,249 >> Initializing global attention on CLS token...\n",
            " 83% 6908/8340 [1:45:39<20:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:16,091 >> Initializing global attention on CLS token...\n",
            " 83% 6909/8340 [1:45:39<20:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:16,927 >> Initializing global attention on CLS token...\n",
            " 83% 6910/8340 [1:45:40<20:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:17,770 >> Initializing global attention on CLS token...\n",
            " 83% 6911/8340 [1:45:41<20:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:18,609 >> Initializing global attention on CLS token...\n",
            " 83% 6912/8340 [1:45:42<20:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:19,448 >> Initializing global attention on CLS token...\n",
            " 83% 6913/8340 [1:45:43<20:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:20,291 >> Initializing global attention on CLS token...\n",
            " 83% 6914/8340 [1:45:44<19:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:21,129 >> Initializing global attention on CLS token...\n",
            " 83% 6915/8340 [1:45:44<19:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:21,967 >> Initializing global attention on CLS token...\n",
            " 83% 6916/8340 [1:45:45<19:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:22,811 >> Initializing global attention on CLS token...\n",
            " 83% 6917/8340 [1:45:46<19:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:23,651 >> Initializing global attention on CLS token...\n",
            " 83% 6918/8340 [1:45:47<19:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:24,491 >> Initializing global attention on CLS token...\n",
            " 83% 6919/8340 [1:45:48<19:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:25,335 >> Initializing global attention on CLS token...\n",
            " 83% 6920/8340 [1:45:49<19:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:26,181 >> Initializing global attention on CLS token...\n",
            " 83% 6921/8340 [1:45:49<19:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:27,033 >> Initializing global attention on CLS token...\n",
            " 83% 6922/8340 [1:45:50<19:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:27,883 >> Initializing global attention on CLS token...\n",
            " 83% 6923/8340 [1:45:51<19:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:28,727 >> Initializing global attention on CLS token...\n",
            " 83% 6924/8340 [1:45:52<19:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:29,574 >> Initializing global attention on CLS token...\n",
            " 83% 6925/8340 [1:45:53<19:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:30,421 >> Initializing global attention on CLS token...\n",
            " 83% 6926/8340 [1:45:54<19:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:31,260 >> Initializing global attention on CLS token...\n",
            " 83% 6927/8340 [1:45:55<19:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:32,097 >> Initializing global attention on CLS token...\n",
            " 83% 6928/8340 [1:45:55<19:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:32,944 >> Initializing global attention on CLS token...\n",
            " 83% 6929/8340 [1:45:56<19:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:33,785 >> Initializing global attention on CLS token...\n",
            " 83% 6930/8340 [1:45:57<19:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:34,621 >> Initializing global attention on CLS token...\n",
            " 83% 6931/8340 [1:45:58<19:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:35,465 >> Initializing global attention on CLS token...\n",
            " 83% 6932/8340 [1:45:59<19:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:36,305 >> Initializing global attention on CLS token...\n",
            " 83% 6933/8340 [1:46:00<19:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:37,148 >> Initializing global attention on CLS token...\n",
            " 83% 6934/8340 [1:46:00<19:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:37,992 >> Initializing global attention on CLS token...\n",
            " 83% 6935/8340 [1:46:01<19:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:38,835 >> Initializing global attention on CLS token...\n",
            " 83% 6936/8340 [1:46:02<19:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:39,683 >> Initializing global attention on CLS token...\n",
            " 83% 6937/8340 [1:46:03<19:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:40,529 >> Initializing global attention on CLS token...\n",
            " 83% 6938/8340 [1:46:04<19:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:41,373 >> Initializing global attention on CLS token...\n",
            " 83% 6939/8340 [1:46:05<19:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:42,215 >> Initializing global attention on CLS token...\n",
            " 83% 6940/8340 [1:46:06<19:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:43,053 >> Initializing global attention on CLS token...\n",
            " 83% 6941/8340 [1:46:06<19:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:43,892 >> Initializing global attention on CLS token...\n",
            " 83% 6942/8340 [1:46:07<19:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:44,734 >> Initializing global attention on CLS token...\n",
            " 83% 6943/8340 [1:46:08<19:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:45,580 >> Initializing global attention on CLS token...\n",
            " 83% 6944/8340 [1:46:09<19:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:46,420 >> Initializing global attention on CLS token...\n",
            " 83% 6945/8340 [1:46:10<19:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:47,266 >> Initializing global attention on CLS token...\n",
            " 83% 6946/8340 [1:46:11<19:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:48,106 >> Initializing global attention on CLS token...\n",
            " 83% 6947/8340 [1:46:11<19:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:48,949 >> Initializing global attention on CLS token...\n",
            " 83% 6948/8340 [1:46:12<19:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:49,787 >> Initializing global attention on CLS token...\n",
            " 83% 6949/8340 [1:46:13<19:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:50,625 >> Initializing global attention on CLS token...\n",
            " 83% 6950/8340 [1:46:14<19:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:51,470 >> Initializing global attention on CLS token...\n",
            " 83% 6951/8340 [1:46:15<19:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:52,314 >> Initializing global attention on CLS token...\n",
            " 83% 6952/8340 [1:46:16<19:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:53,155 >> Initializing global attention on CLS token...\n",
            " 83% 6953/8340 [1:46:16<19:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:54,001 >> Initializing global attention on CLS token...\n",
            " 83% 6954/8340 [1:46:17<19:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:54,844 >> Initializing global attention on CLS token...\n",
            " 83% 6955/8340 [1:46:18<19:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:55,686 >> Initializing global attention on CLS token...\n",
            " 83% 6956/8340 [1:46:19<19:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:56,529 >> Initializing global attention on CLS token...\n",
            " 83% 6957/8340 [1:46:20<19:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:57,367 >> Initializing global attention on CLS token...\n",
            " 83% 6958/8340 [1:46:21<19:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:58,217 >> Initializing global attention on CLS token...\n",
            " 83% 6959/8340 [1:46:22<19:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:59,058 >> Initializing global attention on CLS token...\n",
            " 83% 6960/8340 [1:46:22<19:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:10:59,903 >> Initializing global attention on CLS token...\n",
            " 83% 6961/8340 [1:46:23<19:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:00,745 >> Initializing global attention on CLS token...\n",
            " 83% 6962/8340 [1:46:24<19:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:01,589 >> Initializing global attention on CLS token...\n",
            " 83% 6963/8340 [1:46:25<19:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:02,432 >> Initializing global attention on CLS token...\n",
            " 84% 6964/8340 [1:46:26<19:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:03,273 >> Initializing global attention on CLS token...\n",
            " 84% 6965/8340 [1:46:27<19:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:04,116 >> Initializing global attention on CLS token...\n",
            " 84% 6966/8340 [1:46:27<19:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:04,961 >> Initializing global attention on CLS token...\n",
            " 84% 6967/8340 [1:46:28<19:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:05,801 >> Initializing global attention on CLS token...\n",
            " 84% 6968/8340 [1:46:29<19:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:06,643 >> Initializing global attention on CLS token...\n",
            " 84% 6969/8340 [1:46:30<19:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:07,486 >> Initializing global attention on CLS token...\n",
            " 84% 6970/8340 [1:46:31<19:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:08,325 >> Initializing global attention on CLS token...\n",
            " 84% 6971/8340 [1:46:32<19:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:09,173 >> Initializing global attention on CLS token...\n",
            " 84% 6972/8340 [1:46:32<19:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:10,017 >> Initializing global attention on CLS token...\n",
            " 84% 6973/8340 [1:46:33<19:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:10,859 >> Initializing global attention on CLS token...\n",
            " 84% 6974/8340 [1:46:34<19:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:11,701 >> Initializing global attention on CLS token...\n",
            " 84% 6975/8340 [1:46:35<19:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:12,540 >> Initializing global attention on CLS token...\n",
            " 84% 6976/8340 [1:46:36<19:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:13,387 >> Initializing global attention on CLS token...\n",
            " 84% 6977/8340 [1:46:37<19:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:14,228 >> Initializing global attention on CLS token...\n",
            " 84% 6978/8340 [1:46:38<19:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:15,067 >> Initializing global attention on CLS token...\n",
            " 84% 6979/8340 [1:46:38<19:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:15,909 >> Initializing global attention on CLS token...\n",
            " 84% 6980/8340 [1:46:39<19:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:16,749 >> Initializing global attention on CLS token...\n",
            " 84% 6981/8340 [1:46:40<19:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:17,596 >> Initializing global attention on CLS token...\n",
            " 84% 6982/8340 [1:46:41<19:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:18,437 >> Initializing global attention on CLS token...\n",
            " 84% 6983/8340 [1:46:42<19:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:19,282 >> Initializing global attention on CLS token...\n",
            " 84% 6984/8340 [1:46:43<19:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:20,124 >> Initializing global attention on CLS token...\n",
            " 84% 6985/8340 [1:46:43<19:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:20,965 >> Initializing global attention on CLS token...\n",
            " 84% 6986/8340 [1:46:44<19:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:21,811 >> Initializing global attention on CLS token...\n",
            " 84% 6987/8340 [1:46:45<18:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:22,648 >> Initializing global attention on CLS token...\n",
            " 84% 6988/8340 [1:46:46<18:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:23,491 >> Initializing global attention on CLS token...\n",
            " 84% 6989/8340 [1:46:47<18:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:24,331 >> Initializing global attention on CLS token...\n",
            " 84% 6990/8340 [1:46:48<18:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:25,172 >> Initializing global attention on CLS token...\n",
            " 84% 6991/8340 [1:46:48<18:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:26,019 >> Initializing global attention on CLS token...\n",
            " 84% 6992/8340 [1:46:49<18:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:26,859 >> Initializing global attention on CLS token...\n",
            " 84% 6993/8340 [1:46:50<18:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:27,704 >> Initializing global attention on CLS token...\n",
            " 84% 6994/8340 [1:46:51<18:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:28,547 >> Initializing global attention on CLS token...\n",
            " 84% 6995/8340 [1:46:52<18:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:29,388 >> Initializing global attention on CLS token...\n",
            " 84% 6996/8340 [1:46:53<18:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:30,227 >> Initializing global attention on CLS token...\n",
            " 84% 6997/8340 [1:46:54<18:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:31,069 >> Initializing global attention on CLS token...\n",
            " 84% 6998/8340 [1:46:54<18:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:31,910 >> Initializing global attention on CLS token...\n",
            " 84% 6999/8340 [1:46:55<18:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:32,757 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0463, 'learning_rate': 4.838129496402877e-06, 'epoch': 8.39}\n",
            " 84% 7000/8340 [1:46:56<19:50,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:33,772 >> Initializing global attention on CLS token...\n",
            " 84% 7001/8340 [1:46:57<19:41,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:34,623 >> Initializing global attention on CLS token...\n",
            " 84% 7002/8340 [1:46:58<19:27,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:35,473 >> Initializing global attention on CLS token...\n",
            " 84% 7003/8340 [1:46:59<19:14,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:36,311 >> Initializing global attention on CLS token...\n",
            " 84% 7004/8340 [1:47:00<19:06,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:37,156 >> Initializing global attention on CLS token...\n",
            " 84% 7005/8340 [1:47:00<18:57,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:37,996 >> Initializing global attention on CLS token...\n",
            " 84% 7006/8340 [1:47:01<18:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:38,836 >> Initializing global attention on CLS token...\n",
            " 84% 7007/8340 [1:47:02<18:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:39,674 >> Initializing global attention on CLS token...\n",
            " 84% 7008/8340 [1:47:03<18:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:40,516 >> Initializing global attention on CLS token...\n",
            " 84% 7009/8340 [1:47:04<18:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:41,360 >> Initializing global attention on CLS token...\n",
            " 84% 7010/8340 [1:47:05<18:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:42,202 >> Initializing global attention on CLS token...\n",
            " 84% 7011/8340 [1:47:05<18:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:43,041 >> Initializing global attention on CLS token...\n",
            " 84% 7012/8340 [1:47:06<18:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:43,881 >> Initializing global attention on CLS token...\n",
            " 84% 7013/8340 [1:47:07<18:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:44,723 >> Initializing global attention on CLS token...\n",
            " 84% 7014/8340 [1:47:08<18:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:45,567 >> Initializing global attention on CLS token...\n",
            " 84% 7015/8340 [1:47:09<18:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:46,412 >> Initializing global attention on CLS token...\n",
            " 84% 7016/8340 [1:47:10<18:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:47,255 >> Initializing global attention on CLS token...\n",
            " 84% 7017/8340 [1:47:11<18:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:48,099 >> Initializing global attention on CLS token...\n",
            " 84% 7018/8340 [1:47:11<18:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:48,939 >> Initializing global attention on CLS token...\n",
            " 84% 7019/8340 [1:47:12<18:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:49,774 >> Initializing global attention on CLS token...\n",
            " 84% 7020/8340 [1:47:13<18:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:50,618 >> Initializing global attention on CLS token...\n",
            " 84% 7021/8340 [1:47:14<18:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:51,469 >> Initializing global attention on CLS token...\n",
            " 84% 7022/8340 [1:47:15<18:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:52,313 >> Initializing global attention on CLS token...\n",
            " 84% 7023/8340 [1:47:16<18:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:53,152 >> Initializing global attention on CLS token...\n",
            " 84% 7024/8340 [1:47:16<18:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:54,004 >> Initializing global attention on CLS token...\n",
            " 84% 7025/8340 [1:47:17<18:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:54,847 >> Initializing global attention on CLS token...\n",
            " 84% 7026/8340 [1:47:18<18:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:55,686 >> Initializing global attention on CLS token...\n",
            " 84% 7027/8340 [1:47:19<18:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:56,526 >> Initializing global attention on CLS token...\n",
            " 84% 7028/8340 [1:47:20<18:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:57,369 >> Initializing global attention on CLS token...\n",
            " 84% 7029/8340 [1:47:21<18:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:58,212 >> Initializing global attention on CLS token...\n",
            " 84% 7030/8340 [1:47:22<18:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:59,050 >> Initializing global attention on CLS token...\n",
            " 84% 7031/8340 [1:47:22<18:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:11:59,891 >> Initializing global attention on CLS token...\n",
            " 84% 7032/8340 [1:47:23<18:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:00,731 >> Initializing global attention on CLS token...\n",
            " 84% 7033/8340 [1:47:24<18:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:01,573 >> Initializing global attention on CLS token...\n",
            " 84% 7034/8340 [1:47:25<18:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:02,414 >> Initializing global attention on CLS token...\n",
            " 84% 7035/8340 [1:47:26<18:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:03,255 >> Initializing global attention on CLS token...\n",
            " 84% 7036/8340 [1:47:27<18:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:04,094 >> Initializing global attention on CLS token...\n",
            " 84% 7037/8340 [1:47:27<18:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:04,937 >> Initializing global attention on CLS token...\n",
            " 84% 7038/8340 [1:47:28<18:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:05,782 >> Initializing global attention on CLS token...\n",
            " 84% 7039/8340 [1:47:29<18:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:06,630 >> Initializing global attention on CLS token...\n",
            " 84% 7040/8340 [1:47:30<18:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:07,477 >> Initializing global attention on CLS token...\n",
            " 84% 7041/8340 [1:47:31<18:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:08,315 >> Initializing global attention on CLS token...\n",
            " 84% 7042/8340 [1:47:32<18:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:09,153 >> Initializing global attention on CLS token...\n",
            " 84% 7043/8340 [1:47:32<18:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:09,994 >> Initializing global attention on CLS token...\n",
            " 84% 7044/8340 [1:47:33<18:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:10,836 >> Initializing global attention on CLS token...\n",
            " 84% 7045/8340 [1:47:34<18:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:11,677 >> Initializing global attention on CLS token...\n",
            " 84% 7046/8340 [1:47:35<18:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:12,513 >> Initializing global attention on CLS token...\n",
            " 84% 7047/8340 [1:47:36<18:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:13,358 >> Initializing global attention on CLS token...\n",
            " 85% 7048/8340 [1:47:37<18:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:14,206 >> Initializing global attention on CLS token...\n",
            " 85% 7049/8340 [1:47:38<18:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:15,052 >> Initializing global attention on CLS token...\n",
            " 85% 7050/8340 [1:47:38<18:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:15,890 >> Initializing global attention on CLS token...\n",
            " 85% 7051/8340 [1:47:39<18:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:16,735 >> Initializing global attention on CLS token...\n",
            " 85% 7052/8340 [1:47:40<18:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:17,583 >> Initializing global attention on CLS token...\n",
            " 85% 7053/8340 [1:47:41<18:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:18,427 >> Initializing global attention on CLS token...\n",
            " 85% 7054/8340 [1:47:42<18:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:19,267 >> Initializing global attention on CLS token...\n",
            " 85% 7055/8340 [1:47:43<18:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:20,107 >> Initializing global attention on CLS token...\n",
            " 85% 7056/8340 [1:47:43<18:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:20,951 >> Initializing global attention on CLS token...\n",
            " 85% 7057/8340 [1:47:44<18:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:21,791 >> Initializing global attention on CLS token...\n",
            " 85% 7058/8340 [1:47:45<17:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:22,634 >> Initializing global attention on CLS token...\n",
            " 85% 7059/8340 [1:47:46<17:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:23,473 >> Initializing global attention on CLS token...\n",
            " 85% 7060/8340 [1:47:47<17:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:24,314 >> Initializing global attention on CLS token...\n",
            " 85% 7061/8340 [1:47:48<17:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:25,157 >> Initializing global attention on CLS token...\n",
            " 85% 7062/8340 [1:47:48<17:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:26,000 >> Initializing global attention on CLS token...\n",
            " 85% 7063/8340 [1:47:49<17:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:26,839 >> Initializing global attention on CLS token...\n",
            " 85% 7064/8340 [1:47:50<17:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:27,690 >> Initializing global attention on CLS token...\n",
            " 85% 7065/8340 [1:47:51<17:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:28,531 >> Initializing global attention on CLS token...\n",
            " 85% 7066/8340 [1:47:52<17:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:29,378 >> Initializing global attention on CLS token...\n",
            " 85% 7067/8340 [1:47:53<17:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:30,228 >> Initializing global attention on CLS token...\n",
            " 85% 7068/8340 [1:47:54<17:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:31,072 >> Initializing global attention on CLS token...\n",
            " 85% 7069/8340 [1:47:54<17:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:31,918 >> Initializing global attention on CLS token...\n",
            " 85% 7070/8340 [1:47:55<17:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:32,762 >> Initializing global attention on CLS token...\n",
            " 85% 7071/8340 [1:47:56<17:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:33,605 >> Initializing global attention on CLS token...\n",
            " 85% 7072/8340 [1:47:57<17:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:34,449 >> Initializing global attention on CLS token...\n",
            " 85% 7073/8340 [1:47:58<17:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:35,285 >> Initializing global attention on CLS token...\n",
            " 85% 7074/8340 [1:47:59<17:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:36,128 >> Initializing global attention on CLS token...\n",
            " 85% 7075/8340 [1:47:59<17:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:36,965 >> Initializing global attention on CLS token...\n",
            " 85% 7076/8340 [1:48:00<17:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:37,807 >> Initializing global attention on CLS token...\n",
            " 85% 7077/8340 [1:48:01<17:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:38,650 >> Initializing global attention on CLS token...\n",
            " 85% 7078/8340 [1:48:02<17:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:39,497 >> Initializing global attention on CLS token...\n",
            " 85% 7079/8340 [1:48:03<17:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:40,336 >> Initializing global attention on CLS token...\n",
            " 85% 7080/8340 [1:48:04<17:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:41,174 >> Initializing global attention on CLS token...\n",
            " 85% 7081/8340 [1:48:04<17:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:42,019 >> Initializing global attention on CLS token...\n",
            " 85% 7082/8340 [1:48:05<17:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:42,861 >> Initializing global attention on CLS token...\n",
            " 85% 7083/8340 [1:48:06<17:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:43,703 >> Initializing global attention on CLS token...\n",
            " 85% 7084/8340 [1:48:07<17:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:44,546 >> Initializing global attention on CLS token...\n",
            " 85% 7085/8340 [1:48:08<17:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:45,384 >> Initializing global attention on CLS token...\n",
            " 85% 7086/8340 [1:48:09<17:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:46,228 >> Initializing global attention on CLS token...\n",
            " 85% 7087/8340 [1:48:10<17:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:47,074 >> Initializing global attention on CLS token...\n",
            " 85% 7088/8340 [1:48:10<17:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:47,919 >> Initializing global attention on CLS token...\n",
            " 85% 7089/8340 [1:48:11<17:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:48,771 >> Initializing global attention on CLS token...\n",
            " 85% 7090/8340 [1:48:12<17:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:49,613 >> Initializing global attention on CLS token...\n",
            " 85% 7091/8340 [1:48:13<17:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:50,460 >> Initializing global attention on CLS token...\n",
            " 85% 7092/8340 [1:48:14<17:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:51,296 >> Initializing global attention on CLS token...\n",
            " 85% 7093/8340 [1:48:15<17:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:52,136 >> Initializing global attention on CLS token...\n",
            " 85% 7094/8340 [1:48:15<17:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:52,990 >> Initializing global attention on CLS token...\n",
            " 85% 7095/8340 [1:48:16<17:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:53,832 >> Initializing global attention on CLS token...\n",
            " 85% 7096/8340 [1:48:17<17:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:54,678 >> Initializing global attention on CLS token...\n",
            " 85% 7097/8340 [1:48:18<17:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:55,518 >> Initializing global attention on CLS token...\n",
            " 85% 7098/8340 [1:48:19<17:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:56,359 >> Initializing global attention on CLS token...\n",
            " 85% 7099/8340 [1:48:20<17:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:57,199 >> Initializing global attention on CLS token...\n",
            " 85% 7100/8340 [1:48:20<17:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:58,039 >> Initializing global attention on CLS token...\n",
            " 85% 7101/8340 [1:48:21<17:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:58,881 >> Initializing global attention on CLS token...\n",
            " 85% 7102/8340 [1:48:22<17:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:12:59,722 >> Initializing global attention on CLS token...\n",
            " 85% 7103/8340 [1:48:23<17:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:00,560 >> Initializing global attention on CLS token...\n",
            " 85% 7104/8340 [1:48:24<17:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:01,403 >> Initializing global attention on CLS token...\n",
            " 85% 7105/8340 [1:48:25<17:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:02,243 >> Initializing global attention on CLS token...\n",
            " 85% 7106/8340 [1:48:26<17:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:03,084 >> Initializing global attention on CLS token...\n",
            " 85% 7107/8340 [1:48:26<17:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:03,933 >> Initializing global attention on CLS token...\n",
            " 85% 7108/8340 [1:48:27<17:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:04,775 >> Initializing global attention on CLS token...\n",
            " 85% 7109/8340 [1:48:28<17:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:05,622 >> Initializing global attention on CLS token...\n",
            " 85% 7110/8340 [1:48:29<17:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:06,465 >> Initializing global attention on CLS token...\n",
            " 85% 7111/8340 [1:48:30<17:17,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:07,310 >> Initializing global attention on CLS token...\n",
            " 85% 7112/8340 [1:48:31<17:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:08,149 >> Initializing global attention on CLS token...\n",
            " 85% 7113/8340 [1:48:31<17:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:08,994 >> Initializing global attention on CLS token...\n",
            " 85% 7114/8340 [1:48:32<17:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:09,835 >> Initializing global attention on CLS token...\n",
            " 85% 7115/8340 [1:48:33<17:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:10,674 >> Initializing global attention on CLS token...\n",
            " 85% 7116/8340 [1:48:34<17:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:11,519 >> Initializing global attention on CLS token...\n",
            " 85% 7117/8340 [1:48:35<17:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:12,359 >> Initializing global attention on CLS token...\n",
            " 85% 7118/8340 [1:48:36<17:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:13,197 >> Initializing global attention on CLS token...\n",
            " 85% 7119/8340 [1:48:37<17:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:14,041 >> Initializing global attention on CLS token...\n",
            " 85% 7120/8340 [1:48:37<17:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:14,888 >> Initializing global attention on CLS token...\n",
            " 85% 7121/8340 [1:48:38<17:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:15,727 >> Initializing global attention on CLS token...\n",
            " 85% 7122/8340 [1:48:39<17:08,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:16,578 >> Initializing global attention on CLS token...\n",
            " 85% 7123/8340 [1:48:40<17:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:17,415 >> Initializing global attention on CLS token...\n",
            " 85% 7124/8340 [1:48:41<17:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:18,259 >> Initializing global attention on CLS token...\n",
            " 85% 7125/8340 [1:48:42<17:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:19,103 >> Initializing global attention on CLS token...\n",
            " 85% 7126/8340 [1:48:42<17:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:19,941 >> Initializing global attention on CLS token...\n",
            " 85% 7127/8340 [1:48:43<17:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:20,788 >> Initializing global attention on CLS token...\n",
            " 85% 7128/8340 [1:48:44<17:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:21,629 >> Initializing global attention on CLS token...\n",
            " 85% 7129/8340 [1:48:45<16:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:22,468 >> Initializing global attention on CLS token...\n",
            " 85% 7130/8340 [1:48:46<16:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:23,313 >> Initializing global attention on CLS token...\n",
            " 86% 7131/8340 [1:48:47<16:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:24,155 >> Initializing global attention on CLS token...\n",
            " 86% 7132/8340 [1:48:47<16:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:25,000 >> Initializing global attention on CLS token...\n",
            " 86% 7133/8340 [1:48:48<16:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:25,842 >> Initializing global attention on CLS token...\n",
            " 86% 7134/8340 [1:48:49<16:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:26,683 >> Initializing global attention on CLS token...\n",
            " 86% 7135/8340 [1:48:50<16:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:27,530 >> Initializing global attention on CLS token...\n",
            " 86% 7136/8340 [1:48:51<16:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:28,368 >> Initializing global attention on CLS token...\n",
            " 86% 7137/8340 [1:48:52<16:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:29,220 >> Initializing global attention on CLS token...\n",
            " 86% 7138/8340 [1:48:53<16:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:30,057 >> Initializing global attention on CLS token...\n",
            " 86% 7139/8340 [1:48:53<16:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:30,899 >> Initializing global attention on CLS token...\n",
            " 86% 7140/8340 [1:48:54<16:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:31,740 >> Initializing global attention on CLS token...\n",
            " 86% 7141/8340 [1:48:55<16:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:32,581 >> Initializing global attention on CLS token...\n",
            " 86% 7142/8340 [1:48:56<16:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:33,423 >> Initializing global attention on CLS token...\n",
            " 86% 7143/8340 [1:48:57<16:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:34,262 >> Initializing global attention on CLS token...\n",
            " 86% 7144/8340 [1:48:58<16:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:35,103 >> Initializing global attention on CLS token...\n",
            " 86% 7145/8340 [1:48:58<16:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:35,942 >> Initializing global attention on CLS token...\n",
            " 86% 7146/8340 [1:48:59<16:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:36,781 >> Initializing global attention on CLS token...\n",
            " 86% 7147/8340 [1:49:00<16:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:37,624 >> Initializing global attention on CLS token...\n",
            " 86% 7148/8340 [1:49:01<16:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:38,464 >> Initializing global attention on CLS token...\n",
            " 86% 7149/8340 [1:49:02<16:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:39,308 >> Initializing global attention on CLS token...\n",
            " 86% 7150/8340 [1:49:03<16:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:40,146 >> Initializing global attention on CLS token...\n",
            " 86% 7151/8340 [1:49:03<16:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:40,986 >> Initializing global attention on CLS token...\n",
            " 86% 7152/8340 [1:49:04<16:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:41,830 >> Initializing global attention on CLS token...\n",
            " 86% 7153/8340 [1:49:05<16:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:42,666 >> Initializing global attention on CLS token...\n",
            " 86% 7154/8340 [1:49:06<16:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:43,506 >> Initializing global attention on CLS token...\n",
            " 86% 7155/8340 [1:49:07<16:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:44,350 >> Initializing global attention on CLS token...\n",
            " 86% 7156/8340 [1:49:08<16:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:45,187 >> Initializing global attention on CLS token...\n",
            " 86% 7157/8340 [1:49:08<16:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:46,027 >> Initializing global attention on CLS token...\n",
            " 86% 7158/8340 [1:49:09<16:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:46,870 >> Initializing global attention on CLS token...\n",
            " 86% 7159/8340 [1:49:10<16:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:47,712 >> Initializing global attention on CLS token...\n",
            " 86% 7160/8340 [1:49:11<16:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:48,561 >> Initializing global attention on CLS token...\n",
            " 86% 7161/8340 [1:49:12<16:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:49,404 >> Initializing global attention on CLS token...\n",
            " 86% 7162/8340 [1:49:13<16:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:50,253 >> Initializing global attention on CLS token...\n",
            " 86% 7163/8340 [1:49:14<16:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:51,093 >> Initializing global attention on CLS token...\n",
            " 86% 7164/8340 [1:49:14<16:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:51,935 >> Initializing global attention on CLS token...\n",
            " 86% 7165/8340 [1:49:15<16:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:52,779 >> Initializing global attention on CLS token...\n",
            " 86% 7166/8340 [1:49:16<16:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:53,621 >> Initializing global attention on CLS token...\n",
            " 86% 7167/8340 [1:49:17<16:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:54,463 >> Initializing global attention on CLS token...\n",
            " 86% 7168/8340 [1:49:18<16:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:55,306 >> Initializing global attention on CLS token...\n",
            " 86% 7169/8340 [1:49:19<16:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:56,151 >> Initializing global attention on CLS token...\n",
            " 86% 7170/8340 [1:49:19<16:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:56,987 >> Initializing global attention on CLS token...\n",
            " 86% 7171/8340 [1:49:20<16:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:57,833 >> Initializing global attention on CLS token...\n",
            " 86% 7172/8340 [1:49:21<16:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:58,676 >> Initializing global attention on CLS token...\n",
            " 86% 7173/8340 [1:49:22<16:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:13:59,517 >> Initializing global attention on CLS token...\n",
            " 86% 7174/8340 [1:49:23<16:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:00,353 >> Initializing global attention on CLS token...\n",
            " 86% 7175/8340 [1:49:24<16:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:01,194 >> Initializing global attention on CLS token...\n",
            " 86% 7176/8340 [1:49:24<16:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:02,031 >> Initializing global attention on CLS token...\n",
            " 86% 7177/8340 [1:49:25<16:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:02,876 >> Initializing global attention on CLS token...\n",
            " 86% 7178/8340 [1:49:26<16:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:03,716 >> Initializing global attention on CLS token...\n",
            " 86% 7179/8340 [1:49:27<16:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:04,569 >> Initializing global attention on CLS token...\n",
            " 86% 7180/8340 [1:49:28<16:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:05,420 >> Initializing global attention on CLS token...\n",
            " 86% 7181/8340 [1:49:29<16:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:06,269 >> Initializing global attention on CLS token...\n",
            " 86% 7182/8340 [1:49:30<16:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:07,116 >> Initializing global attention on CLS token...\n",
            " 86% 7183/8340 [1:49:30<16:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:07,962 >> Initializing global attention on CLS token...\n",
            " 86% 7184/8340 [1:49:31<16:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:08,806 >> Initializing global attention on CLS token...\n",
            " 86% 7185/8340 [1:49:32<16:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:09,653 >> Initializing global attention on CLS token...\n",
            " 86% 7186/8340 [1:49:33<16:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:10,498 >> Initializing global attention on CLS token...\n",
            " 86% 7187/8340 [1:49:34<16:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:11,341 >> Initializing global attention on CLS token...\n",
            " 86% 7188/8340 [1:49:35<16:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:12,183 >> Initializing global attention on CLS token...\n",
            " 86% 7189/8340 [1:49:35<16:12,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:13,033 >> Initializing global attention on CLS token...\n",
            " 86% 7190/8340 [1:49:36<16:13,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:13,876 >> Initializing global attention on CLS token...\n",
            " 86% 7191/8340 [1:49:37<16:11,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:14,721 >> Initializing global attention on CLS token...\n",
            " 86% 7192/8340 [1:49:38<16:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:15,563 >> Initializing global attention on CLS token...\n",
            " 86% 7193/8340 [1:49:39<16:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:16,401 >> Initializing global attention on CLS token...\n",
            " 86% 7194/8340 [1:49:40<16:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:17,241 >> Initializing global attention on CLS token...\n",
            " 86% 7195/8340 [1:49:41<16:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:18,083 >> Initializing global attention on CLS token...\n",
            " 86% 7196/8340 [1:49:41<16:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:18,926 >> Initializing global attention on CLS token...\n",
            " 86% 7197/8340 [1:49:42<16:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:19,774 >> Initializing global attention on CLS token...\n",
            " 86% 7198/8340 [1:49:43<16:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:20,618 >> Initializing global attention on CLS token...\n",
            " 86% 7199/8340 [1:49:44<16:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:21,464 >> Initializing global attention on CLS token...\n",
            " 86% 7200/8340 [1:49:45<16:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:22,313 >> Initializing global attention on CLS token...\n",
            " 86% 7201/8340 [1:49:46<16:02,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:23,158 >> Initializing global attention on CLS token...\n",
            " 86% 7202/8340 [1:49:46<16:01,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:24,002 >> Initializing global attention on CLS token...\n",
            " 86% 7203/8340 [1:49:47<16:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:24,846 >> Initializing global attention on CLS token...\n",
            " 86% 7204/8340 [1:49:48<16:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:25,698 >> Initializing global attention on CLS token...\n",
            " 86% 7205/8340 [1:49:49<16:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:26,538 >> Initializing global attention on CLS token...\n",
            " 86% 7206/8340 [1:49:50<15:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:27,390 >> Initializing global attention on CLS token...\n",
            " 86% 7207/8340 [1:49:51<15:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:28,235 >> Initializing global attention on CLS token...\n",
            " 86% 7208/8340 [1:49:52<15:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:29,089 >> Initializing global attention on CLS token...\n",
            " 86% 7209/8340 [1:49:52<15:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:29,932 >> Initializing global attention on CLS token...\n",
            " 86% 7210/8340 [1:49:53<15:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:30,773 >> Initializing global attention on CLS token...\n",
            " 86% 7211/8340 [1:49:54<15:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:31,625 >> Initializing global attention on CLS token...\n",
            " 86% 7212/8340 [1:49:55<15:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:32,471 >> Initializing global attention on CLS token...\n",
            " 86% 7213/8340 [1:49:56<15:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:33,322 >> Initializing global attention on CLS token...\n",
            " 86% 7214/8340 [1:49:57<15:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:34,169 >> Initializing global attention on CLS token...\n",
            " 87% 7215/8340 [1:49:57<15:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:35,029 >> Initializing global attention on CLS token...\n",
            " 87% 7216/8340 [1:49:58<15:57,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:35,879 >> Initializing global attention on CLS token...\n",
            " 87% 7217/8340 [1:49:59<15:56,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:36,731 >> Initializing global attention on CLS token...\n",
            " 87% 7218/8340 [1:50:00<15:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:37,573 >> Initializing global attention on CLS token...\n",
            " 87% 7219/8340 [1:50:01<15:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:38,417 >> Initializing global attention on CLS token...\n",
            " 87% 7220/8340 [1:50:02<15:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:39,266 >> Initializing global attention on CLS token...\n",
            " 87% 7221/8340 [1:50:03<15:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:40,108 >> Initializing global attention on CLS token...\n",
            " 87% 7222/8340 [1:50:03<15:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:40,951 >> Initializing global attention on CLS token...\n",
            " 87% 7223/8340 [1:50:04<15:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:41,795 >> Initializing global attention on CLS token...\n",
            " 87% 7224/8340 [1:50:05<15:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:42,639 >> Initializing global attention on CLS token...\n",
            " 87% 7225/8340 [1:50:06<15:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:43,480 >> Initializing global attention on CLS token...\n",
            " 87% 7226/8340 [1:50:07<15:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:44,321 >> Initializing global attention on CLS token...\n",
            " 87% 7227/8340 [1:50:08<15:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:45,160 >> Initializing global attention on CLS token...\n",
            " 87% 7228/8340 [1:50:08<15:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:46,003 >> Initializing global attention on CLS token...\n",
            " 87% 7229/8340 [1:50:09<15:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:46,848 >> Initializing global attention on CLS token...\n",
            " 87% 7230/8340 [1:50:10<15:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:47,693 >> Initializing global attention on CLS token...\n",
            " 87% 7231/8340 [1:50:11<15:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:48,534 >> Initializing global attention on CLS token...\n",
            " 87% 7232/8340 [1:50:12<15:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:49,376 >> Initializing global attention on CLS token...\n",
            " 87% 7233/8340 [1:50:13<15:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:50,217 >> Initializing global attention on CLS token...\n",
            " 87% 7234/8340 [1:50:14<15:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:51,066 >> Initializing global attention on CLS token...\n",
            " 87% 7235/8340 [1:50:14<15:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:51,909 >> Initializing global attention on CLS token...\n",
            " 87% 7236/8340 [1:50:15<15:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:52,752 >> Initializing global attention on CLS token...\n",
            " 87% 7237/8340 [1:50:16<15:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:53,594 >> Initializing global attention on CLS token...\n",
            " 87% 7238/8340 [1:50:17<15:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:54,439 >> Initializing global attention on CLS token...\n",
            " 87% 7239/8340 [1:50:18<15:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:55,279 >> Initializing global attention on CLS token...\n",
            " 87% 7240/8340 [1:50:19<15:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:56,123 >> Initializing global attention on CLS token...\n",
            " 87% 7241/8340 [1:50:19<15:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:56,968 >> Initializing global attention on CLS token...\n",
            " 87% 7242/8340 [1:50:20<15:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:57,811 >> Initializing global attention on CLS token...\n",
            " 87% 7243/8340 [1:50:21<15:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:58,651 >> Initializing global attention on CLS token...\n",
            " 87% 7244/8340 [1:50:22<15:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:14:59,493 >> Initializing global attention on CLS token...\n",
            " 87% 7245/8340 [1:50:23<15:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:00,336 >> Initializing global attention on CLS token...\n",
            " 87% 7246/8340 [1:50:24<15:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:01,175 >> Initializing global attention on CLS token...\n",
            " 87% 7247/8340 [1:50:24<15:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:02,019 >> Initializing global attention on CLS token...\n",
            " 87% 7248/8340 [1:50:25<15:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:02,861 >> Initializing global attention on CLS token...\n",
            " 87% 7249/8340 [1:50:26<15:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:03,701 >> Initializing global attention on CLS token...\n",
            " 87% 7250/8340 [1:50:27<15:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:04,549 >> Initializing global attention on CLS token...\n",
            " 87% 7251/8340 [1:50:28<15:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:05,396 >> Initializing global attention on CLS token...\n",
            " 87% 7252/8340 [1:50:29<15:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:06,247 >> Initializing global attention on CLS token...\n",
            " 87% 7253/8340 [1:50:30<15:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:07,094 >> Initializing global attention on CLS token...\n",
            " 87% 7254/8340 [1:50:30<15:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:07,936 >> Initializing global attention on CLS token...\n",
            " 87% 7255/8340 [1:50:31<15:19,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:08,786 >> Initializing global attention on CLS token...\n",
            " 87% 7256/8340 [1:50:32<15:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:09,632 >> Initializing global attention on CLS token...\n",
            " 87% 7257/8340 [1:50:33<15:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:10,471 >> Initializing global attention on CLS token...\n",
            " 87% 7258/8340 [1:50:34<15:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:11,310 >> Initializing global attention on CLS token...\n",
            " 87% 7259/8340 [1:50:35<15:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:12,154 >> Initializing global attention on CLS token...\n",
            " 87% 7260/8340 [1:50:35<15:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:13,000 >> Initializing global attention on CLS token...\n",
            " 87% 7261/8340 [1:50:36<15:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:13,845 >> Initializing global attention on CLS token...\n",
            " 87% 7262/8340 [1:50:37<15:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:14,686 >> Initializing global attention on CLS token...\n",
            " 87% 7263/8340 [1:50:38<15:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:15,530 >> Initializing global attention on CLS token...\n",
            " 87% 7264/8340 [1:50:39<15:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:16,371 >> Initializing global attention on CLS token...\n",
            " 87% 7265/8340 [1:50:40<15:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:17,209 >> Initializing global attention on CLS token...\n",
            " 87% 7266/8340 [1:50:41<15:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:18,054 >> Initializing global attention on CLS token...\n",
            " 87% 7267/8340 [1:50:41<15:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:18,898 >> Initializing global attention on CLS token...\n",
            " 87% 7268/8340 [1:50:42<15:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:19,743 >> Initializing global attention on CLS token...\n",
            " 87% 7269/8340 [1:50:43<15:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:20,581 >> Initializing global attention on CLS token...\n",
            " 87% 7270/8340 [1:50:44<14:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:21,418 >> Initializing global attention on CLS token...\n",
            " 87% 7271/8340 [1:50:45<14:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:22,264 >> Initializing global attention on CLS token...\n",
            " 87% 7272/8340 [1:50:46<14:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:23,103 >> Initializing global attention on CLS token...\n",
            " 87% 7273/8340 [1:50:46<14:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:23,945 >> Initializing global attention on CLS token...\n",
            " 87% 7274/8340 [1:50:47<14:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:24,786 >> Initializing global attention on CLS token...\n",
            " 87% 7275/8340 [1:50:48<14:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:25,628 >> Initializing global attention on CLS token...\n",
            " 87% 7276/8340 [1:50:49<14:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:26,467 >> Initializing global attention on CLS token...\n",
            " 87% 7277/8340 [1:50:50<14:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:27,307 >> Initializing global attention on CLS token...\n",
            " 87% 7278/8340 [1:50:51<14:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:28,146 >> Initializing global attention on CLS token...\n",
            " 87% 7279/8340 [1:50:51<14:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:28,990 >> Initializing global attention on CLS token...\n",
            " 87% 7280/8340 [1:50:52<14:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:29,829 >> Initializing global attention on CLS token...\n",
            " 87% 7281/8340 [1:50:53<14:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:30,680 >> Initializing global attention on CLS token...\n",
            " 87% 7282/8340 [1:50:54<14:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:31,520 >> Initializing global attention on CLS token...\n",
            " 87% 7283/8340 [1:50:55<14:52,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:32,366 >> Initializing global attention on CLS token...\n",
            " 87% 7284/8340 [1:50:56<14:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:33,205 >> Initializing global attention on CLS token...\n",
            " 87% 7285/8340 [1:50:57<14:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:34,043 >> Initializing global attention on CLS token...\n",
            " 87% 7286/8340 [1:50:57<14:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:34,886 >> Initializing global attention on CLS token...\n",
            " 87% 7287/8340 [1:50:58<14:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:35,732 >> Initializing global attention on CLS token...\n",
            " 87% 7288/8340 [1:50:59<14:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:36,573 >> Initializing global attention on CLS token...\n",
            " 87% 7289/8340 [1:51:00<14:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:37,416 >> Initializing global attention on CLS token...\n",
            " 87% 7290/8340 [1:51:01<14:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:38,262 >> Initializing global attention on CLS token...\n",
            " 87% 7291/8340 [1:51:02<14:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:39,106 >> Initializing global attention on CLS token...\n",
            " 87% 7292/8340 [1:51:02<14:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:39,949 >> Initializing global attention on CLS token...\n",
            " 87% 7293/8340 [1:51:03<14:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:40,791 >> Initializing global attention on CLS token...\n",
            " 87% 7294/8340 [1:51:04<14:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:41,628 >> Initializing global attention on CLS token...\n",
            " 87% 7295/8340 [1:51:05<14:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:42,473 >> Initializing global attention on CLS token...\n",
            " 87% 7296/8340 [1:51:06<14:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:43,313 >> Initializing global attention on CLS token...\n",
            " 87% 7297/8340 [1:51:07<14:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:44,155 >> Initializing global attention on CLS token...\n",
            " 88% 7298/8340 [1:51:07<14:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:45,004 >> Initializing global attention on CLS token...\n",
            " 88% 7299/8340 [1:51:08<14:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:45,845 >> Initializing global attention on CLS token...\n",
            " 88% 7300/8340 [1:51:09<14:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:46,688 >> Initializing global attention on CLS token...\n",
            " 88% 7301/8340 [1:51:10<14:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:47,536 >> Initializing global attention on CLS token...\n",
            " 88% 7302/8340 [1:51:11<14:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:48,372 >> Initializing global attention on CLS token...\n",
            " 88% 7303/8340 [1:51:12<14:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:49,210 >> Initializing global attention on CLS token...\n",
            " 88% 7304/8340 [1:51:13<14:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:50,055 >> Initializing global attention on CLS token...\n",
            " 88% 7305/8340 [1:51:13<14:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:50,897 >> Initializing global attention on CLS token...\n",
            " 88% 7306/8340 [1:51:14<14:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:51,745 >> Initializing global attention on CLS token...\n",
            " 88% 7307/8340 [1:51:15<14:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:52,586 >> Initializing global attention on CLS token...\n",
            " 88% 7308/8340 [1:51:16<14:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:53,431 >> Initializing global attention on CLS token...\n",
            " 88% 7309/8340 [1:51:17<14:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:54,274 >> Initializing global attention on CLS token...\n",
            " 88% 7310/8340 [1:51:18<14:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:55,118 >> Initializing global attention on CLS token...\n",
            " 88% 7311/8340 [1:51:18<14:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:55,958 >> Initializing global attention on CLS token...\n",
            " 88% 7312/8340 [1:51:19<14:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:56,797 >> Initializing global attention on CLS token...\n",
            " 88% 7313/8340 [1:51:20<14:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:57,647 >> Initializing global attention on CLS token...\n",
            " 88% 7314/8340 [1:51:21<14:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:58,486 >> Initializing global attention on CLS token...\n",
            " 88% 7315/8340 [1:51:22<14:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:15:59,330 >> Initializing global attention on CLS token...\n",
            " 88% 7316/8340 [1:51:23<14:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:00,175 >> Initializing global attention on CLS token...\n",
            " 88% 7317/8340 [1:51:23<14:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:01,020 >> Initializing global attention on CLS token...\n",
            " 88% 7318/8340 [1:51:24<14:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:01,862 >> Initializing global attention on CLS token...\n",
            " 88% 7319/8340 [1:51:25<14:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:02,705 >> Initializing global attention on CLS token...\n",
            " 88% 7320/8340 [1:51:26<14:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:03,558 >> Initializing global attention on CLS token...\n",
            " 88% 7321/8340 [1:51:27<14:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:04,407 >> Initializing global attention on CLS token...\n",
            " 88% 7322/8340 [1:51:28<14:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:05,257 >> Initializing global attention on CLS token...\n",
            " 88% 7323/8340 [1:51:29<14:22,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:06,105 >> Initializing global attention on CLS token...\n",
            " 88% 7324/8340 [1:51:29<14:20,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:06,947 >> Initializing global attention on CLS token...\n",
            " 88% 7325/8340 [1:51:30<14:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:07,791 >> Initializing global attention on CLS token...\n",
            " 88% 7326/8340 [1:51:31<14:16,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:08,633 >> Initializing global attention on CLS token...\n",
            " 88% 7327/8340 [1:51:32<14:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:09,477 >> Initializing global attention on CLS token...\n",
            " 88% 7328/8340 [1:51:33<14:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:10,326 >> Initializing global attention on CLS token...\n",
            " 88% 7329/8340 [1:51:34<14:14,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:11,168 >> Initializing global attention on CLS token...\n",
            " 88% 7330/8340 [1:51:34<14:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:12,005 >> Initializing global attention on CLS token...\n",
            " 88% 7331/8340 [1:51:35<14:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:12,845 >> Initializing global attention on CLS token...\n",
            " 88% 7332/8340 [1:51:36<14:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:13,690 >> Initializing global attention on CLS token...\n",
            " 88% 7333/8340 [1:51:37<14:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:14,528 >> Initializing global attention on CLS token...\n",
            " 88% 7334/8340 [1:51:38<14:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:15,374 >> Initializing global attention on CLS token...\n",
            " 88% 7335/8340 [1:51:39<14:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:16,219 >> Initializing global attention on CLS token...\n",
            " 88% 7336/8340 [1:51:40<14:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:17,060 >> Initializing global attention on CLS token...\n",
            " 88% 7337/8340 [1:51:40<14:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:17,902 >> Initializing global attention on CLS token...\n",
            " 88% 7338/8340 [1:51:41<14:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:18,739 >> Initializing global attention on CLS token...\n",
            " 88% 7339/8340 [1:51:42<14:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:19,582 >> Initializing global attention on CLS token...\n",
            " 88% 7340/8340 [1:51:43<14:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:20,422 >> Initializing global attention on CLS token...\n",
            " 88% 7341/8340 [1:51:44<13:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:21,258 >> Initializing global attention on CLS token...\n",
            " 88% 7342/8340 [1:51:45<13:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:22,108 >> Initializing global attention on CLS token...\n",
            " 88% 7343/8340 [1:51:45<13:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:22,947 >> Initializing global attention on CLS token...\n",
            " 88% 7344/8340 [1:51:46<13:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:23,795 >> Initializing global attention on CLS token...\n",
            " 88% 7345/8340 [1:51:47<13:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:24,633 >> Initializing global attention on CLS token...\n",
            " 88% 7346/8340 [1:51:48<13:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:25,478 >> Initializing global attention on CLS token...\n",
            " 88% 7347/8340 [1:51:49<13:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:26,321 >> Initializing global attention on CLS token...\n",
            " 88% 7348/8340 [1:51:50<13:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:27,162 >> Initializing global attention on CLS token...\n",
            " 88% 7349/8340 [1:51:50<13:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:28,006 >> Initializing global attention on CLS token...\n",
            " 88% 7350/8340 [1:51:51<13:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:28,846 >> Initializing global attention on CLS token...\n",
            " 88% 7351/8340 [1:51:52<13:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:29,689 >> Initializing global attention on CLS token...\n",
            " 88% 7352/8340 [1:51:53<13:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:30,528 >> Initializing global attention on CLS token...\n",
            " 88% 7353/8340 [1:51:54<13:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:31,367 >> Initializing global attention on CLS token...\n",
            " 88% 7354/8340 [1:51:55<13:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:32,209 >> Initializing global attention on CLS token...\n",
            " 88% 7355/8340 [1:51:56<13:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:33,048 >> Initializing global attention on CLS token...\n",
            " 88% 7356/8340 [1:51:56<13:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:33,891 >> Initializing global attention on CLS token...\n",
            " 88% 7357/8340 [1:51:57<13:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:34,732 >> Initializing global attention on CLS token...\n",
            " 88% 7358/8340 [1:51:58<13:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:35,575 >> Initializing global attention on CLS token...\n",
            " 88% 7359/8340 [1:51:59<13:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:36,417 >> Initializing global attention on CLS token...\n",
            " 88% 7360/8340 [1:52:00<13:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:37,258 >> Initializing global attention on CLS token...\n",
            " 88% 7361/8340 [1:52:01<13:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:38,100 >> Initializing global attention on CLS token...\n",
            " 88% 7362/8340 [1:52:01<13:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:38,939 >> Initializing global attention on CLS token...\n",
            " 88% 7363/8340 [1:52:02<13:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:39,791 >> Initializing global attention on CLS token...\n",
            " 88% 7364/8340 [1:52:03<13:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:40,629 >> Initializing global attention on CLS token...\n",
            " 88% 7365/8340 [1:52:04<13:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:41,471 >> Initializing global attention on CLS token...\n",
            " 88% 7366/8340 [1:52:05<13:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:42,310 >> Initializing global attention on CLS token...\n",
            " 88% 7367/8340 [1:52:06<13:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:43,154 >> Initializing global attention on CLS token...\n",
            " 88% 7368/8340 [1:52:06<13:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:43,994 >> Initializing global attention on CLS token...\n",
            " 88% 7369/8340 [1:52:07<13:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:44,832 >> Initializing global attention on CLS token...\n",
            " 88% 7370/8340 [1:52:08<13:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:45,673 >> Initializing global attention on CLS token...\n",
            " 88% 7371/8340 [1:52:09<13:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:46,517 >> Initializing global attention on CLS token...\n",
            " 88% 7372/8340 [1:52:10<13:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:47,364 >> Initializing global attention on CLS token...\n",
            " 88% 7373/8340 [1:52:11<13:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:48,209 >> Initializing global attention on CLS token...\n",
            " 88% 7374/8340 [1:52:12<13:35,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:49,052 >> Initializing global attention on CLS token...\n",
            " 88% 7375/8340 [1:52:12<13:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:49,889 >> Initializing global attention on CLS token...\n",
            " 88% 7376/8340 [1:52:13<13:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:50,732 >> Initializing global attention on CLS token...\n",
            " 88% 7377/8340 [1:52:14<13:32,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:51,581 >> Initializing global attention on CLS token...\n",
            " 88% 7378/8340 [1:52:15<13:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:52,426 >> Initializing global attention on CLS token...\n",
            " 88% 7379/8340 [1:52:16<13:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:53,278 >> Initializing global attention on CLS token...\n",
            " 88% 7380/8340 [1:52:17<13:33,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:54,124 >> Initializing global attention on CLS token...\n",
            " 89% 7381/8340 [1:52:17<13:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:54,966 >> Initializing global attention on CLS token...\n",
            " 89% 7382/8340 [1:52:18<13:29,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:55,809 >> Initializing global attention on CLS token...\n",
            " 89% 7383/8340 [1:52:19<13:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:56,650 >> Initializing global attention on CLS token...\n",
            " 89% 7384/8340 [1:52:20<13:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:57,489 >> Initializing global attention on CLS token...\n",
            " 89% 7385/8340 [1:52:21<13:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:58,333 >> Initializing global attention on CLS token...\n",
            " 89% 7386/8340 [1:52:22<13:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:16:59,174 >> Initializing global attention on CLS token...\n",
            " 89% 7387/8340 [1:52:22<13:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:00,022 >> Initializing global attention on CLS token...\n",
            " 89% 7388/8340 [1:52:23<13:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:00,866 >> Initializing global attention on CLS token...\n",
            " 89% 7389/8340 [1:52:24<13:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:01,706 >> Initializing global attention on CLS token...\n",
            " 89% 7390/8340 [1:52:25<13:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:02,549 >> Initializing global attention on CLS token...\n",
            " 89% 7391/8340 [1:52:26<13:21,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:03,395 >> Initializing global attention on CLS token...\n",
            " 89% 7392/8340 [1:52:27<13:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:04,235 >> Initializing global attention on CLS token...\n",
            " 89% 7393/8340 [1:52:28<13:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:05,074 >> Initializing global attention on CLS token...\n",
            " 89% 7394/8340 [1:52:28<13:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:05,920 >> Initializing global attention on CLS token...\n",
            " 89% 7395/8340 [1:52:29<13:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:06,760 >> Initializing global attention on CLS token...\n",
            " 89% 7396/8340 [1:52:30<13:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:07,602 >> Initializing global attention on CLS token...\n",
            " 89% 7397/8340 [1:52:31<13:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:08,439 >> Initializing global attention on CLS token...\n",
            " 89% 7398/8340 [1:52:32<13:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:09,277 >> Initializing global attention on CLS token...\n",
            " 89% 7399/8340 [1:52:33<13:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:10,117 >> Initializing global attention on CLS token...\n",
            " 89% 7400/8340 [1:52:33<13:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:10,956 >> Initializing global attention on CLS token...\n",
            " 89% 7401/8340 [1:52:34<13:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:11,800 >> Initializing global attention on CLS token...\n",
            " 89% 7402/8340 [1:52:35<13:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:12,645 >> Initializing global attention on CLS token...\n",
            " 89% 7403/8340 [1:52:36<13:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:13,488 >> Initializing global attention on CLS token...\n",
            " 89% 7404/8340 [1:52:37<13:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:14,332 >> Initializing global attention on CLS token...\n",
            " 89% 7405/8340 [1:52:38<13:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:15,185 >> Initializing global attention on CLS token...\n",
            " 89% 7406/8340 [1:52:38<13:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:16,029 >> Initializing global attention on CLS token...\n",
            " 89% 7407/8340 [1:52:39<13:07,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:16,869 >> Initializing global attention on CLS token...\n",
            " 89% 7408/8340 [1:52:40<13:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:17,712 >> Initializing global attention on CLS token...\n",
            " 89% 7409/8340 [1:52:41<13:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:18,557 >> Initializing global attention on CLS token...\n",
            " 89% 7410/8340 [1:52:42<13:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:19,400 >> Initializing global attention on CLS token...\n",
            " 89% 7411/8340 [1:52:43<13:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:20,241 >> Initializing global attention on CLS token...\n",
            " 89% 7412/8340 [1:52:44<13:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:21,080 >> Initializing global attention on CLS token...\n",
            " 89% 7413/8340 [1:52:44<13:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:21,924 >> Initializing global attention on CLS token...\n",
            " 89% 7414/8340 [1:52:45<12:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:22,765 >> Initializing global attention on CLS token...\n",
            " 89% 7415/8340 [1:52:46<12:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:23,604 >> Initializing global attention on CLS token...\n",
            " 89% 7416/8340 [1:52:47<12:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:24,444 >> Initializing global attention on CLS token...\n",
            " 89% 7417/8340 [1:52:48<12:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:25,291 >> Initializing global attention on CLS token...\n",
            " 89% 7418/8340 [1:52:49<12:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:26,137 >> Initializing global attention on CLS token...\n",
            " 89% 7419/8340 [1:52:49<12:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:26,980 >> Initializing global attention on CLS token...\n",
            " 89% 7420/8340 [1:52:50<12:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:27,826 >> Initializing global attention on CLS token...\n",
            " 89% 7421/8340 [1:52:51<12:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:28,675 >> Initializing global attention on CLS token...\n",
            " 89% 7422/8340 [1:52:52<12:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:29,519 >> Initializing global attention on CLS token...\n",
            " 89% 7423/8340 [1:52:53<12:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:30,362 >> Initializing global attention on CLS token...\n",
            " 89% 7424/8340 [1:52:54<12:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:31,206 >> Initializing global attention on CLS token...\n",
            " 89% 7425/8340 [1:52:55<12:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:32,048 >> Initializing global attention on CLS token...\n",
            " 89% 7426/8340 [1:52:55<12:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:32,891 >> Initializing global attention on CLS token...\n",
            " 89% 7427/8340 [1:52:56<12:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:33,731 >> Initializing global attention on CLS token...\n",
            " 89% 7428/8340 [1:52:57<12:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:34,577 >> Initializing global attention on CLS token...\n",
            " 89% 7429/8340 [1:52:58<12:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:35,419 >> Initializing global attention on CLS token...\n",
            " 89% 7430/8340 [1:52:59<12:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:36,261 >> Initializing global attention on CLS token...\n",
            " 89% 7431/8340 [1:53:00<12:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:37,102 >> Initializing global attention on CLS token...\n",
            " 89% 7432/8340 [1:53:00<12:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:37,940 >> Initializing global attention on CLS token...\n",
            " 89% 7433/8340 [1:53:01<12:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:38,782 >> Initializing global attention on CLS token...\n",
            " 89% 7434/8340 [1:53:02<12:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:39,623 >> Initializing global attention on CLS token...\n",
            " 89% 7435/8340 [1:53:03<12:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:40,463 >> Initializing global attention on CLS token...\n",
            " 89% 7436/8340 [1:53:04<12:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:41,300 >> Initializing global attention on CLS token...\n",
            " 89% 7437/8340 [1:53:05<12:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:42,141 >> Initializing global attention on CLS token...\n",
            " 89% 7438/8340 [1:53:05<12:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:42,983 >> Initializing global attention on CLS token...\n",
            " 89% 7439/8340 [1:53:06<12:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:43,822 >> Initializing global attention on CLS token...\n",
            " 89% 7440/8340 [1:53:07<12:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:44,663 >> Initializing global attention on CLS token...\n",
            " 89% 7441/8340 [1:53:08<12:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:45,506 >> Initializing global attention on CLS token...\n",
            " 89% 7442/8340 [1:53:09<12:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:46,344 >> Initializing global attention on CLS token...\n",
            " 89% 7443/8340 [1:53:10<12:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:47,183 >> Initializing global attention on CLS token...\n",
            " 89% 7444/8340 [1:53:10<12:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:48,023 >> Initializing global attention on CLS token...\n",
            " 89% 7445/8340 [1:53:11<12:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:48,863 >> Initializing global attention on CLS token...\n",
            " 89% 7446/8340 [1:53:12<12:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:49,708 >> Initializing global attention on CLS token...\n",
            " 89% 7447/8340 [1:53:13<12:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:50,550 >> Initializing global attention on CLS token...\n",
            " 89% 7448/8340 [1:53:14<12:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:51,388 >> Initializing global attention on CLS token...\n",
            " 89% 7449/8340 [1:53:15<12:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:52,232 >> Initializing global attention on CLS token...\n",
            " 89% 7450/8340 [1:53:16<12:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:53,073 >> Initializing global attention on CLS token...\n",
            " 89% 7451/8340 [1:53:16<12:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:53,913 >> Initializing global attention on CLS token...\n",
            " 89% 7452/8340 [1:53:17<12:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:54,755 >> Initializing global attention on CLS token...\n",
            " 89% 7453/8340 [1:53:18<12:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:55,603 >> Initializing global attention on CLS token...\n",
            " 89% 7454/8340 [1:53:19<12:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:56,444 >> Initializing global attention on CLS token...\n",
            " 89% 7455/8340 [1:53:20<12:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:57,286 >> Initializing global attention on CLS token...\n",
            " 89% 7456/8340 [1:53:21<12:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:58,131 >> Initializing global attention on CLS token...\n",
            " 89% 7457/8340 [1:53:21<12:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:58,970 >> Initializing global attention on CLS token...\n",
            " 89% 7458/8340 [1:53:22<12:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:17:59,812 >> Initializing global attention on CLS token...\n",
            " 89% 7459/8340 [1:53:23<12:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:00,655 >> Initializing global attention on CLS token...\n",
            " 89% 7460/8340 [1:53:24<12:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:01,494 >> Initializing global attention on CLS token...\n",
            " 89% 7461/8340 [1:53:25<12:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:02,337 >> Initializing global attention on CLS token...\n",
            " 89% 7462/8340 [1:53:26<12:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:03,174 >> Initializing global attention on CLS token...\n",
            " 89% 7463/8340 [1:53:26<12:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:04,014 >> Initializing global attention on CLS token...\n",
            " 89% 7464/8340 [1:53:27<12:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:04,854 >> Initializing global attention on CLS token...\n",
            " 90% 7465/8340 [1:53:28<12:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:05,698 >> Initializing global attention on CLS token...\n",
            " 90% 7466/8340 [1:53:29<12:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:06,538 >> Initializing global attention on CLS token...\n",
            " 90% 7467/8340 [1:53:30<12:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:07,382 >> Initializing global attention on CLS token...\n",
            " 90% 7468/8340 [1:53:31<12:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:08,226 >> Initializing global attention on CLS token...\n",
            " 90% 7469/8340 [1:53:32<12:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:09,072 >> Initializing global attention on CLS token...\n",
            " 90% 7470/8340 [1:53:32<12:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:09,911 >> Initializing global attention on CLS token...\n",
            " 90% 7471/8340 [1:53:33<12:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:10,751 >> Initializing global attention on CLS token...\n",
            " 90% 7472/8340 [1:53:34<12:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:11,589 >> Initializing global attention on CLS token...\n",
            " 90% 7473/8340 [1:53:35<12:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:12,433 >> Initializing global attention on CLS token...\n",
            " 90% 7474/8340 [1:53:36<12:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:13,277 >> Initializing global attention on CLS token...\n",
            " 90% 7475/8340 [1:53:37<12:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:14,122 >> Initializing global attention on CLS token...\n",
            " 90% 7476/8340 [1:53:37<12:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:14,963 >> Initializing global attention on CLS token...\n",
            " 90% 7477/8340 [1:53:38<12:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:15,806 >> Initializing global attention on CLS token...\n",
            " 90% 7478/8340 [1:53:39<12:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:16,650 >> Initializing global attention on CLS token...\n",
            " 90% 7479/8340 [1:53:40<12:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:17,495 >> Initializing global attention on CLS token...\n",
            " 90% 7480/8340 [1:53:41<12:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:18,338 >> Initializing global attention on CLS token...\n",
            " 90% 7481/8340 [1:53:42<12:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:19,185 >> Initializing global attention on CLS token...\n",
            " 90% 7482/8340 [1:53:42<12:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:20,029 >> Initializing global attention on CLS token...\n",
            " 90% 7483/8340 [1:53:43<12:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:20,869 >> Initializing global attention on CLS token...\n",
            " 90% 7484/8340 [1:53:44<12:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:21,713 >> Initializing global attention on CLS token...\n",
            " 90% 7485/8340 [1:53:45<12:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:22,560 >> Initializing global attention on CLS token...\n",
            " 90% 7486/8340 [1:53:46<12:00,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:23,401 >> Initializing global attention on CLS token...\n",
            " 90% 7487/8340 [1:53:47<11:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:24,244 >> Initializing global attention on CLS token...\n",
            " 90% 7488/8340 [1:53:48<11:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:25,087 >> Initializing global attention on CLS token...\n",
            " 90% 7489/8340 [1:53:48<11:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:25,930 >> Initializing global attention on CLS token...\n",
            " 90% 7490/8340 [1:53:49<11:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:26,774 >> Initializing global attention on CLS token...\n",
            " 90% 7491/8340 [1:53:50<11:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:27,622 >> Initializing global attention on CLS token...\n",
            " 90% 7492/8340 [1:53:51<11:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:28,462 >> Initializing global attention on CLS token...\n",
            " 90% 7493/8340 [1:53:52<11:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:29,305 >> Initializing global attention on CLS token...\n",
            " 90% 7494/8340 [1:53:53<11:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:30,148 >> Initializing global attention on CLS token...\n",
            " 90% 7495/8340 [1:53:53<11:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:30,988 >> Initializing global attention on CLS token...\n",
            " 90% 7496/8340 [1:53:54<11:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:31,831 >> Initializing global attention on CLS token...\n",
            " 90% 7497/8340 [1:53:55<11:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:32,672 >> Initializing global attention on CLS token...\n",
            " 90% 7498/8340 [1:53:56<11:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:33,511 >> Initializing global attention on CLS token...\n",
            " 90% 7499/8340 [1:53:57<11:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:34,353 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.039, 'learning_rate': 3.039568345323741e-06, 'epoch': 8.99}\n",
            " 90% 7500/8340 [1:53:58<12:26,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:35,361 >> Initializing global attention on CLS token...\n",
            " 90% 7501/8340 [1:53:59<12:16,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:36,203 >> Initializing global attention on CLS token...\n",
            " 90% 7502/8340 [1:54:00<12:06,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:37,049 >> Initializing global attention on CLS token...\n",
            " 90% 7503/8340 [1:54:00<12:00,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:37,892 >> Initializing global attention on CLS token...\n",
            " 90% 7504/8340 [1:54:01<11:55,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:38,736 >> Initializing global attention on CLS token...\n",
            " 90% 7505/8340 [1:54:02<11:50,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:18:39,557 >> Initializing global attention on CLS token...\n",
            " 90% 7506/8340 [1:54:02<09:36,  1.45it/s][INFO|trainer.py:725] 2022-12-10 00:18:39,863 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 00:18:39,865 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 00:18:39,865 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 00:18:39,866 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:39,896 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:40,170 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:31,  7.27it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:40,430 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:43,  5.30it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:40,686 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:49,  4.69it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:40,952 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:52,  4.33it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:41,205 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:54,  4.18it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:41,468 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:55,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:41,725 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:56,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:41,987 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:56,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:42,241 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:56,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:42,497 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:56,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:42,760 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:57,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:43,016 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:56,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:43,276 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:56,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:43,535 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:56,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:43,794 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:56,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:44,051 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:55,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:44,309 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:55,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:44,568 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:55,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:44,823 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:55,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:45,078 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:54,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:45,331 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:54,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:45,599 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:54,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:45,857 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:54,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:46,117 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:54,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:46,379 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:53,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:46,633 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:53,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:46,889 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:52,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:47,145 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:52,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:47,401 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:52,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:47,655 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:51,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:47,910 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:08<00:51,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:48,166 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:51,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:48,422 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:51,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:48,680 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:50,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:48,930 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:09<00:50,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:49,191 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:50,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:49,444 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:49,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:49,696 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:49,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:49,949 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:10<00:49,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:50,219 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:50,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:50,473 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:49,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:50,743 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:49,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:50,997 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:11<00:49,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:51,253 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:48,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:51,509 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:48,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:51,764 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:48,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:52,023 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:12<00:47,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:52,286 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:47,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:52,549 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:47,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:52,801 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:47,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:53,057 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:46,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:53,311 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:46,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:53,573 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:46,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:53,828 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:45,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:54,083 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:45,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:54,339 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:54,597 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:45,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:54,855 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:45,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:55,110 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:55,375 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:55,627 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:44,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:55,883 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:56,136 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:56,388 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:42,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:56,638 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:42,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:56,887 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:42,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:57,137 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:41,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:57,400 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:42,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:57,658 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:41,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:57,912 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:18<00:41,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:58,167 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:41,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:58,420 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:41,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:58,688 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:41,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:58,945 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:19<00:41,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:59,208 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:41,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:59,465 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:40,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:59,718 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:40,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:18:59,978 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:20<00:40,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:00,234 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:39,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:00,496 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:39,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:00,748 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:38,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:01,001 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:21<00:38,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:01,255 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:01,508 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:38,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:01,767 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:37,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:02,026 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:22<00:37,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:02,280 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:02,535 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:37,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:02,789 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:36,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:03,050 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:23<00:36,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:03,307 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:03,563 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:36,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:03,823 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:36,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:04,078 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:35,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:04,347 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:04,600 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:35,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:04,857 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:34,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:05,112 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:05,372 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:05,634 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:34,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:05,893 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:34,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:06,148 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:33,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:06,414 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:33,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:06,667 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:33,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:06,925 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:27<00:33,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:07,192 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:33,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:07,454 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:32,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:07,711 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:32,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:07,987 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:28<00:32,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:08,251 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:32,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:08,508 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:32,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:08,777 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:31,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:09,034 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:29<00:31,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:09,292 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:30,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:09,545 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:29<00:30,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:09,822 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:30,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:10,080 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:30<00:30,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:10,352 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:30,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:10,617 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:30<00:30,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:10,875 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:29,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:11,131 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:31<00:29,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:11,399 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:29,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:11,656 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:31<00:28,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:11,915 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:32<00:28,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:12,167 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:32<00:27,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:12,426 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:12,682 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:32<00:27,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:12,938 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:33<00:27,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:13,202 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:33<00:26,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:13,470 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:26,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:13,732 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:33<00:26,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:13,987 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:34<00:26,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:14,247 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:34<00:25,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:14,503 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:14,758 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:34<00:25,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:15,021 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:35<00:25,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:15,278 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:35<00:24,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:15,535 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:35<00:24,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:15,789 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:35<00:24,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:16,048 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:36<00:23,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:16,302 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:36<00:23,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:16,558 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:36<00:23,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:16,810 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:36<00:23,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:17,073 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:37<00:22,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:17,330 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:17,590 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:37<00:22,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:17,846 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:37<00:22,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:18,103 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:38<00:21,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:18,358 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:18,614 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:38<00:21,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:18,867 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:38<00:21,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:19,124 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:39<00:20,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:19,398 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:20,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:19,654 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:39<00:20,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:19,911 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:40<00:20,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:20,174 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:40<00:20,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:20,432 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:19,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:20,692 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:40<00:19,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:20,956 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:41<00:19,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:21,213 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:41<00:18,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:21,469 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:21,726 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:41<00:18,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:21,988 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:42<00:18,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:22,244 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:42<00:17,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:22,500 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:22,754 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:42<00:17,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:23,008 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:43<00:16,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:23,263 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:43<00:16,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:23,518 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:43<00:16,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:23,774 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:43<00:16,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:24,035 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:44<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:24,288 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:44<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:24,542 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:44<00:15,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:24,798 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:44<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:25,060 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:45<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:25,318 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:45<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:25,577 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:45<00:14,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:25,834 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:45<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:26,086 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:46<00:13,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:26,346 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:46<00:13,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:26,602 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:46<00:13,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:26,858 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:46<00:13,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:27,115 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:47<00:12,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:27,374 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:47<00:12,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:27,630 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:47<00:12,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:27,884 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:47<00:12,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:28,141 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:48<00:11,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:28,399 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:48<00:11,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:28,660 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:48<00:11,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:28,913 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:49<00:11,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:29,169 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:49<00:10,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:29,421 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:49<00:10,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:29,692 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:49<00:10,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:29,950 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:50<00:10,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:30,207 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:50<00:09,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:30,476 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:50<00:09,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:30,731 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:50<00:09,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:31,005 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:51<00:09,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:31,264 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:51<00:08,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:31,532 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:51<00:08,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:31,810 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:51<00:08,  3.73it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:32,073 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:52<00:08,  3.75it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:32,334 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:52<00:07,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:32,592 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:52<00:07,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:32,850 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:52<00:07,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:33,105 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:53<00:06,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:33,365 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:53<00:06,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:33,623 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:53<00:06,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:33,876 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:53<00:06,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:34,148 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:54<00:06,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:34,419 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:54<00:05,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:34,681 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:54<00:05,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:34,954 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:55<00:05,  3.75it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:35,217 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:55<00:05,  3.75it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:35,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:55<00:04,  3.75it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:35,745 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:55<00:04,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:36,002 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:56<00:04,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:36,255 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:56<00:03,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:36,514 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:56<00:03,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:36,772 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:56<00:03,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:37,046 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:57<00:03,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:37,300 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:57<00:02,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:37,566 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:57<00:02,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:37,830 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:57<00:02,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:38,084 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:58<00:02,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:38,344 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:58<00:01,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:38,602 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:58<00:01,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:38,855 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:58<00:01,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:39,109 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:59<00:01,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:39,384 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:59<00:00,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:39,660 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:59<00:00,  3.76it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:39,912 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [01:00<00:00,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:40,149 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.622255802154541, 'eval_f1-micro': 0.775, 'eval_f1-macro': 0.6893669989861765, 'eval_runtime': 60.6533, 'eval_samples_per_second': 23.082, 'eval_steps_per_second': 3.858, 'epoch': 9.0}\n",
            " 90% 7506/8340 [1:55:03<09:36,  1.45it/s]\n",
            "100% 234/234 [01:00<00:00,  3.81it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-10 00:19:40,521 >> Saving model checkpoint to logs/output_1/checkpoint-7506\n",
            "[INFO|configuration_utils.py:447] 2022-12-10 00:19:40,523 >> Configuration saved in logs/output_1/checkpoint-7506/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-10 00:19:40,915 >> Model weights saved in logs/output_1/checkpoint-7506/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-10 00:19:40,917 >> tokenizer config file saved in logs/output_1/checkpoint-7506/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-10 00:19:40,917 >> Special tokens file saved in logs/output_1/checkpoint-7506/special_tokens_map.json\n",
            "[INFO|trainer.py:1852] 2022-12-10 00:19:41,685 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1946] 2022-12-10 00:19:41,686 >> Loading best model from logs/output_1/checkpoint-3336 (score: 0.7821428571428573).\n",
            "{'train_runtime': 6904.8261, 'train_samples_per_second': 7.241, 'train_steps_per_second': 1.208, 'train_loss': 0.34983679655650984, 'epoch': 9.0}\n",
            " 90% 7506/8340 [1:55:04<12:47,  1.09it/s]\n",
            "[INFO|trainer.py:725] 2022-12-10 00:19:41,832 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 00:19:41,834 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 00:19:41,834 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 00:19:41,835 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 00:19:41,867 >> Initializing global attention on CLS token...\n",
            "  0% 0/234 [00:00<?, ?it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:42,123 >> Initializing global attention on CLS token...\n",
            "  1% 2/234 [00:00<00:29,  7.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:42,377 >> Initializing global attention on CLS token...\n",
            "  1% 3/234 [00:00<00:41,  5.57it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:42,630 >> Initializing global attention on CLS token...\n",
            "  2% 4/234 [00:00<00:47,  4.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:42,887 >> Initializing global attention on CLS token...\n",
            "  2% 5/234 [00:01<00:51,  4.44it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:43,142 >> Initializing global attention on CLS token...\n",
            "  3% 6/234 [00:01<00:53,  4.25it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:43,403 >> Initializing global attention on CLS token...\n",
            "  3% 7/234 [00:01<00:55,  4.12it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:43,665 >> Initializing global attention on CLS token...\n",
            "  3% 8/234 [00:01<00:56,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:43,919 >> Initializing global attention on CLS token...\n",
            "  4% 9/234 [00:02<00:56,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:44,181 >> Initializing global attention on CLS token...\n",
            "  4% 10/234 [00:02<00:57,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:44,437 >> Initializing global attention on CLS token...\n",
            "  5% 11/234 [00:02<00:56,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:44,696 >> Initializing global attention on CLS token...\n",
            "  5% 12/234 [00:02<00:56,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:44,950 >> Initializing global attention on CLS token...\n",
            "  6% 13/234 [00:03<00:56,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:45,229 >> Initializing global attention on CLS token...\n",
            "  6% 14/234 [00:03<00:57,  3.82it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:45,486 >> Initializing global attention on CLS token...\n",
            "  6% 15/234 [00:03<00:57,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:45,755 >> Initializing global attention on CLS token...\n",
            "  7% 16/234 [00:03<00:57,  3.81it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:46,030 >> Initializing global attention on CLS token...\n",
            "  7% 17/234 [00:04<00:58,  3.74it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:46,299 >> Initializing global attention on CLS token...\n",
            "  8% 18/234 [00:04<00:57,  3.73it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:46,557 >> Initializing global attention on CLS token...\n",
            "  8% 19/234 [00:04<00:56,  3.78it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:46,834 >> Initializing global attention on CLS token...\n",
            "  9% 20/234 [00:04<00:57,  3.74it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:47,092 >> Initializing global attention on CLS token...\n",
            "  9% 21/234 [00:05<00:56,  3.77it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:47,364 >> Initializing global attention on CLS token...\n",
            "  9% 22/234 [00:05<00:56,  3.74it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:47,645 >> Initializing global attention on CLS token...\n",
            " 10% 23/234 [00:05<00:57,  3.69it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:47,904 >> Initializing global attention on CLS token...\n",
            " 10% 24/234 [00:06<00:56,  3.73it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:48,161 >> Initializing global attention on CLS token...\n",
            " 11% 25/234 [00:06<00:55,  3.78it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:48,436 >> Initializing global attention on CLS token...\n",
            " 11% 26/234 [00:06<00:55,  3.73it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:48,699 >> Initializing global attention on CLS token...\n",
            " 12% 27/234 [00:06<00:55,  3.76it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:48,955 >> Initializing global attention on CLS token...\n",
            " 12% 28/234 [00:07<00:54,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:49,216 >> Initializing global attention on CLS token...\n",
            " 12% 29/234 [00:07<00:53,  3.81it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:49,472 >> Initializing global attention on CLS token...\n",
            " 13% 30/234 [00:07<00:53,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:49,739 >> Initializing global attention on CLS token...\n",
            " 13% 31/234 [00:07<00:53,  3.81it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:49,993 >> Initializing global attention on CLS token...\n",
            " 14% 32/234 [00:08<00:52,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:50,260 >> Initializing global attention on CLS token...\n",
            " 14% 33/234 [00:08<00:52,  3.81it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:50,514 >> Initializing global attention on CLS token...\n",
            " 15% 34/234 [00:08<00:51,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:50,776 >> Initializing global attention on CLS token...\n",
            " 15% 35/234 [00:08<00:51,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:51,030 >> Initializing global attention on CLS token...\n",
            " 15% 36/234 [00:09<00:50,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:51,282 >> Initializing global attention on CLS token...\n",
            " 16% 37/234 [00:09<00:50,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:51,534 >> Initializing global attention on CLS token...\n",
            " 16% 38/234 [00:09<00:50,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:51,791 >> Initializing global attention on CLS token...\n",
            " 17% 39/234 [00:09<00:49,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:52,047 >> Initializing global attention on CLS token...\n",
            " 17% 40/234 [00:10<00:49,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:52,304 >> Initializing global attention on CLS token...\n",
            " 18% 41/234 [00:10<00:49,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:52,569 >> Initializing global attention on CLS token...\n",
            " 18% 42/234 [00:10<00:49,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:52,820 >> Initializing global attention on CLS token...\n",
            " 18% 43/234 [00:10<00:49,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:53,074 >> Initializing global attention on CLS token...\n",
            " 19% 44/234 [00:11<00:48,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:53,328 >> Initializing global attention on CLS token...\n",
            " 19% 45/234 [00:11<00:48,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:53,586 >> Initializing global attention on CLS token...\n",
            " 20% 46/234 [00:11<00:48,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:53,839 >> Initializing global attention on CLS token...\n",
            " 20% 47/234 [00:11<00:47,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:54,096 >> Initializing global attention on CLS token...\n",
            " 21% 48/234 [00:12<00:47,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:54,350 >> Initializing global attention on CLS token...\n",
            " 21% 49/234 [00:12<00:47,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:54,608 >> Initializing global attention on CLS token...\n",
            " 21% 50/234 [00:12<00:47,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:54,872 >> Initializing global attention on CLS token...\n",
            " 22% 51/234 [00:13<00:47,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:55,131 >> Initializing global attention on CLS token...\n",
            " 22% 52/234 [00:13<00:46,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:55,387 >> Initializing global attention on CLS token...\n",
            " 23% 53/234 [00:13<00:46,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:55,641 >> Initializing global attention on CLS token...\n",
            " 23% 54/234 [00:13<00:46,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:55,897 >> Initializing global attention on CLS token...\n",
            " 24% 55/234 [00:14<00:45,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:56,150 >> Initializing global attention on CLS token...\n",
            " 24% 56/234 [00:14<00:45,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:56,406 >> Initializing global attention on CLS token...\n",
            " 24% 57/234 [00:14<00:45,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:56,659 >> Initializing global attention on CLS token...\n",
            " 25% 58/234 [00:14<00:44,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:56,920 >> Initializing global attention on CLS token...\n",
            " 25% 59/234 [00:15<00:44,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:57,177 >> Initializing global attention on CLS token...\n",
            " 26% 60/234 [00:15<00:44,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:57,434 >> Initializing global attention on CLS token...\n",
            " 26% 61/234 [00:15<00:44,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:57,700 >> Initializing global attention on CLS token...\n",
            " 26% 62/234 [00:15<00:44,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:57,963 >> Initializing global attention on CLS token...\n",
            " 27% 63/234 [00:16<00:44,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:58,216 >> Initializing global attention on CLS token...\n",
            " 27% 64/234 [00:16<00:43,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:58,472 >> Initializing global attention on CLS token...\n",
            " 28% 65/234 [00:16<00:43,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:58,725 >> Initializing global attention on CLS token...\n",
            " 28% 66/234 [00:16<00:43,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:58,980 >> Initializing global attention on CLS token...\n",
            " 29% 67/234 [00:17<00:42,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:59,240 >> Initializing global attention on CLS token...\n",
            " 29% 68/234 [00:17<00:42,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:59,491 >> Initializing global attention on CLS token...\n",
            " 29% 69/234 [00:17<00:42,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:59,743 >> Initializing global attention on CLS token...\n",
            " 30% 70/234 [00:17<00:41,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:19:59,999 >> Initializing global attention on CLS token...\n",
            " 30% 71/234 [00:18<00:41,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:00,261 >> Initializing global attention on CLS token...\n",
            " 31% 72/234 [00:18<00:41,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:00,525 >> Initializing global attention on CLS token...\n",
            " 31% 73/234 [00:18<00:41,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:00,785 >> Initializing global attention on CLS token...\n",
            " 32% 74/234 [00:18<00:41,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:01,046 >> Initializing global attention on CLS token...\n",
            " 32% 75/234 [00:19<00:41,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:01,299 >> Initializing global attention on CLS token...\n",
            " 32% 76/234 [00:19<00:40,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:01,558 >> Initializing global attention on CLS token...\n",
            " 33% 77/234 [00:19<00:40,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:01,811 >> Initializing global attention on CLS token...\n",
            " 33% 78/234 [00:19<00:40,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:02,072 >> Initializing global attention on CLS token...\n",
            " 34% 79/234 [00:20<00:39,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:02,328 >> Initializing global attention on CLS token...\n",
            " 34% 80/234 [00:20<00:39,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:02,582 >> Initializing global attention on CLS token...\n",
            " 35% 81/234 [00:20<00:39,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:02,850 >> Initializing global attention on CLS token...\n",
            " 35% 82/234 [00:20<00:39,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:03,110 >> Initializing global attention on CLS token...\n",
            " 35% 83/234 [00:21<00:39,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:03,372 >> Initializing global attention on CLS token...\n",
            " 36% 84/234 [00:21<00:39,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:03,625 >> Initializing global attention on CLS token...\n",
            " 36% 85/234 [00:21<00:38,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:03,886 >> Initializing global attention on CLS token...\n",
            " 37% 86/234 [00:22<00:38,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:04,151 >> Initializing global attention on CLS token...\n",
            " 37% 87/234 [00:22<00:38,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:04,410 >> Initializing global attention on CLS token...\n",
            " 38% 88/234 [00:22<00:37,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:04,682 >> Initializing global attention on CLS token...\n",
            " 38% 89/234 [00:22<00:38,  3.78it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:04,944 >> Initializing global attention on CLS token...\n",
            " 38% 90/234 [00:23<00:37,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:05,214 >> Initializing global attention on CLS token...\n",
            " 39% 91/234 [00:23<00:37,  3.77it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:05,485 >> Initializing global attention on CLS token...\n",
            " 39% 92/234 [00:23<00:37,  3.75it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:05,739 >> Initializing global attention on CLS token...\n",
            " 40% 93/234 [00:23<00:37,  3.81it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:06,000 >> Initializing global attention on CLS token...\n",
            " 40% 94/234 [00:24<00:36,  3.82it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:06,255 >> Initializing global attention on CLS token...\n",
            " 41% 95/234 [00:24<00:36,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:06,517 >> Initializing global attention on CLS token...\n",
            " 41% 96/234 [00:24<00:36,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:06,777 >> Initializing global attention on CLS token...\n",
            " 41% 97/234 [00:24<00:35,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:07,029 >> Initializing global attention on CLS token...\n",
            " 42% 98/234 [00:25<00:35,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:07,296 >> Initializing global attention on CLS token...\n",
            " 42% 99/234 [00:25<00:35,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:07,550 >> Initializing global attention on CLS token...\n",
            " 43% 100/234 [00:25<00:34,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:07,815 >> Initializing global attention on CLS token...\n",
            " 43% 101/234 [00:25<00:34,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:08,073 >> Initializing global attention on CLS token...\n",
            " 44% 102/234 [00:26<00:34,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:08,338 >> Initializing global attention on CLS token...\n",
            " 44% 103/234 [00:26<00:34,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:08,598 >> Initializing global attention on CLS token...\n",
            " 44% 104/234 [00:26<00:33,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:08,854 >> Initializing global attention on CLS token...\n",
            " 45% 105/234 [00:26<00:33,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:09,112 >> Initializing global attention on CLS token...\n",
            " 45% 106/234 [00:27<00:33,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:09,366 >> Initializing global attention on CLS token...\n",
            " 46% 107/234 [00:27<00:32,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:09,630 >> Initializing global attention on CLS token...\n",
            " 46% 108/234 [00:27<00:32,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:09,887 >> Initializing global attention on CLS token...\n",
            " 47% 109/234 [00:28<00:32,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:10,144 >> Initializing global attention on CLS token...\n",
            " 47% 110/234 [00:28<00:32,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:10,400 >> Initializing global attention on CLS token...\n",
            " 47% 111/234 [00:28<00:31,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:10,661 >> Initializing global attention on CLS token...\n",
            " 48% 112/234 [00:28<00:31,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:10,924 >> Initializing global attention on CLS token...\n",
            " 48% 113/234 [00:29<00:31,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:11,178 >> Initializing global attention on CLS token...\n",
            " 49% 114/234 [00:29<00:31,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:11,436 >> Initializing global attention on CLS token...\n",
            " 49% 115/234 [00:29<00:30,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:11,690 >> Initializing global attention on CLS token...\n",
            " 50% 116/234 [00:29<00:30,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:11,949 >> Initializing global attention on CLS token...\n",
            " 50% 117/234 [00:30<00:30,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:12,204 >> Initializing global attention on CLS token...\n",
            " 50% 118/234 [00:30<00:29,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:12,461 >> Initializing global attention on CLS token...\n",
            " 51% 119/234 [00:30<00:29,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:12,718 >> Initializing global attention on CLS token...\n",
            " 51% 120/234 [00:30<00:29,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:12,978 >> Initializing global attention on CLS token...\n",
            " 52% 121/234 [00:31<00:29,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:13,232 >> Initializing global attention on CLS token...\n",
            " 52% 122/234 [00:31<00:28,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:13,503 >> Initializing global attention on CLS token...\n",
            " 53% 123/234 [00:31<00:28,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:13,767 >> Initializing global attention on CLS token...\n",
            " 53% 124/234 [00:31<00:28,  3.81it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:14,022 >> Initializing global attention on CLS token...\n",
            " 53% 125/234 [00:32<00:28,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:14,278 >> Initializing global attention on CLS token...\n",
            " 54% 126/234 [00:32<00:27,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:14,536 >> Initializing global attention on CLS token...\n",
            " 54% 127/234 [00:32<00:27,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:14,797 >> Initializing global attention on CLS token...\n",
            " 55% 128/234 [00:32<00:27,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:15,061 >> Initializing global attention on CLS token...\n",
            " 55% 129/234 [00:33<00:27,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:15,320 >> Initializing global attention on CLS token...\n",
            " 56% 130/234 [00:33<00:26,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:15,572 >> Initializing global attention on CLS token...\n",
            " 56% 131/234 [00:33<00:26,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:15,826 >> Initializing global attention on CLS token...\n",
            " 56% 132/234 [00:33<00:26,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:16,087 >> Initializing global attention on CLS token...\n",
            " 57% 133/234 [00:34<00:26,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:16,343 >> Initializing global attention on CLS token...\n",
            " 57% 134/234 [00:34<00:25,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:16,599 >> Initializing global attention on CLS token...\n",
            " 58% 135/234 [00:34<00:25,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:16,857 >> Initializing global attention on CLS token...\n",
            " 58% 136/234 [00:34<00:25,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:17,116 >> Initializing global attention on CLS token...\n",
            " 59% 137/234 [00:35<00:24,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:17,379 >> Initializing global attention on CLS token...\n",
            " 59% 138/234 [00:35<00:24,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:17,634 >> Initializing global attention on CLS token...\n",
            " 59% 139/234 [00:35<00:24,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:17,892 >> Initializing global attention on CLS token...\n",
            " 60% 140/234 [00:36<00:24,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:18,150 >> Initializing global attention on CLS token...\n",
            " 60% 141/234 [00:36<00:24,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:18,411 >> Initializing global attention on CLS token...\n",
            " 61% 142/234 [00:36<00:23,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:18,668 >> Initializing global attention on CLS token...\n",
            " 61% 143/234 [00:36<00:23,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:18,929 >> Initializing global attention on CLS token...\n",
            " 62% 144/234 [00:37<00:23,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:19,184 >> Initializing global attention on CLS token...\n",
            " 62% 145/234 [00:37<00:22,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:19,441 >> Initializing global attention on CLS token...\n",
            " 62% 146/234 [00:37<00:22,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:19,706 >> Initializing global attention on CLS token...\n",
            " 63% 147/234 [00:37<00:22,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:19,959 >> Initializing global attention on CLS token...\n",
            " 63% 148/234 [00:38<00:22,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:20,220 >> Initializing global attention on CLS token...\n",
            " 64% 149/234 [00:38<00:22,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:20,475 >> Initializing global attention on CLS token...\n",
            " 64% 150/234 [00:38<00:21,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:20,734 >> Initializing global attention on CLS token...\n",
            " 65% 151/234 [00:38<00:21,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:20,991 >> Initializing global attention on CLS token...\n",
            " 65% 152/234 [00:39<00:21,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:21,250 >> Initializing global attention on CLS token...\n",
            " 65% 153/234 [00:39<00:20,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:21,502 >> Initializing global attention on CLS token...\n",
            " 66% 154/234 [00:39<00:20,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:21,756 >> Initializing global attention on CLS token...\n",
            " 66% 155/234 [00:39<00:20,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:22,019 >> Initializing global attention on CLS token...\n",
            " 67% 156/234 [00:40<00:20,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:22,273 >> Initializing global attention on CLS token...\n",
            " 67% 157/234 [00:40<00:19,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:22,533 >> Initializing global attention on CLS token...\n",
            " 68% 158/234 [00:40<00:19,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:22,786 >> Initializing global attention on CLS token...\n",
            " 68% 159/234 [00:40<00:19,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:23,042 >> Initializing global attention on CLS token...\n",
            " 68% 160/234 [00:41<00:18,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:23,298 >> Initializing global attention on CLS token...\n",
            " 69% 161/234 [00:41<00:18,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:23,557 >> Initializing global attention on CLS token...\n",
            " 69% 162/234 [00:41<00:18,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:23,812 >> Initializing global attention on CLS token...\n",
            " 70% 163/234 [00:41<00:18,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:24,075 >> Initializing global attention on CLS token...\n",
            " 70% 164/234 [00:42<00:18,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:24,340 >> Initializing global attention on CLS token...\n",
            " 71% 165/234 [00:42<00:17,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:24,601 >> Initializing global attention on CLS token...\n",
            " 71% 166/234 [00:42<00:17,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:24,854 >> Initializing global attention on CLS token...\n",
            " 71% 167/234 [00:42<00:17,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:25,109 >> Initializing global attention on CLS token...\n",
            " 72% 168/234 [00:43<00:16,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:25,379 >> Initializing global attention on CLS token...\n",
            " 72% 169/234 [00:43<00:16,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:25,635 >> Initializing global attention on CLS token...\n",
            " 73% 170/234 [00:43<00:16,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:25,888 >> Initializing global attention on CLS token...\n",
            " 73% 171/234 [00:44<00:16,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:26,153 >> Initializing global attention on CLS token...\n",
            " 74% 172/234 [00:44<00:16,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:26,410 >> Initializing global attention on CLS token...\n",
            " 74% 173/234 [00:44<00:15,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:26,686 >> Initializing global attention on CLS token...\n",
            " 74% 174/234 [00:44<00:15,  3.79it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:26,942 >> Initializing global attention on CLS token...\n",
            " 75% 175/234 [00:45<00:15,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:27,195 >> Initializing global attention on CLS token...\n",
            " 75% 176/234 [00:45<00:15,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:27,455 >> Initializing global attention on CLS token...\n",
            " 76% 177/234 [00:45<00:14,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:27,715 >> Initializing global attention on CLS token...\n",
            " 76% 178/234 [00:45<00:14,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:27,988 >> Initializing global attention on CLS token...\n",
            " 76% 179/234 [00:46<00:14,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:28,241 >> Initializing global attention on CLS token...\n",
            " 77% 180/234 [00:46<00:14,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:28,500 >> Initializing global attention on CLS token...\n",
            " 77% 181/234 [00:46<00:13,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:28,754 >> Initializing global attention on CLS token...\n",
            " 78% 182/234 [00:46<00:13,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:29,013 >> Initializing global attention on CLS token...\n",
            " 78% 183/234 [00:47<00:13,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:29,268 >> Initializing global attention on CLS token...\n",
            " 79% 184/234 [00:47<00:12,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:29,523 >> Initializing global attention on CLS token...\n",
            " 79% 185/234 [00:47<00:12,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:29,792 >> Initializing global attention on CLS token...\n",
            " 79% 186/234 [00:47<00:12,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:30,047 >> Initializing global attention on CLS token...\n",
            " 80% 187/234 [00:48<00:12,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:30,313 >> Initializing global attention on CLS token...\n",
            " 80% 188/234 [00:48<00:11,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:30,565 >> Initializing global attention on CLS token...\n",
            " 81% 189/234 [00:48<00:11,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:30,825 >> Initializing global attention on CLS token...\n",
            " 81% 190/234 [00:48<00:11,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:31,081 >> Initializing global attention on CLS token...\n",
            " 82% 191/234 [00:49<00:11,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:31,339 >> Initializing global attention on CLS token...\n",
            " 82% 192/234 [00:49<00:10,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:31,602 >> Initializing global attention on CLS token...\n",
            " 82% 193/234 [00:49<00:10,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:31,868 >> Initializing global attention on CLS token...\n",
            " 83% 194/234 [00:49<00:10,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:32,142 >> Initializing global attention on CLS token...\n",
            " 83% 195/234 [00:50<00:10,  3.78it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:32,400 >> Initializing global attention on CLS token...\n",
            " 84% 196/234 [00:50<00:10,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:32,655 >> Initializing global attention on CLS token...\n",
            " 84% 197/234 [00:50<00:09,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:32,911 >> Initializing global attention on CLS token...\n",
            " 85% 198/234 [00:51<00:09,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:33,181 >> Initializing global attention on CLS token...\n",
            " 85% 199/234 [00:51<00:09,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:33,458 >> Initializing global attention on CLS token...\n",
            " 85% 200/234 [00:51<00:09,  3.75it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:33,716 >> Initializing global attention on CLS token...\n",
            " 86% 201/234 [00:51<00:08,  3.79it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:33,980 >> Initializing global attention on CLS token...\n",
            " 86% 202/234 [00:52<00:08,  3.79it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:34,250 >> Initializing global attention on CLS token...\n",
            " 87% 203/234 [00:52<00:08,  3.76it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:34,510 >> Initializing global attention on CLS token...\n",
            " 87% 204/234 [00:52<00:07,  3.78it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:34,773 >> Initializing global attention on CLS token...\n",
            " 88% 205/234 [00:52<00:07,  3.79it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:35,044 >> Initializing global attention on CLS token...\n",
            " 88% 206/234 [00:53<00:07,  3.75it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:35,302 >> Initializing global attention on CLS token...\n",
            " 88% 207/234 [00:53<00:07,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:35,557 >> Initializing global attention on CLS token...\n",
            " 89% 208/234 [00:53<00:06,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:35,812 >> Initializing global attention on CLS token...\n",
            " 89% 209/234 [00:53<00:06,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:36,066 >> Initializing global attention on CLS token...\n",
            " 90% 210/234 [00:54<00:06,  3.87it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:36,324 >> Initializing global attention on CLS token...\n",
            " 90% 211/234 [00:54<00:05,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:36,577 >> Initializing global attention on CLS token...\n",
            " 91% 212/234 [00:54<00:05,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:36,837 >> Initializing global attention on CLS token...\n",
            " 91% 213/234 [00:54<00:05,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:37,091 >> Initializing global attention on CLS token...\n",
            " 91% 214/234 [00:55<00:05,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:37,350 >> Initializing global attention on CLS token...\n",
            " 92% 215/234 [00:55<00:04,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:37,606 >> Initializing global attention on CLS token...\n",
            " 92% 216/234 [00:55<00:04,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:37,862 >> Initializing global attention on CLS token...\n",
            " 93% 217/234 [00:55<00:04,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:38,119 >> Initializing global attention on CLS token...\n",
            " 93% 218/234 [00:56<00:04,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:38,373 >> Initializing global attention on CLS token...\n",
            " 94% 219/234 [00:56<00:03,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:38,625 >> Initializing global attention on CLS token...\n",
            " 94% 220/234 [00:56<00:03,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:38,884 >> Initializing global attention on CLS token...\n",
            " 94% 221/234 [00:57<00:03,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:39,136 >> Initializing global attention on CLS token...\n",
            " 95% 222/234 [00:57<00:03,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:39,394 >> Initializing global attention on CLS token...\n",
            " 95% 223/234 [00:57<00:02,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:39,649 >> Initializing global attention on CLS token...\n",
            " 96% 224/234 [00:57<00:02,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:39,905 >> Initializing global attention on CLS token...\n",
            " 96% 225/234 [00:58<00:02,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:40,158 >> Initializing global attention on CLS token...\n",
            " 97% 226/234 [00:58<00:02,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:40,412 >> Initializing global attention on CLS token...\n",
            " 97% 227/234 [00:58<00:01,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:40,669 >> Initializing global attention on CLS token...\n",
            " 97% 228/234 [00:58<00:01,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:40,926 >> Initializing global attention on CLS token...\n",
            " 98% 229/234 [00:59<00:01,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:41,184 >> Initializing global attention on CLS token...\n",
            " 98% 230/234 [00:59<00:01,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:41,444 >> Initializing global attention on CLS token...\n",
            " 99% 231/234 [00:59<00:00,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:41,702 >> Initializing global attention on CLS token...\n",
            " 99% 232/234 [00:59<00:00,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:41,951 >> Initializing global attention on CLS token...\n",
            "100% 233/234 [01:00<00:00,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-10 00:20:42,187 >> Initializing global attention on CLS token...\n",
            "100% 234/234 [01:00<00:00,  3.87it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        9.0\n",
            "  eval_f1-macro           =     0.6299\n",
            "  eval_f1-micro           =     0.7379\n",
            "  eval_loss               =     1.3065\n",
            "  eval_runtime            = 0:01:00.66\n",
            "  eval_samples_per_second =     23.076\n",
            "  eval_steps_per_second   =      3.857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re"
      ],
      "metadata": {
        "id": "z2d0yLc_allP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)```"
      ],
      "metadata": {
        "id": "s98bKNICA_lc"
      }
    }
  ]
}