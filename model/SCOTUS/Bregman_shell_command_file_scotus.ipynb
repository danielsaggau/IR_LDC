{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyM8ToSiWpXN0Sic1tT1Ldd1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/model/SCOTUS/Bregman_shell_command_file_scotus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naqIWr56jSUf"
      },
      "outputs": [],
      "source": [
        "!git clone https://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@github.com/danielsaggau/IR_LDC.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd IR_LDC"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-rw6QC9ojY5t",
        "outputId": "3a2b9450-3dec-4dd9-b59b-6179097ab7c9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/IR_LDC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "ipRGPbTR45u1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPNE-lbQex_N",
        "outputId": "b343f55e-d4f8-46a1-9a12-265a9012a75b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "!wandb login fd6f7deb3126d40be9abf77ee753bf45f00e2a9a\n",
        "wandb.init(project=\"IR_LDC\")\n",
        "%env WANDB_PROJECT=IR_LDC"
      ],
      "metadata": {
        "id": "XOCuFbIKgDss",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bf37d59c-afea-4fd3-95ca-816535bfb7d3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielsaggau\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/IR_LDC/wandb/run-20221208_154454-2bg72b80</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/danielsaggau/IR_LDC/runs/2bg72b80\" target=\"_blank\">graceful-surf-79</a></strong> to <a href=\"https://wandb.ai/danielsaggau/IR_LDC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "env: WANDB_PROJECT=IR_LDC\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/IR_LDC/model/SCOTUS/bregman_scotus_classification.py \\\n",
        "    --output_dir logs/output_1 \\\n",
        "    --model_name '/content/drive/MyDrive/bregman_scotus_k5_ep10/50000' \\\n",
        "    --model_type 'mean' \\\n",
        "    --load_best_model_at_end \\\n",
        "    --overwrite_output_dir \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --learning_rate 3e-5 \\\n",
        "    --per_device_train_batch_size 6 \\\n",
        "    --per_device_eval_batch_size 6 \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --fp16 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --metric_for_best_model \"f1-micro\" \\\n",
        "    --greater_is_better 1 \\\n",
        "    --report_to 'wandb'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQYL6fodppBA",
        "outputId": "3efbc450-e2f5-451a-9713-71189991b615"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1;30;43mDie letzten 5000Â Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            " 56% 4687/8340 [1:10:59<50:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:24,732 >> Initializing global attention on CLS token...\n",
            " 56% 4688/8340 [1:10:59<50:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:25,573 >> Initializing global attention on CLS token...\n",
            " 56% 4689/8340 [1:11:00<50:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:26,409 >> Initializing global attention on CLS token...\n",
            " 56% 4690/8340 [1:11:01<51:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:27,252 >> Initializing global attention on CLS token...\n",
            " 56% 4691/8340 [1:11:02<51:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:28,093 >> Initializing global attention on CLS token...\n",
            " 56% 4692/8340 [1:11:03<51:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:28,931 >> Initializing global attention on CLS token...\n",
            " 56% 4693/8340 [1:11:04<50:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:29,766 >> Initializing global attention on CLS token...\n",
            " 56% 4694/8340 [1:11:04<50:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:30,604 >> Initializing global attention on CLS token...\n",
            " 56% 4695/8340 [1:11:05<50:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:31,444 >> Initializing global attention on CLS token...\n",
            " 56% 4696/8340 [1:11:06<50:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:32,283 >> Initializing global attention on CLS token...\n",
            " 56% 4697/8340 [1:11:07<50:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:33,119 >> Initializing global attention on CLS token...\n",
            " 56% 4698/8340 [1:11:08<50:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:33,954 >> Initializing global attention on CLS token...\n",
            " 56% 4699/8340 [1:11:09<50:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:34,794 >> Initializing global attention on CLS token...\n",
            " 56% 4700/8340 [1:11:10<50:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:35,631 >> Initializing global attention on CLS token...\n",
            " 56% 4701/8340 [1:11:10<50:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:36,476 >> Initializing global attention on CLS token...\n",
            " 56% 4702/8340 [1:11:11<50:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:37,311 >> Initializing global attention on CLS token...\n",
            " 56% 4703/8340 [1:11:12<50:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:38,156 >> Initializing global attention on CLS token...\n",
            " 56% 4704/8340 [1:11:13<50:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:38,990 >> Initializing global attention on CLS token...\n",
            " 56% 4705/8340 [1:11:14<50:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:39,823 >> Initializing global attention on CLS token...\n",
            " 56% 4706/8340 [1:11:15<50:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:40,660 >> Initializing global attention on CLS token...\n",
            " 56% 4707/8340 [1:11:15<50:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:41,500 >> Initializing global attention on CLS token...\n",
            " 56% 4708/8340 [1:11:16<50:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:42,336 >> Initializing global attention on CLS token...\n",
            " 56% 4709/8340 [1:11:17<50:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:43,175 >> Initializing global attention on CLS token...\n",
            " 56% 4710/8340 [1:11:18<50:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:44,012 >> Initializing global attention on CLS token...\n",
            " 56% 4711/8340 [1:11:19<50:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:44,857 >> Initializing global attention on CLS token...\n",
            " 56% 4712/8340 [1:11:20<50:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:45,695 >> Initializing global attention on CLS token...\n",
            " 57% 4713/8340 [1:11:20<50:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:46,528 >> Initializing global attention on CLS token...\n",
            " 57% 4714/8340 [1:11:21<50:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:47,361 >> Initializing global attention on CLS token...\n",
            " 57% 4715/8340 [1:11:22<50:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:48,197 >> Initializing global attention on CLS token...\n",
            " 57% 4716/8340 [1:11:23<50:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:49,031 >> Initializing global attention on CLS token...\n",
            " 57% 4717/8340 [1:11:24<50:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:49,866 >> Initializing global attention on CLS token...\n",
            " 57% 4718/8340 [1:11:25<50:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:50,702 >> Initializing global attention on CLS token...\n",
            " 57% 4719/8340 [1:11:25<50:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:51,538 >> Initializing global attention on CLS token...\n",
            " 57% 4720/8340 [1:11:26<50:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:52,379 >> Initializing global attention on CLS token...\n",
            " 57% 4721/8340 [1:11:27<50:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:53,216 >> Initializing global attention on CLS token...\n",
            " 57% 4722/8340 [1:11:28<50:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:54,051 >> Initializing global attention on CLS token...\n",
            " 57% 4723/8340 [1:11:29<50:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:54,892 >> Initializing global attention on CLS token...\n",
            " 57% 4724/8340 [1:11:30<50:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:55,729 >> Initializing global attention on CLS token...\n",
            " 57% 4725/8340 [1:11:30<50:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:56,566 >> Initializing global attention on CLS token...\n",
            " 57% 4726/8340 [1:11:31<50:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:57,405 >> Initializing global attention on CLS token...\n",
            " 57% 4727/8340 [1:11:32<50:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:58,241 >> Initializing global attention on CLS token...\n",
            " 57% 4728/8340 [1:11:33<50:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:59,079 >> Initializing global attention on CLS token...\n",
            " 57% 4729/8340 [1:11:34<50:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:14:59,915 >> Initializing global attention on CLS token...\n",
            " 57% 4730/8340 [1:11:35<50:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:00,757 >> Initializing global attention on CLS token...\n",
            " 57% 4731/8340 [1:11:35<50:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:01,594 >> Initializing global attention on CLS token...\n",
            " 57% 4732/8340 [1:11:36<50:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:02,433 >> Initializing global attention on CLS token...\n",
            " 57% 4733/8340 [1:11:37<50:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:03,274 >> Initializing global attention on CLS token...\n",
            " 57% 4734/8340 [1:11:38<50:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:04,110 >> Initializing global attention on CLS token...\n",
            " 57% 4735/8340 [1:11:39<50:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:04,954 >> Initializing global attention on CLS token...\n",
            " 57% 4736/8340 [1:11:40<50:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:05,791 >> Initializing global attention on CLS token...\n",
            " 57% 4737/8340 [1:11:41<50:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:06,626 >> Initializing global attention on CLS token...\n",
            " 57% 4738/8340 [1:11:41<50:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:07,469 >> Initializing global attention on CLS token...\n",
            " 57% 4739/8340 [1:11:42<50:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:08,310 >> Initializing global attention on CLS token...\n",
            " 57% 4740/8340 [1:11:43<50:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:09,151 >> Initializing global attention on CLS token...\n",
            " 57% 4741/8340 [1:11:44<50:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:09,990 >> Initializing global attention on CLS token...\n",
            " 57% 4742/8340 [1:11:45<50:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:10,830 >> Initializing global attention on CLS token...\n",
            " 57% 4743/8340 [1:11:46<50:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:11,671 >> Initializing global attention on CLS token...\n",
            " 57% 4744/8340 [1:11:46<50:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:12,510 >> Initializing global attention on CLS token...\n",
            " 57% 4745/8340 [1:11:47<50:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:13,352 >> Initializing global attention on CLS token...\n",
            " 57% 4746/8340 [1:11:48<50:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:14,189 >> Initializing global attention on CLS token...\n",
            " 57% 4747/8340 [1:11:49<50:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:15,028 >> Initializing global attention on CLS token...\n",
            " 57% 4748/8340 [1:11:50<50:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:15,864 >> Initializing global attention on CLS token...\n",
            " 57% 4749/8340 [1:11:51<50:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:16,706 >> Initializing global attention on CLS token...\n",
            " 57% 4750/8340 [1:11:51<50:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:17,557 >> Initializing global attention on CLS token...\n",
            " 57% 4751/8340 [1:11:52<50:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:18,396 >> Initializing global attention on CLS token...\n",
            " 57% 4752/8340 [1:11:53<50:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:19,233 >> Initializing global attention on CLS token...\n",
            " 57% 4753/8340 [1:11:54<50:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:20,064 >> Initializing global attention on CLS token...\n",
            " 57% 4754/8340 [1:11:55<50:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:20,901 >> Initializing global attention on CLS token...\n",
            " 57% 4755/8340 [1:11:56<50:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:21,739 >> Initializing global attention on CLS token...\n",
            " 57% 4756/8340 [1:11:56<49:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:22,574 >> Initializing global attention on CLS token...\n",
            " 57% 4757/8340 [1:11:57<49:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:23,407 >> Initializing global attention on CLS token...\n",
            " 57% 4758/8340 [1:11:58<49:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:24,244 >> Initializing global attention on CLS token...\n",
            " 57% 4759/8340 [1:11:59<49:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:25,084 >> Initializing global attention on CLS token...\n",
            " 57% 4760/8340 [1:12:00<50:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:25,926 >> Initializing global attention on CLS token...\n",
            " 57% 4761/8340 [1:12:01<50:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:26,764 >> Initializing global attention on CLS token...\n",
            " 57% 4762/8340 [1:12:01<49:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:27,602 >> Initializing global attention on CLS token...\n",
            " 57% 4763/8340 [1:12:02<50:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:28,443 >> Initializing global attention on CLS token...\n",
            " 57% 4764/8340 [1:12:03<50:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:29,281 >> Initializing global attention on CLS token...\n",
            " 57% 4765/8340 [1:12:04<50:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:30,125 >> Initializing global attention on CLS token...\n",
            " 57% 4766/8340 [1:12:05<49:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:30,959 >> Initializing global attention on CLS token...\n",
            " 57% 4767/8340 [1:12:06<49:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:31,799 >> Initializing global attention on CLS token...\n",
            " 57% 4768/8340 [1:12:07<49:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:32,639 >> Initializing global attention on CLS token...\n",
            " 57% 4769/8340 [1:12:07<49:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:33,480 >> Initializing global attention on CLS token...\n",
            " 57% 4770/8340 [1:12:08<49:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:34,319 >> Initializing global attention on CLS token...\n",
            " 57% 4771/8340 [1:12:09<49:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:35,157 >> Initializing global attention on CLS token...\n",
            " 57% 4772/8340 [1:12:10<49:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:35,992 >> Initializing global attention on CLS token...\n",
            " 57% 4773/8340 [1:12:11<49:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:36,833 >> Initializing global attention on CLS token...\n",
            " 57% 4774/8340 [1:12:12<49:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:37,668 >> Initializing global attention on CLS token...\n",
            " 57% 4775/8340 [1:12:12<49:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:38,509 >> Initializing global attention on CLS token...\n",
            " 57% 4776/8340 [1:12:13<49:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:39,343 >> Initializing global attention on CLS token...\n",
            " 57% 4777/8340 [1:12:14<49:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:40,178 >> Initializing global attention on CLS token...\n",
            " 57% 4778/8340 [1:12:15<49:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:41,013 >> Initializing global attention on CLS token...\n",
            " 57% 4779/8340 [1:12:16<49:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:41,849 >> Initializing global attention on CLS token...\n",
            " 57% 4780/8340 [1:12:17<49:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:42,682 >> Initializing global attention on CLS token...\n",
            " 57% 4781/8340 [1:12:17<49:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:43,520 >> Initializing global attention on CLS token...\n",
            " 57% 4782/8340 [1:12:18<49:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:44,364 >> Initializing global attention on CLS token...\n",
            " 57% 4783/8340 [1:12:19<49:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:45,202 >> Initializing global attention on CLS token...\n",
            " 57% 4784/8340 [1:12:20<49:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:46,039 >> Initializing global attention on CLS token...\n",
            " 57% 4785/8340 [1:12:21<49:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:46,879 >> Initializing global attention on CLS token...\n",
            " 57% 4786/8340 [1:12:22<49:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:47,717 >> Initializing global attention on CLS token...\n",
            " 57% 4787/8340 [1:12:22<49:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:48,559 >> Initializing global attention on CLS token...\n",
            " 57% 4788/8340 [1:12:23<49:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:49,395 >> Initializing global attention on CLS token...\n",
            " 57% 4789/8340 [1:12:24<49:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:50,241 >> Initializing global attention on CLS token...\n",
            " 57% 4790/8340 [1:12:25<49:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:51,081 >> Initializing global attention on CLS token...\n",
            " 57% 4791/8340 [1:12:26<49:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:51,924 >> Initializing global attention on CLS token...\n",
            " 57% 4792/8340 [1:12:27<49:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:52,768 >> Initializing global attention on CLS token...\n",
            " 57% 4793/8340 [1:12:27<49:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:53,602 >> Initializing global attention on CLS token...\n",
            " 57% 4794/8340 [1:12:28<49:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:54,438 >> Initializing global attention on CLS token...\n",
            " 57% 4795/8340 [1:12:29<49:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:55,280 >> Initializing global attention on CLS token...\n",
            " 58% 4796/8340 [1:12:30<49:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:56,117 >> Initializing global attention on CLS token...\n",
            " 58% 4797/8340 [1:12:31<49:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:56,956 >> Initializing global attention on CLS token...\n",
            " 58% 4798/8340 [1:12:32<49:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:57,795 >> Initializing global attention on CLS token...\n",
            " 58% 4799/8340 [1:12:33<49:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:58,635 >> Initializing global attention on CLS token...\n",
            " 58% 4800/8340 [1:12:33<49:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:15:59,474 >> Initializing global attention on CLS token...\n",
            " 58% 4801/8340 [1:12:34<49:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:00,319 >> Initializing global attention on CLS token...\n",
            " 58% 4802/8340 [1:12:35<49:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:01,163 >> Initializing global attention on CLS token...\n",
            " 58% 4803/8340 [1:12:36<49:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:02,011 >> Initializing global attention on CLS token...\n",
            " 58% 4804/8340 [1:12:37<49:47,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:02,859 >> Initializing global attention on CLS token...\n",
            " 58% 4805/8340 [1:12:38<49:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:03,701 >> Initializing global attention on CLS token...\n",
            " 58% 4806/8340 [1:12:38<49:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:04,541 >> Initializing global attention on CLS token...\n",
            " 58% 4807/8340 [1:12:39<49:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:05,377 >> Initializing global attention on CLS token...\n",
            " 58% 4808/8340 [1:12:40<49:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:06,220 >> Initializing global attention on CLS token...\n",
            " 58% 4809/8340 [1:12:41<49:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:07,058 >> Initializing global attention on CLS token...\n",
            " 58% 4810/8340 [1:12:42<49:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:07,898 >> Initializing global attention on CLS token...\n",
            " 58% 4811/8340 [1:12:43<49:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:08,744 >> Initializing global attention on CLS token...\n",
            " 58% 4812/8340 [1:12:43<49:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:09,578 >> Initializing global attention on CLS token...\n",
            " 58% 4813/8340 [1:12:44<49:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:10,416 >> Initializing global attention on CLS token...\n",
            " 58% 4814/8340 [1:12:45<49:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:11,257 >> Initializing global attention on CLS token...\n",
            " 58% 4815/8340 [1:12:46<49:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:12,097 >> Initializing global attention on CLS token...\n",
            " 58% 4816/8340 [1:12:47<49:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:12,935 >> Initializing global attention on CLS token...\n",
            " 58% 4817/8340 [1:12:48<49:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:13,772 >> Initializing global attention on CLS token...\n",
            " 58% 4818/8340 [1:12:48<49:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:14,612 >> Initializing global attention on CLS token...\n",
            " 58% 4819/8340 [1:12:49<49:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:15,451 >> Initializing global attention on CLS token...\n",
            " 58% 4820/8340 [1:12:50<49:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:16,291 >> Initializing global attention on CLS token...\n",
            " 58% 4821/8340 [1:12:51<49:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:17,130 >> Initializing global attention on CLS token...\n",
            " 58% 4822/8340 [1:12:52<49:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:17,967 >> Initializing global attention on CLS token...\n",
            " 58% 4823/8340 [1:12:53<49:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:18,811 >> Initializing global attention on CLS token...\n",
            " 58% 4824/8340 [1:12:54<49:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:19,651 >> Initializing global attention on CLS token...\n",
            " 58% 4825/8340 [1:12:54<49:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:20,489 >> Initializing global attention on CLS token...\n",
            " 58% 4826/8340 [1:12:55<49:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:21,332 >> Initializing global attention on CLS token...\n",
            " 58% 4827/8340 [1:12:56<49:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:22,174 >> Initializing global attention on CLS token...\n",
            " 58% 4828/8340 [1:12:57<49:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:23,013 >> Initializing global attention on CLS token...\n",
            " 58% 4829/8340 [1:12:58<49:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:23,856 >> Initializing global attention on CLS token...\n",
            " 58% 4830/8340 [1:12:59<49:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:24,698 >> Initializing global attention on CLS token...\n",
            " 58% 4831/8340 [1:12:59<49:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:25,540 >> Initializing global attention on CLS token...\n",
            " 58% 4832/8340 [1:13:00<49:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:26,383 >> Initializing global attention on CLS token...\n",
            " 58% 4833/8340 [1:13:01<49:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:27,221 >> Initializing global attention on CLS token...\n",
            " 58% 4834/8340 [1:13:02<49:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:28,063 >> Initializing global attention on CLS token...\n",
            " 58% 4835/8340 [1:13:03<49:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:28,905 >> Initializing global attention on CLS token...\n",
            " 58% 4836/8340 [1:13:04<49:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:29,742 >> Initializing global attention on CLS token...\n",
            " 58% 4837/8340 [1:13:04<48:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:30,574 >> Initializing global attention on CLS token...\n",
            " 58% 4838/8340 [1:13:05<48:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:31,411 >> Initializing global attention on CLS token...\n",
            " 58% 4839/8340 [1:13:06<48:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:32,252 >> Initializing global attention on CLS token...\n",
            " 58% 4840/8340 [1:13:07<48:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:33,095 >> Initializing global attention on CLS token...\n",
            " 58% 4841/8340 [1:13:08<48:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:33,935 >> Initializing global attention on CLS token...\n",
            " 58% 4842/8340 [1:13:09<48:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:34,775 >> Initializing global attention on CLS token...\n",
            " 58% 4843/8340 [1:13:09<48:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:35,613 >> Initializing global attention on CLS token...\n",
            " 58% 4844/8340 [1:13:10<48:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:36,446 >> Initializing global attention on CLS token...\n",
            " 58% 4845/8340 [1:13:11<48:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:37,285 >> Initializing global attention on CLS token...\n",
            " 58% 4846/8340 [1:13:12<48:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:38,124 >> Initializing global attention on CLS token...\n",
            " 58% 4847/8340 [1:13:13<48:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:38,966 >> Initializing global attention on CLS token...\n",
            " 58% 4848/8340 [1:13:14<48:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:39,807 >> Initializing global attention on CLS token...\n",
            " 58% 4849/8340 [1:13:15<48:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:40,641 >> Initializing global attention on CLS token...\n",
            " 58% 4850/8340 [1:13:15<48:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:41,483 >> Initializing global attention on CLS token...\n",
            " 58% 4851/8340 [1:13:16<48:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:42,322 >> Initializing global attention on CLS token...\n",
            " 58% 4852/8340 [1:13:17<48:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:43,161 >> Initializing global attention on CLS token...\n",
            " 58% 4853/8340 [1:13:18<48:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:43,996 >> Initializing global attention on CLS token...\n",
            " 58% 4854/8340 [1:13:19<48:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:44,832 >> Initializing global attention on CLS token...\n",
            " 58% 4855/8340 [1:13:20<48:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:45,670 >> Initializing global attention on CLS token...\n",
            " 58% 4856/8340 [1:13:20<48:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:46,511 >> Initializing global attention on CLS token...\n",
            " 58% 4857/8340 [1:13:21<48:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:47,353 >> Initializing global attention on CLS token...\n",
            " 58% 4858/8340 [1:13:22<48:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:48,196 >> Initializing global attention on CLS token...\n",
            " 58% 4859/8340 [1:13:23<48:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:49,039 >> Initializing global attention on CLS token...\n",
            " 58% 4860/8340 [1:13:24<48:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:49,874 >> Initializing global attention on CLS token...\n",
            " 58% 4861/8340 [1:13:25<48:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:50,708 >> Initializing global attention on CLS token...\n",
            " 58% 4862/8340 [1:13:25<48:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:51,558 >> Initializing global attention on CLS token...\n",
            " 58% 4863/8340 [1:13:26<48:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:52,397 >> Initializing global attention on CLS token...\n",
            " 58% 4864/8340 [1:13:27<48:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:53,246 >> Initializing global attention on CLS token...\n",
            " 58% 4865/8340 [1:13:28<48:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:54,087 >> Initializing global attention on CLS token...\n",
            " 58% 4866/8340 [1:13:29<48:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:54,927 >> Initializing global attention on CLS token...\n",
            " 58% 4867/8340 [1:13:30<48:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:55,764 >> Initializing global attention on CLS token...\n",
            " 58% 4868/8340 [1:13:30<48:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:56,602 >> Initializing global attention on CLS token...\n",
            " 58% 4869/8340 [1:13:31<48:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:57,444 >> Initializing global attention on CLS token...\n",
            " 58% 4870/8340 [1:13:32<48:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:58,288 >> Initializing global attention on CLS token...\n",
            " 58% 4871/8340 [1:13:33<48:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:59,122 >> Initializing global attention on CLS token...\n",
            " 58% 4872/8340 [1:13:34<48:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:16:59,957 >> Initializing global attention on CLS token...\n",
            " 58% 4873/8340 [1:13:35<48:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:00,793 >> Initializing global attention on CLS token...\n",
            " 58% 4874/8340 [1:13:36<48:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:01,638 >> Initializing global attention on CLS token...\n",
            " 58% 4875/8340 [1:13:36<48:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:02,478 >> Initializing global attention on CLS token...\n",
            " 58% 4876/8340 [1:13:37<48:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:03,314 >> Initializing global attention on CLS token...\n",
            " 58% 4877/8340 [1:13:38<48:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:04,156 >> Initializing global attention on CLS token...\n",
            " 58% 4878/8340 [1:13:39<48:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:04,997 >> Initializing global attention on CLS token...\n",
            " 59% 4879/8340 [1:13:40<48:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:05,833 >> Initializing global attention on CLS token...\n",
            " 59% 4880/8340 [1:13:41<48:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:06,669 >> Initializing global attention on CLS token...\n",
            " 59% 4881/8340 [1:13:41<48:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:07,511 >> Initializing global attention on CLS token...\n",
            " 59% 4882/8340 [1:13:42<48:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:08,346 >> Initializing global attention on CLS token...\n",
            " 59% 4883/8340 [1:13:43<48:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:09,181 >> Initializing global attention on CLS token...\n",
            " 59% 4884/8340 [1:13:44<48:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:10,014 >> Initializing global attention on CLS token...\n",
            " 59% 4885/8340 [1:13:45<48:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:10,851 >> Initializing global attention on CLS token...\n",
            " 59% 4886/8340 [1:13:46<48:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:11,688 >> Initializing global attention on CLS token...\n",
            " 59% 4887/8340 [1:13:46<48:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:12,527 >> Initializing global attention on CLS token...\n",
            " 59% 4888/8340 [1:13:47<48:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:13,364 >> Initializing global attention on CLS token...\n",
            " 59% 4889/8340 [1:13:48<48:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:14,200 >> Initializing global attention on CLS token...\n",
            " 59% 4890/8340 [1:13:49<48:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:15,036 >> Initializing global attention on CLS token...\n",
            " 59% 4891/8340 [1:13:50<48:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:15,870 >> Initializing global attention on CLS token...\n",
            " 59% 4892/8340 [1:13:51<48:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:16,709 >> Initializing global attention on CLS token...\n",
            " 59% 4893/8340 [1:13:51<48:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:17,552 >> Initializing global attention on CLS token...\n",
            " 59% 4894/8340 [1:13:52<48:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:18,389 >> Initializing global attention on CLS token...\n",
            " 59% 4895/8340 [1:13:53<48:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:19,224 >> Initializing global attention on CLS token...\n",
            " 59% 4896/8340 [1:13:54<48:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:20,066 >> Initializing global attention on CLS token...\n",
            " 59% 4897/8340 [1:13:55<48:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:20,904 >> Initializing global attention on CLS token...\n",
            " 59% 4898/8340 [1:13:56<48:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:21,741 >> Initializing global attention on CLS token...\n",
            " 59% 4899/8340 [1:13:56<48:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:22,583 >> Initializing global attention on CLS token...\n",
            " 59% 4900/8340 [1:13:57<48:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:23,417 >> Initializing global attention on CLS token...\n",
            " 59% 4901/8340 [1:13:58<48:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:24,261 >> Initializing global attention on CLS token...\n",
            " 59% 4902/8340 [1:13:59<48:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:25,098 >> Initializing global attention on CLS token...\n",
            " 59% 4903/8340 [1:14:00<48:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:25,938 >> Initializing global attention on CLS token...\n",
            " 59% 4904/8340 [1:14:01<48:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:26,780 >> Initializing global attention on CLS token...\n",
            " 59% 4905/8340 [1:14:02<48:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:27,617 >> Initializing global attention on CLS token...\n",
            " 59% 4906/8340 [1:14:02<47:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:28,453 >> Initializing global attention on CLS token...\n",
            " 59% 4907/8340 [1:14:03<47:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:29,294 >> Initializing global attention on CLS token...\n",
            " 59% 4908/8340 [1:14:04<48:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:30,140 >> Initializing global attention on CLS token...\n",
            " 59% 4909/8340 [1:14:05<48:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:30,975 >> Initializing global attention on CLS token...\n",
            " 59% 4910/8340 [1:14:06<47:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:31,810 >> Initializing global attention on CLS token...\n",
            " 59% 4911/8340 [1:14:07<47:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:32,644 >> Initializing global attention on CLS token...\n",
            " 59% 4912/8340 [1:14:07<47:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:33,478 >> Initializing global attention on CLS token...\n",
            " 59% 4913/8340 [1:14:08<47:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:34,317 >> Initializing global attention on CLS token...\n",
            " 59% 4914/8340 [1:14:09<47:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:35,159 >> Initializing global attention on CLS token...\n",
            " 59% 4915/8340 [1:14:10<47:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:35,999 >> Initializing global attention on CLS token...\n",
            " 59% 4916/8340 [1:14:11<47:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:36,843 >> Initializing global attention on CLS token...\n",
            " 59% 4917/8340 [1:14:12<47:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:37,684 >> Initializing global attention on CLS token...\n",
            " 59% 4918/8340 [1:14:12<47:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:38,521 >> Initializing global attention on CLS token...\n",
            " 59% 4919/8340 [1:14:13<47:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:39,361 >> Initializing global attention on CLS token...\n",
            " 59% 4920/8340 [1:14:14<47:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:40,201 >> Initializing global attention on CLS token...\n",
            " 59% 4921/8340 [1:14:15<47:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:41,037 >> Initializing global attention on CLS token...\n",
            " 59% 4922/8340 [1:14:16<47:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:41,873 >> Initializing global attention on CLS token...\n",
            " 59% 4923/8340 [1:14:17<47:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:42,709 >> Initializing global attention on CLS token...\n",
            " 59% 4924/8340 [1:14:17<47:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:43,553 >> Initializing global attention on CLS token...\n",
            " 59% 4925/8340 [1:14:18<47:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:44,393 >> Initializing global attention on CLS token...\n",
            " 59% 4926/8340 [1:14:19<47:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:45,231 >> Initializing global attention on CLS token...\n",
            " 59% 4927/8340 [1:14:20<47:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:46,072 >> Initializing global attention on CLS token...\n",
            " 59% 4928/8340 [1:14:21<47:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:46,908 >> Initializing global attention on CLS token...\n",
            " 59% 4929/8340 [1:14:22<47:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:47,748 >> Initializing global attention on CLS token...\n",
            " 59% 4930/8340 [1:14:22<47:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:48,589 >> Initializing global attention on CLS token...\n",
            " 59% 4931/8340 [1:14:23<47:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:49,424 >> Initializing global attention on CLS token...\n",
            " 59% 4932/8340 [1:14:24<47:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:50,268 >> Initializing global attention on CLS token...\n",
            " 59% 4933/8340 [1:14:25<47:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:51,104 >> Initializing global attention on CLS token...\n",
            " 59% 4934/8340 [1:14:26<47:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:51,942 >> Initializing global attention on CLS token...\n",
            " 59% 4935/8340 [1:14:27<47:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:52,782 >> Initializing global attention on CLS token...\n",
            " 59% 4936/8340 [1:14:28<47:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:53,622 >> Initializing global attention on CLS token...\n",
            " 59% 4937/8340 [1:14:28<47:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:54,459 >> Initializing global attention on CLS token...\n",
            " 59% 4938/8340 [1:14:29<47:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:55,298 >> Initializing global attention on CLS token...\n",
            " 59% 4939/8340 [1:14:30<47:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:56,136 >> Initializing global attention on CLS token...\n",
            " 59% 4940/8340 [1:14:31<47:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:56,972 >> Initializing global attention on CLS token...\n",
            " 59% 4941/8340 [1:14:32<47:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:57,814 >> Initializing global attention on CLS token...\n",
            " 59% 4942/8340 [1:14:33<47:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:58,656 >> Initializing global attention on CLS token...\n",
            " 59% 4943/8340 [1:14:33<47:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:17:59,498 >> Initializing global attention on CLS token...\n",
            " 59% 4944/8340 [1:14:34<47:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:00,335 >> Initializing global attention on CLS token...\n",
            " 59% 4945/8340 [1:14:35<47:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:01,182 >> Initializing global attention on CLS token...\n",
            " 59% 4946/8340 [1:14:36<47:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:02,020 >> Initializing global attention on CLS token...\n",
            " 59% 4947/8340 [1:14:37<47:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:02,855 >> Initializing global attention on CLS token...\n",
            " 59% 4948/8340 [1:14:38<47:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:03,692 >> Initializing global attention on CLS token...\n",
            " 59% 4949/8340 [1:14:38<47:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:04,532 >> Initializing global attention on CLS token...\n",
            " 59% 4950/8340 [1:14:39<47:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:05,369 >> Initializing global attention on CLS token...\n",
            " 59% 4951/8340 [1:14:40<47:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:06,206 >> Initializing global attention on CLS token...\n",
            " 59% 4952/8340 [1:14:41<47:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:07,043 >> Initializing global attention on CLS token...\n",
            " 59% 4953/8340 [1:14:42<47:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:07,877 >> Initializing global attention on CLS token...\n",
            " 59% 4954/8340 [1:14:43<47:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:08,710 >> Initializing global attention on CLS token...\n",
            " 59% 4955/8340 [1:14:43<47:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:09,546 >> Initializing global attention on CLS token...\n",
            " 59% 4956/8340 [1:14:44<47:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:10,415 >> Initializing global attention on CLS token...\n",
            " 59% 4957/8340 [1:14:45<47:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:11,278 >> Initializing global attention on CLS token...\n",
            " 59% 4958/8340 [1:14:46<48:08,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:12,133 >> Initializing global attention on CLS token...\n",
            " 59% 4959/8340 [1:14:47<47:57,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:12,975 >> Initializing global attention on CLS token...\n",
            " 59% 4960/8340 [1:14:48<47:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:13,812 >> Initializing global attention on CLS token...\n",
            " 59% 4961/8340 [1:14:49<47:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:14,649 >> Initializing global attention on CLS token...\n",
            " 59% 4962/8340 [1:14:49<47:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:15,485 >> Initializing global attention on CLS token...\n",
            " 60% 4963/8340 [1:14:50<47:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:16,319 >> Initializing global attention on CLS token...\n",
            " 60% 4964/8340 [1:14:51<47:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:17,160 >> Initializing global attention on CLS token...\n",
            " 60% 4965/8340 [1:14:52<47:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:18,002 >> Initializing global attention on CLS token...\n",
            " 60% 4966/8340 [1:14:53<47:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:18,842 >> Initializing global attention on CLS token...\n",
            " 60% 4967/8340 [1:14:54<47:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:19,681 >> Initializing global attention on CLS token...\n",
            " 60% 4968/8340 [1:14:54<47:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:20,513 >> Initializing global attention on CLS token...\n",
            " 60% 4969/8340 [1:14:55<47:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:21,352 >> Initializing global attention on CLS token...\n",
            " 60% 4970/8340 [1:14:56<47:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:22,186 >> Initializing global attention on CLS token...\n",
            " 60% 4971/8340 [1:14:57<47:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:23,029 >> Initializing global attention on CLS token...\n",
            " 60% 4972/8340 [1:14:58<47:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:23,867 >> Initializing global attention on CLS token...\n",
            " 60% 4973/8340 [1:14:59<46:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:24,702 >> Initializing global attention on CLS token...\n",
            " 60% 4974/8340 [1:14:59<46:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:25,534 >> Initializing global attention on CLS token...\n",
            " 60% 4975/8340 [1:15:00<46:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:26,373 >> Initializing global attention on CLS token...\n",
            " 60% 4976/8340 [1:15:01<46:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:27,212 >> Initializing global attention on CLS token...\n",
            " 60% 4977/8340 [1:15:02<47:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:28,053 >> Initializing global attention on CLS token...\n",
            " 60% 4978/8340 [1:15:03<47:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:28,893 >> Initializing global attention on CLS token...\n",
            " 60% 4979/8340 [1:15:04<46:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:29,731 >> Initializing global attention on CLS token...\n",
            " 60% 4980/8340 [1:15:04<46:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:30,571 >> Initializing global attention on CLS token...\n",
            " 60% 4981/8340 [1:15:05<46:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:31,406 >> Initializing global attention on CLS token...\n",
            " 60% 4982/8340 [1:15:06<46:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:32,244 >> Initializing global attention on CLS token...\n",
            " 60% 4983/8340 [1:15:07<47:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:33,090 >> Initializing global attention on CLS token...\n",
            " 60% 4984/8340 [1:15:08<47:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:33,939 >> Initializing global attention on CLS token...\n",
            " 60% 4985/8340 [1:15:09<47:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:34,777 >> Initializing global attention on CLS token...\n",
            " 60% 4986/8340 [1:15:10<47:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:35,618 >> Initializing global attention on CLS token...\n",
            " 60% 4987/8340 [1:15:10<47:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:36,462 >> Initializing global attention on CLS token...\n",
            " 60% 4988/8340 [1:15:11<46:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:37,300 >> Initializing global attention on CLS token...\n",
            " 60% 4989/8340 [1:15:12<46:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:38,137 >> Initializing global attention on CLS token...\n",
            " 60% 4990/8340 [1:15:13<46:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:38,973 >> Initializing global attention on CLS token...\n",
            " 60% 4991/8340 [1:15:14<46:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:39,816 >> Initializing global attention on CLS token...\n",
            " 60% 4992/8340 [1:15:15<46:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:40,655 >> Initializing global attention on CLS token...\n",
            " 60% 4993/8340 [1:15:15<46:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:41,495 >> Initializing global attention on CLS token...\n",
            " 60% 4994/8340 [1:15:16<46:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:42,334 >> Initializing global attention on CLS token...\n",
            " 60% 4995/8340 [1:15:17<46:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:43,174 >> Initializing global attention on CLS token...\n",
            " 60% 4996/8340 [1:15:18<46:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:44,015 >> Initializing global attention on CLS token...\n",
            " 60% 4997/8340 [1:15:19<46:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:44,850 >> Initializing global attention on CLS token...\n",
            " 60% 4998/8340 [1:15:20<46:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:45,683 >> Initializing global attention on CLS token...\n",
            " 60% 4999/8340 [1:15:20<46:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:46,517 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.1357, 'learning_rate': 1.2032374100719425e-05, 'epoch': 6.0}\n",
            " 60% 5000/8340 [1:15:21<48:35,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:47,485 >> Initializing global attention on CLS token...\n",
            " 60% 5001/8340 [1:15:22<48:09,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:48,325 >> Initializing global attention on CLS token...\n",
            " 60% 5002/8340 [1:15:23<47:40,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:49,161 >> Initializing global attention on CLS token...\n",
            " 60% 5003/8340 [1:15:24<47:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:18:49,975 >> Initializing global attention on CLS token...\n",
            " 60% 5004/8340 [1:15:24<38:10,  1.46it/s][INFO|trainer.py:725] 2022-12-08 17:18:50,270 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-08 17:18:50,272 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-08 17:18:50,272 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-08 17:18:50,273 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:50,305 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:50,562 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:29,  7.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:50,815 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:41,  5.53it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:51,072 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:48,  4.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:51,326 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:51,  4.45it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:51,580 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:53,  4.27it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:51,832 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:54,  4.16it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:52,086 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:55,  4.08it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:52,341 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:55,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:52,596 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:55,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:52,847 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:55,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:53,101 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:55,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:53,355 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:55,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:53,611 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:55,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:53,862 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:55,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:54,117 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:55,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:54,371 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:55,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:54,630 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:55,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:54,889 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:55,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:55,144 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:54,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:55,404 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:54,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:55,657 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:54,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:55,920 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:54,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:56,174 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:53,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:56,428 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:53,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:56,681 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:52,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:56,935 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:52,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:57,189 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:52,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:57,447 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:52,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:57,702 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:52,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:57,956 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:51,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:58,211 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:51,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:58,466 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:51,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:58,723 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:51,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:58,980 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:50,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:59,234 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:50,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:59,490 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:50,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:59,746 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:49,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:18:59,996 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:49,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:00,250 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:49,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:00,506 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:49,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:00,761 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:48,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:01,011 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:48,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:01,266 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:48,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:01,520 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:48,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:01,776 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:47,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:02,031 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:47,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:02,294 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:11<00:47,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:02,553 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:47,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:02,806 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:47,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:03,071 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:47,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:03,330 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:47,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:03,603 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:47,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:03,859 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:46,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:04,112 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:46,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:04,373 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:46,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:04,631 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:04,887 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:45,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:05,141 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:45,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:05,398 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:44,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:05,653 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:05,907 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:43,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:06,158 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:06,414 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:06,663 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:42,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:06,913 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:42,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:07,173 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:42,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:07,432 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:42,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:07,685 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:42,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:07,942 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:42,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:08,198 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:41,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:08,455 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:41,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:08,713 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:41,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:08,973 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:41,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:09,230 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:40,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:09,487 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:40,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:09,745 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:40,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:10,003 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:40,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:10,255 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:39,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:10,510 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:39,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:10,761 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:38,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:11,013 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:38,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:11,274 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:38,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:11,529 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:11,781 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:38,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:12,039 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:37,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:12,292 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:21<00:37,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:12,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:12,799 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:36,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:13,056 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:36,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:13,307 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:23<00:36,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:13,563 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:13,821 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:35,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:14,083 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:35,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:14,335 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:35,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:14,588 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:14,840 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:34,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:15,098 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:34,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:15,353 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:15,615 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:15,871 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:34,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:16,125 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:33,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:16,382 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:33,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:16,641 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:33,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:16,895 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:33,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:17,159 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:33,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:17,421 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:32,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:17,673 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:32,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:17,934 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:32,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:18,186 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:31,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:18,441 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:31,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:18,696 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:31,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:18,956 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:31,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:19,217 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:31,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:19,472 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:30,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:19,728 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:29<00:30,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:19,982 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:29,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:20,237 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:29,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:20,492 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:29,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:20,746 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:30<00:29,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:21,001 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:28,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:21,255 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:30<00:28,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:21,508 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:28,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:21,764 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:31<00:27,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:22,016 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:31<00:27,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:22,273 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:31<00:27,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:22,526 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:22,786 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:32<00:27,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:23,054 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:32<00:27,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:23,310 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:33<00:26,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:23,566 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:26,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:23,821 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:33<00:26,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:24,077 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:33<00:25,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:24,331 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:34<00:25,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:24,590 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:24,842 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:34<00:25,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:25,097 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:34<00:24,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:25,345 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:35<00:24,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:25,600 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:35<00:24,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:25,853 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:35<00:23,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:26,107 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:35<00:23,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:26,359 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:36<00:23,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:26,610 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:36<00:22,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:26,861 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:36<00:22,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:27,115 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:36<00:22,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:27,364 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:27,624 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:37<00:22,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:27,878 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:37<00:21,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:28,134 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:37<00:21,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:28,396 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:28,655 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:38<00:21,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:28,910 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:38<00:21,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:29,166 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:38<00:20,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:29,420 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:20,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:29,674 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:39<00:20,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:29,942 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:39<00:20,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:30,195 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:39<00:19,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:30,452 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:19,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:30,703 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:40<00:19,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:30,959 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:40<00:18,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:31,217 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:40<00:18,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:31,469 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:31,721 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:41<00:18,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:31,974 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:41<00:17,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:32,236 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:41<00:17,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:32,490 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:32,759 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:42<00:17,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:33,024 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:42<00:17,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:33,299 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:42<00:17,  3.77it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:33,556 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:43<00:16,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:33,825 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:43<00:16,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:34,091 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:43<00:16,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:34,348 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:44<00:16,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:34,603 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:44<00:15,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:34,857 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:44<00:15,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:35,122 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:44<00:15,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:35,379 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:45<00:14,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:35,633 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:45<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:35,891 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:45<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:36,145 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:45<00:13,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:36,404 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:46<00:13,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:36,657 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:46<00:13,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:36,911 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:46<00:13,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:37,163 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:46<00:12,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:37,424 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:47<00:12,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:37,685 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:47<00:12,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:37,938 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:47<00:12,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:38,193 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:47<00:11,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:38,449 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:48<00:11,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:38,703 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:48<00:11,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:38,961 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:48<00:10,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:39,215 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:48<00:10,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:39,472 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:49<00:10,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:39,724 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:49<00:10,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:39,978 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:49<00:09,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:40,239 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:49<00:09,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:40,491 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:50<00:09,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:40,746 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:50<00:09,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:40,999 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:50<00:08,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:41,257 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:50<00:08,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:41,508 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:51<00:08,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:41,770 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:51<00:08,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:42,028 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:51<00:07,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:42,281 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:51<00:07,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:42,536 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:52<00:07,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:42,796 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:52<00:07,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:43,051 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:52<00:06,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:43,309 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:53<00:06,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:43,561 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:53<00:06,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:43,810 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:53<00:06,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:44,066 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:53<00:05,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:44,321 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:54<00:05,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:44,594 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:54<00:05,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:44,849 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:54<00:05,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:45,102 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:54<00:04,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:45,365 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:55<00:04,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:45,621 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:55<00:04,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:45,874 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:55<00:04,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:46,129 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:55<00:03,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:46,384 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:56<00:03,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:46,643 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:56<00:03,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:46,903 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:56<00:03,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:47,159 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:56<00:02,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:47,415 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:57<00:02,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:47,672 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:57<00:02,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:47,938 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:57<00:02,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:48,206 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:57<00:01,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:48,463 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:58<00:01,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:48,724 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:58<00:01,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:48,981 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:58<00:01,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:49,233 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:58<00:00,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:49,485 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:59<00:00,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:49,737 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:59<00:00,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:49,970 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.4740517139434814, 'eval_f1-micro': 0.762857142857143, 'eval_f1-macro': 0.6825237898270381, 'eval_runtime': 61.0638, 'eval_samples_per_second': 22.927, 'eval_steps_per_second': 3.832, 'epoch': 6.0}\n",
            " 60% 5004/8340 [1:16:25<38:10,  1.46it/s]\n",
            "100% 234/234 [01:00<00:00,  3.93it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-08 17:19:51,339 >> Saving model checkpoint to logs/output_1/checkpoint-5004\n",
            "[INFO|configuration_utils.py:447] 2022-12-08 17:19:51,340 >> Configuration saved in logs/output_1/checkpoint-5004/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-08 17:19:51,576 >> Model weights saved in logs/output_1/checkpoint-5004/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-08 17:19:51,577 >> tokenizer config file saved in logs/output_1/checkpoint-5004/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-08 17:19:51,578 >> Special tokens file saved in logs/output_1/checkpoint-5004/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:19:52,164 >> Initializing global attention on CLS token...\n",
            " 60% 5005/8340 [1:16:27<17:53:10, 19.31s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:53,057 >> Initializing global attention on CLS token...\n",
            " 60% 5006/8340 [1:16:28<12:44:52, 13.77s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:53,889 >> Initializing global attention on CLS token...\n",
            " 60% 5007/8340 [1:16:29<9:09:08,  9.89s/it] [INFO|modeling_longformer.py:1932] 2022-12-08 17:19:54,722 >> Initializing global attention on CLS token...\n",
            " 60% 5008/8340 [1:16:29<6:38:10,  7.17s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:55,556 >> Initializing global attention on CLS token...\n",
            " 60% 5009/8340 [1:16:30<4:52:31,  5.27s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:56,389 >> Initializing global attention on CLS token...\n",
            " 60% 5010/8340 [1:16:31<3:38:37,  3.94s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:57,226 >> Initializing global attention on CLS token...\n",
            " 60% 5011/8340 [1:16:32<2:47:00,  3.01s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:58,068 >> Initializing global attention on CLS token...\n",
            " 60% 5012/8340 [1:16:33<2:10:46,  2.36s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:58,906 >> Initializing global attention on CLS token...\n",
            " 60% 5013/8340 [1:16:34<1:45:26,  1.90s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:19:59,740 >> Initializing global attention on CLS token...\n",
            " 60% 5014/8340 [1:16:34<1:27:35,  1.58s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:00,572 >> Initializing global attention on CLS token...\n",
            " 60% 5015/8340 [1:16:35<1:15:12,  1.36s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:01,407 >> Initializing global attention on CLS token...\n",
            " 60% 5016/8340 [1:16:36<1:06:31,  1.20s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:02,245 >> Initializing global attention on CLS token...\n",
            " 60% 5017/8340 [1:16:37<1:00:31,  1.09s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:03,085 >> Initializing global attention on CLS token...\n",
            " 60% 5018/8340 [1:16:38<56:14,  1.02s/it]  [INFO|modeling_longformer.py:1932] 2022-12-08 17:20:03,920 >> Initializing global attention on CLS token...\n",
            " 60% 5019/8340 [1:16:39<53:17,  1.04it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:04,760 >> Initializing global attention on CLS token...\n",
            " 60% 5020/8340 [1:16:39<51:10,  1.08it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:05,599 >> Initializing global attention on CLS token...\n",
            " 60% 5021/8340 [1:16:40<49:51,  1.11it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:06,448 >> Initializing global attention on CLS token...\n",
            " 60% 5022/8340 [1:16:41<48:52,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:07,286 >> Initializing global attention on CLS token...\n",
            " 60% 5023/8340 [1:16:42<48:04,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:08,126 >> Initializing global attention on CLS token...\n",
            " 60% 5024/8340 [1:16:43<47:37,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:08,964 >> Initializing global attention on CLS token...\n",
            " 60% 5025/8340 [1:16:44<47:07,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:09,797 >> Initializing global attention on CLS token...\n",
            " 60% 5026/8340 [1:16:45<46:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:10,635 >> Initializing global attention on CLS token...\n",
            " 60% 5027/8340 [1:16:45<46:38,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:11,471 >> Initializing global attention on CLS token...\n",
            " 60% 5028/8340 [1:16:46<46:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:12,305 >> Initializing global attention on CLS token...\n",
            " 60% 5029/8340 [1:16:47<46:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:13,140 >> Initializing global attention on CLS token...\n",
            " 60% 5030/8340 [1:16:48<46:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:13,984 >> Initializing global attention on CLS token...\n",
            " 60% 5031/8340 [1:16:49<46:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:14,822 >> Initializing global attention on CLS token...\n",
            " 60% 5032/8340 [1:16:50<46:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:15,659 >> Initializing global attention on CLS token...\n",
            " 60% 5033/8340 [1:16:50<46:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:16,494 >> Initializing global attention on CLS token...\n",
            " 60% 5034/8340 [1:16:51<46:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:17,330 >> Initializing global attention on CLS token...\n",
            " 60% 5035/8340 [1:16:52<46:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:18,173 >> Initializing global attention on CLS token...\n",
            " 60% 5036/8340 [1:16:53<46:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:19,014 >> Initializing global attention on CLS token...\n",
            " 60% 5037/8340 [1:16:54<46:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:19,848 >> Initializing global attention on CLS token...\n",
            " 60% 5038/8340 [1:16:55<46:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:20,686 >> Initializing global attention on CLS token...\n",
            " 60% 5039/8340 [1:16:55<46:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:21,525 >> Initializing global attention on CLS token...\n",
            " 60% 5040/8340 [1:16:56<46:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:22,368 >> Initializing global attention on CLS token...\n",
            " 60% 5041/8340 [1:16:57<46:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:23,209 >> Initializing global attention on CLS token...\n",
            " 60% 5042/8340 [1:16:58<46:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:24,053 >> Initializing global attention on CLS token...\n",
            " 60% 5043/8340 [1:16:59<46:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:24,896 >> Initializing global attention on CLS token...\n",
            " 60% 5044/8340 [1:17:00<46:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:25,743 >> Initializing global attention on CLS token...\n",
            " 60% 5045/8340 [1:17:00<46:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:26,585 >> Initializing global attention on CLS token...\n",
            " 61% 5046/8340 [1:17:01<46:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:27,431 >> Initializing global attention on CLS token...\n",
            " 61% 5047/8340 [1:17:02<46:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:28,269 >> Initializing global attention on CLS token...\n",
            " 61% 5048/8340 [1:17:03<46:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:29,109 >> Initializing global attention on CLS token...\n",
            " 61% 5049/8340 [1:17:04<46:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:29,950 >> Initializing global attention on CLS token...\n",
            " 61% 5050/8340 [1:17:05<46:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:30,790 >> Initializing global attention on CLS token...\n",
            " 61% 5051/8340 [1:17:06<46:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:31,625 >> Initializing global attention on CLS token...\n",
            " 61% 5052/8340 [1:17:06<45:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:32,462 >> Initializing global attention on CLS token...\n",
            " 61% 5053/8340 [1:17:07<45:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:33,296 >> Initializing global attention on CLS token...\n",
            " 61% 5054/8340 [1:17:08<45:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:34,133 >> Initializing global attention on CLS token...\n",
            " 61% 5055/8340 [1:17:09<45:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:34,968 >> Initializing global attention on CLS token...\n",
            " 61% 5056/8340 [1:17:10<45:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:35,810 >> Initializing global attention on CLS token...\n",
            " 61% 5057/8340 [1:17:11<45:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:36,648 >> Initializing global attention on CLS token...\n",
            " 61% 5058/8340 [1:17:11<45:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:37,485 >> Initializing global attention on CLS token...\n",
            " 61% 5059/8340 [1:17:12<45:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:38,323 >> Initializing global attention on CLS token...\n",
            " 61% 5060/8340 [1:17:13<45:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:39,157 >> Initializing global attention on CLS token...\n",
            " 61% 5061/8340 [1:17:14<45:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:39,995 >> Initializing global attention on CLS token...\n",
            " 61% 5062/8340 [1:17:15<45:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:40,833 >> Initializing global attention on CLS token...\n",
            " 61% 5063/8340 [1:17:16<45:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:41,671 >> Initializing global attention on CLS token...\n",
            " 61% 5064/8340 [1:17:16<45:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:42,512 >> Initializing global attention on CLS token...\n",
            " 61% 5065/8340 [1:17:17<45:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:43,353 >> Initializing global attention on CLS token...\n",
            " 61% 5066/8340 [1:17:18<45:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:44,187 >> Initializing global attention on CLS token...\n",
            " 61% 5067/8340 [1:17:19<45:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:45,026 >> Initializing global attention on CLS token...\n",
            " 61% 5068/8340 [1:17:20<45:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:45,869 >> Initializing global attention on CLS token...\n",
            " 61% 5069/8340 [1:17:21<45:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:46,712 >> Initializing global attention on CLS token...\n",
            " 61% 5070/8340 [1:17:21<45:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:47,550 >> Initializing global attention on CLS token...\n",
            " 61% 5071/8340 [1:17:22<45:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:48,393 >> Initializing global attention on CLS token...\n",
            " 61% 5072/8340 [1:17:23<45:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:49,231 >> Initializing global attention on CLS token...\n",
            " 61% 5073/8340 [1:17:24<45:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:50,068 >> Initializing global attention on CLS token...\n",
            " 61% 5074/8340 [1:17:25<45:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:50,906 >> Initializing global attention on CLS token...\n",
            " 61% 5075/8340 [1:17:26<45:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:51,741 >> Initializing global attention on CLS token...\n",
            " 61% 5076/8340 [1:17:26<45:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:52,577 >> Initializing global attention on CLS token...\n",
            " 61% 5077/8340 [1:17:27<45:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:53,412 >> Initializing global attention on CLS token...\n",
            " 61% 5078/8340 [1:17:28<45:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:54,254 >> Initializing global attention on CLS token...\n",
            " 61% 5079/8340 [1:17:29<45:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:55,093 >> Initializing global attention on CLS token...\n",
            " 61% 5080/8340 [1:17:30<45:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:55,930 >> Initializing global attention on CLS token...\n",
            " 61% 5081/8340 [1:17:31<45:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:56,765 >> Initializing global attention on CLS token...\n",
            " 61% 5082/8340 [1:17:31<45:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:57,599 >> Initializing global attention on CLS token...\n",
            " 61% 5083/8340 [1:17:32<45:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:58,433 >> Initializing global attention on CLS token...\n",
            " 61% 5084/8340 [1:17:33<45:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:20:59,275 >> Initializing global attention on CLS token...\n",
            " 61% 5085/8340 [1:17:34<45:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:00,114 >> Initializing global attention on CLS token...\n",
            " 61% 5086/8340 [1:17:35<45:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:00,947 >> Initializing global attention on CLS token...\n",
            " 61% 5087/8340 [1:17:36<45:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:01,787 >> Initializing global attention on CLS token...\n",
            " 61% 5088/8340 [1:17:37<45:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:02,624 >> Initializing global attention on CLS token...\n",
            " 61% 5089/8340 [1:17:37<45:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:03,467 >> Initializing global attention on CLS token...\n",
            " 61% 5090/8340 [1:17:38<45:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:04,303 >> Initializing global attention on CLS token...\n",
            " 61% 5091/8340 [1:17:39<45:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:05,135 >> Initializing global attention on CLS token...\n",
            " 61% 5092/8340 [1:17:40<45:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:05,977 >> Initializing global attention on CLS token...\n",
            " 61% 5093/8340 [1:17:41<45:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:06,810 >> Initializing global attention on CLS token...\n",
            " 61% 5094/8340 [1:17:42<45:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:07,648 >> Initializing global attention on CLS token...\n",
            " 61% 5095/8340 [1:17:42<45:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:08,488 >> Initializing global attention on CLS token...\n",
            " 61% 5096/8340 [1:17:43<45:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:09,329 >> Initializing global attention on CLS token...\n",
            " 61% 5097/8340 [1:17:44<45:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:10,164 >> Initializing global attention on CLS token...\n",
            " 61% 5098/8340 [1:17:45<45:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:11,002 >> Initializing global attention on CLS token...\n",
            " 61% 5099/8340 [1:17:46<45:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:11,843 >> Initializing global attention on CLS token...\n",
            " 61% 5100/8340 [1:17:47<45:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:12,683 >> Initializing global attention on CLS token...\n",
            " 61% 5101/8340 [1:17:47<45:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:13,519 >> Initializing global attention on CLS token...\n",
            " 61% 5102/8340 [1:17:48<45:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:14,357 >> Initializing global attention on CLS token...\n",
            " 61% 5103/8340 [1:17:49<45:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:15,196 >> Initializing global attention on CLS token...\n",
            " 61% 5104/8340 [1:17:50<45:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:16,038 >> Initializing global attention on CLS token...\n",
            " 61% 5105/8340 [1:17:51<45:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:16,876 >> Initializing global attention on CLS token...\n",
            " 61% 5106/8340 [1:17:52<45:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:17,716 >> Initializing global attention on CLS token...\n",
            " 61% 5107/8340 [1:17:52<45:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:18,566 >> Initializing global attention on CLS token...\n",
            " 61% 5108/8340 [1:17:53<45:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:19,407 >> Initializing global attention on CLS token...\n",
            " 61% 5109/8340 [1:17:54<45:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:20,246 >> Initializing global attention on CLS token...\n",
            " 61% 5110/8340 [1:17:55<45:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:21,081 >> Initializing global attention on CLS token...\n",
            " 61% 5111/8340 [1:17:56<45:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:21,919 >> Initializing global attention on CLS token...\n",
            " 61% 5112/8340 [1:17:57<45:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:22,752 >> Initializing global attention on CLS token...\n",
            " 61% 5113/8340 [1:17:57<45:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:23,588 >> Initializing global attention on CLS token...\n",
            " 61% 5114/8340 [1:17:58<45:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:24,431 >> Initializing global attention on CLS token...\n",
            " 61% 5115/8340 [1:17:59<45:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:25,270 >> Initializing global attention on CLS token...\n",
            " 61% 5116/8340 [1:18:00<44:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:26,104 >> Initializing global attention on CLS token...\n",
            " 61% 5117/8340 [1:18:01<44:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:26,939 >> Initializing global attention on CLS token...\n",
            " 61% 5118/8340 [1:18:02<44:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:27,771 >> Initializing global attention on CLS token...\n",
            " 61% 5119/8340 [1:18:02<44:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:28,603 >> Initializing global attention on CLS token...\n",
            " 61% 5120/8340 [1:18:03<44:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:29,438 >> Initializing global attention on CLS token...\n",
            " 61% 5121/8340 [1:18:04<44:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:30,273 >> Initializing global attention on CLS token...\n",
            " 61% 5122/8340 [1:18:05<44:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:31,111 >> Initializing global attention on CLS token...\n",
            " 61% 5123/8340 [1:18:06<44:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:31,950 >> Initializing global attention on CLS token...\n",
            " 61% 5124/8340 [1:18:07<44:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:32,786 >> Initializing global attention on CLS token...\n",
            " 61% 5125/8340 [1:18:08<44:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:33,616 >> Initializing global attention on CLS token...\n",
            " 61% 5126/8340 [1:18:08<44:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:34,457 >> Initializing global attention on CLS token...\n",
            " 61% 5127/8340 [1:18:09<44:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:35,295 >> Initializing global attention on CLS token...\n",
            " 61% 5128/8340 [1:18:10<44:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:36,134 >> Initializing global attention on CLS token...\n",
            " 61% 5129/8340 [1:18:11<44:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:36,973 >> Initializing global attention on CLS token...\n",
            " 62% 5130/8340 [1:18:12<44:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:37,812 >> Initializing global attention on CLS token...\n",
            " 62% 5131/8340 [1:18:13<44:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:38,650 >> Initializing global attention on CLS token...\n",
            " 62% 5132/8340 [1:18:13<44:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:39,485 >> Initializing global attention on CLS token...\n",
            " 62% 5133/8340 [1:18:14<44:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:40,321 >> Initializing global attention on CLS token...\n",
            " 62% 5134/8340 [1:18:15<44:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:41,160 >> Initializing global attention on CLS token...\n",
            " 62% 5135/8340 [1:18:16<44:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:42,002 >> Initializing global attention on CLS token...\n",
            " 62% 5136/8340 [1:18:17<44:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:42,844 >> Initializing global attention on CLS token...\n",
            " 62% 5137/8340 [1:18:18<44:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:43,675 >> Initializing global attention on CLS token...\n",
            " 62% 5138/8340 [1:18:18<44:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:44,507 >> Initializing global attention on CLS token...\n",
            " 62% 5139/8340 [1:18:19<44:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:45,346 >> Initializing global attention on CLS token...\n",
            " 62% 5140/8340 [1:18:20<44:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:46,183 >> Initializing global attention on CLS token...\n",
            " 62% 5141/8340 [1:18:21<44:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:47,022 >> Initializing global attention on CLS token...\n",
            " 62% 5142/8340 [1:18:22<44:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:47,856 >> Initializing global attention on CLS token...\n",
            " 62% 5143/8340 [1:18:23<44:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:48,692 >> Initializing global attention on CLS token...\n",
            " 62% 5144/8340 [1:18:23<44:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:49,526 >> Initializing global attention on CLS token...\n",
            " 62% 5145/8340 [1:18:24<44:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:50,363 >> Initializing global attention on CLS token...\n",
            " 62% 5146/8340 [1:18:25<44:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:51,198 >> Initializing global attention on CLS token...\n",
            " 62% 5147/8340 [1:18:26<44:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:52,034 >> Initializing global attention on CLS token...\n",
            " 62% 5148/8340 [1:18:27<44:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:52,867 >> Initializing global attention on CLS token...\n",
            " 62% 5149/8340 [1:18:28<44:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:53,701 >> Initializing global attention on CLS token...\n",
            " 62% 5150/8340 [1:18:28<44:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:54,534 >> Initializing global attention on CLS token...\n",
            " 62% 5151/8340 [1:18:29<44:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:55,375 >> Initializing global attention on CLS token...\n",
            " 62% 5152/8340 [1:18:30<44:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:56,214 >> Initializing global attention on CLS token...\n",
            " 62% 5153/8340 [1:18:31<44:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:57,054 >> Initializing global attention on CLS token...\n",
            " 62% 5154/8340 [1:18:32<44:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:57,887 >> Initializing global attention on CLS token...\n",
            " 62% 5155/8340 [1:18:33<44:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:58,721 >> Initializing global attention on CLS token...\n",
            " 62% 5156/8340 [1:18:33<44:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:21:59,561 >> Initializing global attention on CLS token...\n",
            " 62% 5157/8340 [1:18:34<44:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:00,399 >> Initializing global attention on CLS token...\n",
            " 62% 5158/8340 [1:18:35<44:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:01,241 >> Initializing global attention on CLS token...\n",
            " 62% 5159/8340 [1:18:36<44:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:02,077 >> Initializing global attention on CLS token...\n",
            " 62% 5160/8340 [1:18:37<44:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:02,918 >> Initializing global attention on CLS token...\n",
            " 62% 5161/8340 [1:18:38<44:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:03,754 >> Initializing global attention on CLS token...\n",
            " 62% 5162/8340 [1:18:38<44:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:04,587 >> Initializing global attention on CLS token...\n",
            " 62% 5163/8340 [1:18:39<44:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:05,432 >> Initializing global attention on CLS token...\n",
            " 62% 5164/8340 [1:18:40<44:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:06,265 >> Initializing global attention on CLS token...\n",
            " 62% 5165/8340 [1:18:41<44:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:07,103 >> Initializing global attention on CLS token...\n",
            " 62% 5166/8340 [1:18:42<44:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:07,943 >> Initializing global attention on CLS token...\n",
            " 62% 5167/8340 [1:18:43<44:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:08,788 >> Initializing global attention on CLS token...\n",
            " 62% 5168/8340 [1:18:44<44:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:09,627 >> Initializing global attention on CLS token...\n",
            " 62% 5169/8340 [1:18:44<44:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:10,472 >> Initializing global attention on CLS token...\n",
            " 62% 5170/8340 [1:18:45<44:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:11,308 >> Initializing global attention on CLS token...\n",
            " 62% 5171/8340 [1:18:46<44:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:12,152 >> Initializing global attention on CLS token...\n",
            " 62% 5172/8340 [1:18:47<44:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:12,987 >> Initializing global attention on CLS token...\n",
            " 62% 5173/8340 [1:18:48<44:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:13,826 >> Initializing global attention on CLS token...\n",
            " 62% 5174/8340 [1:18:49<44:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:14,659 >> Initializing global attention on CLS token...\n",
            " 62% 5175/8340 [1:18:49<44:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:15,498 >> Initializing global attention on CLS token...\n",
            " 62% 5176/8340 [1:18:50<44:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:16,333 >> Initializing global attention on CLS token...\n",
            " 62% 5177/8340 [1:18:51<44:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:17,174 >> Initializing global attention on CLS token...\n",
            " 62% 5178/8340 [1:18:52<44:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:18,009 >> Initializing global attention on CLS token...\n",
            " 62% 5179/8340 [1:18:53<44:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:18,842 >> Initializing global attention on CLS token...\n",
            " 62% 5180/8340 [1:18:54<44:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:19,676 >> Initializing global attention on CLS token...\n",
            " 62% 5181/8340 [1:18:54<44:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:20,518 >> Initializing global attention on CLS token...\n",
            " 62% 5182/8340 [1:18:55<44:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:21,355 >> Initializing global attention on CLS token...\n",
            " 62% 5183/8340 [1:18:56<44:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:22,198 >> Initializing global attention on CLS token...\n",
            " 62% 5184/8340 [1:18:57<44:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:23,037 >> Initializing global attention on CLS token...\n",
            " 62% 5185/8340 [1:18:58<44:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:23,877 >> Initializing global attention on CLS token...\n",
            " 62% 5186/8340 [1:18:59<44:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:24,707 >> Initializing global attention on CLS token...\n",
            " 62% 5187/8340 [1:18:59<43:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:25,545 >> Initializing global attention on CLS token...\n",
            " 62% 5188/8340 [1:19:00<43:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:26,382 >> Initializing global attention on CLS token...\n",
            " 62% 5189/8340 [1:19:01<44:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:27,223 >> Initializing global attention on CLS token...\n",
            " 62% 5190/8340 [1:19:02<44:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:28,063 >> Initializing global attention on CLS token...\n",
            " 62% 5191/8340 [1:19:03<43:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:28,898 >> Initializing global attention on CLS token...\n",
            " 62% 5192/8340 [1:19:04<43:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:29,733 >> Initializing global attention on CLS token...\n",
            " 62% 5193/8340 [1:19:04<43:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:30,569 >> Initializing global attention on CLS token...\n",
            " 62% 5194/8340 [1:19:05<44:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:31,416 >> Initializing global attention on CLS token...\n",
            " 62% 5195/8340 [1:19:06<43:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:32,252 >> Initializing global attention on CLS token...\n",
            " 62% 5196/8340 [1:19:07<43:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:33,091 >> Initializing global attention on CLS token...\n",
            " 62% 5197/8340 [1:19:08<44:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:33,934 >> Initializing global attention on CLS token...\n",
            " 62% 5198/8340 [1:19:09<43:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:34,773 >> Initializing global attention on CLS token...\n",
            " 62% 5199/8340 [1:19:09<43:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:35,608 >> Initializing global attention on CLS token...\n",
            " 62% 5200/8340 [1:19:10<43:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:36,449 >> Initializing global attention on CLS token...\n",
            " 62% 5201/8340 [1:19:11<43:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:37,290 >> Initializing global attention on CLS token...\n",
            " 62% 5202/8340 [1:19:12<43:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:38,129 >> Initializing global attention on CLS token...\n",
            " 62% 5203/8340 [1:19:13<43:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:38,972 >> Initializing global attention on CLS token...\n",
            " 62% 5204/8340 [1:19:14<43:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:39,815 >> Initializing global attention on CLS token...\n",
            " 62% 5205/8340 [1:19:15<43:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:40,648 >> Initializing global attention on CLS token...\n",
            " 62% 5206/8340 [1:19:15<43:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:41,481 >> Initializing global attention on CLS token...\n",
            " 62% 5207/8340 [1:19:16<43:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:42,320 >> Initializing global attention on CLS token...\n",
            " 62% 5208/8340 [1:19:17<43:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:43,158 >> Initializing global attention on CLS token...\n",
            " 62% 5209/8340 [1:19:18<43:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:43,993 >> Initializing global attention on CLS token...\n",
            " 62% 5210/8340 [1:19:19<43:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:44,829 >> Initializing global attention on CLS token...\n",
            " 62% 5211/8340 [1:19:20<43:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:45,669 >> Initializing global attention on CLS token...\n",
            " 62% 5212/8340 [1:19:20<43:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:46,504 >> Initializing global attention on CLS token...\n",
            " 63% 5213/8340 [1:19:21<43:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:47,341 >> Initializing global attention on CLS token...\n",
            " 63% 5214/8340 [1:19:22<43:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:48,177 >> Initializing global attention on CLS token...\n",
            " 63% 5215/8340 [1:19:23<43:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:49,018 >> Initializing global attention on CLS token...\n",
            " 63% 5216/8340 [1:19:24<43:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:49,856 >> Initializing global attention on CLS token...\n",
            " 63% 5217/8340 [1:19:25<43:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:50,695 >> Initializing global attention on CLS token...\n",
            " 63% 5218/8340 [1:19:25<43:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:51,532 >> Initializing global attention on CLS token...\n",
            " 63% 5219/8340 [1:19:26<43:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:52,367 >> Initializing global attention on CLS token...\n",
            " 63% 5220/8340 [1:19:27<43:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:53,203 >> Initializing global attention on CLS token...\n",
            " 63% 5221/8340 [1:19:28<43:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:54,039 >> Initializing global attention on CLS token...\n",
            " 63% 5222/8340 [1:19:29<43:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:54,881 >> Initializing global attention on CLS token...\n",
            " 63% 5223/8340 [1:19:30<43:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:55,722 >> Initializing global attention on CLS token...\n",
            " 63% 5224/8340 [1:19:30<43:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:56,559 >> Initializing global attention on CLS token...\n",
            " 63% 5225/8340 [1:19:31<43:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:57,398 >> Initializing global attention on CLS token...\n",
            " 63% 5226/8340 [1:19:32<43:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:58,235 >> Initializing global attention on CLS token...\n",
            " 63% 5227/8340 [1:19:33<43:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:59,078 >> Initializing global attention on CLS token...\n",
            " 63% 5228/8340 [1:19:34<43:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:22:59,923 >> Initializing global attention on CLS token...\n",
            " 63% 5229/8340 [1:19:35<43:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:00,767 >> Initializing global attention on CLS token...\n",
            " 63% 5230/8340 [1:19:35<43:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:01,607 >> Initializing global attention on CLS token...\n",
            " 63% 5231/8340 [1:19:36<43:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:02,442 >> Initializing global attention on CLS token...\n",
            " 63% 5232/8340 [1:19:37<43:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:03,281 >> Initializing global attention on CLS token...\n",
            " 63% 5233/8340 [1:19:38<43:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:04,115 >> Initializing global attention on CLS token...\n",
            " 63% 5234/8340 [1:19:39<43:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:04,952 >> Initializing global attention on CLS token...\n",
            " 63% 5235/8340 [1:19:40<43:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:05,792 >> Initializing global attention on CLS token...\n",
            " 63% 5236/8340 [1:19:41<43:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:06,629 >> Initializing global attention on CLS token...\n",
            " 63% 5237/8340 [1:19:41<43:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:07,463 >> Initializing global attention on CLS token...\n",
            " 63% 5238/8340 [1:19:42<43:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:08,303 >> Initializing global attention on CLS token...\n",
            " 63% 5239/8340 [1:19:43<43:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:09,139 >> Initializing global attention on CLS token...\n",
            " 63% 5240/8340 [1:19:44<43:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:09,988 >> Initializing global attention on CLS token...\n",
            " 63% 5241/8340 [1:19:45<43:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:10,822 >> Initializing global attention on CLS token...\n",
            " 63% 5242/8340 [1:19:46<43:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:11,658 >> Initializing global attention on CLS token...\n",
            " 63% 5243/8340 [1:19:46<43:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:12,496 >> Initializing global attention on CLS token...\n",
            " 63% 5244/8340 [1:19:47<43:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:13,339 >> Initializing global attention on CLS token...\n",
            " 63% 5245/8340 [1:19:48<43:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:14,176 >> Initializing global attention on CLS token...\n",
            " 63% 5246/8340 [1:19:49<43:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:15,013 >> Initializing global attention on CLS token...\n",
            " 63% 5247/8340 [1:19:50<43:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:15,850 >> Initializing global attention on CLS token...\n",
            " 63% 5248/8340 [1:19:51<43:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:16,683 >> Initializing global attention on CLS token...\n",
            " 63% 5249/8340 [1:19:51<43:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:17,524 >> Initializing global attention on CLS token...\n",
            " 63% 5250/8340 [1:19:52<43:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:18,359 >> Initializing global attention on CLS token...\n",
            " 63% 5251/8340 [1:19:53<43:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:19,194 >> Initializing global attention on CLS token...\n",
            " 63% 5252/8340 [1:19:54<43:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:20,031 >> Initializing global attention on CLS token...\n",
            " 63% 5253/8340 [1:19:55<43:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:20,870 >> Initializing global attention on CLS token...\n",
            " 63% 5254/8340 [1:19:56<43:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:21,705 >> Initializing global attention on CLS token...\n",
            " 63% 5255/8340 [1:19:56<43:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:22,544 >> Initializing global attention on CLS token...\n",
            " 63% 5256/8340 [1:19:57<43:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:23,382 >> Initializing global attention on CLS token...\n",
            " 63% 5257/8340 [1:19:58<43:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:24,219 >> Initializing global attention on CLS token...\n",
            " 63% 5258/8340 [1:19:59<43:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:25,056 >> Initializing global attention on CLS token...\n",
            " 63% 5259/8340 [1:20:00<42:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:25,900 >> Initializing global attention on CLS token...\n",
            " 63% 5260/8340 [1:20:01<43:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:26,746 >> Initializing global attention on CLS token...\n",
            " 63% 5261/8340 [1:20:01<43:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:27,583 >> Initializing global attention on CLS token...\n",
            " 63% 5262/8340 [1:20:02<43:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:28,425 >> Initializing global attention on CLS token...\n",
            " 63% 5263/8340 [1:20:03<43:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:29,263 >> Initializing global attention on CLS token...\n",
            " 63% 5264/8340 [1:20:04<43:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:30,101 >> Initializing global attention on CLS token...\n",
            " 63% 5265/8340 [1:20:05<42:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:30,936 >> Initializing global attention on CLS token...\n",
            " 63% 5266/8340 [1:20:06<42:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:31,777 >> Initializing global attention on CLS token...\n",
            " 63% 5267/8340 [1:20:07<43:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:32,623 >> Initializing global attention on CLS token...\n",
            " 63% 5268/8340 [1:20:07<42:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:33,458 >> Initializing global attention on CLS token...\n",
            " 63% 5269/8340 [1:20:08<42:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:34,290 >> Initializing global attention on CLS token...\n",
            " 63% 5270/8340 [1:20:09<42:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:35,125 >> Initializing global attention on CLS token...\n",
            " 63% 5271/8340 [1:20:10<42:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:35,965 >> Initializing global attention on CLS token...\n",
            " 63% 5272/8340 [1:20:11<42:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:36,803 >> Initializing global attention on CLS token...\n",
            " 63% 5273/8340 [1:20:12<42:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:37,645 >> Initializing global attention on CLS token...\n",
            " 63% 5274/8340 [1:20:12<42:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:38,478 >> Initializing global attention on CLS token...\n",
            " 63% 5275/8340 [1:20:13<42:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:39,314 >> Initializing global attention on CLS token...\n",
            " 63% 5276/8340 [1:20:14<42:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:40,154 >> Initializing global attention on CLS token...\n",
            " 63% 5277/8340 [1:20:15<42:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:40,993 >> Initializing global attention on CLS token...\n",
            " 63% 5278/8340 [1:20:16<42:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:41,829 >> Initializing global attention on CLS token...\n",
            " 63% 5279/8340 [1:20:17<42:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:42,665 >> Initializing global attention on CLS token...\n",
            " 63% 5280/8340 [1:20:17<42:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:43,500 >> Initializing global attention on CLS token...\n",
            " 63% 5281/8340 [1:20:18<42:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:44,336 >> Initializing global attention on CLS token...\n",
            " 63% 5282/8340 [1:20:19<42:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:45,175 >> Initializing global attention on CLS token...\n",
            " 63% 5283/8340 [1:20:20<42:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:46,015 >> Initializing global attention on CLS token...\n",
            " 63% 5284/8340 [1:20:21<42:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:46,855 >> Initializing global attention on CLS token...\n",
            " 63% 5285/8340 [1:20:22<42:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:47,706 >> Initializing global attention on CLS token...\n",
            " 63% 5286/8340 [1:20:22<42:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:48,550 >> Initializing global attention on CLS token...\n",
            " 63% 5287/8340 [1:20:23<42:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:49,395 >> Initializing global attention on CLS token...\n",
            " 63% 5288/8340 [1:20:24<42:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:50,238 >> Initializing global attention on CLS token...\n",
            " 63% 5289/8340 [1:20:25<42:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:51,082 >> Initializing global attention on CLS token...\n",
            " 63% 5290/8340 [1:20:26<42:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:51,917 >> Initializing global attention on CLS token...\n",
            " 63% 5291/8340 [1:20:27<42:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:52,751 >> Initializing global attention on CLS token...\n",
            " 63% 5292/8340 [1:20:27<42:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:53,587 >> Initializing global attention on CLS token...\n",
            " 63% 5293/8340 [1:20:28<42:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:54,422 >> Initializing global attention on CLS token...\n",
            " 63% 5294/8340 [1:20:29<42:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:55,258 >> Initializing global attention on CLS token...\n",
            " 63% 5295/8340 [1:20:30<42:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:56,092 >> Initializing global attention on CLS token...\n",
            " 64% 5296/8340 [1:20:31<42:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:56,925 >> Initializing global attention on CLS token...\n",
            " 64% 5297/8340 [1:20:32<42:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:57,758 >> Initializing global attention on CLS token...\n",
            " 64% 5298/8340 [1:20:32<42:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:58,595 >> Initializing global attention on CLS token...\n",
            " 64% 5299/8340 [1:20:33<42:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:23:59,431 >> Initializing global attention on CLS token...\n",
            " 64% 5300/8340 [1:20:34<42:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:00,265 >> Initializing global attention on CLS token...\n",
            " 64% 5301/8340 [1:20:35<42:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:01,102 >> Initializing global attention on CLS token...\n",
            " 64% 5302/8340 [1:20:36<42:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:01,939 >> Initializing global attention on CLS token...\n",
            " 64% 5303/8340 [1:20:37<42:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:02,773 >> Initializing global attention on CLS token...\n",
            " 64% 5304/8340 [1:20:37<42:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:03,606 >> Initializing global attention on CLS token...\n",
            " 64% 5305/8340 [1:20:38<42:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:04,446 >> Initializing global attention on CLS token...\n",
            " 64% 5306/8340 [1:20:39<42:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:05,288 >> Initializing global attention on CLS token...\n",
            " 64% 5307/8340 [1:20:40<42:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:06,129 >> Initializing global attention on CLS token...\n",
            " 64% 5308/8340 [1:20:41<42:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:06,963 >> Initializing global attention on CLS token...\n",
            " 64% 5309/8340 [1:20:42<42:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:07,800 >> Initializing global attention on CLS token...\n",
            " 64% 5310/8340 [1:20:43<42:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:08,636 >> Initializing global attention on CLS token...\n",
            " 64% 5311/8340 [1:20:43<42:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:09,475 >> Initializing global attention on CLS token...\n",
            " 64% 5312/8340 [1:20:44<42:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:10,313 >> Initializing global attention on CLS token...\n",
            " 64% 5313/8340 [1:20:45<42:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:11,153 >> Initializing global attention on CLS token...\n",
            " 64% 5314/8340 [1:20:46<42:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:11,993 >> Initializing global attention on CLS token...\n",
            " 64% 5315/8340 [1:20:47<42:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:12,830 >> Initializing global attention on CLS token...\n",
            " 64% 5316/8340 [1:20:48<42:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:13,668 >> Initializing global attention on CLS token...\n",
            " 64% 5317/8340 [1:20:48<42:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:14,505 >> Initializing global attention on CLS token...\n",
            " 64% 5318/8340 [1:20:49<42:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:15,344 >> Initializing global attention on CLS token...\n",
            " 64% 5319/8340 [1:20:50<42:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:16,194 >> Initializing global attention on CLS token...\n",
            " 64% 5320/8340 [1:20:51<42:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:17,037 >> Initializing global attention on CLS token...\n",
            " 64% 5321/8340 [1:20:52<42:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:17,875 >> Initializing global attention on CLS token...\n",
            " 64% 5322/8340 [1:20:53<42:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:18,711 >> Initializing global attention on CLS token...\n",
            " 64% 5323/8340 [1:20:53<42:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:19,552 >> Initializing global attention on CLS token...\n",
            " 64% 5324/8340 [1:20:54<42:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:20,425 >> Initializing global attention on CLS token...\n",
            " 64% 5325/8340 [1:20:55<42:49,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:21,291 >> Initializing global attention on CLS token...\n",
            " 64% 5326/8340 [1:20:56<42:55,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:22,142 >> Initializing global attention on CLS token...\n",
            " 64% 5327/8340 [1:20:57<42:50,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:22,997 >> Initializing global attention on CLS token...\n",
            " 64% 5328/8340 [1:20:58<42:46,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:23,835 >> Initializing global attention on CLS token...\n",
            " 64% 5329/8340 [1:20:59<42:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:24,668 >> Initializing global attention on CLS token...\n",
            " 64% 5330/8340 [1:20:59<42:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:25,506 >> Initializing global attention on CLS token...\n",
            " 64% 5331/8340 [1:21:00<42:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:26,350 >> Initializing global attention on CLS token...\n",
            " 64% 5332/8340 [1:21:01<42:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:27,191 >> Initializing global attention on CLS token...\n",
            " 64% 5333/8340 [1:21:02<42:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:28,031 >> Initializing global attention on CLS token...\n",
            " 64% 5334/8340 [1:21:03<42:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:28,871 >> Initializing global attention on CLS token...\n",
            " 64% 5335/8340 [1:21:04<42:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:29,712 >> Initializing global attention on CLS token...\n",
            " 64% 5336/8340 [1:21:04<42:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:30,551 >> Initializing global attention on CLS token...\n",
            " 64% 5337/8340 [1:21:05<42:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:31,390 >> Initializing global attention on CLS token...\n",
            " 64% 5338/8340 [1:21:06<42:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:32,229 >> Initializing global attention on CLS token...\n",
            " 64% 5339/8340 [1:21:07<41:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:33,065 >> Initializing global attention on CLS token...\n",
            " 64% 5340/8340 [1:21:08<41:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:33,904 >> Initializing global attention on CLS token...\n",
            " 64% 5341/8340 [1:21:09<41:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:34,741 >> Initializing global attention on CLS token...\n",
            " 64% 5342/8340 [1:21:09<41:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:35,582 >> Initializing global attention on CLS token...\n",
            " 64% 5343/8340 [1:21:10<41:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:36,417 >> Initializing global attention on CLS token...\n",
            " 64% 5344/8340 [1:21:11<41:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:37,256 >> Initializing global attention on CLS token...\n",
            " 64% 5345/8340 [1:21:12<41:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:38,094 >> Initializing global attention on CLS token...\n",
            " 64% 5346/8340 [1:21:13<41:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:38,933 >> Initializing global attention on CLS token...\n",
            " 64% 5347/8340 [1:21:14<41:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:39,772 >> Initializing global attention on CLS token...\n",
            " 64% 5348/8340 [1:21:14<41:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:40,614 >> Initializing global attention on CLS token...\n",
            " 64% 5349/8340 [1:21:15<41:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:41,459 >> Initializing global attention on CLS token...\n",
            " 64% 5350/8340 [1:21:16<41:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:42,296 >> Initializing global attention on CLS token...\n",
            " 64% 5351/8340 [1:21:17<41:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:43,142 >> Initializing global attention on CLS token...\n",
            " 64% 5352/8340 [1:21:18<41:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:43,977 >> Initializing global attention on CLS token...\n",
            " 64% 5353/8340 [1:21:19<41:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:44,815 >> Initializing global attention on CLS token...\n",
            " 64% 5354/8340 [1:21:20<41:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:45,648 >> Initializing global attention on CLS token...\n",
            " 64% 5355/8340 [1:21:20<41:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:46,482 >> Initializing global attention on CLS token...\n",
            " 64% 5356/8340 [1:21:21<41:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:47,319 >> Initializing global attention on CLS token...\n",
            " 64% 5357/8340 [1:21:22<41:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:48,164 >> Initializing global attention on CLS token...\n",
            " 64% 5358/8340 [1:21:23<41:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:48,998 >> Initializing global attention on CLS token...\n",
            " 64% 5359/8340 [1:21:24<41:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:49,833 >> Initializing global attention on CLS token...\n",
            " 64% 5360/8340 [1:21:25<41:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:50,671 >> Initializing global attention on CLS token...\n",
            " 64% 5361/8340 [1:21:25<41:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:51,506 >> Initializing global attention on CLS token...\n",
            " 64% 5362/8340 [1:21:26<41:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:52,342 >> Initializing global attention on CLS token...\n",
            " 64% 5363/8340 [1:21:27<41:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:53,181 >> Initializing global attention on CLS token...\n",
            " 64% 5364/8340 [1:21:28<41:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:54,022 >> Initializing global attention on CLS token...\n",
            " 64% 5365/8340 [1:21:29<41:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:54,860 >> Initializing global attention on CLS token...\n",
            " 64% 5366/8340 [1:21:30<41:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:55,699 >> Initializing global attention on CLS token...\n",
            " 64% 5367/8340 [1:21:30<41:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:56,541 >> Initializing global attention on CLS token...\n",
            " 64% 5368/8340 [1:21:31<41:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:57,384 >> Initializing global attention on CLS token...\n",
            " 64% 5369/8340 [1:21:32<41:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:58,226 >> Initializing global attention on CLS token...\n",
            " 64% 5370/8340 [1:21:33<41:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:59,069 >> Initializing global attention on CLS token...\n",
            " 64% 5371/8340 [1:21:34<41:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:24:59,909 >> Initializing global attention on CLS token...\n",
            " 64% 5372/8340 [1:21:35<41:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:00,750 >> Initializing global attention on CLS token...\n",
            " 64% 5373/8340 [1:21:35<41:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:01,587 >> Initializing global attention on CLS token...\n",
            " 64% 5374/8340 [1:21:36<41:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:02,426 >> Initializing global attention on CLS token...\n",
            " 64% 5375/8340 [1:21:37<41:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:03,262 >> Initializing global attention on CLS token...\n",
            " 64% 5376/8340 [1:21:38<41:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:04,098 >> Initializing global attention on CLS token...\n",
            " 64% 5377/8340 [1:21:39<41:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:04,933 >> Initializing global attention on CLS token...\n",
            " 64% 5378/8340 [1:21:40<41:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:05,765 >> Initializing global attention on CLS token...\n",
            " 64% 5379/8340 [1:21:40<41:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:06,602 >> Initializing global attention on CLS token...\n",
            " 65% 5380/8340 [1:21:41<41:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:07,441 >> Initializing global attention on CLS token...\n",
            " 65% 5381/8340 [1:21:42<41:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:08,280 >> Initializing global attention on CLS token...\n",
            " 65% 5382/8340 [1:21:43<41:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:09,116 >> Initializing global attention on CLS token...\n",
            " 65% 5383/8340 [1:21:44<41:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:09,959 >> Initializing global attention on CLS token...\n",
            " 65% 5384/8340 [1:21:45<41:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:10,799 >> Initializing global attention on CLS token...\n",
            " 65% 5385/8340 [1:21:46<41:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:11,635 >> Initializing global attention on CLS token...\n",
            " 65% 5386/8340 [1:21:46<41:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:12,476 >> Initializing global attention on CLS token...\n",
            " 65% 5387/8340 [1:21:47<41:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:13,315 >> Initializing global attention on CLS token...\n",
            " 65% 5388/8340 [1:21:48<41:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:14,150 >> Initializing global attention on CLS token...\n",
            " 65% 5389/8340 [1:21:49<41:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:14,984 >> Initializing global attention on CLS token...\n",
            " 65% 5390/8340 [1:21:50<41:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:15,818 >> Initializing global attention on CLS token...\n",
            " 65% 5391/8340 [1:21:51<41:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:16,652 >> Initializing global attention on CLS token...\n",
            " 65% 5392/8340 [1:21:51<41:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:17,491 >> Initializing global attention on CLS token...\n",
            " 65% 5393/8340 [1:21:52<41:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:18,325 >> Initializing global attention on CLS token...\n",
            " 65% 5394/8340 [1:21:53<41:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:19,162 >> Initializing global attention on CLS token...\n",
            " 65% 5395/8340 [1:21:54<41:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:19,998 >> Initializing global attention on CLS token...\n",
            " 65% 5396/8340 [1:21:55<41:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:20,835 >> Initializing global attention on CLS token...\n",
            " 65% 5397/8340 [1:21:56<41:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:21,670 >> Initializing global attention on CLS token...\n",
            " 65% 5398/8340 [1:21:56<40:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:22,505 >> Initializing global attention on CLS token...\n",
            " 65% 5399/8340 [1:21:57<40:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:23,338 >> Initializing global attention on CLS token...\n",
            " 65% 5400/8340 [1:21:58<40:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:24,180 >> Initializing global attention on CLS token...\n",
            " 65% 5401/8340 [1:21:59<41:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:25,019 >> Initializing global attention on CLS token...\n",
            " 65% 5402/8340 [1:22:00<40:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:25,854 >> Initializing global attention on CLS token...\n",
            " 65% 5403/8340 [1:22:01<40:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:26,690 >> Initializing global attention on CLS token...\n",
            " 65% 5404/8340 [1:22:01<40:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:27,526 >> Initializing global attention on CLS token...\n",
            " 65% 5405/8340 [1:22:02<40:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:28,363 >> Initializing global attention on CLS token...\n",
            " 65% 5406/8340 [1:22:03<40:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:29,201 >> Initializing global attention on CLS token...\n",
            " 65% 5407/8340 [1:22:04<40:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:30,037 >> Initializing global attention on CLS token...\n",
            " 65% 5408/8340 [1:22:05<40:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:30,879 >> Initializing global attention on CLS token...\n",
            " 65% 5409/8340 [1:22:06<40:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:31,717 >> Initializing global attention on CLS token...\n",
            " 65% 5410/8340 [1:22:06<40:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:32,557 >> Initializing global attention on CLS token...\n",
            " 65% 5411/8340 [1:22:07<40:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:33,393 >> Initializing global attention on CLS token...\n",
            " 65% 5412/8340 [1:22:08<40:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:34,233 >> Initializing global attention on CLS token...\n",
            " 65% 5413/8340 [1:22:09<40:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:35,068 >> Initializing global attention on CLS token...\n",
            " 65% 5414/8340 [1:22:10<40:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:35,900 >> Initializing global attention on CLS token...\n",
            " 65% 5415/8340 [1:22:11<40:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:36,734 >> Initializing global attention on CLS token...\n",
            " 65% 5416/8340 [1:22:11<40:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:37,574 >> Initializing global attention on CLS token...\n",
            " 65% 5417/8340 [1:22:12<40:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:38,416 >> Initializing global attention on CLS token...\n",
            " 65% 5418/8340 [1:22:13<40:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:39,251 >> Initializing global attention on CLS token...\n",
            " 65% 5419/8340 [1:22:14<40:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:40,093 >> Initializing global attention on CLS token...\n",
            " 65% 5420/8340 [1:22:15<40:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:40,934 >> Initializing global attention on CLS token...\n",
            " 65% 5421/8340 [1:22:16<40:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:41,773 >> Initializing global attention on CLS token...\n",
            " 65% 5422/8340 [1:22:16<40:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:42,613 >> Initializing global attention on CLS token...\n",
            " 65% 5423/8340 [1:22:17<40:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:43,454 >> Initializing global attention on CLS token...\n",
            " 65% 5424/8340 [1:22:18<40:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:44,292 >> Initializing global attention on CLS token...\n",
            " 65% 5425/8340 [1:22:19<40:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:45,136 >> Initializing global attention on CLS token...\n",
            " 65% 5426/8340 [1:22:20<40:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:45,980 >> Initializing global attention on CLS token...\n",
            " 65% 5427/8340 [1:22:21<40:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:46,829 >> Initializing global attention on CLS token...\n",
            " 65% 5428/8340 [1:22:22<40:58,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:47,672 >> Initializing global attention on CLS token...\n",
            " 65% 5429/8340 [1:22:22<40:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:48,509 >> Initializing global attention on CLS token...\n",
            " 65% 5430/8340 [1:22:23<40:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:49,342 >> Initializing global attention on CLS token...\n",
            " 65% 5431/8340 [1:22:24<40:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:50,183 >> Initializing global attention on CLS token...\n",
            " 65% 5432/8340 [1:22:25<40:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:51,025 >> Initializing global attention on CLS token...\n",
            " 65% 5433/8340 [1:22:26<40:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:51,865 >> Initializing global attention on CLS token...\n",
            " 65% 5434/8340 [1:22:27<40:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:52,701 >> Initializing global attention on CLS token...\n",
            " 65% 5435/8340 [1:22:27<40:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:53,535 >> Initializing global attention on CLS token...\n",
            " 65% 5436/8340 [1:22:28<40:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:54,379 >> Initializing global attention on CLS token...\n",
            " 65% 5437/8340 [1:22:29<40:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:55,212 >> Initializing global attention on CLS token...\n",
            " 65% 5438/8340 [1:22:30<40:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:56,049 >> Initializing global attention on CLS token...\n",
            " 65% 5439/8340 [1:22:31<40:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:56,879 >> Initializing global attention on CLS token...\n",
            " 65% 5440/8340 [1:22:32<40:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:57,721 >> Initializing global attention on CLS token...\n",
            " 65% 5441/8340 [1:22:32<40:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:58,555 >> Initializing global attention on CLS token...\n",
            " 65% 5442/8340 [1:22:33<40:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:25:59,396 >> Initializing global attention on CLS token...\n",
            " 65% 5443/8340 [1:22:34<40:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:00,233 >> Initializing global attention on CLS token...\n",
            " 65% 5444/8340 [1:22:35<40:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:01,070 >> Initializing global attention on CLS token...\n",
            " 65% 5445/8340 [1:22:36<40:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:01,906 >> Initializing global attention on CLS token...\n",
            " 65% 5446/8340 [1:22:37<40:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:02,740 >> Initializing global attention on CLS token...\n",
            " 65% 5447/8340 [1:22:37<40:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:03,573 >> Initializing global attention on CLS token...\n",
            " 65% 5448/8340 [1:22:38<40:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:04,408 >> Initializing global attention on CLS token...\n",
            " 65% 5449/8340 [1:22:39<40:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:05,244 >> Initializing global attention on CLS token...\n",
            " 65% 5450/8340 [1:22:40<40:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:06,084 >> Initializing global attention on CLS token...\n",
            " 65% 5451/8340 [1:22:41<40:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:06,921 >> Initializing global attention on CLS token...\n",
            " 65% 5452/8340 [1:22:42<40:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:07,760 >> Initializing global attention on CLS token...\n",
            " 65% 5453/8340 [1:22:42<40:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:08,592 >> Initializing global attention on CLS token...\n",
            " 65% 5454/8340 [1:22:43<40:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:09,427 >> Initializing global attention on CLS token...\n",
            " 65% 5455/8340 [1:22:44<40:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:10,266 >> Initializing global attention on CLS token...\n",
            " 65% 5456/8340 [1:22:45<40:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:11,102 >> Initializing global attention on CLS token...\n",
            " 65% 5457/8340 [1:22:46<40:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:11,940 >> Initializing global attention on CLS token...\n",
            " 65% 5458/8340 [1:22:47<40:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:12,779 >> Initializing global attention on CLS token...\n",
            " 65% 5459/8340 [1:22:47<40:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:13,612 >> Initializing global attention on CLS token...\n",
            " 65% 5460/8340 [1:22:48<40:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:14,450 >> Initializing global attention on CLS token...\n",
            " 65% 5461/8340 [1:22:49<40:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:15,286 >> Initializing global attention on CLS token...\n",
            " 65% 5462/8340 [1:22:50<40:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:16,118 >> Initializing global attention on CLS token...\n",
            " 66% 5463/8340 [1:22:51<40:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:16,952 >> Initializing global attention on CLS token...\n",
            " 66% 5464/8340 [1:22:52<40:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:17,793 >> Initializing global attention on CLS token...\n",
            " 66% 5465/8340 [1:22:53<40:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:18,627 >> Initializing global attention on CLS token...\n",
            " 66% 5466/8340 [1:22:53<40:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:19,467 >> Initializing global attention on CLS token...\n",
            " 66% 5467/8340 [1:22:54<40:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:20,306 >> Initializing global attention on CLS token...\n",
            " 66% 5468/8340 [1:22:55<40:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:21,144 >> Initializing global attention on CLS token...\n",
            " 66% 5469/8340 [1:22:56<40:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:21,987 >> Initializing global attention on CLS token...\n",
            " 66% 5470/8340 [1:22:57<40:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:22,824 >> Initializing global attention on CLS token...\n",
            " 66% 5471/8340 [1:22:58<40:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:23,663 >> Initializing global attention on CLS token...\n",
            " 66% 5472/8340 [1:22:58<40:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:24,501 >> Initializing global attention on CLS token...\n",
            " 66% 5473/8340 [1:22:59<40:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:25,343 >> Initializing global attention on CLS token...\n",
            " 66% 5474/8340 [1:23:00<40:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:26,183 >> Initializing global attention on CLS token...\n",
            " 66% 5475/8340 [1:23:01<40:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:27,022 >> Initializing global attention on CLS token...\n",
            " 66% 5476/8340 [1:23:02<40:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:27,861 >> Initializing global attention on CLS token...\n",
            " 66% 5477/8340 [1:23:03<40:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:28,705 >> Initializing global attention on CLS token...\n",
            " 66% 5478/8340 [1:23:03<40:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:29,548 >> Initializing global attention on CLS token...\n",
            " 66% 5479/8340 [1:23:04<40:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:30,381 >> Initializing global attention on CLS token...\n",
            " 66% 5480/8340 [1:23:05<39:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:31,216 >> Initializing global attention on CLS token...\n",
            " 66% 5481/8340 [1:23:06<39:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:32,061 >> Initializing global attention on CLS token...\n",
            " 66% 5482/8340 [1:23:07<40:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:32,900 >> Initializing global attention on CLS token...\n",
            " 66% 5483/8340 [1:23:08<39:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:33,735 >> Initializing global attention on CLS token...\n",
            " 66% 5484/8340 [1:23:08<39:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:34,571 >> Initializing global attention on CLS token...\n",
            " 66% 5485/8340 [1:23:09<39:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:35,405 >> Initializing global attention on CLS token...\n",
            " 66% 5486/8340 [1:23:10<39:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:36,245 >> Initializing global attention on CLS token...\n",
            " 66% 5487/8340 [1:23:11<39:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:37,084 >> Initializing global attention on CLS token...\n",
            " 66% 5488/8340 [1:23:12<39:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:37,925 >> Initializing global attention on CLS token...\n",
            " 66% 5489/8340 [1:23:13<39:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:38,774 >> Initializing global attention on CLS token...\n",
            " 66% 5490/8340 [1:23:13<39:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:39,616 >> Initializing global attention on CLS token...\n",
            " 66% 5491/8340 [1:23:14<39:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:40,456 >> Initializing global attention on CLS token...\n",
            " 66% 5492/8340 [1:23:15<39:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:41,293 >> Initializing global attention on CLS token...\n",
            " 66% 5493/8340 [1:23:16<39:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:42,134 >> Initializing global attention on CLS token...\n",
            " 66% 5494/8340 [1:23:17<39:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:42,976 >> Initializing global attention on CLS token...\n",
            " 66% 5495/8340 [1:23:18<39:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:43,817 >> Initializing global attention on CLS token...\n",
            " 66% 5496/8340 [1:23:19<39:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:44,649 >> Initializing global attention on CLS token...\n",
            " 66% 5497/8340 [1:23:19<39:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:45,483 >> Initializing global attention on CLS token...\n",
            " 66% 5498/8340 [1:23:20<39:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:46,318 >> Initializing global attention on CLS token...\n",
            " 66% 5499/8340 [1:23:21<39:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:47,155 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0836, 'learning_rate': 1.0233812949640287e-05, 'epoch': 6.59}\n",
            " 66% 5500/8340 [1:23:22<41:23,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:48,119 >> Initializing global attention on CLS token...\n",
            " 66% 5501/8340 [1:23:23<40:53,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:48,957 >> Initializing global attention on CLS token...\n",
            " 66% 5502/8340 [1:23:24<40:29,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:49,795 >> Initializing global attention on CLS token...\n",
            " 66% 5503/8340 [1:23:25<40:15,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:50,635 >> Initializing global attention on CLS token...\n",
            " 66% 5504/8340 [1:23:25<40:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:51,476 >> Initializing global attention on CLS token...\n",
            " 66% 5505/8340 [1:23:26<39:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:52,320 >> Initializing global attention on CLS token...\n",
            " 66% 5506/8340 [1:23:27<39:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:53,159 >> Initializing global attention on CLS token...\n",
            " 66% 5507/8340 [1:23:28<39:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:54,000 >> Initializing global attention on CLS token...\n",
            " 66% 5508/8340 [1:23:29<39:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:54,835 >> Initializing global attention on CLS token...\n",
            " 66% 5509/8340 [1:23:30<39:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:55,671 >> Initializing global attention on CLS token...\n",
            " 66% 5510/8340 [1:23:30<39:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:56,512 >> Initializing global attention on CLS token...\n",
            " 66% 5511/8340 [1:23:31<39:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:57,351 >> Initializing global attention on CLS token...\n",
            " 66% 5512/8340 [1:23:32<39:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:58,193 >> Initializing global attention on CLS token...\n",
            " 66% 5513/8340 [1:23:33<39:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:59,035 >> Initializing global attention on CLS token...\n",
            " 66% 5514/8340 [1:23:34<39:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:26:59,870 >> Initializing global attention on CLS token...\n",
            " 66% 5515/8340 [1:23:35<39:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:00,707 >> Initializing global attention on CLS token...\n",
            " 66% 5516/8340 [1:23:35<39:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:01,544 >> Initializing global attention on CLS token...\n",
            " 66% 5517/8340 [1:23:36<39:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:02,382 >> Initializing global attention on CLS token...\n",
            " 66% 5518/8340 [1:23:37<39:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:03,226 >> Initializing global attention on CLS token...\n",
            " 66% 5519/8340 [1:23:38<39:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:04,058 >> Initializing global attention on CLS token...\n",
            " 66% 5520/8340 [1:23:39<39:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:04,892 >> Initializing global attention on CLS token...\n",
            " 66% 5521/8340 [1:23:40<39:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:05,728 >> Initializing global attention on CLS token...\n",
            " 66% 5522/8340 [1:23:40<39:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:06,566 >> Initializing global attention on CLS token...\n",
            " 66% 5523/8340 [1:23:41<39:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:07,402 >> Initializing global attention on CLS token...\n",
            " 66% 5524/8340 [1:23:42<39:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:08,237 >> Initializing global attention on CLS token...\n",
            " 66% 5525/8340 [1:23:43<39:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:09,071 >> Initializing global attention on CLS token...\n",
            " 66% 5526/8340 [1:23:44<39:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:09,909 >> Initializing global attention on CLS token...\n",
            " 66% 5527/8340 [1:23:45<39:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:10,748 >> Initializing global attention on CLS token...\n",
            " 66% 5528/8340 [1:23:45<39:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:11,588 >> Initializing global attention on CLS token...\n",
            " 66% 5529/8340 [1:23:46<39:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:12,428 >> Initializing global attention on CLS token...\n",
            " 66% 5530/8340 [1:23:47<39:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:13,272 >> Initializing global attention on CLS token...\n",
            " 66% 5531/8340 [1:23:48<39:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:14,111 >> Initializing global attention on CLS token...\n",
            " 66% 5532/8340 [1:23:49<39:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:14,945 >> Initializing global attention on CLS token...\n",
            " 66% 5533/8340 [1:23:50<39:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:15,780 >> Initializing global attention on CLS token...\n",
            " 66% 5534/8340 [1:23:50<39:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:16,616 >> Initializing global attention on CLS token...\n",
            " 66% 5535/8340 [1:23:51<39:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:17,458 >> Initializing global attention on CLS token...\n",
            " 66% 5536/8340 [1:23:52<39:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:18,304 >> Initializing global attention on CLS token...\n",
            " 66% 5537/8340 [1:23:53<39:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:19,138 >> Initializing global attention on CLS token...\n",
            " 66% 5538/8340 [1:23:54<39:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:19,974 >> Initializing global attention on CLS token...\n",
            " 66% 5539/8340 [1:23:55<39:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:20,810 >> Initializing global attention on CLS token...\n",
            " 66% 5540/8340 [1:23:56<39:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:21,646 >> Initializing global attention on CLS token...\n",
            " 66% 5541/8340 [1:23:56<39:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:22,492 >> Initializing global attention on CLS token...\n",
            " 66% 5542/8340 [1:23:57<39:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:23,327 >> Initializing global attention on CLS token...\n",
            " 66% 5543/8340 [1:23:58<39:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:24,161 >> Initializing global attention on CLS token...\n",
            " 66% 5544/8340 [1:23:59<39:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:25,000 >> Initializing global attention on CLS token...\n",
            " 66% 5545/8340 [1:24:00<39:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:25,835 >> Initializing global attention on CLS token...\n",
            " 66% 5546/8340 [1:24:01<38:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:26,671 >> Initializing global attention on CLS token...\n",
            " 67% 5547/8340 [1:24:01<38:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:27,509 >> Initializing global attention on CLS token...\n",
            " 67% 5548/8340 [1:24:02<38:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:28,354 >> Initializing global attention on CLS token...\n",
            " 67% 5549/8340 [1:24:03<39:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:29,195 >> Initializing global attention on CLS token...\n",
            " 67% 5550/8340 [1:24:04<39:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:30,037 >> Initializing global attention on CLS token...\n",
            " 67% 5551/8340 [1:24:05<39:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:30,879 >> Initializing global attention on CLS token...\n",
            " 67% 5552/8340 [1:24:06<39:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:31,715 >> Initializing global attention on CLS token...\n",
            " 67% 5553/8340 [1:24:06<39:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:32,553 >> Initializing global attention on CLS token...\n",
            " 67% 5554/8340 [1:24:07<38:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:33,388 >> Initializing global attention on CLS token...\n",
            " 67% 5555/8340 [1:24:08<38:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:34,223 >> Initializing global attention on CLS token...\n",
            " 67% 5556/8340 [1:24:09<38:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:35,056 >> Initializing global attention on CLS token...\n",
            " 67% 5557/8340 [1:24:10<38:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:35,894 >> Initializing global attention on CLS token...\n",
            " 67% 5558/8340 [1:24:11<38:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:36,724 >> Initializing global attention on CLS token...\n",
            " 67% 5559/8340 [1:24:11<38:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:37,560 >> Initializing global attention on CLS token...\n",
            " 67% 5560/8340 [1:24:12<38:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:38,396 >> Initializing global attention on CLS token...\n",
            " 67% 5561/8340 [1:24:13<38:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:39,230 >> Initializing global attention on CLS token...\n",
            " 67% 5562/8340 [1:24:14<38:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:40,064 >> Initializing global attention on CLS token...\n",
            " 67% 5563/8340 [1:24:15<38:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:40,904 >> Initializing global attention on CLS token...\n",
            " 67% 5564/8340 [1:24:16<38:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:41,743 >> Initializing global attention on CLS token...\n",
            " 67% 5565/8340 [1:24:16<38:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:42,586 >> Initializing global attention on CLS token...\n",
            " 67% 5566/8340 [1:24:17<38:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:43,432 >> Initializing global attention on CLS token...\n",
            " 67% 5567/8340 [1:24:18<38:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:44,269 >> Initializing global attention on CLS token...\n",
            " 67% 5568/8340 [1:24:19<38:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:45,104 >> Initializing global attention on CLS token...\n",
            " 67% 5569/8340 [1:24:20<38:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:45,942 >> Initializing global attention on CLS token...\n",
            " 67% 5570/8340 [1:24:21<38:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:46,779 >> Initializing global attention on CLS token...\n",
            " 67% 5571/8340 [1:24:22<38:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:47,624 >> Initializing global attention on CLS token...\n",
            " 67% 5572/8340 [1:24:22<38:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:48,461 >> Initializing global attention on CLS token...\n",
            " 67% 5573/8340 [1:24:23<38:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:49,298 >> Initializing global attention on CLS token...\n",
            " 67% 5574/8340 [1:24:24<38:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:50,140 >> Initializing global attention on CLS token...\n",
            " 67% 5575/8340 [1:24:25<38:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:50,977 >> Initializing global attention on CLS token...\n",
            " 67% 5576/8340 [1:24:26<38:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:51,813 >> Initializing global attention on CLS token...\n",
            " 67% 5577/8340 [1:24:27<38:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:52,647 >> Initializing global attention on CLS token...\n",
            " 67% 5578/8340 [1:24:27<38:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:53,480 >> Initializing global attention on CLS token...\n",
            " 67% 5579/8340 [1:24:28<38:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:54,318 >> Initializing global attention on CLS token...\n",
            " 67% 5580/8340 [1:24:29<38:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:55,152 >> Initializing global attention on CLS token...\n",
            " 67% 5581/8340 [1:24:30<38:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:55,986 >> Initializing global attention on CLS token...\n",
            " 67% 5582/8340 [1:24:31<38:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:56,826 >> Initializing global attention on CLS token...\n",
            " 67% 5583/8340 [1:24:32<38:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:57,663 >> Initializing global attention on CLS token...\n",
            " 67% 5584/8340 [1:24:32<38:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:58,504 >> Initializing global attention on CLS token...\n",
            " 67% 5585/8340 [1:24:33<38:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:27:59,340 >> Initializing global attention on CLS token...\n",
            " 67% 5586/8340 [1:24:34<38:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:00,174 >> Initializing global attention on CLS token...\n",
            " 67% 5587/8340 [1:24:35<38:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:01,010 >> Initializing global attention on CLS token...\n",
            " 67% 5588/8340 [1:24:36<38:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:01,848 >> Initializing global attention on CLS token...\n",
            " 67% 5589/8340 [1:24:37<38:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:02,690 >> Initializing global attention on CLS token...\n",
            " 67% 5590/8340 [1:24:37<38:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:03,528 >> Initializing global attention on CLS token...\n",
            " 67% 5591/8340 [1:24:38<38:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:04,367 >> Initializing global attention on CLS token...\n",
            " 67% 5592/8340 [1:24:39<38:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:05,198 >> Initializing global attention on CLS token...\n",
            " 67% 5593/8340 [1:24:40<38:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:06,040 >> Initializing global attention on CLS token...\n",
            " 67% 5594/8340 [1:24:41<38:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:06,878 >> Initializing global attention on CLS token...\n",
            " 67% 5595/8340 [1:24:42<38:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:07,715 >> Initializing global attention on CLS token...\n",
            " 67% 5596/8340 [1:24:42<38:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:08,548 >> Initializing global attention on CLS token...\n",
            " 67% 5597/8340 [1:24:43<38:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:09,385 >> Initializing global attention on CLS token...\n",
            " 67% 5598/8340 [1:24:44<38:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:10,220 >> Initializing global attention on CLS token...\n",
            " 67% 5599/8340 [1:24:45<38:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:11,054 >> Initializing global attention on CLS token...\n",
            " 67% 5600/8340 [1:24:46<38:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:11,888 >> Initializing global attention on CLS token...\n",
            " 67% 5601/8340 [1:24:47<38:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:12,731 >> Initializing global attention on CLS token...\n",
            " 67% 5602/8340 [1:24:47<38:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:13,571 >> Initializing global attention on CLS token...\n",
            " 67% 5603/8340 [1:24:48<38:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:14,405 >> Initializing global attention on CLS token...\n",
            " 67% 5604/8340 [1:24:49<38:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:15,240 >> Initializing global attention on CLS token...\n",
            " 67% 5605/8340 [1:24:50<38:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:16,075 >> Initializing global attention on CLS token...\n",
            " 67% 5606/8340 [1:24:51<38:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:16,917 >> Initializing global attention on CLS token...\n",
            " 67% 5607/8340 [1:24:52<38:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:17,751 >> Initializing global attention on CLS token...\n",
            " 67% 5608/8340 [1:24:52<38:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:18,594 >> Initializing global attention on CLS token...\n",
            " 67% 5609/8340 [1:24:53<38:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:19,430 >> Initializing global attention on CLS token...\n",
            " 67% 5610/8340 [1:24:54<38:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:20,274 >> Initializing global attention on CLS token...\n",
            " 67% 5611/8340 [1:24:55<38:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:21,115 >> Initializing global attention on CLS token...\n",
            " 67% 5612/8340 [1:24:56<38:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:21,953 >> Initializing global attention on CLS token...\n",
            " 67% 5613/8340 [1:24:57<38:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:22,798 >> Initializing global attention on CLS token...\n",
            " 67% 5614/8340 [1:24:58<38:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:23,635 >> Initializing global attention on CLS token...\n",
            " 67% 5615/8340 [1:24:58<38:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:24,472 >> Initializing global attention on CLS token...\n",
            " 67% 5616/8340 [1:24:59<38:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:25,307 >> Initializing global attention on CLS token...\n",
            " 67% 5617/8340 [1:25:00<38:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:26,145 >> Initializing global attention on CLS token...\n",
            " 67% 5618/8340 [1:25:01<38:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:26,986 >> Initializing global attention on CLS token...\n",
            " 67% 5619/8340 [1:25:02<37:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:27,822 >> Initializing global attention on CLS token...\n",
            " 67% 5620/8340 [1:25:03<38:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:28,661 >> Initializing global attention on CLS token...\n",
            " 67% 5621/8340 [1:25:03<37:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:29,498 >> Initializing global attention on CLS token...\n",
            " 67% 5622/8340 [1:25:04<37:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:30,336 >> Initializing global attention on CLS token...\n",
            " 67% 5623/8340 [1:25:05<37:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:31,172 >> Initializing global attention on CLS token...\n",
            " 67% 5624/8340 [1:25:06<37:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:32,009 >> Initializing global attention on CLS token...\n",
            " 67% 5625/8340 [1:25:07<37:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:32,850 >> Initializing global attention on CLS token...\n",
            " 67% 5626/8340 [1:25:08<38:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:33,698 >> Initializing global attention on CLS token...\n",
            " 67% 5627/8340 [1:25:08<37:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:34,530 >> Initializing global attention on CLS token...\n",
            " 67% 5628/8340 [1:25:09<37:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:35,370 >> Initializing global attention on CLS token...\n",
            " 67% 5629/8340 [1:25:10<37:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:36,204 >> Initializing global attention on CLS token...\n",
            " 68% 5630/8340 [1:25:11<37:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:37,038 >> Initializing global attention on CLS token...\n",
            " 68% 5631/8340 [1:25:12<37:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:37,873 >> Initializing global attention on CLS token...\n",
            " 68% 5632/8340 [1:25:13<37:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:38,708 >> Initializing global attention on CLS token...\n",
            " 68% 5633/8340 [1:25:13<37:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:39,549 >> Initializing global attention on CLS token...\n",
            " 68% 5634/8340 [1:25:14<37:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:40,389 >> Initializing global attention on CLS token...\n",
            " 68% 5635/8340 [1:25:15<37:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:41,231 >> Initializing global attention on CLS token...\n",
            " 68% 5636/8340 [1:25:16<37:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:42,069 >> Initializing global attention on CLS token...\n",
            " 68% 5637/8340 [1:25:17<37:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:42,908 >> Initializing global attention on CLS token...\n",
            " 68% 5638/8340 [1:25:18<37:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:43,742 >> Initializing global attention on CLS token...\n",
            " 68% 5639/8340 [1:25:18<37:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:44,575 >> Initializing global attention on CLS token...\n",
            " 68% 5640/8340 [1:25:19<37:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:45,409 >> Initializing global attention on CLS token...\n",
            " 68% 5641/8340 [1:25:20<37:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:46,244 >> Initializing global attention on CLS token...\n",
            " 68% 5642/8340 [1:25:21<37:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:47,079 >> Initializing global attention on CLS token...\n",
            " 68% 5643/8340 [1:25:22<37:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:47,920 >> Initializing global attention on CLS token...\n",
            " 68% 5644/8340 [1:25:23<37:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:48,761 >> Initializing global attention on CLS token...\n",
            " 68% 5645/8340 [1:25:23<37:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:49,598 >> Initializing global attention on CLS token...\n",
            " 68% 5646/8340 [1:25:24<37:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:50,438 >> Initializing global attention on CLS token...\n",
            " 68% 5647/8340 [1:25:25<37:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:51,277 >> Initializing global attention on CLS token...\n",
            " 68% 5648/8340 [1:25:26<37:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:52,113 >> Initializing global attention on CLS token...\n",
            " 68% 5649/8340 [1:25:27<37:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:52,948 >> Initializing global attention on CLS token...\n",
            " 68% 5650/8340 [1:25:28<37:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:53,790 >> Initializing global attention on CLS token...\n",
            " 68% 5651/8340 [1:25:29<37:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:54,629 >> Initializing global attention on CLS token...\n",
            " 68% 5652/8340 [1:25:29<37:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:55,466 >> Initializing global attention on CLS token...\n",
            " 68% 5653/8340 [1:25:30<37:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:56,305 >> Initializing global attention on CLS token...\n",
            " 68% 5654/8340 [1:25:31<37:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:57,138 >> Initializing global attention on CLS token...\n",
            " 68% 5655/8340 [1:25:32<37:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:57,973 >> Initializing global attention on CLS token...\n",
            " 68% 5656/8340 [1:25:33<37:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:58,807 >> Initializing global attention on CLS token...\n",
            " 68% 5657/8340 [1:25:34<37:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:28:59,641 >> Initializing global attention on CLS token...\n",
            " 68% 5658/8340 [1:25:34<37:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:00,484 >> Initializing global attention on CLS token...\n",
            " 68% 5659/8340 [1:25:35<37:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:01,319 >> Initializing global attention on CLS token...\n",
            " 68% 5660/8340 [1:25:36<37:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:02,152 >> Initializing global attention on CLS token...\n",
            " 68% 5661/8340 [1:25:37<37:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:02,993 >> Initializing global attention on CLS token...\n",
            " 68% 5662/8340 [1:25:38<37:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:03,826 >> Initializing global attention on CLS token...\n",
            " 68% 5663/8340 [1:25:39<37:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:04,659 >> Initializing global attention on CLS token...\n",
            " 68% 5664/8340 [1:25:39<37:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:05,495 >> Initializing global attention on CLS token...\n",
            " 68% 5665/8340 [1:25:40<37:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:06,332 >> Initializing global attention on CLS token...\n",
            " 68% 5666/8340 [1:25:41<37:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:07,173 >> Initializing global attention on CLS token...\n",
            " 68% 5667/8340 [1:25:42<37:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:08,014 >> Initializing global attention on CLS token...\n",
            " 68% 5668/8340 [1:25:43<37:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:08,853 >> Initializing global attention on CLS token...\n",
            " 68% 5669/8340 [1:25:44<37:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:09,695 >> Initializing global attention on CLS token...\n",
            " 68% 5670/8340 [1:25:44<37:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:10,535 >> Initializing global attention on CLS token...\n",
            " 68% 5671/8340 [1:25:45<37:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:11,373 >> Initializing global attention on CLS token...\n",
            " 68% 5672/8340 [1:25:46<37:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:12,211 >> Initializing global attention on CLS token...\n",
            " 68% 5673/8340 [1:25:47<37:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:13,049 >> Initializing global attention on CLS token...\n",
            " 68% 5674/8340 [1:25:48<37:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:13,889 >> Initializing global attention on CLS token...\n",
            " 68% 5675/8340 [1:25:49<37:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:14,722 >> Initializing global attention on CLS token...\n",
            " 68% 5676/8340 [1:25:49<37:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:15,557 >> Initializing global attention on CLS token...\n",
            " 68% 5677/8340 [1:25:50<37:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:16,390 >> Initializing global attention on CLS token...\n",
            " 68% 5678/8340 [1:25:51<37:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:17,228 >> Initializing global attention on CLS token...\n",
            " 68% 5679/8340 [1:25:52<37:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:18,071 >> Initializing global attention on CLS token...\n",
            " 68% 5680/8340 [1:25:53<37:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:18,907 >> Initializing global attention on CLS token...\n",
            " 68% 5681/8340 [1:25:54<37:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:19,745 >> Initializing global attention on CLS token...\n",
            " 68% 5682/8340 [1:25:54<37:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:20,578 >> Initializing global attention on CLS token...\n",
            " 68% 5683/8340 [1:25:55<37:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:21,415 >> Initializing global attention on CLS token...\n",
            " 68% 5684/8340 [1:25:56<37:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:22,250 >> Initializing global attention on CLS token...\n",
            " 68% 5685/8340 [1:25:57<36:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:23,086 >> Initializing global attention on CLS token...\n",
            " 68% 5686/8340 [1:25:58<37:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:23,927 >> Initializing global attention on CLS token...\n",
            " 68% 5687/8340 [1:25:59<37:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:24,762 >> Initializing global attention on CLS token...\n",
            " 68% 5688/8340 [1:25:59<37:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:25,603 >> Initializing global attention on CLS token...\n",
            " 68% 5689/8340 [1:26:00<37:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:26,439 >> Initializing global attention on CLS token...\n",
            " 68% 5690/8340 [1:26:01<36:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:27,275 >> Initializing global attention on CLS token...\n",
            " 68% 5691/8340 [1:26:02<36:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:28,112 >> Initializing global attention on CLS token...\n",
            " 68% 5692/8340 [1:26:03<36:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:28,950 >> Initializing global attention on CLS token...\n",
            " 68% 5693/8340 [1:26:04<36:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:29,785 >> Initializing global attention on CLS token...\n",
            " 68% 5694/8340 [1:26:05<36:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:30,627 >> Initializing global attention on CLS token...\n",
            " 68% 5695/8340 [1:26:05<36:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:31,466 >> Initializing global attention on CLS token...\n",
            " 68% 5696/8340 [1:26:06<36:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:32,302 >> Initializing global attention on CLS token...\n",
            " 68% 5697/8340 [1:26:07<36:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:33,142 >> Initializing global attention on CLS token...\n",
            " 68% 5698/8340 [1:26:08<36:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:33,974 >> Initializing global attention on CLS token...\n",
            " 68% 5699/8340 [1:26:09<36:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:34,807 >> Initializing global attention on CLS token...\n",
            " 68% 5700/8340 [1:26:10<36:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:35,645 >> Initializing global attention on CLS token...\n",
            " 68% 5701/8340 [1:26:10<36:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:36,483 >> Initializing global attention on CLS token...\n",
            " 68% 5702/8340 [1:26:11<36:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:37,321 >> Initializing global attention on CLS token...\n",
            " 68% 5703/8340 [1:26:12<36:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:38,156 >> Initializing global attention on CLS token...\n",
            " 68% 5704/8340 [1:26:13<36:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:38,990 >> Initializing global attention on CLS token...\n",
            " 68% 5705/8340 [1:26:14<36:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:39,825 >> Initializing global attention on CLS token...\n",
            " 68% 5706/8340 [1:26:15<36:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:40,660 >> Initializing global attention on CLS token...\n",
            " 68% 5707/8340 [1:26:15<36:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:41,493 >> Initializing global attention on CLS token...\n",
            " 68% 5708/8340 [1:26:16<36:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:42,326 >> Initializing global attention on CLS token...\n",
            " 68% 5709/8340 [1:26:17<36:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:43,161 >> Initializing global attention on CLS token...\n",
            " 68% 5710/8340 [1:26:18<36:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:43,996 >> Initializing global attention on CLS token...\n",
            " 68% 5711/8340 [1:26:19<36:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:44,832 >> Initializing global attention on CLS token...\n",
            " 68% 5712/8340 [1:26:20<36:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:45,670 >> Initializing global attention on CLS token...\n",
            " 69% 5713/8340 [1:26:20<36:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:46,504 >> Initializing global attention on CLS token...\n",
            " 69% 5714/8340 [1:26:21<36:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:47,340 >> Initializing global attention on CLS token...\n",
            " 69% 5715/8340 [1:26:22<36:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:48,175 >> Initializing global attention on CLS token...\n",
            " 69% 5716/8340 [1:26:23<36:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:49,010 >> Initializing global attention on CLS token...\n",
            " 69% 5717/8340 [1:26:24<36:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:49,856 >> Initializing global attention on CLS token...\n",
            " 69% 5718/8340 [1:26:25<36:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:50,697 >> Initializing global attention on CLS token...\n",
            " 69% 5719/8340 [1:26:25<36:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:51,533 >> Initializing global attention on CLS token...\n",
            " 69% 5720/8340 [1:26:26<36:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:52,370 >> Initializing global attention on CLS token...\n",
            " 69% 5721/8340 [1:26:27<36:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:53,209 >> Initializing global attention on CLS token...\n",
            " 69% 5722/8340 [1:26:28<36:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:54,044 >> Initializing global attention on CLS token...\n",
            " 69% 5723/8340 [1:26:29<36:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:54,880 >> Initializing global attention on CLS token...\n",
            " 69% 5724/8340 [1:26:30<36:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:55,715 >> Initializing global attention on CLS token...\n",
            " 69% 5725/8340 [1:26:30<36:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:56,554 >> Initializing global attention on CLS token...\n",
            " 69% 5726/8340 [1:26:31<36:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:57,388 >> Initializing global attention on CLS token...\n",
            " 69% 5727/8340 [1:26:32<36:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:58,223 >> Initializing global attention on CLS token...\n",
            " 69% 5728/8340 [1:26:33<36:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:59,060 >> Initializing global attention on CLS token...\n",
            " 69% 5729/8340 [1:26:34<36:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:29:59,899 >> Initializing global attention on CLS token...\n",
            " 69% 5730/8340 [1:26:35<36:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:00,734 >> Initializing global attention on CLS token...\n",
            " 69% 5731/8340 [1:26:35<36:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:01,572 >> Initializing global attention on CLS token...\n",
            " 69% 5732/8340 [1:26:36<36:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:02,412 >> Initializing global attention on CLS token...\n",
            " 69% 5733/8340 [1:26:37<36:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:03,245 >> Initializing global attention on CLS token...\n",
            " 69% 5734/8340 [1:26:38<36:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:04,078 >> Initializing global attention on CLS token...\n",
            " 69% 5735/8340 [1:26:39<36:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:04,912 >> Initializing global attention on CLS token...\n",
            " 69% 5736/8340 [1:26:40<36:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:05,745 >> Initializing global attention on CLS token...\n",
            " 69% 5737/8340 [1:26:40<36:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:06,581 >> Initializing global attention on CLS token...\n",
            " 69% 5738/8340 [1:26:41<36:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:07,415 >> Initializing global attention on CLS token...\n",
            " 69% 5739/8340 [1:26:42<36:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:08,257 >> Initializing global attention on CLS token...\n",
            " 69% 5740/8340 [1:26:43<36:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:09,090 >> Initializing global attention on CLS token...\n",
            " 69% 5741/8340 [1:26:44<36:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:09,925 >> Initializing global attention on CLS token...\n",
            " 69% 5742/8340 [1:26:45<36:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:10,763 >> Initializing global attention on CLS token...\n",
            " 69% 5743/8340 [1:26:45<36:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:11,598 >> Initializing global attention on CLS token...\n",
            " 69% 5744/8340 [1:26:46<36:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:12,434 >> Initializing global attention on CLS token...\n",
            " 69% 5745/8340 [1:26:47<36:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:13,271 >> Initializing global attention on CLS token...\n",
            " 69% 5746/8340 [1:26:48<36:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:14,107 >> Initializing global attention on CLS token...\n",
            " 69% 5747/8340 [1:26:49<36:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:14,944 >> Initializing global attention on CLS token...\n",
            " 69% 5748/8340 [1:26:50<36:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:15,781 >> Initializing global attention on CLS token...\n",
            " 69% 5749/8340 [1:26:51<36:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:16,620 >> Initializing global attention on CLS token...\n",
            " 69% 5750/8340 [1:26:51<36:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:17,456 >> Initializing global attention on CLS token...\n",
            " 69% 5751/8340 [1:26:52<36:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:18,288 >> Initializing global attention on CLS token...\n",
            " 69% 5752/8340 [1:26:53<36:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:19,123 >> Initializing global attention on CLS token...\n",
            " 69% 5753/8340 [1:26:54<36:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:19,965 >> Initializing global attention on CLS token...\n",
            " 69% 5754/8340 [1:26:55<36:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:20,803 >> Initializing global attention on CLS token...\n",
            " 69% 5755/8340 [1:26:56<36:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:21,642 >> Initializing global attention on CLS token...\n",
            " 69% 5756/8340 [1:26:56<36:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:22,475 >> Initializing global attention on CLS token...\n",
            " 69% 5757/8340 [1:26:57<35:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:23,310 >> Initializing global attention on CLS token...\n",
            " 69% 5758/8340 [1:26:58<35:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:24,142 >> Initializing global attention on CLS token...\n",
            " 69% 5759/8340 [1:26:59<35:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:24,978 >> Initializing global attention on CLS token...\n",
            " 69% 5760/8340 [1:27:00<35:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:25,814 >> Initializing global attention on CLS token...\n",
            " 69% 5761/8340 [1:27:01<35:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:26,654 >> Initializing global attention on CLS token...\n",
            " 69% 5762/8340 [1:27:01<35:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:27,491 >> Initializing global attention on CLS token...\n",
            " 69% 5763/8340 [1:27:02<35:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:28,326 >> Initializing global attention on CLS token...\n",
            " 69% 5764/8340 [1:27:03<35:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:29,161 >> Initializing global attention on CLS token...\n",
            " 69% 5765/8340 [1:27:04<35:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:30,015 >> Initializing global attention on CLS token...\n",
            " 69% 5766/8340 [1:27:05<36:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:30,879 >> Initializing global attention on CLS token...\n",
            " 69% 5767/8340 [1:27:06<36:27,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:31,727 >> Initializing global attention on CLS token...\n",
            " 69% 5768/8340 [1:27:06<36:24,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:32,580 >> Initializing global attention on CLS token...\n",
            " 69% 5769/8340 [1:27:07<36:28,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:33,430 >> Initializing global attention on CLS token...\n",
            " 69% 5770/8340 [1:27:08<36:18,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:34,263 >> Initializing global attention on CLS token...\n",
            " 69% 5771/8340 [1:27:09<36:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:35,098 >> Initializing global attention on CLS token...\n",
            " 69% 5772/8340 [1:27:10<35:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:35,932 >> Initializing global attention on CLS token...\n",
            " 69% 5773/8340 [1:27:11<35:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:36,766 >> Initializing global attention on CLS token...\n",
            " 69% 5774/8340 [1:27:11<35:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:37,600 >> Initializing global attention on CLS token...\n",
            " 69% 5775/8340 [1:27:12<35:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:38,433 >> Initializing global attention on CLS token...\n",
            " 69% 5776/8340 [1:27:13<35:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:39,269 >> Initializing global attention on CLS token...\n",
            " 69% 5777/8340 [1:27:14<35:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:40,106 >> Initializing global attention on CLS token...\n",
            " 69% 5778/8340 [1:27:15<35:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:40,943 >> Initializing global attention on CLS token...\n",
            " 69% 5779/8340 [1:27:16<35:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:41,781 >> Initializing global attention on CLS token...\n",
            " 69% 5780/8340 [1:27:16<35:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:42,617 >> Initializing global attention on CLS token...\n",
            " 69% 5781/8340 [1:27:17<35:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:43,453 >> Initializing global attention on CLS token...\n",
            " 69% 5782/8340 [1:27:18<35:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:44,290 >> Initializing global attention on CLS token...\n",
            " 69% 5783/8340 [1:27:19<35:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:45,129 >> Initializing global attention on CLS token...\n",
            " 69% 5784/8340 [1:27:20<35:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:45,964 >> Initializing global attention on CLS token...\n",
            " 69% 5785/8340 [1:27:21<35:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:46,802 >> Initializing global attention on CLS token...\n",
            " 69% 5786/8340 [1:27:22<35:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:47,649 >> Initializing global attention on CLS token...\n",
            " 69% 5787/8340 [1:27:22<35:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:48,492 >> Initializing global attention on CLS token...\n",
            " 69% 5788/8340 [1:27:23<35:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:49,330 >> Initializing global attention on CLS token...\n",
            " 69% 5789/8340 [1:27:24<35:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:50,164 >> Initializing global attention on CLS token...\n",
            " 69% 5790/8340 [1:27:25<35:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:51,010 >> Initializing global attention on CLS token...\n",
            " 69% 5791/8340 [1:27:26<35:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:51,848 >> Initializing global attention on CLS token...\n",
            " 69% 5792/8340 [1:27:27<35:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:52,687 >> Initializing global attention on CLS token...\n",
            " 69% 5793/8340 [1:27:27<35:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:53,523 >> Initializing global attention on CLS token...\n",
            " 69% 5794/8340 [1:27:28<35:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:54,357 >> Initializing global attention on CLS token...\n",
            " 69% 5795/8340 [1:27:29<35:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:55,188 >> Initializing global attention on CLS token...\n",
            " 69% 5796/8340 [1:27:30<35:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:56,028 >> Initializing global attention on CLS token...\n",
            " 70% 5797/8340 [1:27:31<35:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:56,863 >> Initializing global attention on CLS token...\n",
            " 70% 5798/8340 [1:27:32<35:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:57,702 >> Initializing global attention on CLS token...\n",
            " 70% 5799/8340 [1:27:32<35:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:58,537 >> Initializing global attention on CLS token...\n",
            " 70% 5800/8340 [1:27:33<35:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:30:59,373 >> Initializing global attention on CLS token...\n",
            " 70% 5801/8340 [1:27:34<35:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:00,213 >> Initializing global attention on CLS token...\n",
            " 70% 5802/8340 [1:27:35<35:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:01,051 >> Initializing global attention on CLS token...\n",
            " 70% 5803/8340 [1:27:36<35:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:01,887 >> Initializing global attention on CLS token...\n",
            " 70% 5804/8340 [1:27:37<35:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:02,724 >> Initializing global attention on CLS token...\n",
            " 70% 5805/8340 [1:27:37<35:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:03,560 >> Initializing global attention on CLS token...\n",
            " 70% 5806/8340 [1:27:38<35:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:04,396 >> Initializing global attention on CLS token...\n",
            " 70% 5807/8340 [1:27:39<35:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:05,237 >> Initializing global attention on CLS token...\n",
            " 70% 5808/8340 [1:27:40<35:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:06,075 >> Initializing global attention on CLS token...\n",
            " 70% 5809/8340 [1:27:41<35:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:06,913 >> Initializing global attention on CLS token...\n",
            " 70% 5810/8340 [1:27:42<35:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:07,753 >> Initializing global attention on CLS token...\n",
            " 70% 5811/8340 [1:27:42<35:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:08,592 >> Initializing global attention on CLS token...\n",
            " 70% 5812/8340 [1:27:43<35:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:09,429 >> Initializing global attention on CLS token...\n",
            " 70% 5813/8340 [1:27:44<35:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:10,267 >> Initializing global attention on CLS token...\n",
            " 70% 5814/8340 [1:27:45<35:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:11,101 >> Initializing global attention on CLS token...\n",
            " 70% 5815/8340 [1:27:46<35:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:11,934 >> Initializing global attention on CLS token...\n",
            " 70% 5816/8340 [1:27:47<35:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:12,768 >> Initializing global attention on CLS token...\n",
            " 70% 5817/8340 [1:27:47<35:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:13,602 >> Initializing global attention on CLS token...\n",
            " 70% 5818/8340 [1:27:48<35:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:14,436 >> Initializing global attention on CLS token...\n",
            " 70% 5819/8340 [1:27:49<35:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:15,271 >> Initializing global attention on CLS token...\n",
            " 70% 5820/8340 [1:27:50<35:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:16,109 >> Initializing global attention on CLS token...\n",
            " 70% 5821/8340 [1:27:51<35:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:16,949 >> Initializing global attention on CLS token...\n",
            " 70% 5822/8340 [1:27:52<35:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:17,786 >> Initializing global attention on CLS token...\n",
            " 70% 5823/8340 [1:27:53<35:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:18,626 >> Initializing global attention on CLS token...\n",
            " 70% 5824/8340 [1:27:53<35:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:19,465 >> Initializing global attention on CLS token...\n",
            " 70% 5825/8340 [1:27:54<35:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:20,303 >> Initializing global attention on CLS token...\n",
            " 70% 5826/8340 [1:27:55<35:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:21,144 >> Initializing global attention on CLS token...\n",
            " 70% 5827/8340 [1:27:56<35:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:21,977 >> Initializing global attention on CLS token...\n",
            " 70% 5828/8340 [1:27:57<35:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:22,811 >> Initializing global attention on CLS token...\n",
            " 70% 5829/8340 [1:27:58<34:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:23,646 >> Initializing global attention on CLS token...\n",
            " 70% 5830/8340 [1:27:58<34:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:24,480 >> Initializing global attention on CLS token...\n",
            " 70% 5831/8340 [1:27:59<34:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:25,316 >> Initializing global attention on CLS token...\n",
            " 70% 5832/8340 [1:28:00<34:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:26,156 >> Initializing global attention on CLS token...\n",
            " 70% 5833/8340 [1:28:01<35:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:26,998 >> Initializing global attention on CLS token...\n",
            " 70% 5834/8340 [1:28:02<34:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:27,832 >> Initializing global attention on CLS token...\n",
            " 70% 5835/8340 [1:28:03<34:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:28,668 >> Initializing global attention on CLS token...\n",
            " 70% 5836/8340 [1:28:03<34:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:29,505 >> Initializing global attention on CLS token...\n",
            " 70% 5837/8340 [1:28:04<34:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:31:30,325 >> Initializing global attention on CLS token...\n",
            " 70% 5838/8340 [1:28:05<28:16,  1.47it/s][INFO|trainer.py:725] 2022-12-08 17:31:30,620 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-08 17:31:30,622 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-08 17:31:30,623 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-08 17:31:30,623 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:30,655 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:30,922 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:30,  7.54it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:31,185 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:43,  5.34it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:31,440 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:48,  4.70it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:31,695 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:51,  4.41it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:31,947 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:53,  4.25it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:32,210 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:55,  4.09it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:32,464 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:55,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:32,722 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:56,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:32,974 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:56,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:33,231 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:56,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:33,485 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:56,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:33,737 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:55,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:33,991 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:55,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:34,245 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:55,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:34,500 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:55,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:34,757 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:55,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:35,017 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:55,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:35,271 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:54,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:35,527 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:54,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:35,780 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:54,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:36,045 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:54,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:36,298 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:54,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:36,555 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:53,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:36,806 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:53,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:37,061 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:52,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:37,311 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:52,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:37,564 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:52,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:37,817 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:51,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:38,070 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:51,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:38,323 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:51,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:38,580 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:51,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:38,840 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:51,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:39,095 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:51,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:39,351 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:50,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:39,603 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:50,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:39,863 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:50,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:40,114 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:49,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:40,364 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:49,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:40,614 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:49,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:40,878 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:49,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:41,133 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:48,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:41,384 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:48,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:41,639 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:48,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:41,902 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:48,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:42,155 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:48,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:42,415 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:48,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:42,676 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:12<00:47,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:42,935 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:47,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:43,189 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:47,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:43,443 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:46,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:43,711 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:47,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:43,965 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:46,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:44,216 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:45,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:44,465 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:45,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:44,719 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:45,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:44,974 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:45,228 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:44,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:45,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:44,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:45,742 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:44,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:45,995 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:46,251 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:44,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:46,510 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:46,765 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:47,019 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:42,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:47,268 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:42,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:47,517 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:42,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:47,770 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:41,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:48,040 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:42,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:48,295 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:42,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:48,555 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:42,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:48,813 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:41,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:49,074 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:41,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:49,335 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:41,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:49,588 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:40,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:49,847 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:40,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:50,118 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:41,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:50,375 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:40,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:50,626 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:39,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:50,884 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:39,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:51,138 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:39,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:51,399 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:38,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:51,651 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:38,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:51,905 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:52,163 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:38,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:52,424 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:38,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:52,680 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:22<00:37,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:52,933 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:53,201 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:37,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:53,453 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:36,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:53,707 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:23<00:36,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:53,961 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:54,212 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:35,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:54,465 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:35,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:54,722 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:35,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:54,976 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:55,228 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:34,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:55,484 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:34,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:55,736 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:55,993 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:56,246 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:33,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:56,503 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:33,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:56,761 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:33,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:57,022 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:33,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:57,274 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:32,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:57,529 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:32,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:57,783 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:32,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:58,035 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:32,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:58,290 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:31,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:58,541 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:31,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:58,793 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:31,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:59,047 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:30,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:59,302 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:30,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:59,554 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:30,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:31:59,805 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:30,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:00,064 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:29<00:29,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:00,317 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:29,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:00,573 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:29,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:00,823 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:29,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:01,081 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:30<00:29,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:01,336 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:28,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:01,590 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:30<00:28,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:01,849 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:28,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:02,107 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:31<00:28,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:02,360 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:31<00:27,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:02,613 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:31<00:27,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:02,883 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:03,137 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:32<00:27,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:03,400 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:32<00:27,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:03,656 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:32<00:26,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:03,909 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:26,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:04,175 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:33<00:26,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:04,429 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:33<00:26,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:04,699 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:34<00:26,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:04,950 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:05,206 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:34<00:25,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:05,456 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:34<00:24,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:05,714 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:35<00:24,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:05,966 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:35<00:24,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:06,218 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:35<00:23,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:06,470 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:35<00:23,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:06,729 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:36<00:23,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:06,979 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:36<00:22,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:07,228 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:36<00:22,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:07,480 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:36<00:22,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:07,732 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:07,987 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:37<00:21,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:08,243 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:37<00:21,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:08,500 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:37<00:21,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:08,752 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:09,008 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:38<00:21,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:09,261 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:38<00:20,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:09,524 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:38<00:20,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:09,781 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:20,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:10,034 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:39<00:20,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:10,287 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:39<00:19,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:10,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:39<00:19,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:10,802 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:19,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:11,064 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:40<00:19,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:11,320 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:40<00:19,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:11,573 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:40<00:18,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:11,822 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:12,077 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:41<00:18,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:12,334 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:41<00:17,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:12,587 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:41<00:17,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:12,846 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:13,100 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:42<00:17,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:13,362 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:42<00:16,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:13,615 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:42<00:16,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:13,874 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:43<00:16,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:14,130 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:43<00:16,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:14,393 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:43<00:15,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:14,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:43<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:14,902 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:44<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:15,157 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:44<00:15,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:15,421 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:44<00:15,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:15,678 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:45<00:14,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:15,933 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:45<00:14,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:16,192 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:45<00:14,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:16,446 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:45<00:13,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:16,698 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:46<00:13,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:16,954 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:46<00:13,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:17,208 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:46<00:13,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:17,462 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:46<00:12,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:17,717 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:47<00:12,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:17,971 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:47<00:12,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:18,230 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:47<00:12,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:18,483 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:47<00:11,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:18,742 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:48<00:11,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:19,009 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:48<00:11,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:19,264 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:48<00:11,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:19,525 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:48<00:10,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:19,778 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:49<00:10,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:20,031 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:49<00:10,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:20,285 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:49<00:09,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:20,548 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:49<00:09,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:20,801 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:50<00:09,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:21,058 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:50<00:09,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:21,313 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:50<00:08,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:21,566 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:50<00:08,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:21,822 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:51<00:08,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:22,075 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:51<00:08,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:22,335 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:51<00:07,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:22,586 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:51<00:07,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:22,854 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:52<00:07,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:23,108 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:52<00:07,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:23,364 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:52<00:06,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:23,617 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:52<00:06,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:23,872 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:53<00:06,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:24,120 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:53<00:06,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:24,369 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:53<00:05,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:24,623 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:53<00:05,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:24,876 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:54<00:05,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:25,129 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:54<00:05,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:25,381 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:54<00:04,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:25,634 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:54<00:04,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:25,895 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:55<00:04,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:26,153 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:55<00:04,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:26,408 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:55<00:03,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:26,665 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:56<00:03,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:26,917 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:56<00:03,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:27,172 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:56<00:03,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:27,427 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:56<00:02,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:27,682 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:57<00:02,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:27,938 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:57<00:02,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:28,198 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:57<00:02,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:28,450 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:57<00:01,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:28,706 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:58<00:01,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:28,958 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:58<00:01,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:29,219 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:58<00:01,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:29,471 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:58<00:00,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:29,723 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:59<00:00,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:29,975 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:59<00:00,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:30,210 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.5286707878112793, 'eval_f1-micro': 0.7692857142857142, 'eval_f1-macro': 0.6914908973442988, 'eval_runtime': 61.0003, 'eval_samples_per_second': 22.951, 'eval_steps_per_second': 3.836, 'epoch': 7.0}\n",
            " 70% 5838/8340 [1:29:06<28:16,  1.47it/s]\n",
            "100% 234/234 [01:00<00:00,  3.94it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-08 17:32:31,625 >> Saving model checkpoint to logs/output_1/checkpoint-5838\n",
            "[INFO|configuration_utils.py:447] 2022-12-08 17:32:31,626 >> Configuration saved in logs/output_1/checkpoint-5838/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-08 17:32:31,856 >> Model weights saved in logs/output_1/checkpoint-5838/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-08 17:32:31,857 >> tokenizer config file saved in logs/output_1/checkpoint-5838/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-08 17:32:31,858 >> Special tokens file saved in logs/output_1/checkpoint-5838/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:32:32,450 >> Initializing global attention on CLS token...\n",
            " 70% 5839/8340 [1:29:07<13:23:40, 19.28s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:33,338 >> Initializing global attention on CLS token...\n",
            " 70% 5840/8340 [1:29:08<9:32:47, 13.75s/it] [INFO|modeling_longformer.py:1932] 2022-12-08 17:32:34,172 >> Initializing global attention on CLS token...\n",
            " 70% 5841/8340 [1:29:09<6:51:13,  9.87s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:35,006 >> Initializing global attention on CLS token...\n",
            " 70% 5842/8340 [1:29:10<4:58:10,  7.16s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:35,842 >> Initializing global attention on CLS token...\n",
            " 70% 5843/8340 [1:29:11<3:39:04,  5.26s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:36,677 >> Initializing global attention on CLS token...\n",
            " 70% 5844/8340 [1:29:11<2:43:43,  3.94s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:37,513 >> Initializing global attention on CLS token...\n",
            " 70% 5845/8340 [1:29:12<2:05:02,  3.01s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:38,356 >> Initializing global attention on CLS token...\n",
            " 70% 5846/8340 [1:29:13<1:37:57,  2.36s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:39,192 >> Initializing global attention on CLS token...\n",
            " 70% 5847/8340 [1:29:14<1:18:55,  1.90s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:40,025 >> Initializing global attention on CLS token...\n",
            " 70% 5848/8340 [1:29:15<1:05:39,  1.58s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:40,867 >> Initializing global attention on CLS token...\n",
            " 70% 5849/8340 [1:29:16<56:30,  1.36s/it]  [INFO|modeling_longformer.py:1932] 2022-12-08 17:32:41,711 >> Initializing global attention on CLS token...\n",
            " 70% 5850/8340 [1:29:16<49:53,  1.20s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:42,545 >> Initializing global attention on CLS token...\n",
            " 70% 5851/8340 [1:29:17<45:19,  1.09s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:43,382 >> Initializing global attention on CLS token...\n",
            " 70% 5852/8340 [1:29:18<42:10,  1.02s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:44,219 >> Initializing global attention on CLS token...\n",
            " 70% 5853/8340 [1:29:19<39:54,  1.04it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:45,056 >> Initializing global attention on CLS token...\n",
            " 70% 5854/8340 [1:29:20<38:20,  1.08it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:45,895 >> Initializing global attention on CLS token...\n",
            " 70% 5855/8340 [1:29:21<37:10,  1.11it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:46,727 >> Initializing global attention on CLS token...\n",
            " 70% 5856/8340 [1:29:21<36:25,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:47,568 >> Initializing global attention on CLS token...\n",
            " 70% 5857/8340 [1:29:22<35:51,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:48,404 >> Initializing global attention on CLS token...\n",
            " 70% 5858/8340 [1:29:23<35:28,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:49,236 >> Initializing global attention on CLS token...\n",
            " 70% 5859/8340 [1:29:24<35:13,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:50,078 >> Initializing global attention on CLS token...\n",
            " 70% 5860/8340 [1:29:25<35:03,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:50,918 >> Initializing global attention on CLS token...\n",
            " 70% 5861/8340 [1:29:26<34:55,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:51,754 >> Initializing global attention on CLS token...\n",
            " 70% 5862/8340 [1:29:26<34:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:52,585 >> Initializing global attention on CLS token...\n",
            " 70% 5863/8340 [1:29:27<34:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:53,423 >> Initializing global attention on CLS token...\n",
            " 70% 5864/8340 [1:29:28<34:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:54,255 >> Initializing global attention on CLS token...\n",
            " 70% 5865/8340 [1:29:29<34:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:55,094 >> Initializing global attention on CLS token...\n",
            " 70% 5866/8340 [1:29:30<34:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:55,933 >> Initializing global attention on CLS token...\n",
            " 70% 5867/8340 [1:29:31<34:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:56,768 >> Initializing global attention on CLS token...\n",
            " 70% 5868/8340 [1:29:31<34:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:57,602 >> Initializing global attention on CLS token...\n",
            " 70% 5869/8340 [1:29:32<34:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:58,445 >> Initializing global attention on CLS token...\n",
            " 70% 5870/8340 [1:29:33<34:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:32:59,279 >> Initializing global attention on CLS token...\n",
            " 70% 5871/8340 [1:29:34<34:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:00,117 >> Initializing global attention on CLS token...\n",
            " 70% 5872/8340 [1:29:35<34:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:00,956 >> Initializing global attention on CLS token...\n",
            " 70% 5873/8340 [1:29:36<34:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:01,797 >> Initializing global attention on CLS token...\n",
            " 70% 5874/8340 [1:29:37<34:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:02,638 >> Initializing global attention on CLS token...\n",
            " 70% 5875/8340 [1:29:37<34:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:03,474 >> Initializing global attention on CLS token...\n",
            " 70% 5876/8340 [1:29:38<34:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:04,312 >> Initializing global attention on CLS token...\n",
            " 70% 5877/8340 [1:29:39<34:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:05,145 >> Initializing global attention on CLS token...\n",
            " 70% 5878/8340 [1:29:40<34:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:05,980 >> Initializing global attention on CLS token...\n",
            " 70% 5879/8340 [1:29:41<34:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:06,817 >> Initializing global attention on CLS token...\n",
            " 71% 5880/8340 [1:29:42<34:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:07,653 >> Initializing global attention on CLS token...\n",
            " 71% 5881/8340 [1:29:42<34:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:08,491 >> Initializing global attention on CLS token...\n",
            " 71% 5882/8340 [1:29:43<34:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:09,332 >> Initializing global attention on CLS token...\n",
            " 71% 5883/8340 [1:29:44<34:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:10,170 >> Initializing global attention on CLS token...\n",
            " 71% 5884/8340 [1:29:45<34:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:11,004 >> Initializing global attention on CLS token...\n",
            " 71% 5885/8340 [1:29:46<34:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:11,840 >> Initializing global attention on CLS token...\n",
            " 71% 5886/8340 [1:29:47<34:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:12,679 >> Initializing global attention on CLS token...\n",
            " 71% 5887/8340 [1:29:47<34:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:13,514 >> Initializing global attention on CLS token...\n",
            " 71% 5888/8340 [1:29:48<34:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:14,348 >> Initializing global attention on CLS token...\n",
            " 71% 5889/8340 [1:29:49<34:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:15,186 >> Initializing global attention on CLS token...\n",
            " 71% 5890/8340 [1:29:50<34:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:16,021 >> Initializing global attention on CLS token...\n",
            " 71% 5891/8340 [1:29:51<34:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:16,854 >> Initializing global attention on CLS token...\n",
            " 71% 5892/8340 [1:29:52<34:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:17,693 >> Initializing global attention on CLS token...\n",
            " 71% 5893/8340 [1:29:52<34:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:18,536 >> Initializing global attention on CLS token...\n",
            " 71% 5894/8340 [1:29:53<34:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:19,373 >> Initializing global attention on CLS token...\n",
            " 71% 5895/8340 [1:29:54<34:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:20,212 >> Initializing global attention on CLS token...\n",
            " 71% 5896/8340 [1:29:55<34:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:21,049 >> Initializing global attention on CLS token...\n",
            " 71% 5897/8340 [1:29:56<34:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:21,890 >> Initializing global attention on CLS token...\n",
            " 71% 5898/8340 [1:29:57<34:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:22,726 >> Initializing global attention on CLS token...\n",
            " 71% 5899/8340 [1:29:57<34:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:23,561 >> Initializing global attention on CLS token...\n",
            " 71% 5900/8340 [1:29:58<34:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:24,404 >> Initializing global attention on CLS token...\n",
            " 71% 5901/8340 [1:29:59<34:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:25,247 >> Initializing global attention on CLS token...\n",
            " 71% 5902/8340 [1:30:00<34:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:26,085 >> Initializing global attention on CLS token...\n",
            " 71% 5903/8340 [1:30:01<34:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:26,920 >> Initializing global attention on CLS token...\n",
            " 71% 5904/8340 [1:30:02<34:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:27,759 >> Initializing global attention on CLS token...\n",
            " 71% 5905/8340 [1:30:02<34:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:28,595 >> Initializing global attention on CLS token...\n",
            " 71% 5906/8340 [1:30:03<33:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:29,434 >> Initializing global attention on CLS token...\n",
            " 71% 5907/8340 [1:30:04<33:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:30,267 >> Initializing global attention on CLS token...\n",
            " 71% 5908/8340 [1:30:05<33:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:31,106 >> Initializing global attention on CLS token...\n",
            " 71% 5909/8340 [1:30:06<33:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:31,944 >> Initializing global attention on CLS token...\n",
            " 71% 5910/8340 [1:30:07<33:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:32,781 >> Initializing global attention on CLS token...\n",
            " 71% 5911/8340 [1:30:08<33:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:33,624 >> Initializing global attention on CLS token...\n",
            " 71% 5912/8340 [1:30:08<33:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:34,462 >> Initializing global attention on CLS token...\n",
            " 71% 5913/8340 [1:30:09<33:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:35,302 >> Initializing global attention on CLS token...\n",
            " 71% 5914/8340 [1:30:10<33:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:36,140 >> Initializing global attention on CLS token...\n",
            " 71% 5915/8340 [1:30:11<33:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:36,974 >> Initializing global attention on CLS token...\n",
            " 71% 5916/8340 [1:30:12<33:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:37,811 >> Initializing global attention on CLS token...\n",
            " 71% 5917/8340 [1:30:13<33:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:38,644 >> Initializing global attention on CLS token...\n",
            " 71% 5918/8340 [1:30:13<33:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:39,479 >> Initializing global attention on CLS token...\n",
            " 71% 5919/8340 [1:30:14<33:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:40,319 >> Initializing global attention on CLS token...\n",
            " 71% 5920/8340 [1:30:15<33:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:41,159 >> Initializing global attention on CLS token...\n",
            " 71% 5921/8340 [1:30:16<33:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:41,996 >> Initializing global attention on CLS token...\n",
            " 71% 5922/8340 [1:30:17<33:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:42,832 >> Initializing global attention on CLS token...\n",
            " 71% 5923/8340 [1:30:18<33:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:43,665 >> Initializing global attention on CLS token...\n",
            " 71% 5924/8340 [1:30:18<33:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:44,501 >> Initializing global attention on CLS token...\n",
            " 71% 5925/8340 [1:30:19<33:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:45,333 >> Initializing global attention on CLS token...\n",
            " 71% 5926/8340 [1:30:20<33:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:46,168 >> Initializing global attention on CLS token...\n",
            " 71% 5927/8340 [1:30:21<33:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:47,001 >> Initializing global attention on CLS token...\n",
            " 71% 5928/8340 [1:30:22<33:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:47,838 >> Initializing global attention on CLS token...\n",
            " 71% 5929/8340 [1:30:23<33:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:48,676 >> Initializing global attention on CLS token...\n",
            " 71% 5930/8340 [1:30:23<33:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:49,516 >> Initializing global attention on CLS token...\n",
            " 71% 5931/8340 [1:30:24<33:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:50,353 >> Initializing global attention on CLS token...\n",
            " 71% 5932/8340 [1:30:25<33:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:51,186 >> Initializing global attention on CLS token...\n",
            " 71% 5933/8340 [1:30:26<33:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:52,019 >> Initializing global attention on CLS token...\n",
            " 71% 5934/8340 [1:30:27<33:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:52,852 >> Initializing global attention on CLS token...\n",
            " 71% 5935/8340 [1:30:28<33:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:53,688 >> Initializing global attention on CLS token...\n",
            " 71% 5936/8340 [1:30:28<33:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:54,529 >> Initializing global attention on CLS token...\n",
            " 71% 5937/8340 [1:30:29<33:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:55,363 >> Initializing global attention on CLS token...\n",
            " 71% 5938/8340 [1:30:30<33:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:56,199 >> Initializing global attention on CLS token...\n",
            " 71% 5939/8340 [1:30:31<33:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:57,037 >> Initializing global attention on CLS token...\n",
            " 71% 5940/8340 [1:30:32<33:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:57,872 >> Initializing global attention on CLS token...\n",
            " 71% 5941/8340 [1:30:33<33:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:58,712 >> Initializing global attention on CLS token...\n",
            " 71% 5942/8340 [1:30:33<33:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:33:59,549 >> Initializing global attention on CLS token...\n",
            " 71% 5943/8340 [1:30:34<33:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:00,381 >> Initializing global attention on CLS token...\n",
            " 71% 5944/8340 [1:30:35<33:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:01,215 >> Initializing global attention on CLS token...\n",
            " 71% 5945/8340 [1:30:36<33:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:02,052 >> Initializing global attention on CLS token...\n",
            " 71% 5946/8340 [1:30:37<33:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:02,887 >> Initializing global attention on CLS token...\n",
            " 71% 5947/8340 [1:30:38<33:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:03,721 >> Initializing global attention on CLS token...\n",
            " 71% 5948/8340 [1:30:38<33:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:04,555 >> Initializing global attention on CLS token...\n",
            " 71% 5949/8340 [1:30:39<33:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:05,389 >> Initializing global attention on CLS token...\n",
            " 71% 5950/8340 [1:30:40<33:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:06,225 >> Initializing global attention on CLS token...\n",
            " 71% 5951/8340 [1:30:41<33:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:07,062 >> Initializing global attention on CLS token...\n",
            " 71% 5952/8340 [1:30:42<33:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:07,896 >> Initializing global attention on CLS token...\n",
            " 71% 5953/8340 [1:30:43<33:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:08,731 >> Initializing global attention on CLS token...\n",
            " 71% 5954/8340 [1:30:43<33:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:09,571 >> Initializing global attention on CLS token...\n",
            " 71% 5955/8340 [1:30:44<33:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:10,408 >> Initializing global attention on CLS token...\n",
            " 71% 5956/8340 [1:30:45<33:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:11,250 >> Initializing global attention on CLS token...\n",
            " 71% 5957/8340 [1:30:46<33:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:12,087 >> Initializing global attention on CLS token...\n",
            " 71% 5958/8340 [1:30:47<33:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:12,920 >> Initializing global attention on CLS token...\n",
            " 71% 5959/8340 [1:30:48<33:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:13,755 >> Initializing global attention on CLS token...\n",
            " 71% 5960/8340 [1:30:48<33:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:14,591 >> Initializing global attention on CLS token...\n",
            " 71% 5961/8340 [1:30:49<33:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:15,427 >> Initializing global attention on CLS token...\n",
            " 71% 5962/8340 [1:30:50<33:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:16,262 >> Initializing global attention on CLS token...\n",
            " 71% 5963/8340 [1:30:51<33:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:17,101 >> Initializing global attention on CLS token...\n",
            " 72% 5964/8340 [1:30:52<33:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:17,939 >> Initializing global attention on CLS token...\n",
            " 72% 5965/8340 [1:30:53<33:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:18,776 >> Initializing global attention on CLS token...\n",
            " 72% 5966/8340 [1:30:53<33:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:19,613 >> Initializing global attention on CLS token...\n",
            " 72% 5967/8340 [1:30:54<33:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:20,456 >> Initializing global attention on CLS token...\n",
            " 72% 5968/8340 [1:30:55<33:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:21,291 >> Initializing global attention on CLS token...\n",
            " 72% 5969/8340 [1:30:56<33:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:22,128 >> Initializing global attention on CLS token...\n",
            " 72% 5970/8340 [1:30:57<33:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:22,971 >> Initializing global attention on CLS token...\n",
            " 72% 5971/8340 [1:30:58<33:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:23,811 >> Initializing global attention on CLS token...\n",
            " 72% 5972/8340 [1:30:59<33:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:24,646 >> Initializing global attention on CLS token...\n",
            " 72% 5973/8340 [1:30:59<33:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:25,478 >> Initializing global attention on CLS token...\n",
            " 72% 5974/8340 [1:31:00<32:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:26,314 >> Initializing global attention on CLS token...\n",
            " 72% 5975/8340 [1:31:01<32:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:27,149 >> Initializing global attention on CLS token...\n",
            " 72% 5976/8340 [1:31:02<32:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:27,983 >> Initializing global attention on CLS token...\n",
            " 72% 5977/8340 [1:31:03<32:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:28,815 >> Initializing global attention on CLS token...\n",
            " 72% 5978/8340 [1:31:04<32:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:29,647 >> Initializing global attention on CLS token...\n",
            " 72% 5979/8340 [1:31:04<32:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:30,482 >> Initializing global attention on CLS token...\n",
            " 72% 5980/8340 [1:31:05<32:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:31,319 >> Initializing global attention on CLS token...\n",
            " 72% 5981/8340 [1:31:06<32:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:32,160 >> Initializing global attention on CLS token...\n",
            " 72% 5982/8340 [1:31:07<32:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:32,998 >> Initializing global attention on CLS token...\n",
            " 72% 5983/8340 [1:31:08<32:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:33,834 >> Initializing global attention on CLS token...\n",
            " 72% 5984/8340 [1:31:09<32:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:34,662 >> Initializing global attention on CLS token...\n",
            " 72% 5985/8340 [1:31:09<32:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:35,500 >> Initializing global attention on CLS token...\n",
            " 72% 5986/8340 [1:31:10<32:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:36,336 >> Initializing global attention on CLS token...\n",
            " 72% 5987/8340 [1:31:11<32:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:37,171 >> Initializing global attention on CLS token...\n",
            " 72% 5988/8340 [1:31:12<32:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:38,006 >> Initializing global attention on CLS token...\n",
            " 72% 5989/8340 [1:31:13<32:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:38,839 >> Initializing global attention on CLS token...\n",
            " 72% 5990/8340 [1:31:14<32:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:39,673 >> Initializing global attention on CLS token...\n",
            " 72% 5991/8340 [1:31:14<32:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:40,508 >> Initializing global attention on CLS token...\n",
            " 72% 5992/8340 [1:31:15<32:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:41,344 >> Initializing global attention on CLS token...\n",
            " 72% 5993/8340 [1:31:16<32:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:42,175 >> Initializing global attention on CLS token...\n",
            " 72% 5994/8340 [1:31:17<32:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:43,010 >> Initializing global attention on CLS token...\n",
            " 72% 5995/8340 [1:31:18<32:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:43,847 >> Initializing global attention on CLS token...\n",
            " 72% 5996/8340 [1:31:19<32:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:44,687 >> Initializing global attention on CLS token...\n",
            " 72% 5997/8340 [1:31:19<32:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:45,527 >> Initializing global attention on CLS token...\n",
            " 72% 5998/8340 [1:31:20<32:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:46,365 >> Initializing global attention on CLS token...\n",
            " 72% 5999/8340 [1:31:21<32:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:47,199 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0532, 'learning_rate': 8.435251798561151e-06, 'epoch': 7.19}\n",
            " 72% 6000/8340 [1:31:22<33:58,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:48,160 >> Initializing global attention on CLS token...\n",
            " 72% 6001/8340 [1:31:23<33:38,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:48,994 >> Initializing global attention on CLS token...\n",
            " 72% 6002/8340 [1:31:24<33:19,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:49,835 >> Initializing global attention on CLS token...\n",
            " 72% 6003/8340 [1:31:25<33:05,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:50,669 >> Initializing global attention on CLS token...\n",
            " 72% 6004/8340 [1:31:25<32:57,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:51,510 >> Initializing global attention on CLS token...\n",
            " 72% 6005/8340 [1:31:26<32:54,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:52,351 >> Initializing global attention on CLS token...\n",
            " 72% 6006/8340 [1:31:27<32:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:53,186 >> Initializing global attention on CLS token...\n",
            " 72% 6007/8340 [1:31:28<32:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:54,020 >> Initializing global attention on CLS token...\n",
            " 72% 6008/8340 [1:31:29<32:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:54,853 >> Initializing global attention on CLS token...\n",
            " 72% 6009/8340 [1:31:30<32:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:55,687 >> Initializing global attention on CLS token...\n",
            " 72% 6010/8340 [1:31:30<32:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:56,528 >> Initializing global attention on CLS token...\n",
            " 72% 6011/8340 [1:31:31<32:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:57,361 >> Initializing global attention on CLS token...\n",
            " 72% 6012/8340 [1:31:32<32:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:58,194 >> Initializing global attention on CLS token...\n",
            " 72% 6013/8340 [1:31:33<32:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:59,028 >> Initializing global attention on CLS token...\n",
            " 72% 6014/8340 [1:31:34<32:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:34:59,862 >> Initializing global attention on CLS token...\n",
            " 72% 6015/8340 [1:31:35<32:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:00,696 >> Initializing global attention on CLS token...\n",
            " 72% 6016/8340 [1:31:35<32:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:01,532 >> Initializing global attention on CLS token...\n",
            " 72% 6017/8340 [1:31:36<32:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:02,365 >> Initializing global attention on CLS token...\n",
            " 72% 6018/8340 [1:31:37<32:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:03,195 >> Initializing global attention on CLS token...\n",
            " 72% 6019/8340 [1:31:38<32:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:04,033 >> Initializing global attention on CLS token...\n",
            " 72% 6020/8340 [1:31:39<32:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:04,871 >> Initializing global attention on CLS token...\n",
            " 72% 6021/8340 [1:31:40<32:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:05,709 >> Initializing global attention on CLS token...\n",
            " 72% 6022/8340 [1:31:40<32:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:06,548 >> Initializing global attention on CLS token...\n",
            " 72% 6023/8340 [1:31:41<32:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:07,383 >> Initializing global attention on CLS token...\n",
            " 72% 6024/8340 [1:31:42<32:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:08,218 >> Initializing global attention on CLS token...\n",
            " 72% 6025/8340 [1:31:43<32:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:09,050 >> Initializing global attention on CLS token...\n",
            " 72% 6026/8340 [1:31:44<32:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:09,888 >> Initializing global attention on CLS token...\n",
            " 72% 6027/8340 [1:31:45<32:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:10,721 >> Initializing global attention on CLS token...\n",
            " 72% 6028/8340 [1:31:45<32:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:11,555 >> Initializing global attention on CLS token...\n",
            " 72% 6029/8340 [1:31:46<32:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:12,392 >> Initializing global attention on CLS token...\n",
            " 72% 6030/8340 [1:31:47<32:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:13,247 >> Initializing global attention on CLS token...\n",
            " 72% 6031/8340 [1:31:48<32:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:14,081 >> Initializing global attention on CLS token...\n",
            " 72% 6032/8340 [1:31:49<32:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:14,920 >> Initializing global attention on CLS token...\n",
            " 72% 6033/8340 [1:31:50<32:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:15,761 >> Initializing global attention on CLS token...\n",
            " 72% 6034/8340 [1:31:50<32:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:16,599 >> Initializing global attention on CLS token...\n",
            " 72% 6035/8340 [1:31:51<32:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:17,437 >> Initializing global attention on CLS token...\n",
            " 72% 6036/8340 [1:31:52<32:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:18,275 >> Initializing global attention on CLS token...\n",
            " 72% 6037/8340 [1:31:53<32:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:19,109 >> Initializing global attention on CLS token...\n",
            " 72% 6038/8340 [1:31:54<32:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:19,944 >> Initializing global attention on CLS token...\n",
            " 72% 6039/8340 [1:31:55<32:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:20,782 >> Initializing global attention on CLS token...\n",
            " 72% 6040/8340 [1:31:56<32:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:21,621 >> Initializing global attention on CLS token...\n",
            " 72% 6041/8340 [1:31:56<32:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:22,454 >> Initializing global attention on CLS token...\n",
            " 72% 6042/8340 [1:31:57<31:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:23,287 >> Initializing global attention on CLS token...\n",
            " 72% 6043/8340 [1:31:58<31:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:24,122 >> Initializing global attention on CLS token...\n",
            " 72% 6044/8340 [1:31:59<31:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:24,958 >> Initializing global attention on CLS token...\n",
            " 72% 6045/8340 [1:32:00<31:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:25,791 >> Initializing global attention on CLS token...\n",
            " 72% 6046/8340 [1:32:01<31:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:26,626 >> Initializing global attention on CLS token...\n",
            " 73% 6047/8340 [1:32:01<31:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:27,461 >> Initializing global attention on CLS token...\n",
            " 73% 6048/8340 [1:32:02<31:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:28,296 >> Initializing global attention on CLS token...\n",
            " 73% 6049/8340 [1:32:03<31:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:29,131 >> Initializing global attention on CLS token...\n",
            " 73% 6050/8340 [1:32:04<31:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:29,968 >> Initializing global attention on CLS token...\n",
            " 73% 6051/8340 [1:32:05<31:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:30,802 >> Initializing global attention on CLS token...\n",
            " 73% 6052/8340 [1:32:06<31:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:31,638 >> Initializing global attention on CLS token...\n",
            " 73% 6053/8340 [1:32:06<31:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:32,473 >> Initializing global attention on CLS token...\n",
            " 73% 6054/8340 [1:32:07<31:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:33,313 >> Initializing global attention on CLS token...\n",
            " 73% 6055/8340 [1:32:08<31:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:34,153 >> Initializing global attention on CLS token...\n",
            " 73% 6056/8340 [1:32:09<31:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:34,984 >> Initializing global attention on CLS token...\n",
            " 73% 6057/8340 [1:32:10<31:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:35,820 >> Initializing global attention on CLS token...\n",
            " 73% 6058/8340 [1:32:11<31:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:36,655 >> Initializing global attention on CLS token...\n",
            " 73% 6059/8340 [1:32:11<31:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:37,490 >> Initializing global attention on CLS token...\n",
            " 73% 6060/8340 [1:32:12<31:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:38,326 >> Initializing global attention on CLS token...\n",
            " 73% 6061/8340 [1:32:13<31:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:39,155 >> Initializing global attention on CLS token...\n",
            " 73% 6062/8340 [1:32:14<31:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:39,990 >> Initializing global attention on CLS token...\n",
            " 73% 6063/8340 [1:32:15<31:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:40,826 >> Initializing global attention on CLS token...\n",
            " 73% 6064/8340 [1:32:16<31:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:41,660 >> Initializing global attention on CLS token...\n",
            " 73% 6065/8340 [1:32:16<31:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:42,495 >> Initializing global attention on CLS token...\n",
            " 73% 6066/8340 [1:32:17<31:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:43,328 >> Initializing global attention on CLS token...\n",
            " 73% 6067/8340 [1:32:18<31:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:44,162 >> Initializing global attention on CLS token...\n",
            " 73% 6068/8340 [1:32:19<31:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:44,997 >> Initializing global attention on CLS token...\n",
            " 73% 6069/8340 [1:32:20<31:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:45,833 >> Initializing global attention on CLS token...\n",
            " 73% 6070/8340 [1:32:21<31:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:46,667 >> Initializing global attention on CLS token...\n",
            " 73% 6071/8340 [1:32:21<31:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:47,503 >> Initializing global attention on CLS token...\n",
            " 73% 6072/8340 [1:32:22<31:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:48,339 >> Initializing global attention on CLS token...\n",
            " 73% 6073/8340 [1:32:23<31:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:49,178 >> Initializing global attention on CLS token...\n",
            " 73% 6074/8340 [1:32:24<31:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:50,014 >> Initializing global attention on CLS token...\n",
            " 73% 6075/8340 [1:32:25<31:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:50,848 >> Initializing global attention on CLS token...\n",
            " 73% 6076/8340 [1:32:26<31:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:51,683 >> Initializing global attention on CLS token...\n",
            " 73% 6077/8340 [1:32:26<31:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:52,522 >> Initializing global attention on CLS token...\n",
            " 73% 6078/8340 [1:32:27<31:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:53,359 >> Initializing global attention on CLS token...\n",
            " 73% 6079/8340 [1:32:28<31:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:54,194 >> Initializing global attention on CLS token...\n",
            " 73% 6080/8340 [1:32:29<31:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:55,029 >> Initializing global attention on CLS token...\n",
            " 73% 6081/8340 [1:32:30<31:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:55,869 >> Initializing global attention on CLS token...\n",
            " 73% 6082/8340 [1:32:31<31:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:56,701 >> Initializing global attention on CLS token...\n",
            " 73% 6083/8340 [1:32:31<31:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:57,536 >> Initializing global attention on CLS token...\n",
            " 73% 6084/8340 [1:32:32<31:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:58,368 >> Initializing global attention on CLS token...\n",
            " 73% 6085/8340 [1:32:33<31:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:35:59,201 >> Initializing global attention on CLS token...\n",
            " 73% 6086/8340 [1:32:34<31:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:00,034 >> Initializing global attention on CLS token...\n",
            " 73% 6087/8340 [1:32:35<31:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:00,869 >> Initializing global attention on CLS token...\n",
            " 73% 6088/8340 [1:32:36<31:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:01,704 >> Initializing global attention on CLS token...\n",
            " 73% 6089/8340 [1:32:36<31:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:02,543 >> Initializing global attention on CLS token...\n",
            " 73% 6090/8340 [1:32:37<31:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:03,379 >> Initializing global attention on CLS token...\n",
            " 73% 6091/8340 [1:32:38<31:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:04,226 >> Initializing global attention on CLS token...\n",
            " 73% 6092/8340 [1:32:39<31:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:05,063 >> Initializing global attention on CLS token...\n",
            " 73% 6093/8340 [1:32:40<31:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:05,902 >> Initializing global attention on CLS token...\n",
            " 73% 6094/8340 [1:32:41<31:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:06,737 >> Initializing global attention on CLS token...\n",
            " 73% 6095/8340 [1:32:41<31:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:07,571 >> Initializing global attention on CLS token...\n",
            " 73% 6096/8340 [1:32:42<31:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:08,410 >> Initializing global attention on CLS token...\n",
            " 73% 6097/8340 [1:32:43<31:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:09,246 >> Initializing global attention on CLS token...\n",
            " 73% 6098/8340 [1:32:44<31:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:10,082 >> Initializing global attention on CLS token...\n",
            " 73% 6099/8340 [1:32:45<31:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:10,914 >> Initializing global attention on CLS token...\n",
            " 73% 6100/8340 [1:32:46<31:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:11,749 >> Initializing global attention on CLS token...\n",
            " 73% 6101/8340 [1:32:46<31:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:12,583 >> Initializing global attention on CLS token...\n",
            " 73% 6102/8340 [1:32:47<31:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:13,417 >> Initializing global attention on CLS token...\n",
            " 73% 6103/8340 [1:32:48<31:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:14,254 >> Initializing global attention on CLS token...\n",
            " 73% 6104/8340 [1:32:49<31:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:15,093 >> Initializing global attention on CLS token...\n",
            " 73% 6105/8340 [1:32:50<31:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:15,933 >> Initializing global attention on CLS token...\n",
            " 73% 6106/8340 [1:32:51<31:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:16,773 >> Initializing global attention on CLS token...\n",
            " 73% 6107/8340 [1:32:51<31:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:17,606 >> Initializing global attention on CLS token...\n",
            " 73% 6108/8340 [1:32:52<31:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:18,442 >> Initializing global attention on CLS token...\n",
            " 73% 6109/8340 [1:32:53<31:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:19,279 >> Initializing global attention on CLS token...\n",
            " 73% 6110/8340 [1:32:54<31:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:20,137 >> Initializing global attention on CLS token...\n",
            " 73% 6111/8340 [1:32:55<31:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:21,009 >> Initializing global attention on CLS token...\n",
            " 73% 6112/8340 [1:32:56<31:39,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:21,878 >> Initializing global attention on CLS token...\n",
            " 73% 6113/8340 [1:32:57<31:46,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:22,730 >> Initializing global attention on CLS token...\n",
            " 73% 6114/8340 [1:32:57<31:44,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:23,584 >> Initializing global attention on CLS token...\n",
            " 73% 6115/8340 [1:32:58<31:39,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:24,427 >> Initializing global attention on CLS token...\n",
            " 73% 6116/8340 [1:32:59<31:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:25,266 >> Initializing global attention on CLS token...\n",
            " 73% 6117/8340 [1:33:00<31:23,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:26,102 >> Initializing global attention on CLS token...\n",
            " 73% 6118/8340 [1:33:01<31:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:26,940 >> Initializing global attention on CLS token...\n",
            " 73% 6119/8340 [1:33:02<31:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:27,778 >> Initializing global attention on CLS token...\n",
            " 73% 6120/8340 [1:33:02<31:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:28,616 >> Initializing global attention on CLS token...\n",
            " 73% 6121/8340 [1:33:03<31:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:29,453 >> Initializing global attention on CLS token...\n",
            " 73% 6122/8340 [1:33:04<30:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:30,287 >> Initializing global attention on CLS token...\n",
            " 73% 6123/8340 [1:33:05<30:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:31,123 >> Initializing global attention on CLS token...\n",
            " 73% 6124/8340 [1:33:06<30:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:31,959 >> Initializing global attention on CLS token...\n",
            " 73% 6125/8340 [1:33:07<30:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:32,794 >> Initializing global attention on CLS token...\n",
            " 73% 6126/8340 [1:33:08<30:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:33,629 >> Initializing global attention on CLS token...\n",
            " 73% 6127/8340 [1:33:08<30:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:34,463 >> Initializing global attention on CLS token...\n",
            " 73% 6128/8340 [1:33:09<30:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:35,300 >> Initializing global attention on CLS token...\n",
            " 73% 6129/8340 [1:33:10<30:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:36,134 >> Initializing global attention on CLS token...\n",
            " 74% 6130/8340 [1:33:11<30:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:36,969 >> Initializing global attention on CLS token...\n",
            " 74% 6131/8340 [1:33:12<30:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:37,803 >> Initializing global attention on CLS token...\n",
            " 74% 6132/8340 [1:33:13<30:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:38,636 >> Initializing global attention on CLS token...\n",
            " 74% 6133/8340 [1:33:13<30:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:39,476 >> Initializing global attention on CLS token...\n",
            " 74% 6134/8340 [1:33:14<30:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:40,309 >> Initializing global attention on CLS token...\n",
            " 74% 6135/8340 [1:33:15<30:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:41,152 >> Initializing global attention on CLS token...\n",
            " 74% 6136/8340 [1:33:16<30:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:41,992 >> Initializing global attention on CLS token...\n",
            " 74% 6137/8340 [1:33:17<30:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:42,827 >> Initializing global attention on CLS token...\n",
            " 74% 6138/8340 [1:33:18<30:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:43,658 >> Initializing global attention on CLS token...\n",
            " 74% 6139/8340 [1:33:18<30:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:44,493 >> Initializing global attention on CLS token...\n",
            " 74% 6140/8340 [1:33:19<30:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:45,328 >> Initializing global attention on CLS token...\n",
            " 74% 6141/8340 [1:33:20<30:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:46,162 >> Initializing global attention on CLS token...\n",
            " 74% 6142/8340 [1:33:21<30:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:46,995 >> Initializing global attention on CLS token...\n",
            " 74% 6143/8340 [1:33:22<30:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:47,830 >> Initializing global attention on CLS token...\n",
            " 74% 6144/8340 [1:33:23<30:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:48,661 >> Initializing global attention on CLS token...\n",
            " 74% 6145/8340 [1:33:23<30:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:49,497 >> Initializing global attention on CLS token...\n",
            " 74% 6146/8340 [1:33:24<30:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:50,332 >> Initializing global attention on CLS token...\n",
            " 74% 6147/8340 [1:33:25<30:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:51,168 >> Initializing global attention on CLS token...\n",
            " 74% 6148/8340 [1:33:26<30:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:52,007 >> Initializing global attention on CLS token...\n",
            " 74% 6149/8340 [1:33:27<30:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:52,847 >> Initializing global attention on CLS token...\n",
            " 74% 6150/8340 [1:33:28<30:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:53,687 >> Initializing global attention on CLS token...\n",
            " 74% 6151/8340 [1:33:28<30:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:54,521 >> Initializing global attention on CLS token...\n",
            " 74% 6152/8340 [1:33:29<30:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:55,356 >> Initializing global attention on CLS token...\n",
            " 74% 6153/8340 [1:33:30<30:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:56,193 >> Initializing global attention on CLS token...\n",
            " 74% 6154/8340 [1:33:31<30:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:57,033 >> Initializing global attention on CLS token...\n",
            " 74% 6155/8340 [1:33:32<30:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:57,872 >> Initializing global attention on CLS token...\n",
            " 74% 6156/8340 [1:33:33<30:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:58,704 >> Initializing global attention on CLS token...\n",
            " 74% 6157/8340 [1:33:33<30:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:36:59,544 >> Initializing global attention on CLS token...\n",
            " 74% 6158/8340 [1:33:34<30:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:00,379 >> Initializing global attention on CLS token...\n",
            " 74% 6159/8340 [1:33:35<30:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:01,213 >> Initializing global attention on CLS token...\n",
            " 74% 6160/8340 [1:33:36<30:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:02,047 >> Initializing global attention on CLS token...\n",
            " 74% 6161/8340 [1:33:37<30:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:02,885 >> Initializing global attention on CLS token...\n",
            " 74% 6162/8340 [1:33:38<30:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:03,715 >> Initializing global attention on CLS token...\n",
            " 74% 6163/8340 [1:33:38<30:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:04,549 >> Initializing global attention on CLS token...\n",
            " 74% 6164/8340 [1:33:39<30:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:05,380 >> Initializing global attention on CLS token...\n",
            " 74% 6165/8340 [1:33:40<30:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:06,214 >> Initializing global attention on CLS token...\n",
            " 74% 6166/8340 [1:33:41<30:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:07,046 >> Initializing global attention on CLS token...\n",
            " 74% 6167/8340 [1:33:42<30:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:07,880 >> Initializing global attention on CLS token...\n",
            " 74% 6168/8340 [1:33:43<30:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:08,714 >> Initializing global attention on CLS token...\n",
            " 74% 6169/8340 [1:33:43<30:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:09,549 >> Initializing global attention on CLS token...\n",
            " 74% 6170/8340 [1:33:44<30:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:10,382 >> Initializing global attention on CLS token...\n",
            " 74% 6171/8340 [1:33:45<30:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:11,219 >> Initializing global attention on CLS token...\n",
            " 74% 6172/8340 [1:33:46<30:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:12,058 >> Initializing global attention on CLS token...\n",
            " 74% 6173/8340 [1:33:47<30:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:12,891 >> Initializing global attention on CLS token...\n",
            " 74% 6174/8340 [1:33:48<30:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:13,726 >> Initializing global attention on CLS token...\n",
            " 74% 6175/8340 [1:33:48<30:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:14,560 >> Initializing global attention on CLS token...\n",
            " 74% 6176/8340 [1:33:49<30:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:15,395 >> Initializing global attention on CLS token...\n",
            " 74% 6177/8340 [1:33:50<30:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:16,229 >> Initializing global attention on CLS token...\n",
            " 74% 6178/8340 [1:33:51<30:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:17,064 >> Initializing global attention on CLS token...\n",
            " 74% 6179/8340 [1:33:52<30:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:17,898 >> Initializing global attention on CLS token...\n",
            " 74% 6180/8340 [1:33:53<30:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:18,733 >> Initializing global attention on CLS token...\n",
            " 74% 6181/8340 [1:33:53<30:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:19,566 >> Initializing global attention on CLS token...\n",
            " 74% 6182/8340 [1:33:54<29:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:20,398 >> Initializing global attention on CLS token...\n",
            " 74% 6183/8340 [1:33:55<29:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:21,232 >> Initializing global attention on CLS token...\n",
            " 74% 6184/8340 [1:33:56<29:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:22,066 >> Initializing global attention on CLS token...\n",
            " 74% 6185/8340 [1:33:57<29:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:22,900 >> Initializing global attention on CLS token...\n",
            " 74% 6186/8340 [1:33:58<29:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:23,739 >> Initializing global attention on CLS token...\n",
            " 74% 6187/8340 [1:33:58<30:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:24,580 >> Initializing global attention on CLS token...\n",
            " 74% 6188/8340 [1:33:59<30:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:25,414 >> Initializing global attention on CLS token...\n",
            " 74% 6189/8340 [1:34:00<29:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:26,250 >> Initializing global attention on CLS token...\n",
            " 74% 6190/8340 [1:34:01<29:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:27,085 >> Initializing global attention on CLS token...\n",
            " 74% 6191/8340 [1:34:02<29:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:27,922 >> Initializing global attention on CLS token...\n",
            " 74% 6192/8340 [1:34:03<29:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:28,760 >> Initializing global attention on CLS token...\n",
            " 74% 6193/8340 [1:34:03<29:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:29,597 >> Initializing global attention on CLS token...\n",
            " 74% 6194/8340 [1:34:04<29:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:30,432 >> Initializing global attention on CLS token...\n",
            " 74% 6195/8340 [1:34:05<29:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:31,273 >> Initializing global attention on CLS token...\n",
            " 74% 6196/8340 [1:34:06<29:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:32,114 >> Initializing global attention on CLS token...\n",
            " 74% 6197/8340 [1:34:07<29:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:32,948 >> Initializing global attention on CLS token...\n",
            " 74% 6198/8340 [1:34:08<29:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:33,779 >> Initializing global attention on CLS token...\n",
            " 74% 6199/8340 [1:34:08<29:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:34,614 >> Initializing global attention on CLS token...\n",
            " 74% 6200/8340 [1:34:09<29:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:35,448 >> Initializing global attention on CLS token...\n",
            " 74% 6201/8340 [1:34:10<29:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:36,278 >> Initializing global attention on CLS token...\n",
            " 74% 6202/8340 [1:34:11<29:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:37,114 >> Initializing global attention on CLS token...\n",
            " 74% 6203/8340 [1:34:12<29:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:37,948 >> Initializing global attention on CLS token...\n",
            " 74% 6204/8340 [1:34:13<29:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:38,789 >> Initializing global attention on CLS token...\n",
            " 74% 6205/8340 [1:34:14<29:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:39,624 >> Initializing global attention on CLS token...\n",
            " 74% 6206/8340 [1:34:14<29:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:40,465 >> Initializing global attention on CLS token...\n",
            " 74% 6207/8340 [1:34:15<29:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:41,300 >> Initializing global attention on CLS token...\n",
            " 74% 6208/8340 [1:34:16<29:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:42,134 >> Initializing global attention on CLS token...\n",
            " 74% 6209/8340 [1:34:17<29:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:42,968 >> Initializing global attention on CLS token...\n",
            " 74% 6210/8340 [1:34:18<29:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:43,803 >> Initializing global attention on CLS token...\n",
            " 74% 6211/8340 [1:34:19<29:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:44,639 >> Initializing global attention on CLS token...\n",
            " 74% 6212/8340 [1:34:19<29:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:45,471 >> Initializing global attention on CLS token...\n",
            " 74% 6213/8340 [1:34:20<29:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:46,305 >> Initializing global attention on CLS token...\n",
            " 75% 6214/8340 [1:34:21<29:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:47,141 >> Initializing global attention on CLS token...\n",
            " 75% 6215/8340 [1:34:22<29:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:47,976 >> Initializing global attention on CLS token...\n",
            " 75% 6216/8340 [1:34:23<29:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:48,812 >> Initializing global attention on CLS token...\n",
            " 75% 6217/8340 [1:34:24<29:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:49,645 >> Initializing global attention on CLS token...\n",
            " 75% 6218/8340 [1:34:24<29:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:50,481 >> Initializing global attention on CLS token...\n",
            " 75% 6219/8340 [1:34:25<29:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:51,316 >> Initializing global attention on CLS token...\n",
            " 75% 6220/8340 [1:34:26<29:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:52,148 >> Initializing global attention on CLS token...\n",
            " 75% 6221/8340 [1:34:27<29:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:52,990 >> Initializing global attention on CLS token...\n",
            " 75% 6222/8340 [1:34:28<29:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:53,831 >> Initializing global attention on CLS token...\n",
            " 75% 6223/8340 [1:34:29<29:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:54,667 >> Initializing global attention on CLS token...\n",
            " 75% 6224/8340 [1:34:29<29:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:55,508 >> Initializing global attention on CLS token...\n",
            " 75% 6225/8340 [1:34:30<29:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:56,343 >> Initializing global attention on CLS token...\n",
            " 75% 6226/8340 [1:34:31<29:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:57,179 >> Initializing global attention on CLS token...\n",
            " 75% 6227/8340 [1:34:32<29:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:58,018 >> Initializing global attention on CLS token...\n",
            " 75% 6228/8340 [1:34:33<29:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:58,855 >> Initializing global attention on CLS token...\n",
            " 75% 6229/8340 [1:34:34<29:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:37:59,694 >> Initializing global attention on CLS token...\n",
            " 75% 6230/8340 [1:34:34<29:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:00,540 >> Initializing global attention on CLS token...\n",
            " 75% 6231/8340 [1:34:35<29:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:01,371 >> Initializing global attention on CLS token...\n",
            " 75% 6232/8340 [1:34:36<29:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:02,214 >> Initializing global attention on CLS token...\n",
            " 75% 6233/8340 [1:34:37<29:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:03,052 >> Initializing global attention on CLS token...\n",
            " 75% 6234/8340 [1:34:38<29:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:03,888 >> Initializing global attention on CLS token...\n",
            " 75% 6235/8340 [1:34:39<29:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:04,728 >> Initializing global attention on CLS token...\n",
            " 75% 6236/8340 [1:34:39<29:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:05,561 >> Initializing global attention on CLS token...\n",
            " 75% 6237/8340 [1:34:40<29:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:06,394 >> Initializing global attention on CLS token...\n",
            " 75% 6238/8340 [1:34:41<29:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:07,231 >> Initializing global attention on CLS token...\n",
            " 75% 6239/8340 [1:34:42<29:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:08,066 >> Initializing global attention on CLS token...\n",
            " 75% 6240/8340 [1:34:43<29:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:08,906 >> Initializing global attention on CLS token...\n",
            " 75% 6241/8340 [1:34:44<29:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:09,742 >> Initializing global attention on CLS token...\n",
            " 75% 6242/8340 [1:34:44<29:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:10,577 >> Initializing global attention on CLS token...\n",
            " 75% 6243/8340 [1:34:45<29:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:11,416 >> Initializing global attention on CLS token...\n",
            " 75% 6244/8340 [1:34:46<29:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:12,249 >> Initializing global attention on CLS token...\n",
            " 75% 6245/8340 [1:34:47<29:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:13,084 >> Initializing global attention on CLS token...\n",
            " 75% 6246/8340 [1:34:48<29:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:13,918 >> Initializing global attention on CLS token...\n",
            " 75% 6247/8340 [1:34:49<29:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:14,753 >> Initializing global attention on CLS token...\n",
            " 75% 6248/8340 [1:34:49<29:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:15,585 >> Initializing global attention on CLS token...\n",
            " 75% 6249/8340 [1:34:50<29:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:16,419 >> Initializing global attention on CLS token...\n",
            " 75% 6250/8340 [1:34:51<29:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:17,257 >> Initializing global attention on CLS token...\n",
            " 75% 6251/8340 [1:34:52<29:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:18,095 >> Initializing global attention on CLS token...\n",
            " 75% 6252/8340 [1:34:53<29:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:18,936 >> Initializing global attention on CLS token...\n",
            " 75% 6253/8340 [1:34:54<29:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:19,773 >> Initializing global attention on CLS token...\n",
            " 75% 6254/8340 [1:34:54<29:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:20,608 >> Initializing global attention on CLS token...\n",
            " 75% 6255/8340 [1:34:55<29:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:21,444 >> Initializing global attention on CLS token...\n",
            " 75% 6256/8340 [1:34:56<29:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:22,278 >> Initializing global attention on CLS token...\n",
            " 75% 6257/8340 [1:34:57<29:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:23,113 >> Initializing global attention on CLS token...\n",
            " 75% 6258/8340 [1:34:58<29:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:23,957 >> Initializing global attention on CLS token...\n",
            " 75% 6259/8340 [1:34:59<29:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:24,800 >> Initializing global attention on CLS token...\n",
            " 75% 6260/8340 [1:35:00<29:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:25,641 >> Initializing global attention on CLS token...\n",
            " 75% 6261/8340 [1:35:00<29:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:26,475 >> Initializing global attention on CLS token...\n",
            " 75% 6262/8340 [1:35:01<28:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:27,309 >> Initializing global attention on CLS token...\n",
            " 75% 6263/8340 [1:35:02<28:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:28,144 >> Initializing global attention on CLS token...\n",
            " 75% 6264/8340 [1:35:03<28:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:28,980 >> Initializing global attention on CLS token...\n",
            " 75% 6265/8340 [1:35:04<28:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:29,814 >> Initializing global attention on CLS token...\n",
            " 75% 6266/8340 [1:35:05<28:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:30,654 >> Initializing global attention on CLS token...\n",
            " 75% 6267/8340 [1:35:05<28:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:31,487 >> Initializing global attention on CLS token...\n",
            " 75% 6268/8340 [1:35:06<28:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:32,321 >> Initializing global attention on CLS token...\n",
            " 75% 6269/8340 [1:35:07<28:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:33,156 >> Initializing global attention on CLS token...\n",
            " 75% 6270/8340 [1:35:08<28:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:33,994 >> Initializing global attention on CLS token...\n",
            " 75% 6271/8340 [1:35:09<28:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:34,833 >> Initializing global attention on CLS token...\n",
            " 75% 6272/8340 [1:35:10<28:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:35,675 >> Initializing global attention on CLS token...\n",
            " 75% 6273/8340 [1:35:10<28:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:36,512 >> Initializing global attention on CLS token...\n",
            " 75% 6274/8340 [1:35:11<28:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:37,347 >> Initializing global attention on CLS token...\n",
            " 75% 6275/8340 [1:35:12<28:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:38,183 >> Initializing global attention on CLS token...\n",
            " 75% 6276/8340 [1:35:13<28:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:39,022 >> Initializing global attention on CLS token...\n",
            " 75% 6277/8340 [1:35:14<28:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:39,867 >> Initializing global attention on CLS token...\n",
            " 75% 6278/8340 [1:35:15<28:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:40,701 >> Initializing global attention on CLS token...\n",
            " 75% 6279/8340 [1:35:15<28:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:41,533 >> Initializing global attention on CLS token...\n",
            " 75% 6280/8340 [1:35:16<28:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:42,369 >> Initializing global attention on CLS token...\n",
            " 75% 6281/8340 [1:35:17<28:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:43,205 >> Initializing global attention on CLS token...\n",
            " 75% 6282/8340 [1:35:18<28:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:44,041 >> Initializing global attention on CLS token...\n",
            " 75% 6283/8340 [1:35:19<28:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:44,876 >> Initializing global attention on CLS token...\n",
            " 75% 6284/8340 [1:35:20<28:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:45,715 >> Initializing global attention on CLS token...\n",
            " 75% 6285/8340 [1:35:20<28:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:46,550 >> Initializing global attention on CLS token...\n",
            " 75% 6286/8340 [1:35:21<28:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:47,382 >> Initializing global attention on CLS token...\n",
            " 75% 6287/8340 [1:35:22<28:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:48,217 >> Initializing global attention on CLS token...\n",
            " 75% 6288/8340 [1:35:23<28:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:49,051 >> Initializing global attention on CLS token...\n",
            " 75% 6289/8340 [1:35:24<28:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:49,887 >> Initializing global attention on CLS token...\n",
            " 75% 6290/8340 [1:35:25<28:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:50,720 >> Initializing global attention on CLS token...\n",
            " 75% 6291/8340 [1:35:25<28:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:51,553 >> Initializing global attention on CLS token...\n",
            " 75% 6292/8340 [1:35:26<28:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:52,383 >> Initializing global attention on CLS token...\n",
            " 75% 6293/8340 [1:35:27<28:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:53,221 >> Initializing global attention on CLS token...\n",
            " 75% 6294/8340 [1:35:28<28:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:54,054 >> Initializing global attention on CLS token...\n",
            " 75% 6295/8340 [1:35:29<28:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:54,891 >> Initializing global attention on CLS token...\n",
            " 75% 6296/8340 [1:35:30<28:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:55,725 >> Initializing global attention on CLS token...\n",
            " 76% 6297/8340 [1:35:30<28:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:56,559 >> Initializing global attention on CLS token...\n",
            " 76% 6298/8340 [1:35:31<28:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:57,394 >> Initializing global attention on CLS token...\n",
            " 76% 6299/8340 [1:35:32<28:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:58,228 >> Initializing global attention on CLS token...\n",
            " 76% 6300/8340 [1:35:33<28:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:59,065 >> Initializing global attention on CLS token...\n",
            " 76% 6301/8340 [1:35:34<28:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:38:59,894 >> Initializing global attention on CLS token...\n",
            " 76% 6302/8340 [1:35:35<28:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:00,725 >> Initializing global attention on CLS token...\n",
            " 76% 6303/8340 [1:35:35<28:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:01,563 >> Initializing global attention on CLS token...\n",
            " 76% 6304/8340 [1:35:36<28:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:02,399 >> Initializing global attention on CLS token...\n",
            " 76% 6305/8340 [1:35:37<28:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:03,243 >> Initializing global attention on CLS token...\n",
            " 76% 6306/8340 [1:35:38<28:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:04,081 >> Initializing global attention on CLS token...\n",
            " 76% 6307/8340 [1:35:39<28:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:04,916 >> Initializing global attention on CLS token...\n",
            " 76% 6308/8340 [1:35:40<28:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:05,750 >> Initializing global attention on CLS token...\n",
            " 76% 6309/8340 [1:35:40<28:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:06,582 >> Initializing global attention on CLS token...\n",
            " 76% 6310/8340 [1:35:41<28:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:07,418 >> Initializing global attention on CLS token...\n",
            " 76% 6311/8340 [1:35:42<28:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:08,251 >> Initializing global attention on CLS token...\n",
            " 76% 6312/8340 [1:35:43<28:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:09,085 >> Initializing global attention on CLS token...\n",
            " 76% 6313/8340 [1:35:44<28:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:09,918 >> Initializing global attention on CLS token...\n",
            " 76% 6314/8340 [1:35:45<28:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:10,754 >> Initializing global attention on CLS token...\n",
            " 76% 6315/8340 [1:35:45<28:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:11,587 >> Initializing global attention on CLS token...\n",
            " 76% 6316/8340 [1:35:46<28:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:12,423 >> Initializing global attention on CLS token...\n",
            " 76% 6317/8340 [1:35:47<28:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:13,259 >> Initializing global attention on CLS token...\n",
            " 76% 6318/8340 [1:35:48<28:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:14,096 >> Initializing global attention on CLS token...\n",
            " 76% 6319/8340 [1:35:49<28:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:14,935 >> Initializing global attention on CLS token...\n",
            " 76% 6320/8340 [1:35:50<28:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:15,773 >> Initializing global attention on CLS token...\n",
            " 76% 6321/8340 [1:35:50<28:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:16,610 >> Initializing global attention on CLS token...\n",
            " 76% 6322/8340 [1:35:51<28:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:17,446 >> Initializing global attention on CLS token...\n",
            " 76% 6323/8340 [1:35:52<28:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:18,281 >> Initializing global attention on CLS token...\n",
            " 76% 6324/8340 [1:35:53<28:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:19,120 >> Initializing global attention on CLS token...\n",
            " 76% 6325/8340 [1:35:54<28:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:19,958 >> Initializing global attention on CLS token...\n",
            " 76% 6326/8340 [1:35:55<28:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:20,794 >> Initializing global attention on CLS token...\n",
            " 76% 6327/8340 [1:35:56<28:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:21,629 >> Initializing global attention on CLS token...\n",
            " 76% 6328/8340 [1:35:56<28:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:22,462 >> Initializing global attention on CLS token...\n",
            " 76% 6329/8340 [1:35:57<27:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:23,295 >> Initializing global attention on CLS token...\n",
            " 76% 6330/8340 [1:35:58<27:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:24,130 >> Initializing global attention on CLS token...\n",
            " 76% 6331/8340 [1:35:59<27:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:24,966 >> Initializing global attention on CLS token...\n",
            " 76% 6332/8340 [1:36:00<27:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:25,800 >> Initializing global attention on CLS token...\n",
            " 76% 6333/8340 [1:36:01<27:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:26,635 >> Initializing global attention on CLS token...\n",
            " 76% 6334/8340 [1:36:01<27:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:27,467 >> Initializing global attention on CLS token...\n",
            " 76% 6335/8340 [1:36:02<27:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:28,309 >> Initializing global attention on CLS token...\n",
            " 76% 6336/8340 [1:36:03<28:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:29,161 >> Initializing global attention on CLS token...\n",
            " 76% 6337/8340 [1:36:04<28:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:30,001 >> Initializing global attention on CLS token...\n",
            " 76% 6338/8340 [1:36:05<28:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:30,839 >> Initializing global attention on CLS token...\n",
            " 76% 6339/8340 [1:36:06<27:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:31,673 >> Initializing global attention on CLS token...\n",
            " 76% 6340/8340 [1:36:06<27:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:32,507 >> Initializing global attention on CLS token...\n",
            " 76% 6341/8340 [1:36:07<27:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:33,339 >> Initializing global attention on CLS token...\n",
            " 76% 6342/8340 [1:36:08<27:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:34,171 >> Initializing global attention on CLS token...\n",
            " 76% 6343/8340 [1:36:09<27:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:35,005 >> Initializing global attention on CLS token...\n",
            " 76% 6344/8340 [1:36:10<27:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:35,840 >> Initializing global attention on CLS token...\n",
            " 76% 6345/8340 [1:36:11<27:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:36,673 >> Initializing global attention on CLS token...\n",
            " 76% 6346/8340 [1:36:11<27:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:37,508 >> Initializing global attention on CLS token...\n",
            " 76% 6347/8340 [1:36:12<27:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:38,343 >> Initializing global attention on CLS token...\n",
            " 76% 6348/8340 [1:36:13<27:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:39,175 >> Initializing global attention on CLS token...\n",
            " 76% 6349/8340 [1:36:14<27:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:40,009 >> Initializing global attention on CLS token...\n",
            " 76% 6350/8340 [1:36:15<27:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:40,840 >> Initializing global attention on CLS token...\n",
            " 76% 6351/8340 [1:36:16<27:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:41,676 >> Initializing global attention on CLS token...\n",
            " 76% 6352/8340 [1:36:16<27:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:42,509 >> Initializing global attention on CLS token...\n",
            " 76% 6353/8340 [1:36:17<27:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:43,342 >> Initializing global attention on CLS token...\n",
            " 76% 6354/8340 [1:36:18<27:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:44,175 >> Initializing global attention on CLS token...\n",
            " 76% 6355/8340 [1:36:19<27:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:45,009 >> Initializing global attention on CLS token...\n",
            " 76% 6356/8340 [1:36:20<27:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:45,843 >> Initializing global attention on CLS token...\n",
            " 76% 6357/8340 [1:36:21<27:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:46,678 >> Initializing global attention on CLS token...\n",
            " 76% 6358/8340 [1:36:21<27:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:47,511 >> Initializing global attention on CLS token...\n",
            " 76% 6359/8340 [1:36:22<27:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:48,348 >> Initializing global attention on CLS token...\n",
            " 76% 6360/8340 [1:36:23<27:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:49,185 >> Initializing global attention on CLS token...\n",
            " 76% 6361/8340 [1:36:24<27:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:50,022 >> Initializing global attention on CLS token...\n",
            " 76% 6362/8340 [1:36:25<27:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:50,856 >> Initializing global attention on CLS token...\n",
            " 76% 6363/8340 [1:36:26<27:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:51,691 >> Initializing global attention on CLS token...\n",
            " 76% 6364/8340 [1:36:26<27:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:52,525 >> Initializing global attention on CLS token...\n",
            " 76% 6365/8340 [1:36:27<27:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:53,358 >> Initializing global attention on CLS token...\n",
            " 76% 6366/8340 [1:36:28<27:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:54,194 >> Initializing global attention on CLS token...\n",
            " 76% 6367/8340 [1:36:29<27:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:55,023 >> Initializing global attention on CLS token...\n",
            " 76% 6368/8340 [1:36:30<27:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:55,862 >> Initializing global attention on CLS token...\n",
            " 76% 6369/8340 [1:36:31<27:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:56,696 >> Initializing global attention on CLS token...\n",
            " 76% 6370/8340 [1:36:31<27:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:57,532 >> Initializing global attention on CLS token...\n",
            " 76% 6371/8340 [1:36:32<27:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:58,369 >> Initializing global attention on CLS token...\n",
            " 76% 6372/8340 [1:36:33<27:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:39:59,203 >> Initializing global attention on CLS token...\n",
            " 76% 6373/8340 [1:36:34<27:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:00,037 >> Initializing global attention on CLS token...\n",
            " 76% 6374/8340 [1:36:35<27:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:00,880 >> Initializing global attention on CLS token...\n",
            " 76% 6375/8340 [1:36:36<27:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:01,713 >> Initializing global attention on CLS token...\n",
            " 76% 6376/8340 [1:36:36<27:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:02,550 >> Initializing global attention on CLS token...\n",
            " 76% 6377/8340 [1:36:37<27:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:03,383 >> Initializing global attention on CLS token...\n",
            " 76% 6378/8340 [1:36:38<27:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:04,217 >> Initializing global attention on CLS token...\n",
            " 76% 6379/8340 [1:36:39<27:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:05,051 >> Initializing global attention on CLS token...\n",
            " 76% 6380/8340 [1:36:40<27:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:05,889 >> Initializing global attention on CLS token...\n",
            " 77% 6381/8340 [1:36:41<27:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:06,726 >> Initializing global attention on CLS token...\n",
            " 77% 6382/8340 [1:36:41<27:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:07,561 >> Initializing global attention on CLS token...\n",
            " 77% 6383/8340 [1:36:42<27:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:08,397 >> Initializing global attention on CLS token...\n",
            " 77% 6384/8340 [1:36:43<27:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:09,232 >> Initializing global attention on CLS token...\n",
            " 77% 6385/8340 [1:36:44<27:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:10,064 >> Initializing global attention on CLS token...\n",
            " 77% 6386/8340 [1:36:45<27:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:10,901 >> Initializing global attention on CLS token...\n",
            " 77% 6387/8340 [1:36:46<27:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:11,738 >> Initializing global attention on CLS token...\n",
            " 77% 6388/8340 [1:36:46<27:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:12,571 >> Initializing global attention on CLS token...\n",
            " 77% 6389/8340 [1:36:47<27:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:13,405 >> Initializing global attention on CLS token...\n",
            " 77% 6390/8340 [1:36:48<27:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:14,240 >> Initializing global attention on CLS token...\n",
            " 77% 6391/8340 [1:36:49<27:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:15,080 >> Initializing global attention on CLS token...\n",
            " 77% 6392/8340 [1:36:50<27:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:15,914 >> Initializing global attention on CLS token...\n",
            " 77% 6393/8340 [1:36:51<27:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:16,750 >> Initializing global attention on CLS token...\n",
            " 77% 6394/8340 [1:36:51<27:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:17,582 >> Initializing global attention on CLS token...\n",
            " 77% 6395/8340 [1:36:52<27:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:18,420 >> Initializing global attention on CLS token...\n",
            " 77% 6396/8340 [1:36:53<27:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:19,258 >> Initializing global attention on CLS token...\n",
            " 77% 6397/8340 [1:36:54<27:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:20,095 >> Initializing global attention on CLS token...\n",
            " 77% 6398/8340 [1:36:55<27:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:20,935 >> Initializing global attention on CLS token...\n",
            " 77% 6399/8340 [1:36:56<27:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:21,783 >> Initializing global attention on CLS token...\n",
            " 77% 6400/8340 [1:36:57<27:11,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:22,621 >> Initializing global attention on CLS token...\n",
            " 77% 6401/8340 [1:36:57<27:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:23,460 >> Initializing global attention on CLS token...\n",
            " 77% 6402/8340 [1:36:58<27:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:24,296 >> Initializing global attention on CLS token...\n",
            " 77% 6403/8340 [1:36:59<27:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:25,132 >> Initializing global attention on CLS token...\n",
            " 77% 6404/8340 [1:37:00<27:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:25,974 >> Initializing global attention on CLS token...\n",
            " 77% 6405/8340 [1:37:01<27:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:26,814 >> Initializing global attention on CLS token...\n",
            " 77% 6406/8340 [1:37:02<27:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:27,651 >> Initializing global attention on CLS token...\n",
            " 77% 6407/8340 [1:37:02<27:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:28,495 >> Initializing global attention on CLS token...\n",
            " 77% 6408/8340 [1:37:03<27:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:29,339 >> Initializing global attention on CLS token...\n",
            " 77% 6409/8340 [1:37:04<27:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:30,175 >> Initializing global attention on CLS token...\n",
            " 77% 6410/8340 [1:37:05<26:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:31,011 >> Initializing global attention on CLS token...\n",
            " 77% 6411/8340 [1:37:06<26:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:31,848 >> Initializing global attention on CLS token...\n",
            " 77% 6412/8340 [1:37:07<26:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:32,682 >> Initializing global attention on CLS token...\n",
            " 77% 6413/8340 [1:37:07<26:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:33,514 >> Initializing global attention on CLS token...\n",
            " 77% 6414/8340 [1:37:08<26:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:34,349 >> Initializing global attention on CLS token...\n",
            " 77% 6415/8340 [1:37:09<26:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:35,187 >> Initializing global attention on CLS token...\n",
            " 77% 6416/8340 [1:37:10<26:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:36,031 >> Initializing global attention on CLS token...\n",
            " 77% 6417/8340 [1:37:11<26:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:36,863 >> Initializing global attention on CLS token...\n",
            " 77% 6418/8340 [1:37:12<26:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:37,702 >> Initializing global attention on CLS token...\n",
            " 77% 6419/8340 [1:37:12<26:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:38,538 >> Initializing global attention on CLS token...\n",
            " 77% 6420/8340 [1:37:13<26:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:39,374 >> Initializing global attention on CLS token...\n",
            " 77% 6421/8340 [1:37:14<26:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:40,209 >> Initializing global attention on CLS token...\n",
            " 77% 6422/8340 [1:37:15<26:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:41,045 >> Initializing global attention on CLS token...\n",
            " 77% 6423/8340 [1:37:16<26:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:41,880 >> Initializing global attention on CLS token...\n",
            " 77% 6424/8340 [1:37:17<26:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:42,718 >> Initializing global attention on CLS token...\n",
            " 77% 6425/8340 [1:37:17<26:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:43,557 >> Initializing global attention on CLS token...\n",
            " 77% 6426/8340 [1:37:18<26:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:44,392 >> Initializing global attention on CLS token...\n",
            " 77% 6427/8340 [1:37:19<26:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:45,225 >> Initializing global attention on CLS token...\n",
            " 77% 6428/8340 [1:37:20<26:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:46,057 >> Initializing global attention on CLS token...\n",
            " 77% 6429/8340 [1:37:21<26:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:46,893 >> Initializing global attention on CLS token...\n",
            " 77% 6430/8340 [1:37:22<26:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:47,727 >> Initializing global attention on CLS token...\n",
            " 77% 6431/8340 [1:37:22<26:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:48,564 >> Initializing global attention on CLS token...\n",
            " 77% 6432/8340 [1:37:23<26:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:49,398 >> Initializing global attention on CLS token...\n",
            " 77% 6433/8340 [1:37:24<26:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:50,232 >> Initializing global attention on CLS token...\n",
            " 77% 6434/8340 [1:37:25<26:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:51,065 >> Initializing global attention on CLS token...\n",
            " 77% 6435/8340 [1:37:26<26:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:51,900 >> Initializing global attention on CLS token...\n",
            " 77% 6436/8340 [1:37:27<26:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:52,733 >> Initializing global attention on CLS token...\n",
            " 77% 6437/8340 [1:37:27<26:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:53,567 >> Initializing global attention on CLS token...\n",
            " 77% 6438/8340 [1:37:28<26:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:54,402 >> Initializing global attention on CLS token...\n",
            " 77% 6439/8340 [1:37:29<26:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:55,235 >> Initializing global attention on CLS token...\n",
            " 77% 6440/8340 [1:37:30<26:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:56,065 >> Initializing global attention on CLS token...\n",
            " 77% 6441/8340 [1:37:31<26:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:56,899 >> Initializing global attention on CLS token...\n",
            " 77% 6442/8340 [1:37:32<26:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:57,736 >> Initializing global attention on CLS token...\n",
            " 77% 6443/8340 [1:37:32<26:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:58,568 >> Initializing global attention on CLS token...\n",
            " 77% 6444/8340 [1:37:33<26:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:40:59,402 >> Initializing global attention on CLS token...\n",
            " 77% 6445/8340 [1:37:34<26:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:00,235 >> Initializing global attention on CLS token...\n",
            " 77% 6446/8340 [1:37:35<26:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:01,072 >> Initializing global attention on CLS token...\n",
            " 77% 6447/8340 [1:37:36<26:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:01,913 >> Initializing global attention on CLS token...\n",
            " 77% 6448/8340 [1:37:37<26:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:02,746 >> Initializing global attention on CLS token...\n",
            " 77% 6449/8340 [1:37:37<26:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:03,576 >> Initializing global attention on CLS token...\n",
            " 77% 6450/8340 [1:37:38<26:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:04,413 >> Initializing global attention on CLS token...\n",
            " 77% 6451/8340 [1:37:39<26:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:05,247 >> Initializing global attention on CLS token...\n",
            " 77% 6452/8340 [1:37:40<26:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:06,078 >> Initializing global attention on CLS token...\n",
            " 77% 6453/8340 [1:37:41<26:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:06,915 >> Initializing global attention on CLS token...\n",
            " 77% 6454/8340 [1:37:42<26:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:07,748 >> Initializing global attention on CLS token...\n",
            " 77% 6455/8340 [1:37:42<26:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:08,581 >> Initializing global attention on CLS token...\n",
            " 77% 6456/8340 [1:37:43<26:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:09,419 >> Initializing global attention on CLS token...\n",
            " 77% 6457/8340 [1:37:44<26:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:10,261 >> Initializing global attention on CLS token...\n",
            " 77% 6458/8340 [1:37:45<26:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:11,094 >> Initializing global attention on CLS token...\n",
            " 77% 6459/8340 [1:37:46<26:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:11,934 >> Initializing global attention on CLS token...\n",
            " 77% 6460/8340 [1:37:47<26:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:12,776 >> Initializing global attention on CLS token...\n",
            " 77% 6461/8340 [1:37:47<26:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:13,613 >> Initializing global attention on CLS token...\n",
            " 77% 6462/8340 [1:37:48<26:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:14,446 >> Initializing global attention on CLS token...\n",
            " 77% 6463/8340 [1:37:49<26:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:15,280 >> Initializing global attention on CLS token...\n",
            " 78% 6464/8340 [1:37:50<26:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:16,114 >> Initializing global attention on CLS token...\n",
            " 78% 6465/8340 [1:37:51<26:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:16,949 >> Initializing global attention on CLS token...\n",
            " 78% 6466/8340 [1:37:52<26:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:17,782 >> Initializing global attention on CLS token...\n",
            " 78% 6467/8340 [1:37:53<26:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:18,616 >> Initializing global attention on CLS token...\n",
            " 78% 6468/8340 [1:37:53<26:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:19,448 >> Initializing global attention on CLS token...\n",
            " 78% 6469/8340 [1:37:54<26:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:20,281 >> Initializing global attention on CLS token...\n",
            " 78% 6470/8340 [1:37:55<25:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:21,114 >> Initializing global attention on CLS token...\n",
            " 78% 6471/8340 [1:37:56<26:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:21,952 >> Initializing global attention on CLS token...\n",
            " 78% 6472/8340 [1:37:57<25:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:22,787 >> Initializing global attention on CLS token...\n",
            " 78% 6473/8340 [1:37:58<25:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:23,621 >> Initializing global attention on CLS token...\n",
            " 78% 6474/8340 [1:37:58<25:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:24,460 >> Initializing global attention on CLS token...\n",
            " 78% 6475/8340 [1:37:59<25:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:25,295 >> Initializing global attention on CLS token...\n",
            " 78% 6476/8340 [1:38:00<25:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:26,132 >> Initializing global attention on CLS token...\n",
            " 78% 6477/8340 [1:38:01<25:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:26,971 >> Initializing global attention on CLS token...\n",
            " 78% 6478/8340 [1:38:02<25:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:27,809 >> Initializing global attention on CLS token...\n",
            " 78% 6479/8340 [1:38:03<25:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:28,645 >> Initializing global attention on CLS token...\n",
            " 78% 6480/8340 [1:38:03<25:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:29,486 >> Initializing global attention on CLS token...\n",
            " 78% 6481/8340 [1:38:04<25:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:30,324 >> Initializing global attention on CLS token...\n",
            " 78% 6482/8340 [1:38:05<25:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:31,160 >> Initializing global attention on CLS token...\n",
            " 78% 6483/8340 [1:38:06<25:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:31,997 >> Initializing global attention on CLS token...\n",
            " 78% 6484/8340 [1:38:07<25:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:32,840 >> Initializing global attention on CLS token...\n",
            " 78% 6485/8340 [1:38:08<25:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:33,675 >> Initializing global attention on CLS token...\n",
            " 78% 6486/8340 [1:38:08<25:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:34,509 >> Initializing global attention on CLS token...\n",
            " 78% 6487/8340 [1:38:09<25:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:35,346 >> Initializing global attention on CLS token...\n",
            " 78% 6488/8340 [1:38:10<25:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:36,182 >> Initializing global attention on CLS token...\n",
            " 78% 6489/8340 [1:38:11<25:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:37,017 >> Initializing global attention on CLS token...\n",
            " 78% 6490/8340 [1:38:12<25:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:37,850 >> Initializing global attention on CLS token...\n",
            " 78% 6491/8340 [1:38:13<25:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:38,683 >> Initializing global attention on CLS token...\n",
            " 78% 6492/8340 [1:38:13<25:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:39,520 >> Initializing global attention on CLS token...\n",
            " 78% 6493/8340 [1:38:14<25:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:40,355 >> Initializing global attention on CLS token...\n",
            " 78% 6494/8340 [1:38:15<25:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:41,191 >> Initializing global attention on CLS token...\n",
            " 78% 6495/8340 [1:38:16<25:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:42,034 >> Initializing global attention on CLS token...\n",
            " 78% 6496/8340 [1:38:17<25:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:42,870 >> Initializing global attention on CLS token...\n",
            " 78% 6497/8340 [1:38:18<25:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:43,706 >> Initializing global attention on CLS token...\n",
            " 78% 6498/8340 [1:38:18<25:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:44,540 >> Initializing global attention on CLS token...\n",
            " 78% 6499/8340 [1:38:19<25:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:45,376 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.044, 'learning_rate': 6.636690647482015e-06, 'epoch': 7.79}\n",
            " 78% 6500/8340 [1:38:20<26:44,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:46,334 >> Initializing global attention on CLS token...\n",
            " 78% 6501/8340 [1:38:21<26:25,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:47,171 >> Initializing global attention on CLS token...\n",
            " 78% 6502/8340 [1:38:22<26:10,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:48,008 >> Initializing global attention on CLS token...\n",
            " 78% 6503/8340 [1:38:23<25:59,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:48,843 >> Initializing global attention on CLS token...\n",
            " 78% 6504/8340 [1:38:24<25:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:49,679 >> Initializing global attention on CLS token...\n",
            " 78% 6505/8340 [1:38:24<25:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:50,515 >> Initializing global attention on CLS token...\n",
            " 78% 6506/8340 [1:38:25<25:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:51,352 >> Initializing global attention on CLS token...\n",
            " 78% 6507/8340 [1:38:26<25:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:52,193 >> Initializing global attention on CLS token...\n",
            " 78% 6508/8340 [1:38:27<25:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:53,030 >> Initializing global attention on CLS token...\n",
            " 78% 6509/8340 [1:38:28<25:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:53,866 >> Initializing global attention on CLS token...\n",
            " 78% 6510/8340 [1:38:29<25:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:54,705 >> Initializing global attention on CLS token...\n",
            " 78% 6511/8340 [1:38:29<25:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:55,544 >> Initializing global attention on CLS token...\n",
            " 78% 6512/8340 [1:38:30<25:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:56,381 >> Initializing global attention on CLS token...\n",
            " 78% 6513/8340 [1:38:31<25:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:57,213 >> Initializing global attention on CLS token...\n",
            " 78% 6514/8340 [1:38:32<25:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:58,050 >> Initializing global attention on CLS token...\n",
            " 78% 6515/8340 [1:38:33<25:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:58,888 >> Initializing global attention on CLS token...\n",
            " 78% 6516/8340 [1:38:34<25:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:41:59,722 >> Initializing global attention on CLS token...\n",
            " 78% 6517/8340 [1:38:34<25:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:00,557 >> Initializing global attention on CLS token...\n",
            " 78% 6518/8340 [1:38:35<25:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:01,394 >> Initializing global attention on CLS token...\n",
            " 78% 6519/8340 [1:38:36<25:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:02,235 >> Initializing global attention on CLS token...\n",
            " 78% 6520/8340 [1:38:37<25:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:03,087 >> Initializing global attention on CLS token...\n",
            " 78% 6521/8340 [1:38:38<25:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:03,931 >> Initializing global attention on CLS token...\n",
            " 78% 6522/8340 [1:38:39<25:32,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:04,799 >> Initializing global attention on CLS token...\n",
            " 78% 6523/8340 [1:38:40<25:46,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:05,653 >> Initializing global attention on CLS token...\n",
            " 78% 6524/8340 [1:38:40<25:46,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:06,507 >> Initializing global attention on CLS token...\n",
            " 78% 6525/8340 [1:38:41<25:44,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:07,344 >> Initializing global attention on CLS token...\n",
            " 78% 6526/8340 [1:38:42<25:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:08,183 >> Initializing global attention on CLS token...\n",
            " 78% 6527/8340 [1:38:43<25:31,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:09,020 >> Initializing global attention on CLS token...\n",
            " 78% 6528/8340 [1:38:44<25:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:09,855 >> Initializing global attention on CLS token...\n",
            " 78% 6529/8340 [1:38:45<25:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:10,694 >> Initializing global attention on CLS token...\n",
            " 78% 6530/8340 [1:38:45<25:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:11,531 >> Initializing global attention on CLS token...\n",
            " 78% 6531/8340 [1:38:46<25:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:12,370 >> Initializing global attention on CLS token...\n",
            " 78% 6532/8340 [1:38:47<25:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:13,204 >> Initializing global attention on CLS token...\n",
            " 78% 6533/8340 [1:38:48<25:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:14,038 >> Initializing global attention on CLS token...\n",
            " 78% 6534/8340 [1:38:49<25:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:14,870 >> Initializing global attention on CLS token...\n",
            " 78% 6535/8340 [1:38:50<25:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:15,708 >> Initializing global attention on CLS token...\n",
            " 78% 6536/8340 [1:38:50<25:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:16,544 >> Initializing global attention on CLS token...\n",
            " 78% 6537/8340 [1:38:51<25:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:17,382 >> Initializing global attention on CLS token...\n",
            " 78% 6538/8340 [1:38:52<25:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:18,217 >> Initializing global attention on CLS token...\n",
            " 78% 6539/8340 [1:38:53<25:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:19,050 >> Initializing global attention on CLS token...\n",
            " 78% 6540/8340 [1:38:54<25:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:19,885 >> Initializing global attention on CLS token...\n",
            " 78% 6541/8340 [1:38:55<25:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:20,720 >> Initializing global attention on CLS token...\n",
            " 78% 6542/8340 [1:38:55<25:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:21,559 >> Initializing global attention on CLS token...\n",
            " 78% 6543/8340 [1:38:56<25:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:22,396 >> Initializing global attention on CLS token...\n",
            " 78% 6544/8340 [1:38:57<25:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:23,231 >> Initializing global attention on CLS token...\n",
            " 78% 6545/8340 [1:38:58<24:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:24,062 >> Initializing global attention on CLS token...\n",
            " 78% 6546/8340 [1:38:59<25:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:24,903 >> Initializing global attention on CLS token...\n",
            " 79% 6547/8340 [1:39:00<24:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:25,739 >> Initializing global attention on CLS token...\n",
            " 79% 6548/8340 [1:39:00<24:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:26,574 >> Initializing global attention on CLS token...\n",
            " 79% 6549/8340 [1:39:01<24:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:27,412 >> Initializing global attention on CLS token...\n",
            " 79% 6550/8340 [1:39:02<24:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:28,260 >> Initializing global attention on CLS token...\n",
            " 79% 6551/8340 [1:39:03<25:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:29,107 >> Initializing global attention on CLS token...\n",
            " 79% 6552/8340 [1:39:04<25:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:29,947 >> Initializing global attention on CLS token...\n",
            " 79% 6553/8340 [1:39:05<25:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:30,780 >> Initializing global attention on CLS token...\n",
            " 79% 6554/8340 [1:39:06<24:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:31,619 >> Initializing global attention on CLS token...\n",
            " 79% 6555/8340 [1:39:06<24:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:32,460 >> Initializing global attention on CLS token...\n",
            " 79% 6556/8340 [1:39:07<24:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:33,297 >> Initializing global attention on CLS token...\n",
            " 79% 6557/8340 [1:39:08<24:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:34,130 >> Initializing global attention on CLS token...\n",
            " 79% 6558/8340 [1:39:09<24:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:34,968 >> Initializing global attention on CLS token...\n",
            " 79% 6559/8340 [1:39:10<24:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:35,800 >> Initializing global attention on CLS token...\n",
            " 79% 6560/8340 [1:39:11<24:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:36,635 >> Initializing global attention on CLS token...\n",
            " 79% 6561/8340 [1:39:11<24:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:37,471 >> Initializing global attention on CLS token...\n",
            " 79% 6562/8340 [1:39:12<24:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:38,312 >> Initializing global attention on CLS token...\n",
            " 79% 6563/8340 [1:39:13<24:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:39,152 >> Initializing global attention on CLS token...\n",
            " 79% 6564/8340 [1:39:14<24:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:39,987 >> Initializing global attention on CLS token...\n",
            " 79% 6565/8340 [1:39:15<24:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:40,823 >> Initializing global attention on CLS token...\n",
            " 79% 6566/8340 [1:39:16<24:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:41,655 >> Initializing global attention on CLS token...\n",
            " 79% 6567/8340 [1:39:16<24:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:42,489 >> Initializing global attention on CLS token...\n",
            " 79% 6568/8340 [1:39:17<24:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:43,325 >> Initializing global attention on CLS token...\n",
            " 79% 6569/8340 [1:39:18<24:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:44,159 >> Initializing global attention on CLS token...\n",
            " 79% 6570/8340 [1:39:19<24:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:44,994 >> Initializing global attention on CLS token...\n",
            " 79% 6571/8340 [1:39:20<24:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:45,829 >> Initializing global attention on CLS token...\n",
            " 79% 6572/8340 [1:39:21<24:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:46,670 >> Initializing global attention on CLS token...\n",
            " 79% 6573/8340 [1:39:21<24:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:47,502 >> Initializing global attention on CLS token...\n",
            " 79% 6574/8340 [1:39:22<24:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:48,342 >> Initializing global attention on CLS token...\n",
            " 79% 6575/8340 [1:39:23<24:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:49,179 >> Initializing global attention on CLS token...\n",
            " 79% 6576/8340 [1:39:24<24:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:50,014 >> Initializing global attention on CLS token...\n",
            " 79% 6577/8340 [1:39:25<24:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:50,853 >> Initializing global attention on CLS token...\n",
            " 79% 6578/8340 [1:39:26<24:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:51,690 >> Initializing global attention on CLS token...\n",
            " 79% 6579/8340 [1:39:26<24:35,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:52,532 >> Initializing global attention on CLS token...\n",
            " 79% 6580/8340 [1:39:27<24:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:53,382 >> Initializing global attention on CLS token...\n",
            " 79% 6581/8340 [1:39:28<24:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:54,218 >> Initializing global attention on CLS token...\n",
            " 79% 6582/8340 [1:39:29<24:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:55,056 >> Initializing global attention on CLS token...\n",
            " 79% 6583/8340 [1:39:30<24:33,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:55,890 >> Initializing global attention on CLS token...\n",
            " 79% 6584/8340 [1:39:31<24:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:56,725 >> Initializing global attention on CLS token...\n",
            " 79% 6585/8340 [1:39:31<24:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:57,560 >> Initializing global attention on CLS token...\n",
            " 79% 6586/8340 [1:39:32<24:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:58,396 >> Initializing global attention on CLS token...\n",
            " 79% 6587/8340 [1:39:33<24:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:42:59,236 >> Initializing global attention on CLS token...\n",
            " 79% 6588/8340 [1:39:34<24:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:00,073 >> Initializing global attention on CLS token...\n",
            " 79% 6589/8340 [1:39:35<24:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:00,910 >> Initializing global attention on CLS token...\n",
            " 79% 6590/8340 [1:39:36<24:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:01,748 >> Initializing global attention on CLS token...\n",
            " 79% 6591/8340 [1:39:36<24:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:02,583 >> Initializing global attention on CLS token...\n",
            " 79% 6592/8340 [1:39:37<24:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:03,424 >> Initializing global attention on CLS token...\n",
            " 79% 6593/8340 [1:39:38<24:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:04,259 >> Initializing global attention on CLS token...\n",
            " 79% 6594/8340 [1:39:39<24:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:05,095 >> Initializing global attention on CLS token...\n",
            " 79% 6595/8340 [1:39:40<24:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:05,930 >> Initializing global attention on CLS token...\n",
            " 79% 6596/8340 [1:39:41<24:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:06,766 >> Initializing global attention on CLS token...\n",
            " 79% 6597/8340 [1:39:41<24:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:07,595 >> Initializing global attention on CLS token...\n",
            " 79% 6598/8340 [1:39:42<24:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:08,416 >> Initializing global attention on CLS token...\n",
            " 79% 6599/8340 [1:39:43<24:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:09,251 >> Initializing global attention on CLS token...\n",
            " 79% 6600/8340 [1:39:44<24:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:10,086 >> Initializing global attention on CLS token...\n",
            " 79% 6601/8340 [1:39:45<24:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:10,920 >> Initializing global attention on CLS token...\n",
            " 79% 6602/8340 [1:39:46<24:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:11,759 >> Initializing global attention on CLS token...\n",
            " 79% 6603/8340 [1:39:46<24:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:12,591 >> Initializing global attention on CLS token...\n",
            " 79% 6604/8340 [1:39:47<24:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:13,427 >> Initializing global attention on CLS token...\n",
            " 79% 6605/8340 [1:39:48<24:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:14,262 >> Initializing global attention on CLS token...\n",
            " 79% 6606/8340 [1:39:49<24:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:15,095 >> Initializing global attention on CLS token...\n",
            " 79% 6607/8340 [1:39:50<24:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:15,925 >> Initializing global attention on CLS token...\n",
            " 79% 6608/8340 [1:39:51<24:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:16,761 >> Initializing global attention on CLS token...\n",
            " 79% 6609/8340 [1:39:51<24:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:17,599 >> Initializing global attention on CLS token...\n",
            " 79% 6610/8340 [1:39:52<24:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:18,432 >> Initializing global attention on CLS token...\n",
            " 79% 6611/8340 [1:39:53<24:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:19,264 >> Initializing global attention on CLS token...\n",
            " 79% 6612/8340 [1:39:54<24:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:20,100 >> Initializing global attention on CLS token...\n",
            " 79% 6613/8340 [1:39:55<24:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:20,935 >> Initializing global attention on CLS token...\n",
            " 79% 6614/8340 [1:39:56<24:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:21,773 >> Initializing global attention on CLS token...\n",
            " 79% 6615/8340 [1:39:56<24:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:22,607 >> Initializing global attention on CLS token...\n",
            " 79% 6616/8340 [1:39:57<23:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:23,443 >> Initializing global attention on CLS token...\n",
            " 79% 6617/8340 [1:39:58<23:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:24,277 >> Initializing global attention on CLS token...\n",
            " 79% 6618/8340 [1:39:59<23:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:25,109 >> Initializing global attention on CLS token...\n",
            " 79% 6619/8340 [1:40:00<23:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:25,944 >> Initializing global attention on CLS token...\n",
            " 79% 6620/8340 [1:40:01<23:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:26,779 >> Initializing global attention on CLS token...\n",
            " 79% 6621/8340 [1:40:01<23:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:27,612 >> Initializing global attention on CLS token...\n",
            " 79% 6622/8340 [1:40:02<23:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:28,447 >> Initializing global attention on CLS token...\n",
            " 79% 6623/8340 [1:40:03<23:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:29,280 >> Initializing global attention on CLS token...\n",
            " 79% 6624/8340 [1:40:04<23:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:30,115 >> Initializing global attention on CLS token...\n",
            " 79% 6625/8340 [1:40:05<23:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:30,956 >> Initializing global attention on CLS token...\n",
            " 79% 6626/8340 [1:40:06<23:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:31,790 >> Initializing global attention on CLS token...\n",
            " 79% 6627/8340 [1:40:07<23:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:32,624 >> Initializing global attention on CLS token...\n",
            " 79% 6628/8340 [1:40:07<23:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:33,462 >> Initializing global attention on CLS token...\n",
            " 79% 6629/8340 [1:40:08<23:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:34,300 >> Initializing global attention on CLS token...\n",
            " 79% 6630/8340 [1:40:09<23:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:35,132 >> Initializing global attention on CLS token...\n",
            " 80% 6631/8340 [1:40:10<23:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:35,968 >> Initializing global attention on CLS token...\n",
            " 80% 6632/8340 [1:40:11<23:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:36,804 >> Initializing global attention on CLS token...\n",
            " 80% 6633/8340 [1:40:12<23:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:37,638 >> Initializing global attention on CLS token...\n",
            " 80% 6634/8340 [1:40:12<23:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:38,472 >> Initializing global attention on CLS token...\n",
            " 80% 6635/8340 [1:40:13<23:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:39,306 >> Initializing global attention on CLS token...\n",
            " 80% 6636/8340 [1:40:14<23:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:40,142 >> Initializing global attention on CLS token...\n",
            " 80% 6637/8340 [1:40:15<23:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:40,983 >> Initializing global attention on CLS token...\n",
            " 80% 6638/8340 [1:40:16<23:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:41,819 >> Initializing global attention on CLS token...\n",
            " 80% 6639/8340 [1:40:17<23:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:42,655 >> Initializing global attention on CLS token...\n",
            " 80% 6640/8340 [1:40:17<23:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:43,491 >> Initializing global attention on CLS token...\n",
            " 80% 6641/8340 [1:40:18<23:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:44,330 >> Initializing global attention on CLS token...\n",
            " 80% 6642/8340 [1:40:19<23:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:45,172 >> Initializing global attention on CLS token...\n",
            " 80% 6643/8340 [1:40:20<23:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:46,010 >> Initializing global attention on CLS token...\n",
            " 80% 6644/8340 [1:40:21<23:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:46,844 >> Initializing global attention on CLS token...\n",
            " 80% 6645/8340 [1:40:22<23:38,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:47,680 >> Initializing global attention on CLS token...\n",
            " 80% 6646/8340 [1:40:22<23:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:48,516 >> Initializing global attention on CLS token...\n",
            " 80% 6647/8340 [1:40:23<23:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:49,350 >> Initializing global attention on CLS token...\n",
            " 80% 6648/8340 [1:40:24<23:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:50,185 >> Initializing global attention on CLS token...\n",
            " 80% 6649/8340 [1:40:25<23:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:51,020 >> Initializing global attention on CLS token...\n",
            " 80% 6650/8340 [1:40:26<23:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:51,854 >> Initializing global attention on CLS token...\n",
            " 80% 6651/8340 [1:40:27<23:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:52,686 >> Initializing global attention on CLS token...\n",
            " 80% 6652/8340 [1:40:27<23:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:53,518 >> Initializing global attention on CLS token...\n",
            " 80% 6653/8340 [1:40:28<23:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:54,352 >> Initializing global attention on CLS token...\n",
            " 80% 6654/8340 [1:40:29<23:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:55,190 >> Initializing global attention on CLS token...\n",
            " 80% 6655/8340 [1:40:30<23:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:56,024 >> Initializing global attention on CLS token...\n",
            " 80% 6656/8340 [1:40:31<23:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:56,866 >> Initializing global attention on CLS token...\n",
            " 80% 6657/8340 [1:40:32<23:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:57,698 >> Initializing global attention on CLS token...\n",
            " 80% 6658/8340 [1:40:32<23:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:58,535 >> Initializing global attention on CLS token...\n",
            " 80% 6659/8340 [1:40:33<23:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:43:59,373 >> Initializing global attention on CLS token...\n",
            " 80% 6660/8340 [1:40:34<23:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:00,206 >> Initializing global attention on CLS token...\n",
            " 80% 6661/8340 [1:40:35<23:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:01,041 >> Initializing global attention on CLS token...\n",
            " 80% 6662/8340 [1:40:36<23:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:01,875 >> Initializing global attention on CLS token...\n",
            " 80% 6663/8340 [1:40:37<23:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:02,714 >> Initializing global attention on CLS token...\n",
            " 80% 6664/8340 [1:40:37<23:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:03,551 >> Initializing global attention on CLS token...\n",
            " 80% 6665/8340 [1:40:38<23:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:04,388 >> Initializing global attention on CLS token...\n",
            " 80% 6666/8340 [1:40:39<23:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:05,229 >> Initializing global attention on CLS token...\n",
            " 80% 6667/8340 [1:40:40<23:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:06,065 >> Initializing global attention on CLS token...\n",
            " 80% 6668/8340 [1:40:41<23:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:06,904 >> Initializing global attention on CLS token...\n",
            " 80% 6669/8340 [1:40:42<23:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:07,737 >> Initializing global attention on CLS token...\n",
            " 80% 6670/8340 [1:40:42<23:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:08,578 >> Initializing global attention on CLS token...\n",
            " 80% 6671/8340 [1:40:43<23:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:44:09,395 >> Initializing global attention on CLS token...\n",
            " 80% 6672/8340 [1:40:44<18:51,  1.47it/s][INFO|trainer.py:725] 2022-12-08 17:44:09,691 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-08 17:44:09,693 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-08 17:44:09,693 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-08 17:44:09,694 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:09,725 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:09,981 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:29,  7.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:10,238 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:41,  5.55it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:10,490 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:47,  4.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:10,742 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:51,  4.48it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:10,995 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:53,  4.29it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:11,258 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:55,  4.13it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:11,513 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:55,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:11,775 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:56,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:12,036 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:56,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:12,286 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:56,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:12,544 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:56,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:12,795 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:56,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:13,049 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:55,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:13,304 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:55,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:13,567 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:55,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:13,822 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:55,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:14,082 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:55,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:14,337 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:55,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:14,591 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:54,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:14,853 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:55,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:15,110 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:54,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:15,368 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:54,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:15,619 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:53,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:15,873 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:53,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:16,123 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:52,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:16,375 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:52,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:16,630 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:52,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:16,885 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:52,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:17,138 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:51,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:17,403 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:52,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:17,658 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:52,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:17,917 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:51,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:18,170 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:51,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:18,429 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:50,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:18,680 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:50,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:18,938 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:50,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:19,191 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:49,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:19,441 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:49,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:19,696 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:49,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:19,949 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:48,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:20,203 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:48,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:20,458 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:48,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:20,717 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:48,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:20,969 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:48,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:21,229 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:48,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:21,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:47,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:21,739 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:12<00:47,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:21,991 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:47,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:22,247 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:46,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:22,508 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:46,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:22,761 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:46,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:23,014 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:46,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:23,267 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:45,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:23,535 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:46,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:23,793 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:45,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:24,050 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:24,304 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:45,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:24,559 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:24,812 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:44,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:25,065 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:25,328 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:44,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:25,581 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:25,834 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:26,083 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:42,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:26,333 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:42,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:26,579 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:41,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:26,830 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:41,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:27,088 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:41,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:27,347 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:41,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:27,599 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:41,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:27,855 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:41,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:28,112 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:41,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:28,366 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:40,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:28,620 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:40,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:28,873 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:40,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:29,131 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:40,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:29,396 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:40,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:29,651 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:39,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:29,920 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:40,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:30,173 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:39,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:30,425 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:38,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:30,677 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:38,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:30,930 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:31,186 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:38,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:31,447 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:37,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:31,714 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:21<00:38,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:31,966 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:32,232 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:37,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:32,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:37,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:32,741 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:23<00:36,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:32,996 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:33,247 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:36,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:33,506 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:35,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:33,774 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:36,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:34,031 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:34,282 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:35,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:34,535 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:34,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:34,787 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:35,062 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:35,321 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:34,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:35,576 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:34,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:35,841 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:34,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:36,095 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:33,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:36,367 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:33,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:36,624 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:33,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:36,888 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:33,  3.81it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:37,156 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:33,  3.79it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:37,422 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:33,  3.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:37,678 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:32,  3.82it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:37,931 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:31,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:38,188 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:31,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:38,443 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:31,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:38,701 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:30,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:38,957 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:30,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:39,211 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:29<00:30,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:39,467 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:29,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:39,719 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:29,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:39,968 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:29,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:40,223 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:30<00:28,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:40,479 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:28,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:40,732 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:31<00:28,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:41,000 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:28,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:41,251 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:31<00:28,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:41,504 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:31<00:27,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:41,755 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:32<00:27,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:42,013 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:42,266 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:32<00:27,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:42,523 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:32<00:26,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:42,776 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:33<00:26,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:43,030 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:26,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:43,286 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:33<00:25,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:43,543 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:33<00:25,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:43,800 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:34<00:25,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:44,052 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:44,317 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:34<00:25,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:44,570 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:34<00:24,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:44,821 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:35<00:24,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:45,074 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:35<00:24,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:45,328 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:35<00:23,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:45,580 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:35<00:23,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:45,835 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:36<00:23,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:46,084 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:36<00:22,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:46,355 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:36<00:23,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:46,604 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:36<00:22,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:46,854 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:47,106 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:37<00:22,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:47,358 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:37<00:21,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:47,612 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:37<00:21,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:47,866 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:48,120 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:38<00:21,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:48,378 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:38<00:20,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:48,633 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:38<00:20,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:48,884 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:20,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:49,142 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:39<00:20,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:49,397 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:39<00:19,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:49,651 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:39<00:19,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:49,904 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:19,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:50,167 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:40<00:19,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:50,422 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:40<00:18,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:50,674 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:40<00:18,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:50,928 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:51,180 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:41<00:18,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:51,433 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:41<00:17,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:51,694 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:41<00:17,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:51,943 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:52,195 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:42<00:17,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:52,448 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:42<00:16,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:52,704 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:42<00:16,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:52,956 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:43<00:16,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:53,209 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:43<00:15,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:53,461 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:43<00:15,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:53,712 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:43<00:15,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:53,962 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:44<00:15,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:54,215 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:44<00:14,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:54,465 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:44<00:14,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:54,717 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:44<00:14,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:54,968 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:45<00:14,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:55,218 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:45<00:13,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:55,474 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:45<00:13,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:55,727 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:46<00:13,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:55,981 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:46<00:13,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:56,235 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:46<00:12,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:56,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:46<00:12,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:56,740 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:47<00:12,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:56,992 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:47<00:12,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:57,245 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:47<00:11,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:57,497 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:47<00:11,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:57,751 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:48<00:11,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:58,003 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:48<00:11,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:58,257 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:48<00:10,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:58,506 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:48<00:10,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:58,764 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:49<00:10,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:59,016 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:49<00:10,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:59,269 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:49<00:09,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:59,525 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:49<00:09,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:44:59,788 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:50<00:09,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:00,044 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:50<00:09,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:00,297 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:50<00:08,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:00,551 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:50<00:08,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:00,803 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:51<00:08,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:01,059 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:51<00:08,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:01,314 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:51<00:07,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:01,569 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:51<00:07,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:01,822 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:52<00:07,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:02,078 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:52<00:07,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:02,330 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:52<00:06,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:02,584 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:52<00:06,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:02,832 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:53<00:06,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:03,080 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:53<00:06,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:03,330 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:53<00:05,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:03,586 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:53<00:05,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:03,837 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:54<00:05,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:04,090 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:54<00:05,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:04,338 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:54<00:04,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:04,592 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:54<00:04,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:04,842 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:55<00:04,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:05,095 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:55<00:04,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:05,349 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:55<00:03,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:05,601 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:55<00:03,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:05,852 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:56<00:03,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:06,110 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:56<00:03,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:06,364 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:56<00:02,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:06,625 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:56<00:02,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:06,877 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:57<00:02,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:07,130 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:57<00:02,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:07,385 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:57<00:01,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:07,636 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:57<00:01,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:07,893 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:58<00:01,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:08,150 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:58<00:01,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:08,410 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:58<00:00,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:08,666 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:58<00:00,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:08,921 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:59<00:00,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:09,155 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.6395901441574097, 'eval_f1-micro': 0.765, 'eval_f1-macro': 0.6824200514101282, 'eval_runtime': 60.9012, 'eval_samples_per_second': 22.988, 'eval_steps_per_second': 3.842, 'epoch': 8.0}\n",
            " 80% 6672/8340 [1:41:45<18:51,  1.47it/s]\n",
            "100% 234/234 [01:00<00:00,  3.90it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-08 17:45:10,597 >> Saving model checkpoint to logs/output_1/checkpoint-6672\n",
            "[INFO|configuration_utils.py:447] 2022-12-08 17:45:10,598 >> Configuration saved in logs/output_1/checkpoint-6672/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-08 17:45:10,827 >> Model weights saved in logs/output_1/checkpoint-6672/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-08 17:45:10,828 >> tokenizer config file saved in logs/output_1/checkpoint-6672/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-08 17:45:10,828 >> Special tokens file saved in logs/output_1/checkpoint-6672/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:45:11,390 >> Initializing global attention on CLS token...\n",
            " 80% 6673/8340 [1:41:46<8:54:42, 19.25s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:12,293 >> Initializing global attention on CLS token...\n",
            " 80% 6674/8340 [1:41:47<6:21:01, 13.72s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:13,126 >> Initializing global attention on CLS token...\n",
            " 80% 6675/8340 [1:41:48<4:33:30,  9.86s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:13,961 >> Initializing global attention on CLS token...\n",
            " 80% 6676/8340 [1:41:49<3:18:16,  7.15s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:14,796 >> Initializing global attention on CLS token...\n",
            " 80% 6677/8340 [1:41:50<2:25:42,  5.26s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:15,636 >> Initializing global attention on CLS token...\n",
            " 80% 6678/8340 [1:41:50<1:48:53,  3.93s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:16,471 >> Initializing global attention on CLS token...\n",
            " 80% 6679/8340 [1:41:51<1:23:05,  3.00s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:17,305 >> Initializing global attention on CLS token...\n",
            " 80% 6680/8340 [1:41:52<1:05:02,  2.35s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:18,138 >> Initializing global attention on CLS token...\n",
            " 80% 6681/8340 [1:41:53<52:23,  1.89s/it]  [INFO|modeling_longformer.py:1932] 2022-12-08 17:45:18,968 >> Initializing global attention on CLS token...\n",
            " 80% 6682/8340 [1:41:54<43:35,  1.58s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:19,806 >> Initializing global attention on CLS token...\n",
            " 80% 6683/8340 [1:41:55<37:24,  1.35s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:20,641 >> Initializing global attention on CLS token...\n",
            " 80% 6684/8340 [1:41:55<33:06,  1.20s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:21,478 >> Initializing global attention on CLS token...\n",
            " 80% 6685/8340 [1:41:56<30:02,  1.09s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:22,313 >> Initializing global attention on CLS token...\n",
            " 80% 6686/8340 [1:41:57<27:56,  1.01s/it][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:23,147 >> Initializing global attention on CLS token...\n",
            " 80% 6687/8340 [1:41:58<26:24,  1.04it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:23,978 >> Initializing global attention on CLS token...\n",
            " 80% 6688/8340 [1:41:59<25:21,  1.09it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:24,811 >> Initializing global attention on CLS token...\n",
            " 80% 6689/8340 [1:42:00<24:38,  1.12it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:25,651 >> Initializing global attention on CLS token...\n",
            " 80% 6690/8340 [1:42:00<24:10,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:26,495 >> Initializing global attention on CLS token...\n",
            " 80% 6691/8340 [1:42:01<23:53,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:27,337 >> Initializing global attention on CLS token...\n",
            " 80% 6692/8340 [1:42:02<23:39,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:28,179 >> Initializing global attention on CLS token...\n",
            " 80% 6693/8340 [1:42:03<23:27,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:29,017 >> Initializing global attention on CLS token...\n",
            " 80% 6694/8340 [1:42:04<23:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:29,855 >> Initializing global attention on CLS token...\n",
            " 80% 6695/8340 [1:42:05<23:10,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:30,688 >> Initializing global attention on CLS token...\n",
            " 80% 6696/8340 [1:42:05<23:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:31,521 >> Initializing global attention on CLS token...\n",
            " 80% 6697/8340 [1:42:06<22:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:32,355 >> Initializing global attention on CLS token...\n",
            " 80% 6698/8340 [1:42:07<22:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:33,189 >> Initializing global attention on CLS token...\n",
            " 80% 6699/8340 [1:42:08<22:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:34,025 >> Initializing global attention on CLS token...\n",
            " 80% 6700/8340 [1:42:09<22:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:34,857 >> Initializing global attention on CLS token...\n",
            " 80% 6701/8340 [1:42:10<22:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:35,692 >> Initializing global attention on CLS token...\n",
            " 80% 6702/8340 [1:42:10<22:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:36,528 >> Initializing global attention on CLS token...\n",
            " 80% 6703/8340 [1:42:11<22:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:37,366 >> Initializing global attention on CLS token...\n",
            " 80% 6704/8340 [1:42:12<22:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:38,204 >> Initializing global attention on CLS token...\n",
            " 80% 6705/8340 [1:42:13<22:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:39,045 >> Initializing global attention on CLS token...\n",
            " 80% 6706/8340 [1:42:14<22:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:39,880 >> Initializing global attention on CLS token...\n",
            " 80% 6707/8340 [1:42:15<22:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:40,715 >> Initializing global attention on CLS token...\n",
            " 80% 6708/8340 [1:42:15<22:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:41,550 >> Initializing global attention on CLS token...\n",
            " 80% 6709/8340 [1:42:16<22:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:42,387 >> Initializing global attention on CLS token...\n",
            " 80% 6710/8340 [1:42:17<22:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:43,222 >> Initializing global attention on CLS token...\n",
            " 80% 6711/8340 [1:42:18<22:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:44,064 >> Initializing global attention on CLS token...\n",
            " 80% 6712/8340 [1:42:19<22:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:44,898 >> Initializing global attention on CLS token...\n",
            " 80% 6713/8340 [1:42:20<22:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:45,733 >> Initializing global attention on CLS token...\n",
            " 81% 6714/8340 [1:42:20<22:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:46,567 >> Initializing global attention on CLS token...\n",
            " 81% 6715/8340 [1:42:21<22:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:47,402 >> Initializing global attention on CLS token...\n",
            " 81% 6716/8340 [1:42:22<22:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:48,232 >> Initializing global attention on CLS token...\n",
            " 81% 6717/8340 [1:42:23<22:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:49,067 >> Initializing global attention on CLS token...\n",
            " 81% 6718/8340 [1:42:24<22:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:49,902 >> Initializing global attention on CLS token...\n",
            " 81% 6719/8340 [1:42:25<22:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:50,738 >> Initializing global attention on CLS token...\n",
            " 81% 6720/8340 [1:42:25<22:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:51,572 >> Initializing global attention on CLS token...\n",
            " 81% 6721/8340 [1:42:26<22:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:52,409 >> Initializing global attention on CLS token...\n",
            " 81% 6722/8340 [1:42:27<22:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:53,244 >> Initializing global attention on CLS token...\n",
            " 81% 6723/8340 [1:42:28<22:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:54,078 >> Initializing global attention on CLS token...\n",
            " 81% 6724/8340 [1:42:29<22:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:54,914 >> Initializing global attention on CLS token...\n",
            " 81% 6725/8340 [1:42:30<22:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:55,751 >> Initializing global attention on CLS token...\n",
            " 81% 6726/8340 [1:42:30<22:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:56,584 >> Initializing global attention on CLS token...\n",
            " 81% 6727/8340 [1:42:31<22:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:57,425 >> Initializing global attention on CLS token...\n",
            " 81% 6728/8340 [1:42:32<22:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:58,264 >> Initializing global attention on CLS token...\n",
            " 81% 6729/8340 [1:42:33<22:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:59,102 >> Initializing global attention on CLS token...\n",
            " 81% 6730/8340 [1:42:34<22:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:45:59,937 >> Initializing global attention on CLS token...\n",
            " 81% 6731/8340 [1:42:35<22:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:00,774 >> Initializing global attention on CLS token...\n",
            " 81% 6732/8340 [1:42:35<22:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:01,612 >> Initializing global attention on CLS token...\n",
            " 81% 6733/8340 [1:42:36<22:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:02,452 >> Initializing global attention on CLS token...\n",
            " 81% 6734/8340 [1:42:37<22:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:03,288 >> Initializing global attention on CLS token...\n",
            " 81% 6735/8340 [1:42:38<22:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:04,120 >> Initializing global attention on CLS token...\n",
            " 81% 6736/8340 [1:42:39<22:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:04,955 >> Initializing global attention on CLS token...\n",
            " 81% 6737/8340 [1:42:40<22:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:05,792 >> Initializing global attention on CLS token...\n",
            " 81% 6738/8340 [1:42:41<22:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:06,623 >> Initializing global attention on CLS token...\n",
            " 81% 6739/8340 [1:42:41<22:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:07,458 >> Initializing global attention on CLS token...\n",
            " 81% 6740/8340 [1:42:42<22:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:08,288 >> Initializing global attention on CLS token...\n",
            " 81% 6741/8340 [1:42:43<22:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:09,124 >> Initializing global attention on CLS token...\n",
            " 81% 6742/8340 [1:42:44<22:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:09,963 >> Initializing global attention on CLS token...\n",
            " 81% 6743/8340 [1:42:45<22:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:10,799 >> Initializing global attention on CLS token...\n",
            " 81% 6744/8340 [1:42:46<22:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:11,634 >> Initializing global attention on CLS token...\n",
            " 81% 6745/8340 [1:42:46<22:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:12,467 >> Initializing global attention on CLS token...\n",
            " 81% 6746/8340 [1:42:47<22:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:13,306 >> Initializing global attention on CLS token...\n",
            " 81% 6747/8340 [1:42:48<22:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:14,135 >> Initializing global attention on CLS token...\n",
            " 81% 6748/8340 [1:42:49<22:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:14,971 >> Initializing global attention on CLS token...\n",
            " 81% 6749/8340 [1:42:50<22:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:15,807 >> Initializing global attention on CLS token...\n",
            " 81% 6750/8340 [1:42:51<22:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:16,646 >> Initializing global attention on CLS token...\n",
            " 81% 6751/8340 [1:42:51<22:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:17,487 >> Initializing global attention on CLS token...\n",
            " 81% 6752/8340 [1:42:52<22:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:18,331 >> Initializing global attention on CLS token...\n",
            " 81% 6753/8340 [1:42:53<22:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:19,163 >> Initializing global attention on CLS token...\n",
            " 81% 6754/8340 [1:42:54<22:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:19,997 >> Initializing global attention on CLS token...\n",
            " 81% 6755/8340 [1:42:55<22:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:20,830 >> Initializing global attention on CLS token...\n",
            " 81% 6756/8340 [1:42:56<22:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:21,664 >> Initializing global attention on CLS token...\n",
            " 81% 6757/8340 [1:42:56<21:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:22,495 >> Initializing global attention on CLS token...\n",
            " 81% 6758/8340 [1:42:57<21:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:23,327 >> Initializing global attention on CLS token...\n",
            " 81% 6759/8340 [1:42:58<21:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:24,160 >> Initializing global attention on CLS token...\n",
            " 81% 6760/8340 [1:42:59<21:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:24,996 >> Initializing global attention on CLS token...\n",
            " 81% 6761/8340 [1:43:00<21:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:25,836 >> Initializing global attention on CLS token...\n",
            " 81% 6762/8340 [1:43:01<22:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:26,674 >> Initializing global attention on CLS token...\n",
            " 81% 6763/8340 [1:43:01<22:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:27,513 >> Initializing global attention on CLS token...\n",
            " 81% 6764/8340 [1:43:02<21:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:28,346 >> Initializing global attention on CLS token...\n",
            " 81% 6765/8340 [1:43:03<21:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:29,181 >> Initializing global attention on CLS token...\n",
            " 81% 6766/8340 [1:43:04<21:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:30,021 >> Initializing global attention on CLS token...\n",
            " 81% 6767/8340 [1:43:05<21:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:30,861 >> Initializing global attention on CLS token...\n",
            " 81% 6768/8340 [1:43:06<21:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:31,700 >> Initializing global attention on CLS token...\n",
            " 81% 6769/8340 [1:43:06<21:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:32,541 >> Initializing global attention on CLS token...\n",
            " 81% 6770/8340 [1:43:07<21:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:33,374 >> Initializing global attention on CLS token...\n",
            " 81% 6771/8340 [1:43:08<21:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:34,204 >> Initializing global attention on CLS token...\n",
            " 81% 6772/8340 [1:43:09<21:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:35,039 >> Initializing global attention on CLS token...\n",
            " 81% 6773/8340 [1:43:10<21:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:35,873 >> Initializing global attention on CLS token...\n",
            " 81% 6774/8340 [1:43:11<21:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:36,711 >> Initializing global attention on CLS token...\n",
            " 81% 6775/8340 [1:43:11<21:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:37,548 >> Initializing global attention on CLS token...\n",
            " 81% 6776/8340 [1:43:12<21:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:38,379 >> Initializing global attention on CLS token...\n",
            " 81% 6777/8340 [1:43:13<21:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:39,212 >> Initializing global attention on CLS token...\n",
            " 81% 6778/8340 [1:43:14<21:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:40,051 >> Initializing global attention on CLS token...\n",
            " 81% 6779/8340 [1:43:15<21:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:40,884 >> Initializing global attention on CLS token...\n",
            " 81% 6780/8340 [1:43:16<21:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:41,719 >> Initializing global attention on CLS token...\n",
            " 81% 6781/8340 [1:43:16<21:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:42,555 >> Initializing global attention on CLS token...\n",
            " 81% 6782/8340 [1:43:17<21:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:43,390 >> Initializing global attention on CLS token...\n",
            " 81% 6783/8340 [1:43:18<21:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:44,227 >> Initializing global attention on CLS token...\n",
            " 81% 6784/8340 [1:43:19<21:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:45,063 >> Initializing global attention on CLS token...\n",
            " 81% 6785/8340 [1:43:20<21:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:45,898 >> Initializing global attention on CLS token...\n",
            " 81% 6786/8340 [1:43:21<21:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:46,730 >> Initializing global attention on CLS token...\n",
            " 81% 6787/8340 [1:43:21<21:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:47,562 >> Initializing global attention on CLS token...\n",
            " 81% 6788/8340 [1:43:22<21:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:48,399 >> Initializing global attention on CLS token...\n",
            " 81% 6789/8340 [1:43:23<21:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:49,235 >> Initializing global attention on CLS token...\n",
            " 81% 6790/8340 [1:43:24<21:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:50,071 >> Initializing global attention on CLS token...\n",
            " 81% 6791/8340 [1:43:25<21:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:50,909 >> Initializing global attention on CLS token...\n",
            " 81% 6792/8340 [1:43:26<21:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:51,744 >> Initializing global attention on CLS token...\n",
            " 81% 6793/8340 [1:43:26<21:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:52,577 >> Initializing global attention on CLS token...\n",
            " 81% 6794/8340 [1:43:27<21:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:53,408 >> Initializing global attention on CLS token...\n",
            " 81% 6795/8340 [1:43:28<21:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:54,237 >> Initializing global attention on CLS token...\n",
            " 81% 6796/8340 [1:43:29<21:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:55,067 >> Initializing global attention on CLS token...\n",
            " 81% 6797/8340 [1:43:30<21:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:55,905 >> Initializing global attention on CLS token...\n",
            " 82% 6798/8340 [1:43:31<21:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:56,740 >> Initializing global attention on CLS token...\n",
            " 82% 6799/8340 [1:43:31<21:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:57,578 >> Initializing global attention on CLS token...\n",
            " 82% 6800/8340 [1:43:32<21:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:58,412 >> Initializing global attention on CLS token...\n",
            " 82% 6801/8340 [1:43:33<21:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:46:59,245 >> Initializing global attention on CLS token...\n",
            " 82% 6802/8340 [1:43:34<21:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:00,078 >> Initializing global attention on CLS token...\n",
            " 82% 6803/8340 [1:43:35<21:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:00,910 >> Initializing global attention on CLS token...\n",
            " 82% 6804/8340 [1:43:36<21:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:01,746 >> Initializing global attention on CLS token...\n",
            " 82% 6805/8340 [1:43:36<21:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:02,579 >> Initializing global attention on CLS token...\n",
            " 82% 6806/8340 [1:43:37<21:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:03,412 >> Initializing global attention on CLS token...\n",
            " 82% 6807/8340 [1:43:38<21:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:04,251 >> Initializing global attention on CLS token...\n",
            " 82% 6808/8340 [1:43:39<21:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:05,085 >> Initializing global attention on CLS token...\n",
            " 82% 6809/8340 [1:43:40<21:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:05,923 >> Initializing global attention on CLS token...\n",
            " 82% 6810/8340 [1:43:41<21:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:06,763 >> Initializing global attention on CLS token...\n",
            " 82% 6811/8340 [1:43:41<21:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:07,600 >> Initializing global attention on CLS token...\n",
            " 82% 6812/8340 [1:43:42<21:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:08,434 >> Initializing global attention on CLS token...\n",
            " 82% 6813/8340 [1:43:43<21:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:09,274 >> Initializing global attention on CLS token...\n",
            " 82% 6814/8340 [1:43:44<21:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:10,113 >> Initializing global attention on CLS token...\n",
            " 82% 6815/8340 [1:43:45<21:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:10,944 >> Initializing global attention on CLS token...\n",
            " 82% 6816/8340 [1:43:46<21:15,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:11,782 >> Initializing global attention on CLS token...\n",
            " 82% 6817/8340 [1:43:46<21:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:12,615 >> Initializing global attention on CLS token...\n",
            " 82% 6818/8340 [1:43:47<21:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:13,455 >> Initializing global attention on CLS token...\n",
            " 82% 6819/8340 [1:43:48<21:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:14,288 >> Initializing global attention on CLS token...\n",
            " 82% 6820/8340 [1:43:49<21:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:15,123 >> Initializing global attention on CLS token...\n",
            " 82% 6821/8340 [1:43:50<21:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:15,958 >> Initializing global attention on CLS token...\n",
            " 82% 6822/8340 [1:43:51<21:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:16,791 >> Initializing global attention on CLS token...\n",
            " 82% 6823/8340 [1:43:52<21:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:17,628 >> Initializing global attention on CLS token...\n",
            " 82% 6824/8340 [1:43:52<21:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:18,461 >> Initializing global attention on CLS token...\n",
            " 82% 6825/8340 [1:43:53<21:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:19,296 >> Initializing global attention on CLS token...\n",
            " 82% 6826/8340 [1:43:54<21:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:20,133 >> Initializing global attention on CLS token...\n",
            " 82% 6827/8340 [1:43:55<21:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:20,968 >> Initializing global attention on CLS token...\n",
            " 82% 6828/8340 [1:43:56<21:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:21,810 >> Initializing global attention on CLS token...\n",
            " 82% 6829/8340 [1:43:57<21:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:22,645 >> Initializing global attention on CLS token...\n",
            " 82% 6830/8340 [1:43:57<21:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:23,481 >> Initializing global attention on CLS token...\n",
            " 82% 6831/8340 [1:43:58<21:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:24,315 >> Initializing global attention on CLS token...\n",
            " 82% 6832/8340 [1:43:59<21:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:25,152 >> Initializing global attention on CLS token...\n",
            " 82% 6833/8340 [1:44:00<20:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:25,985 >> Initializing global attention on CLS token...\n",
            " 82% 6834/8340 [1:44:01<20:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:26,819 >> Initializing global attention on CLS token...\n",
            " 82% 6835/8340 [1:44:02<20:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:27,654 >> Initializing global attention on CLS token...\n",
            " 82% 6836/8340 [1:44:02<20:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:28,494 >> Initializing global attention on CLS token...\n",
            " 82% 6837/8340 [1:44:03<20:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:29,328 >> Initializing global attention on CLS token...\n",
            " 82% 6838/8340 [1:44:04<20:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:30,167 >> Initializing global attention on CLS token...\n",
            " 82% 6839/8340 [1:44:05<20:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:31,001 >> Initializing global attention on CLS token...\n",
            " 82% 6840/8340 [1:44:06<20:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:31,839 >> Initializing global attention on CLS token...\n",
            " 82% 6841/8340 [1:44:07<20:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:32,675 >> Initializing global attention on CLS token...\n",
            " 82% 6842/8340 [1:44:07<20:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:33,508 >> Initializing global attention on CLS token...\n",
            " 82% 6843/8340 [1:44:08<20:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:34,341 >> Initializing global attention on CLS token...\n",
            " 82% 6844/8340 [1:44:09<20:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:35,176 >> Initializing global attention on CLS token...\n",
            " 82% 6845/8340 [1:44:10<20:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:36,014 >> Initializing global attention on CLS token...\n",
            " 82% 6846/8340 [1:44:11<20:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:36,844 >> Initializing global attention on CLS token...\n",
            " 82% 6847/8340 [1:44:12<20:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:37,680 >> Initializing global attention on CLS token...\n",
            " 82% 6848/8340 [1:44:12<20:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:38,514 >> Initializing global attention on CLS token...\n",
            " 82% 6849/8340 [1:44:13<20:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:39,351 >> Initializing global attention on CLS token...\n",
            " 82% 6850/8340 [1:44:14<20:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:40,188 >> Initializing global attention on CLS token...\n",
            " 82% 6851/8340 [1:44:15<20:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:41,023 >> Initializing global attention on CLS token...\n",
            " 82% 6852/8340 [1:44:16<20:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:41,858 >> Initializing global attention on CLS token...\n",
            " 82% 6853/8340 [1:44:17<20:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:42,693 >> Initializing global attention on CLS token...\n",
            " 82% 6854/8340 [1:44:17<20:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:43,529 >> Initializing global attention on CLS token...\n",
            " 82% 6855/8340 [1:44:18<20:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:44,361 >> Initializing global attention on CLS token...\n",
            " 82% 6856/8340 [1:44:19<20:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:45,197 >> Initializing global attention on CLS token...\n",
            " 82% 6857/8340 [1:44:20<20:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:46,032 >> Initializing global attention on CLS token...\n",
            " 82% 6858/8340 [1:44:21<20:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:46,870 >> Initializing global attention on CLS token...\n",
            " 82% 6859/8340 [1:44:22<20:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:47,705 >> Initializing global attention on CLS token...\n",
            " 82% 6860/8340 [1:44:22<20:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:48,546 >> Initializing global attention on CLS token...\n",
            " 82% 6861/8340 [1:44:23<20:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:49,380 >> Initializing global attention on CLS token...\n",
            " 82% 6862/8340 [1:44:24<20:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:50,212 >> Initializing global attention on CLS token...\n",
            " 82% 6863/8340 [1:44:25<20:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:51,045 >> Initializing global attention on CLS token...\n",
            " 82% 6864/8340 [1:44:26<20:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:51,880 >> Initializing global attention on CLS token...\n",
            " 82% 6865/8340 [1:44:27<20:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:52,717 >> Initializing global attention on CLS token...\n",
            " 82% 6866/8340 [1:44:27<20:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:53,552 >> Initializing global attention on CLS token...\n",
            " 82% 6867/8340 [1:44:28<20:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:54,386 >> Initializing global attention on CLS token...\n",
            " 82% 6868/8340 [1:44:29<20:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:55,221 >> Initializing global attention on CLS token...\n",
            " 82% 6869/8340 [1:44:30<20:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:56,055 >> Initializing global attention on CLS token...\n",
            " 82% 6870/8340 [1:44:31<20:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:56,919 >> Initializing global attention on CLS token...\n",
            " 82% 6871/8340 [1:44:32<20:46,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:57,798 >> Initializing global attention on CLS token...\n",
            " 82% 6872/8340 [1:44:33<20:54,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:58,668 >> Initializing global attention on CLS token...\n",
            " 82% 6873/8340 [1:44:33<21:00,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:47:59,535 >> Initializing global attention on CLS token...\n",
            " 82% 6874/8340 [1:44:34<21:04,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:00,398 >> Initializing global attention on CLS token...\n",
            " 82% 6875/8340 [1:44:35<21:05,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:01,265 >> Initializing global attention on CLS token...\n",
            " 82% 6876/8340 [1:44:36<21:01,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:02,113 >> Initializing global attention on CLS token...\n",
            " 82% 6877/8340 [1:44:37<20:53,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:02,949 >> Initializing global attention on CLS token...\n",
            " 82% 6878/8340 [1:44:38<20:43,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:03,786 >> Initializing global attention on CLS token...\n",
            " 82% 6879/8340 [1:44:39<20:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:04,622 >> Initializing global attention on CLS token...\n",
            " 82% 6880/8340 [1:44:39<20:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:05,455 >> Initializing global attention on CLS token...\n",
            " 83% 6881/8340 [1:44:40<20:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:06,289 >> Initializing global attention on CLS token...\n",
            " 83% 6882/8340 [1:44:41<20:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:07,123 >> Initializing global attention on CLS token...\n",
            " 83% 6883/8340 [1:44:42<20:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:07,956 >> Initializing global attention on CLS token...\n",
            " 83% 6884/8340 [1:44:43<20:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:08,790 >> Initializing global attention on CLS token...\n",
            " 83% 6885/8340 [1:44:44<20:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:09,623 >> Initializing global attention on CLS token...\n",
            " 83% 6886/8340 [1:44:44<20:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:10,456 >> Initializing global attention on CLS token...\n",
            " 83% 6887/8340 [1:44:45<20:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:11,291 >> Initializing global attention on CLS token...\n",
            " 83% 6888/8340 [1:44:46<20:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:12,124 >> Initializing global attention on CLS token...\n",
            " 83% 6889/8340 [1:44:47<20:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:12,958 >> Initializing global attention on CLS token...\n",
            " 83% 6890/8340 [1:44:48<20:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:13,793 >> Initializing global attention on CLS token...\n",
            " 83% 6891/8340 [1:44:49<20:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:14,628 >> Initializing global attention on CLS token...\n",
            " 83% 6892/8340 [1:44:49<20:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:15,460 >> Initializing global attention on CLS token...\n",
            " 83% 6893/8340 [1:44:50<20:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:16,295 >> Initializing global attention on CLS token...\n",
            " 83% 6894/8340 [1:44:51<20:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:17,127 >> Initializing global attention on CLS token...\n",
            " 83% 6895/8340 [1:44:52<20:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:17,962 >> Initializing global attention on CLS token...\n",
            " 83% 6896/8340 [1:44:53<20:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:18,797 >> Initializing global attention on CLS token...\n",
            " 83% 6897/8340 [1:44:54<20:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:19,629 >> Initializing global attention on CLS token...\n",
            " 83% 6898/8340 [1:44:54<20:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:20,464 >> Initializing global attention on CLS token...\n",
            " 83% 6899/8340 [1:44:55<20:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:21,300 >> Initializing global attention on CLS token...\n",
            " 83% 6900/8340 [1:44:56<20:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:22,134 >> Initializing global attention on CLS token...\n",
            " 83% 6901/8340 [1:44:57<20:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:22,972 >> Initializing global attention on CLS token...\n",
            " 83% 6902/8340 [1:44:58<20:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:23,811 >> Initializing global attention on CLS token...\n",
            " 83% 6903/8340 [1:44:59<19:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:24,642 >> Initializing global attention on CLS token...\n",
            " 83% 6904/8340 [1:44:59<19:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:25,478 >> Initializing global attention on CLS token...\n",
            " 83% 6905/8340 [1:45:00<19:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:26,312 >> Initializing global attention on CLS token...\n",
            " 83% 6906/8340 [1:45:01<19:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:27,146 >> Initializing global attention on CLS token...\n",
            " 83% 6907/8340 [1:45:02<19:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:27,978 >> Initializing global attention on CLS token...\n",
            " 83% 6908/8340 [1:45:03<19:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:28,817 >> Initializing global attention on CLS token...\n",
            " 83% 6909/8340 [1:45:04<19:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:29,646 >> Initializing global attention on CLS token...\n",
            " 83% 6910/8340 [1:45:04<19:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:30,478 >> Initializing global attention on CLS token...\n",
            " 83% 6911/8340 [1:45:05<19:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:31,308 >> Initializing global attention on CLS token...\n",
            " 83% 6912/8340 [1:45:06<19:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:32,147 >> Initializing global attention on CLS token...\n",
            " 83% 6913/8340 [1:45:07<19:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:32,986 >> Initializing global attention on CLS token...\n",
            " 83% 6914/8340 [1:45:08<19:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:33,817 >> Initializing global attention on CLS token...\n",
            " 83% 6915/8340 [1:45:09<19:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:34,650 >> Initializing global attention on CLS token...\n",
            " 83% 6916/8340 [1:45:09<19:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:35,484 >> Initializing global attention on CLS token...\n",
            " 83% 6917/8340 [1:45:10<19:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:36,315 >> Initializing global attention on CLS token...\n",
            " 83% 6918/8340 [1:45:11<19:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:37,146 >> Initializing global attention on CLS token...\n",
            " 83% 6919/8340 [1:45:12<19:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:37,982 >> Initializing global attention on CLS token...\n",
            " 83% 6920/8340 [1:45:13<19:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:38,819 >> Initializing global attention on CLS token...\n",
            " 83% 6921/8340 [1:45:14<19:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:39,657 >> Initializing global attention on CLS token...\n",
            " 83% 6922/8340 [1:45:14<19:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:40,495 >> Initializing global attention on CLS token...\n",
            " 83% 6923/8340 [1:45:15<19:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:41,338 >> Initializing global attention on CLS token...\n",
            " 83% 6924/8340 [1:45:16<19:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:42,172 >> Initializing global attention on CLS token...\n",
            " 83% 6925/8340 [1:45:17<19:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:43,008 >> Initializing global attention on CLS token...\n",
            " 83% 6926/8340 [1:45:18<19:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:43,840 >> Initializing global attention on CLS token...\n",
            " 83% 6927/8340 [1:45:19<19:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:44,670 >> Initializing global attention on CLS token...\n",
            " 83% 6928/8340 [1:45:19<19:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:45,504 >> Initializing global attention on CLS token...\n",
            " 83% 6929/8340 [1:45:20<19:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:46,342 >> Initializing global attention on CLS token...\n",
            " 83% 6930/8340 [1:45:21<19:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:47,174 >> Initializing global attention on CLS token...\n",
            " 83% 6931/8340 [1:45:22<19:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:48,007 >> Initializing global attention on CLS token...\n",
            " 83% 6932/8340 [1:45:23<19:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:48,838 >> Initializing global attention on CLS token...\n",
            " 83% 6933/8340 [1:45:24<19:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:49,676 >> Initializing global attention on CLS token...\n",
            " 83% 6934/8340 [1:45:24<19:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:50,513 >> Initializing global attention on CLS token...\n",
            " 83% 6935/8340 [1:45:25<19:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:51,348 >> Initializing global attention on CLS token...\n",
            " 83% 6936/8340 [1:45:26<19:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:52,182 >> Initializing global attention on CLS token...\n",
            " 83% 6937/8340 [1:45:27<19:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:53,017 >> Initializing global attention on CLS token...\n",
            " 83% 6938/8340 [1:45:28<19:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:53,853 >> Initializing global attention on CLS token...\n",
            " 83% 6939/8340 [1:45:29<19:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:54,692 >> Initializing global attention on CLS token...\n",
            " 83% 6940/8340 [1:45:29<19:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:55,529 >> Initializing global attention on CLS token...\n",
            " 83% 6941/8340 [1:45:30<19:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:56,363 >> Initializing global attention on CLS token...\n",
            " 83% 6942/8340 [1:45:31<19:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:57,205 >> Initializing global attention on CLS token...\n",
            " 83% 6943/8340 [1:45:32<19:29,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:58,040 >> Initializing global attention on CLS token...\n",
            " 83% 6944/8340 [1:45:33<19:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:58,876 >> Initializing global attention on CLS token...\n",
            " 83% 6945/8340 [1:45:34<19:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:48:59,712 >> Initializing global attention on CLS token...\n",
            " 83% 6946/8340 [1:45:34<19:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:00,552 >> Initializing global attention on CLS token...\n",
            " 83% 6947/8340 [1:45:35<19:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:01,386 >> Initializing global attention on CLS token...\n",
            " 83% 6948/8340 [1:45:36<19:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:02,219 >> Initializing global attention on CLS token...\n",
            " 83% 6949/8340 [1:45:37<19:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:03,058 >> Initializing global attention on CLS token...\n",
            " 83% 6950/8340 [1:45:38<19:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:03,895 >> Initializing global attention on CLS token...\n",
            " 83% 6951/8340 [1:45:39<19:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:04,730 >> Initializing global attention on CLS token...\n",
            " 83% 6952/8340 [1:45:39<19:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:05,565 >> Initializing global attention on CLS token...\n",
            " 83% 6953/8340 [1:45:40<19:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:06,399 >> Initializing global attention on CLS token...\n",
            " 83% 6954/8340 [1:45:41<19:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:07,233 >> Initializing global attention on CLS token...\n",
            " 83% 6955/8340 [1:45:42<19:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:08,069 >> Initializing global attention on CLS token...\n",
            " 83% 6956/8340 [1:45:43<19:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:08,905 >> Initializing global attention on CLS token...\n",
            " 83% 6957/8340 [1:45:44<19:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:09,740 >> Initializing global attention on CLS token...\n",
            " 83% 6958/8340 [1:45:44<19:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:10,575 >> Initializing global attention on CLS token...\n",
            " 83% 6959/8340 [1:45:45<19:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:11,414 >> Initializing global attention on CLS token...\n",
            " 83% 6960/8340 [1:45:46<19:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:12,250 >> Initializing global attention on CLS token...\n",
            " 83% 6961/8340 [1:45:47<19:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:13,086 >> Initializing global attention on CLS token...\n",
            " 83% 6962/8340 [1:45:48<19:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:13,922 >> Initializing global attention on CLS token...\n",
            " 83% 6963/8340 [1:45:49<19:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:14,756 >> Initializing global attention on CLS token...\n",
            " 84% 6964/8340 [1:45:49<19:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:15,589 >> Initializing global attention on CLS token...\n",
            " 84% 6965/8340 [1:45:50<19:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:16,424 >> Initializing global attention on CLS token...\n",
            " 84% 6966/8340 [1:45:51<19:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:17,261 >> Initializing global attention on CLS token...\n",
            " 84% 6967/8340 [1:45:52<19:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:18,099 >> Initializing global attention on CLS token...\n",
            " 84% 6968/8340 [1:45:53<19:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:18,933 >> Initializing global attention on CLS token...\n",
            " 84% 6969/8340 [1:45:54<19:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:19,772 >> Initializing global attention on CLS token...\n",
            " 84% 6970/8340 [1:45:54<19:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:20,606 >> Initializing global attention on CLS token...\n",
            " 84% 6971/8340 [1:45:55<19:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:21,444 >> Initializing global attention on CLS token...\n",
            " 84% 6972/8340 [1:45:56<19:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:22,283 >> Initializing global attention on CLS token...\n",
            " 84% 6973/8340 [1:45:57<19:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:23,118 >> Initializing global attention on CLS token...\n",
            " 84% 6974/8340 [1:45:58<19:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:23,953 >> Initializing global attention on CLS token...\n",
            " 84% 6975/8340 [1:45:59<19:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:24,792 >> Initializing global attention on CLS token...\n",
            " 84% 6976/8340 [1:46:00<19:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:25,625 >> Initializing global attention on CLS token...\n",
            " 84% 6977/8340 [1:46:00<18:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:26,460 >> Initializing global attention on CLS token...\n",
            " 84% 6978/8340 [1:46:01<18:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:27,291 >> Initializing global attention on CLS token...\n",
            " 84% 6979/8340 [1:46:02<18:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:28,127 >> Initializing global attention on CLS token...\n",
            " 84% 6980/8340 [1:46:03<18:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:28,963 >> Initializing global attention on CLS token...\n",
            " 84% 6981/8340 [1:46:04<18:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:29,798 >> Initializing global attention on CLS token...\n",
            " 84% 6982/8340 [1:46:05<18:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:30,631 >> Initializing global attention on CLS token...\n",
            " 84% 6983/8340 [1:46:05<18:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:31,466 >> Initializing global attention on CLS token...\n",
            " 84% 6984/8340 [1:46:06<18:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:32,299 >> Initializing global attention on CLS token...\n",
            " 84% 6985/8340 [1:46:07<18:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:33,133 >> Initializing global attention on CLS token...\n",
            " 84% 6986/8340 [1:46:08<18:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:33,967 >> Initializing global attention on CLS token...\n",
            " 84% 6987/8340 [1:46:09<18:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:34,800 >> Initializing global attention on CLS token...\n",
            " 84% 6988/8340 [1:46:10<18:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:35,633 >> Initializing global attention on CLS token...\n",
            " 84% 6989/8340 [1:46:10<18:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:36,469 >> Initializing global attention on CLS token...\n",
            " 84% 6990/8340 [1:46:11<18:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:37,302 >> Initializing global attention on CLS token...\n",
            " 84% 6991/8340 [1:46:12<18:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:38,138 >> Initializing global attention on CLS token...\n",
            " 84% 6992/8340 [1:46:13<18:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:38,975 >> Initializing global attention on CLS token...\n",
            " 84% 6993/8340 [1:46:14<18:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:39,808 >> Initializing global attention on CLS token...\n",
            " 84% 6994/8340 [1:46:15<18:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:40,648 >> Initializing global attention on CLS token...\n",
            " 84% 6995/8340 [1:46:15<18:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:41,480 >> Initializing global attention on CLS token...\n",
            " 84% 6996/8340 [1:46:16<18:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:42,318 >> Initializing global attention on CLS token...\n",
            " 84% 6997/8340 [1:46:17<18:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:43,151 >> Initializing global attention on CLS token...\n",
            " 84% 6998/8340 [1:46:18<18:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:43,991 >> Initializing global attention on CLS token...\n",
            " 84% 6999/8340 [1:46:19<18:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:44,828 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0375, 'learning_rate': 4.841726618705037e-06, 'epoch': 8.39}\n",
            " 84% 7000/8340 [1:46:20<19:36,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:45,814 >> Initializing global attention on CLS token...\n",
            " 84% 7001/8340 [1:46:21<19:25,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:46,657 >> Initializing global attention on CLS token...\n",
            " 84% 7002/8340 [1:46:21<19:13,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:47,496 >> Initializing global attention on CLS token...\n",
            " 84% 7003/8340 [1:46:22<19:02,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:48,339 >> Initializing global attention on CLS token...\n",
            " 84% 7004/8340 [1:46:23<18:56,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:49,174 >> Initializing global attention on CLS token...\n",
            " 84% 7005/8340 [1:46:24<18:48,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:50,006 >> Initializing global attention on CLS token...\n",
            " 84% 7006/8340 [1:46:25<18:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:50,840 >> Initializing global attention on CLS token...\n",
            " 84% 7007/8340 [1:46:26<18:39,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:51,674 >> Initializing global attention on CLS token...\n",
            " 84% 7008/8340 [1:46:26<18:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:52,511 >> Initializing global attention on CLS token...\n",
            " 84% 7009/8340 [1:46:27<18:34,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:53,345 >> Initializing global attention on CLS token...\n",
            " 84% 7010/8340 [1:46:28<18:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:54,177 >> Initializing global attention on CLS token...\n",
            " 84% 7011/8340 [1:46:29<18:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:55,009 >> Initializing global attention on CLS token...\n",
            " 84% 7012/8340 [1:46:30<18:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:55,846 >> Initializing global attention on CLS token...\n",
            " 84% 7013/8340 [1:46:31<18:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:56,678 >> Initializing global attention on CLS token...\n",
            " 84% 7014/8340 [1:46:31<18:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:57,514 >> Initializing global attention on CLS token...\n",
            " 84% 7015/8340 [1:46:32<18:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:58,353 >> Initializing global attention on CLS token...\n",
            " 84% 7016/8340 [1:46:33<18:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:49:59,191 >> Initializing global attention on CLS token...\n",
            " 84% 7017/8340 [1:46:34<18:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:00,026 >> Initializing global attention on CLS token...\n",
            " 84% 7018/8340 [1:46:35<18:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:00,859 >> Initializing global attention on CLS token...\n",
            " 84% 7019/8340 [1:46:36<18:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:01,690 >> Initializing global attention on CLS token...\n",
            " 84% 7020/8340 [1:46:36<18:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:02,527 >> Initializing global attention on CLS token...\n",
            " 84% 7021/8340 [1:46:37<18:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:03,361 >> Initializing global attention on CLS token...\n",
            " 84% 7022/8340 [1:46:38<18:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:04,198 >> Initializing global attention on CLS token...\n",
            " 84% 7023/8340 [1:46:39<18:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:05,031 >> Initializing global attention on CLS token...\n",
            " 84% 7024/8340 [1:46:40<18:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:05,866 >> Initializing global attention on CLS token...\n",
            " 84% 7025/8340 [1:46:41<18:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:06,702 >> Initializing global attention on CLS token...\n",
            " 84% 7026/8340 [1:46:41<18:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:07,535 >> Initializing global attention on CLS token...\n",
            " 84% 7027/8340 [1:46:42<18:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:08,368 >> Initializing global attention on CLS token...\n",
            " 84% 7028/8340 [1:46:43<18:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:09,202 >> Initializing global attention on CLS token...\n",
            " 84% 7029/8340 [1:46:44<18:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:10,037 >> Initializing global attention on CLS token...\n",
            " 84% 7030/8340 [1:46:45<18:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:10,874 >> Initializing global attention on CLS token...\n",
            " 84% 7031/8340 [1:46:46<18:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:11,711 >> Initializing global attention on CLS token...\n",
            " 84% 7032/8340 [1:46:46<18:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:12,545 >> Initializing global attention on CLS token...\n",
            " 84% 7033/8340 [1:46:47<18:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:13,377 >> Initializing global attention on CLS token...\n",
            " 84% 7034/8340 [1:46:48<18:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:14,210 >> Initializing global attention on CLS token...\n",
            " 84% 7035/8340 [1:46:49<18:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:15,045 >> Initializing global attention on CLS token...\n",
            " 84% 7036/8340 [1:46:50<18:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:15,877 >> Initializing global attention on CLS token...\n",
            " 84% 7037/8340 [1:46:51<18:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:16,714 >> Initializing global attention on CLS token...\n",
            " 84% 7038/8340 [1:46:51<18:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:17,547 >> Initializing global attention on CLS token...\n",
            " 84% 7039/8340 [1:46:52<18:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:18,381 >> Initializing global attention on CLS token...\n",
            " 84% 7040/8340 [1:46:53<18:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:19,215 >> Initializing global attention on CLS token...\n",
            " 84% 7041/8340 [1:46:54<18:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:20,049 >> Initializing global attention on CLS token...\n",
            " 84% 7042/8340 [1:46:55<18:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:20,882 >> Initializing global attention on CLS token...\n",
            " 84% 7043/8340 [1:46:56<18:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:21,716 >> Initializing global attention on CLS token...\n",
            " 84% 7044/8340 [1:46:56<18:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:22,551 >> Initializing global attention on CLS token...\n",
            " 84% 7045/8340 [1:46:57<18:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:23,387 >> Initializing global attention on CLS token...\n",
            " 84% 7046/8340 [1:46:58<17:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:24,222 >> Initializing global attention on CLS token...\n",
            " 84% 7047/8340 [1:46:59<18:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:25,060 >> Initializing global attention on CLS token...\n",
            " 85% 7048/8340 [1:47:00<18:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:25,898 >> Initializing global attention on CLS token...\n",
            " 85% 7049/8340 [1:47:01<17:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:26,734 >> Initializing global attention on CLS token...\n",
            " 85% 7050/8340 [1:47:01<17:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:27,564 >> Initializing global attention on CLS token...\n",
            " 85% 7051/8340 [1:47:02<17:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:28,403 >> Initializing global attention on CLS token...\n",
            " 85% 7052/8340 [1:47:03<17:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:29,237 >> Initializing global attention on CLS token...\n",
            " 85% 7053/8340 [1:47:04<17:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:30,085 >> Initializing global attention on CLS token...\n",
            " 85% 7054/8340 [1:47:05<17:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:30,923 >> Initializing global attention on CLS token...\n",
            " 85% 7055/8340 [1:47:06<17:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:31,756 >> Initializing global attention on CLS token...\n",
            " 85% 7056/8340 [1:47:06<17:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:32,591 >> Initializing global attention on CLS token...\n",
            " 85% 7057/8340 [1:47:07<17:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:33,428 >> Initializing global attention on CLS token...\n",
            " 85% 7058/8340 [1:47:08<17:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:34,266 >> Initializing global attention on CLS token...\n",
            " 85% 7059/8340 [1:47:09<17:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:35,106 >> Initializing global attention on CLS token...\n",
            " 85% 7060/8340 [1:47:10<17:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:35,946 >> Initializing global attention on CLS token...\n",
            " 85% 7061/8340 [1:47:11<17:52,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:36,783 >> Initializing global attention on CLS token...\n",
            " 85% 7062/8340 [1:47:12<17:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:37,621 >> Initializing global attention on CLS token...\n",
            " 85% 7063/8340 [1:47:12<17:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:38,457 >> Initializing global attention on CLS token...\n",
            " 85% 7064/8340 [1:47:13<17:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:39,292 >> Initializing global attention on CLS token...\n",
            " 85% 7065/8340 [1:47:14<17:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:40,129 >> Initializing global attention on CLS token...\n",
            " 85% 7066/8340 [1:47:15<17:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:40,967 >> Initializing global attention on CLS token...\n",
            " 85% 7067/8340 [1:47:16<17:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:41,804 >> Initializing global attention on CLS token...\n",
            " 85% 7068/8340 [1:47:17<17:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:42,644 >> Initializing global attention on CLS token...\n",
            " 85% 7069/8340 [1:47:17<17:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:43,476 >> Initializing global attention on CLS token...\n",
            " 85% 7070/8340 [1:47:18<17:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:44,309 >> Initializing global attention on CLS token...\n",
            " 85% 7071/8340 [1:47:19<17:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:45,143 >> Initializing global attention on CLS token...\n",
            " 85% 7072/8340 [1:47:20<17:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:45,978 >> Initializing global attention on CLS token...\n",
            " 85% 7073/8340 [1:47:21<17:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:46,810 >> Initializing global attention on CLS token...\n",
            " 85% 7074/8340 [1:47:22<17:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:47,645 >> Initializing global attention on CLS token...\n",
            " 85% 7075/8340 [1:47:22<17:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:48,476 >> Initializing global attention on CLS token...\n",
            " 85% 7076/8340 [1:47:23<17:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:49,316 >> Initializing global attention on CLS token...\n",
            " 85% 7077/8340 [1:47:24<17:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:50,153 >> Initializing global attention on CLS token...\n",
            " 85% 7078/8340 [1:47:25<17:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:50,991 >> Initializing global attention on CLS token...\n",
            " 85% 7079/8340 [1:47:26<17:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:51,822 >> Initializing global attention on CLS token...\n",
            " 85% 7080/8340 [1:47:27<17:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:52,660 >> Initializing global attention on CLS token...\n",
            " 85% 7081/8340 [1:47:27<17:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:53,497 >> Initializing global attention on CLS token...\n",
            " 85% 7082/8340 [1:47:28<17:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:54,332 >> Initializing global attention on CLS token...\n",
            " 85% 7083/8340 [1:47:29<17:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:55,167 >> Initializing global attention on CLS token...\n",
            " 85% 7084/8340 [1:47:30<17:31,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:56,007 >> Initializing global attention on CLS token...\n",
            " 85% 7085/8340 [1:47:31<17:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:56,843 >> Initializing global attention on CLS token...\n",
            " 85% 7086/8340 [1:47:32<17:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:57,676 >> Initializing global attention on CLS token...\n",
            " 85% 7087/8340 [1:47:32<17:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:58,515 >> Initializing global attention on CLS token...\n",
            " 85% 7088/8340 [1:47:33<17:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:50:59,351 >> Initializing global attention on CLS token...\n",
            " 85% 7089/8340 [1:47:34<17:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:00,187 >> Initializing global attention on CLS token...\n",
            " 85% 7090/8340 [1:47:35<17:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:01,024 >> Initializing global attention on CLS token...\n",
            " 85% 7091/8340 [1:47:36<17:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:01,868 >> Initializing global attention on CLS token...\n",
            " 85% 7092/8340 [1:47:37<17:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:02,700 >> Initializing global attention on CLS token...\n",
            " 85% 7093/8340 [1:47:37<17:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:03,535 >> Initializing global attention on CLS token...\n",
            " 85% 7094/8340 [1:47:38<17:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:04,369 >> Initializing global attention on CLS token...\n",
            " 85% 7095/8340 [1:47:39<17:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:05,205 >> Initializing global attention on CLS token...\n",
            " 85% 7096/8340 [1:47:40<17:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:06,040 >> Initializing global attention on CLS token...\n",
            " 85% 7097/8340 [1:47:41<17:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:06,880 >> Initializing global attention on CLS token...\n",
            " 85% 7098/8340 [1:47:42<17:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:07,714 >> Initializing global attention on CLS token...\n",
            " 85% 7099/8340 [1:47:42<17:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:08,550 >> Initializing global attention on CLS token...\n",
            " 85% 7100/8340 [1:47:43<17:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:09,386 >> Initializing global attention on CLS token...\n",
            " 85% 7101/8340 [1:47:44<17:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:10,220 >> Initializing global attention on CLS token...\n",
            " 85% 7102/8340 [1:47:45<17:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:11,053 >> Initializing global attention on CLS token...\n",
            " 85% 7103/8340 [1:47:46<17:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:11,889 >> Initializing global attention on CLS token...\n",
            " 85% 7104/8340 [1:47:47<17:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:12,721 >> Initializing global attention on CLS token...\n",
            " 85% 7105/8340 [1:47:47<17:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:13,553 >> Initializing global attention on CLS token...\n",
            " 85% 7106/8340 [1:47:48<17:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:14,390 >> Initializing global attention on CLS token...\n",
            " 85% 7107/8340 [1:47:49<17:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:15,227 >> Initializing global attention on CLS token...\n",
            " 85% 7108/8340 [1:47:50<17:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:16,058 >> Initializing global attention on CLS token...\n",
            " 85% 7109/8340 [1:47:51<17:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:16,897 >> Initializing global attention on CLS token...\n",
            " 85% 7110/8340 [1:47:52<17:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:17,734 >> Initializing global attention on CLS token...\n",
            " 85% 7111/8340 [1:47:52<17:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:18,567 >> Initializing global attention on CLS token...\n",
            " 85% 7112/8340 [1:47:53<17:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:19,399 >> Initializing global attention on CLS token...\n",
            " 85% 7113/8340 [1:47:54<17:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:20,234 >> Initializing global attention on CLS token...\n",
            " 85% 7114/8340 [1:47:55<17:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:21,070 >> Initializing global attention on CLS token...\n",
            " 85% 7115/8340 [1:47:56<17:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:21,908 >> Initializing global attention on CLS token...\n",
            " 85% 7116/8340 [1:47:57<17:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:22,743 >> Initializing global attention on CLS token...\n",
            " 85% 7117/8340 [1:47:57<17:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:23,576 >> Initializing global attention on CLS token...\n",
            " 85% 7118/8340 [1:47:58<17:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:24,411 >> Initializing global attention on CLS token...\n",
            " 85% 7119/8340 [1:47:59<16:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:25,251 >> Initializing global attention on CLS token...\n",
            " 85% 7120/8340 [1:48:00<17:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:26,094 >> Initializing global attention on CLS token...\n",
            " 85% 7121/8340 [1:48:01<17:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:26,932 >> Initializing global attention on CLS token...\n",
            " 85% 7122/8340 [1:48:02<17:00,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:27,772 >> Initializing global attention on CLS token...\n",
            " 85% 7123/8340 [1:48:02<17:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:28,610 >> Initializing global attention on CLS token...\n",
            " 85% 7124/8340 [1:48:03<16:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:29,443 >> Initializing global attention on CLS token...\n",
            " 85% 7125/8340 [1:48:04<16:58,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:30,285 >> Initializing global attention on CLS token...\n",
            " 85% 7126/8340 [1:48:05<16:56,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:31,117 >> Initializing global attention on CLS token...\n",
            " 85% 7127/8340 [1:48:06<16:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:31,952 >> Initializing global attention on CLS token...\n",
            " 85% 7128/8340 [1:48:07<16:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:32,786 >> Initializing global attention on CLS token...\n",
            " 85% 7129/8340 [1:48:08<16:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:33,620 >> Initializing global attention on CLS token...\n",
            " 85% 7130/8340 [1:48:08<16:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:34,454 >> Initializing global attention on CLS token...\n",
            " 86% 7131/8340 [1:48:09<16:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:35,290 >> Initializing global attention on CLS token...\n",
            " 86% 7132/8340 [1:48:10<16:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:36,132 >> Initializing global attention on CLS token...\n",
            " 86% 7133/8340 [1:48:11<16:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:36,967 >> Initializing global attention on CLS token...\n",
            " 86% 7134/8340 [1:48:12<16:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:37,801 >> Initializing global attention on CLS token...\n",
            " 86% 7135/8340 [1:48:13<16:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:38,633 >> Initializing global attention on CLS token...\n",
            " 86% 7136/8340 [1:48:13<16:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:39,467 >> Initializing global attention on CLS token...\n",
            " 86% 7137/8340 [1:48:14<16:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:40,306 >> Initializing global attention on CLS token...\n",
            " 86% 7138/8340 [1:48:15<16:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:41,139 >> Initializing global attention on CLS token...\n",
            " 86% 7139/8340 [1:48:16<16:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:41,971 >> Initializing global attention on CLS token...\n",
            " 86% 7140/8340 [1:48:17<16:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:42,806 >> Initializing global attention on CLS token...\n",
            " 86% 7141/8340 [1:48:18<16:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:43,646 >> Initializing global attention on CLS token...\n",
            " 86% 7142/8340 [1:48:18<16:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:44,480 >> Initializing global attention on CLS token...\n",
            " 86% 7143/8340 [1:48:19<16:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:45,314 >> Initializing global attention on CLS token...\n",
            " 86% 7144/8340 [1:48:20<16:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:46,151 >> Initializing global attention on CLS token...\n",
            " 86% 7145/8340 [1:48:21<16:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:46,984 >> Initializing global attention on CLS token...\n",
            " 86% 7146/8340 [1:48:22<16:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:47,819 >> Initializing global attention on CLS token...\n",
            " 86% 7147/8340 [1:48:23<16:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:48,654 >> Initializing global attention on CLS token...\n",
            " 86% 7148/8340 [1:48:23<16:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:49,489 >> Initializing global attention on CLS token...\n",
            " 86% 7149/8340 [1:48:24<16:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:50,320 >> Initializing global attention on CLS token...\n",
            " 86% 7150/8340 [1:48:25<16:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:51,155 >> Initializing global attention on CLS token...\n",
            " 86% 7151/8340 [1:48:26<16:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:51,995 >> Initializing global attention on CLS token...\n",
            " 86% 7152/8340 [1:48:27<16:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:52,828 >> Initializing global attention on CLS token...\n",
            " 86% 7153/8340 [1:48:28<16:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:53,659 >> Initializing global attention on CLS token...\n",
            " 86% 7154/8340 [1:48:28<16:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:54,494 >> Initializing global attention on CLS token...\n",
            " 86% 7155/8340 [1:48:29<16:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:55,329 >> Initializing global attention on CLS token...\n",
            " 86% 7156/8340 [1:48:30<16:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:56,160 >> Initializing global attention on CLS token...\n",
            " 86% 7157/8340 [1:48:31<16:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:56,995 >> Initializing global attention on CLS token...\n",
            " 86% 7158/8340 [1:48:32<16:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:57,829 >> Initializing global attention on CLS token...\n",
            " 86% 7159/8340 [1:48:33<16:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:58,662 >> Initializing global attention on CLS token...\n",
            " 86% 7160/8340 [1:48:33<16:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:51:59,501 >> Initializing global attention on CLS token...\n",
            " 86% 7161/8340 [1:48:34<16:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:00,340 >> Initializing global attention on CLS token...\n",
            " 86% 7162/8340 [1:48:35<16:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:01,179 >> Initializing global attention on CLS token...\n",
            " 86% 7163/8340 [1:48:36<16:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:02,015 >> Initializing global attention on CLS token...\n",
            " 86% 7164/8340 [1:48:37<16:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:02,851 >> Initializing global attention on CLS token...\n",
            " 86% 7165/8340 [1:48:38<16:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:03,687 >> Initializing global attention on CLS token...\n",
            " 86% 7166/8340 [1:48:38<16:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:04,520 >> Initializing global attention on CLS token...\n",
            " 86% 7167/8340 [1:48:39<16:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:05,359 >> Initializing global attention on CLS token...\n",
            " 86% 7168/8340 [1:48:40<16:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:06,196 >> Initializing global attention on CLS token...\n",
            " 86% 7169/8340 [1:48:41<16:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:07,029 >> Initializing global attention on CLS token...\n",
            " 86% 7170/8340 [1:48:42<16:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:07,862 >> Initializing global attention on CLS token...\n",
            " 86% 7171/8340 [1:48:43<16:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:08,701 >> Initializing global attention on CLS token...\n",
            " 86% 7172/8340 [1:48:43<16:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:09,538 >> Initializing global attention on CLS token...\n",
            " 86% 7173/8340 [1:48:44<16:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:10,371 >> Initializing global attention on CLS token...\n",
            " 86% 7174/8340 [1:48:45<16:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:11,201 >> Initializing global attention on CLS token...\n",
            " 86% 7175/8340 [1:48:46<16:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:12,035 >> Initializing global attention on CLS token...\n",
            " 86% 7176/8340 [1:48:47<16:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:12,871 >> Initializing global attention on CLS token...\n",
            " 86% 7177/8340 [1:48:48<16:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:13,704 >> Initializing global attention on CLS token...\n",
            " 86% 7178/8340 [1:48:48<16:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:14,540 >> Initializing global attention on CLS token...\n",
            " 86% 7179/8340 [1:48:49<16:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:15,379 >> Initializing global attention on CLS token...\n",
            " 86% 7180/8340 [1:48:50<16:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:16,219 >> Initializing global attention on CLS token...\n",
            " 86% 7181/8340 [1:48:51<16:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:17,055 >> Initializing global attention on CLS token...\n",
            " 86% 7182/8340 [1:48:52<16:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:17,894 >> Initializing global attention on CLS token...\n",
            " 86% 7183/8340 [1:48:53<16:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:18,732 >> Initializing global attention on CLS token...\n",
            " 86% 7184/8340 [1:48:53<16:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:19,569 >> Initializing global attention on CLS token...\n",
            " 86% 7185/8340 [1:48:54<16:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:20,405 >> Initializing global attention on CLS token...\n",
            " 86% 7186/8340 [1:48:55<16:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:21,243 >> Initializing global attention on CLS token...\n",
            " 86% 7187/8340 [1:48:56<16:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:22,078 >> Initializing global attention on CLS token...\n",
            " 86% 7188/8340 [1:48:57<16:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:22,909 >> Initializing global attention on CLS token...\n",
            " 86% 7189/8340 [1:48:58<16:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:23,744 >> Initializing global attention on CLS token...\n",
            " 86% 7190/8340 [1:48:58<15:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:24,577 >> Initializing global attention on CLS token...\n",
            " 86% 7191/8340 [1:48:59<15:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:25,413 >> Initializing global attention on CLS token...\n",
            " 86% 7192/8340 [1:49:00<15:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:26,246 >> Initializing global attention on CLS token...\n",
            " 86% 7193/8340 [1:49:01<15:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:27,082 >> Initializing global attention on CLS token...\n",
            " 86% 7194/8340 [1:49:02<15:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:27,916 >> Initializing global attention on CLS token...\n",
            " 86% 7195/8340 [1:49:03<15:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:28,758 >> Initializing global attention on CLS token...\n",
            " 86% 7196/8340 [1:49:03<15:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:29,597 >> Initializing global attention on CLS token...\n",
            " 86% 7197/8340 [1:49:04<15:57,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:30,436 >> Initializing global attention on CLS token...\n",
            " 86% 7198/8340 [1:49:05<15:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:31,265 >> Initializing global attention on CLS token...\n",
            " 86% 7199/8340 [1:49:06<15:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:32,107 >> Initializing global attention on CLS token...\n",
            " 86% 7200/8340 [1:49:07<15:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:32,944 >> Initializing global attention on CLS token...\n",
            " 86% 7201/8340 [1:49:08<15:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:33,780 >> Initializing global attention on CLS token...\n",
            " 86% 7202/8340 [1:49:08<15:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:34,613 >> Initializing global attention on CLS token...\n",
            " 86% 7203/8340 [1:49:09<15:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:35,454 >> Initializing global attention on CLS token...\n",
            " 86% 7204/8340 [1:49:10<15:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:36,290 >> Initializing global attention on CLS token...\n",
            " 86% 7205/8340 [1:49:11<15:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:37,127 >> Initializing global attention on CLS token...\n",
            " 86% 7206/8340 [1:49:12<15:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:37,963 >> Initializing global attention on CLS token...\n",
            " 86% 7207/8340 [1:49:13<15:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:38,802 >> Initializing global attention on CLS token...\n",
            " 86% 7208/8340 [1:49:14<15:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:39,639 >> Initializing global attention on CLS token...\n",
            " 86% 7209/8340 [1:49:14<15:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:40,475 >> Initializing global attention on CLS token...\n",
            " 86% 7210/8340 [1:49:15<15:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:41,309 >> Initializing global attention on CLS token...\n",
            " 86% 7211/8340 [1:49:16<15:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:42,144 >> Initializing global attention on CLS token...\n",
            " 86% 7212/8340 [1:49:17<15:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:42,979 >> Initializing global attention on CLS token...\n",
            " 86% 7213/8340 [1:49:18<15:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:43,815 >> Initializing global attention on CLS token...\n",
            " 86% 7214/8340 [1:49:19<15:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:44,652 >> Initializing global attention on CLS token...\n",
            " 87% 7215/8340 [1:49:19<15:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:45,487 >> Initializing global attention on CLS token...\n",
            " 87% 7216/8340 [1:49:20<15:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:46,324 >> Initializing global attention on CLS token...\n",
            " 87% 7217/8340 [1:49:21<15:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:47,160 >> Initializing global attention on CLS token...\n",
            " 87% 7218/8340 [1:49:22<15:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:47,997 >> Initializing global attention on CLS token...\n",
            " 87% 7219/8340 [1:49:23<15:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:48,830 >> Initializing global attention on CLS token...\n",
            " 87% 7220/8340 [1:49:24<15:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:49,667 >> Initializing global attention on CLS token...\n",
            " 87% 7221/8340 [1:49:24<15:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:50,502 >> Initializing global attention on CLS token...\n",
            " 87% 7222/8340 [1:49:25<15:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:51,338 >> Initializing global attention on CLS token...\n",
            " 87% 7223/8340 [1:49:26<15:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:52,174 >> Initializing global attention on CLS token...\n",
            " 87% 7224/8340 [1:49:27<15:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:53,010 >> Initializing global attention on CLS token...\n",
            " 87% 7225/8340 [1:49:28<15:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:53,842 >> Initializing global attention on CLS token...\n",
            " 87% 7226/8340 [1:49:29<15:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:54,676 >> Initializing global attention on CLS token...\n",
            " 87% 7227/8340 [1:49:29<15:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:55,507 >> Initializing global attention on CLS token...\n",
            " 87% 7228/8340 [1:49:30<15:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:56,344 >> Initializing global attention on CLS token...\n",
            " 87% 7229/8340 [1:49:31<15:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:57,177 >> Initializing global attention on CLS token...\n",
            " 87% 7230/8340 [1:49:32<15:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:58,014 >> Initializing global attention on CLS token...\n",
            " 87% 7231/8340 [1:49:33<15:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:58,850 >> Initializing global attention on CLS token...\n",
            " 87% 7232/8340 [1:49:34<15:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:52:59,687 >> Initializing global attention on CLS token...\n",
            " 87% 7233/8340 [1:49:34<15:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:00,525 >> Initializing global attention on CLS token...\n",
            " 87% 7234/8340 [1:49:35<15:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:01,363 >> Initializing global attention on CLS token...\n",
            " 87% 7235/8340 [1:49:36<15:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:02,201 >> Initializing global attention on CLS token...\n",
            " 87% 7236/8340 [1:49:37<15:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:03,034 >> Initializing global attention on CLS token...\n",
            " 87% 7237/8340 [1:49:38<15:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:03,870 >> Initializing global attention on CLS token...\n",
            " 87% 7238/8340 [1:49:39<15:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:04,706 >> Initializing global attention on CLS token...\n",
            " 87% 7239/8340 [1:49:39<15:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:05,543 >> Initializing global attention on CLS token...\n",
            " 87% 7240/8340 [1:49:40<15:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:06,381 >> Initializing global attention on CLS token...\n",
            " 87% 7241/8340 [1:49:41<15:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:07,221 >> Initializing global attention on CLS token...\n",
            " 87% 7242/8340 [1:49:42<15:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:08,057 >> Initializing global attention on CLS token...\n",
            " 87% 7243/8340 [1:49:43<15:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:08,901 >> Initializing global attention on CLS token...\n",
            " 87% 7244/8340 [1:49:44<15:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:09,733 >> Initializing global attention on CLS token...\n",
            " 87% 7245/8340 [1:49:44<15:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:10,569 >> Initializing global attention on CLS token...\n",
            " 87% 7246/8340 [1:49:45<15:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:11,405 >> Initializing global attention on CLS token...\n",
            " 87% 7247/8340 [1:49:46<15:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:12,238 >> Initializing global attention on CLS token...\n",
            " 87% 7248/8340 [1:49:47<15:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:13,071 >> Initializing global attention on CLS token...\n",
            " 87% 7249/8340 [1:49:48<15:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:13,904 >> Initializing global attention on CLS token...\n",
            " 87% 7250/8340 [1:49:49<15:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:14,739 >> Initializing global attention on CLS token...\n",
            " 87% 7251/8340 [1:49:49<15:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:15,576 >> Initializing global attention on CLS token...\n",
            " 87% 7252/8340 [1:49:50<15:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:16,411 >> Initializing global attention on CLS token...\n",
            " 87% 7253/8340 [1:49:51<15:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:17,245 >> Initializing global attention on CLS token...\n",
            " 87% 7254/8340 [1:49:52<15:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:18,083 >> Initializing global attention on CLS token...\n",
            " 87% 7255/8340 [1:49:53<15:07,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:18,922 >> Initializing global attention on CLS token...\n",
            " 87% 7256/8340 [1:49:54<15:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:19,759 >> Initializing global attention on CLS token...\n",
            " 87% 7257/8340 [1:49:54<15:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:20,594 >> Initializing global attention on CLS token...\n",
            " 87% 7258/8340 [1:49:55<15:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:21,429 >> Initializing global attention on CLS token...\n",
            " 87% 7259/8340 [1:49:56<15:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:22,261 >> Initializing global attention on CLS token...\n",
            " 87% 7260/8340 [1:49:57<15:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:23,099 >> Initializing global attention on CLS token...\n",
            " 87% 7261/8340 [1:49:58<15:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:23,938 >> Initializing global attention on CLS token...\n",
            " 87% 7262/8340 [1:49:59<15:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:24,769 >> Initializing global attention on CLS token...\n",
            " 87% 7263/8340 [1:49:59<14:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:25,603 >> Initializing global attention on CLS token...\n",
            " 87% 7264/8340 [1:50:00<14:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:26,437 >> Initializing global attention on CLS token...\n",
            " 87% 7265/8340 [1:50:01<14:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:27,272 >> Initializing global attention on CLS token...\n",
            " 87% 7266/8340 [1:50:02<14:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:28,108 >> Initializing global attention on CLS token...\n",
            " 87% 7267/8340 [1:50:03<14:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:28,944 >> Initializing global attention on CLS token...\n",
            " 87% 7268/8340 [1:50:04<14:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:29,778 >> Initializing global attention on CLS token...\n",
            " 87% 7269/8340 [1:50:04<14:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:30,610 >> Initializing global attention on CLS token...\n",
            " 87% 7270/8340 [1:50:05<14:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:31,445 >> Initializing global attention on CLS token...\n",
            " 87% 7271/8340 [1:50:06<14:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:32,281 >> Initializing global attention on CLS token...\n",
            " 87% 7272/8340 [1:50:07<14:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:33,113 >> Initializing global attention on CLS token...\n",
            " 87% 7273/8340 [1:50:08<14:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:33,950 >> Initializing global attention on CLS token...\n",
            " 87% 7274/8340 [1:50:09<14:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:34,784 >> Initializing global attention on CLS token...\n",
            " 87% 7275/8340 [1:50:10<14:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:35,621 >> Initializing global attention on CLS token...\n",
            " 87% 7276/8340 [1:50:10<14:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:36,456 >> Initializing global attention on CLS token...\n",
            " 87% 7277/8340 [1:50:11<14:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:37,288 >> Initializing global attention on CLS token...\n",
            " 87% 7278/8340 [1:50:12<14:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:38,123 >> Initializing global attention on CLS token...\n",
            " 87% 7279/8340 [1:50:13<14:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:38,955 >> Initializing global attention on CLS token...\n",
            " 87% 7280/8340 [1:50:14<14:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:39,786 >> Initializing global attention on CLS token...\n",
            " 87% 7281/8340 [1:50:15<14:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:40,627 >> Initializing global attention on CLS token...\n",
            " 87% 7282/8340 [1:50:15<14:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:41,463 >> Initializing global attention on CLS token...\n",
            " 87% 7283/8340 [1:50:16<14:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:42,298 >> Initializing global attention on CLS token...\n",
            " 87% 7284/8340 [1:50:17<14:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:43,131 >> Initializing global attention on CLS token...\n",
            " 87% 7285/8340 [1:50:18<14:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:43,961 >> Initializing global attention on CLS token...\n",
            " 87% 7286/8340 [1:50:19<14:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:44,795 >> Initializing global attention on CLS token...\n",
            " 87% 7287/8340 [1:50:20<14:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:45,633 >> Initializing global attention on CLS token...\n",
            " 87% 7288/8340 [1:50:20<14:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:46,468 >> Initializing global attention on CLS token...\n",
            " 87% 7289/8340 [1:50:21<14:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:47,305 >> Initializing global attention on CLS token...\n",
            " 87% 7290/8340 [1:50:22<14:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:48,141 >> Initializing global attention on CLS token...\n",
            " 87% 7291/8340 [1:50:23<14:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:48,976 >> Initializing global attention on CLS token...\n",
            " 87% 7292/8340 [1:50:24<14:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:49,814 >> Initializing global attention on CLS token...\n",
            " 87% 7293/8340 [1:50:25<14:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:50,652 >> Initializing global attention on CLS token...\n",
            " 87% 7294/8340 [1:50:25<14:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:51,485 >> Initializing global attention on CLS token...\n",
            " 87% 7295/8340 [1:50:26<14:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:52,318 >> Initializing global attention on CLS token...\n",
            " 87% 7296/8340 [1:50:27<14:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:53,151 >> Initializing global attention on CLS token...\n",
            " 87% 7297/8340 [1:50:28<14:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:53,984 >> Initializing global attention on CLS token...\n",
            " 88% 7298/8340 [1:50:29<14:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:54,848 >> Initializing global attention on CLS token...\n",
            " 88% 7299/8340 [1:50:30<14:39,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:55,717 >> Initializing global attention on CLS token...\n",
            " 88% 7300/8340 [1:50:30<14:48,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:56,582 >> Initializing global attention on CLS token...\n",
            " 88% 7301/8340 [1:50:31<14:48,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:57,440 >> Initializing global attention on CLS token...\n",
            " 88% 7302/8340 [1:50:32<14:47,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:58,278 >> Initializing global attention on CLS token...\n",
            " 88% 7303/8340 [1:50:33<14:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:59,114 >> Initializing global attention on CLS token...\n",
            " 88% 7304/8340 [1:50:34<14:37,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:53:59,960 >> Initializing global attention on CLS token...\n",
            " 88% 7305/8340 [1:50:35<14:34,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:00,794 >> Initializing global attention on CLS token...\n",
            " 88% 7306/8340 [1:50:36<14:30,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:01,629 >> Initializing global attention on CLS token...\n",
            " 88% 7307/8340 [1:50:36<14:27,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:02,464 >> Initializing global attention on CLS token...\n",
            " 88% 7308/8340 [1:50:37<14:24,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:03,297 >> Initializing global attention on CLS token...\n",
            " 88% 7309/8340 [1:50:38<14:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:04,133 >> Initializing global attention on CLS token...\n",
            " 88% 7310/8340 [1:50:39<14:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:04,971 >> Initializing global attention on CLS token...\n",
            " 88% 7311/8340 [1:50:40<14:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:05,809 >> Initializing global attention on CLS token...\n",
            " 88% 7312/8340 [1:50:41<14:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:06,646 >> Initializing global attention on CLS token...\n",
            " 88% 7313/8340 [1:50:41<14:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:07,484 >> Initializing global attention on CLS token...\n",
            " 88% 7314/8340 [1:50:42<14:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:08,319 >> Initializing global attention on CLS token...\n",
            " 88% 7315/8340 [1:50:43<14:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:09,154 >> Initializing global attention on CLS token...\n",
            " 88% 7316/8340 [1:50:44<14:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:09,990 >> Initializing global attention on CLS token...\n",
            " 88% 7317/8340 [1:50:45<14:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:10,831 >> Initializing global attention on CLS token...\n",
            " 88% 7318/8340 [1:50:46<14:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:11,668 >> Initializing global attention on CLS token...\n",
            " 88% 7319/8340 [1:50:46<14:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:12,500 >> Initializing global attention on CLS token...\n",
            " 88% 7320/8340 [1:50:47<14:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:13,335 >> Initializing global attention on CLS token...\n",
            " 88% 7321/8340 [1:50:48<14:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:14,172 >> Initializing global attention on CLS token...\n",
            " 88% 7322/8340 [1:50:49<14:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:15,003 >> Initializing global attention on CLS token...\n",
            " 88% 7323/8340 [1:50:50<14:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:15,840 >> Initializing global attention on CLS token...\n",
            " 88% 7324/8340 [1:50:51<14:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:16,675 >> Initializing global attention on CLS token...\n",
            " 88% 7325/8340 [1:50:51<14:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:17,511 >> Initializing global attention on CLS token...\n",
            " 88% 7326/8340 [1:50:52<14:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:18,345 >> Initializing global attention on CLS token...\n",
            " 88% 7327/8340 [1:50:53<14:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:19,180 >> Initializing global attention on CLS token...\n",
            " 88% 7328/8340 [1:50:54<14:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:20,014 >> Initializing global attention on CLS token...\n",
            " 88% 7329/8340 [1:50:55<14:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:20,854 >> Initializing global attention on CLS token...\n",
            " 88% 7330/8340 [1:50:56<14:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:21,688 >> Initializing global attention on CLS token...\n",
            " 88% 7331/8340 [1:50:56<14:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:22,547 >> Initializing global attention on CLS token...\n",
            " 88% 7332/8340 [1:50:57<14:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:23,383 >> Initializing global attention on CLS token...\n",
            " 88% 7333/8340 [1:50:58<14:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:24,218 >> Initializing global attention on CLS token...\n",
            " 88% 7334/8340 [1:50:59<14:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:25,053 >> Initializing global attention on CLS token...\n",
            " 88% 7335/8340 [1:51:00<14:01,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:25,886 >> Initializing global attention on CLS token...\n",
            " 88% 7336/8340 [1:51:01<13:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:26,721 >> Initializing global attention on CLS token...\n",
            " 88% 7337/8340 [1:51:01<13:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:27,557 >> Initializing global attention on CLS token...\n",
            " 88% 7338/8340 [1:51:02<13:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:28,388 >> Initializing global attention on CLS token...\n",
            " 88% 7339/8340 [1:51:03<13:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:29,222 >> Initializing global attention on CLS token...\n",
            " 88% 7340/8340 [1:51:04<13:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:30,055 >> Initializing global attention on CLS token...\n",
            " 88% 7341/8340 [1:51:05<13:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:30,892 >> Initializing global attention on CLS token...\n",
            " 88% 7342/8340 [1:51:06<13:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:31,726 >> Initializing global attention on CLS token...\n",
            " 88% 7343/8340 [1:51:06<13:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:32,561 >> Initializing global attention on CLS token...\n",
            " 88% 7344/8340 [1:51:07<13:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:33,393 >> Initializing global attention on CLS token...\n",
            " 88% 7345/8340 [1:51:08<13:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:34,231 >> Initializing global attention on CLS token...\n",
            " 88% 7346/8340 [1:51:09<13:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:35,068 >> Initializing global attention on CLS token...\n",
            " 88% 7347/8340 [1:51:10<13:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:35,902 >> Initializing global attention on CLS token...\n",
            " 88% 7348/8340 [1:51:11<13:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:36,738 >> Initializing global attention on CLS token...\n",
            " 88% 7349/8340 [1:51:11<13:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:37,576 >> Initializing global attention on CLS token...\n",
            " 88% 7350/8340 [1:51:12<13:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:38,414 >> Initializing global attention on CLS token...\n",
            " 88% 7351/8340 [1:51:13<13:47,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:39,251 >> Initializing global attention on CLS token...\n",
            " 88% 7352/8340 [1:51:14<13:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:40,086 >> Initializing global attention on CLS token...\n",
            " 88% 7353/8340 [1:51:15<13:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:40,923 >> Initializing global attention on CLS token...\n",
            " 88% 7354/8340 [1:51:16<13:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:41,759 >> Initializing global attention on CLS token...\n",
            " 88% 7355/8340 [1:51:16<13:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:42,594 >> Initializing global attention on CLS token...\n",
            " 88% 7356/8340 [1:51:17<13:43,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:43,432 >> Initializing global attention on CLS token...\n",
            " 88% 7357/8340 [1:51:18<13:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:44,268 >> Initializing global attention on CLS token...\n",
            " 88% 7358/8340 [1:51:19<13:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:45,103 >> Initializing global attention on CLS token...\n",
            " 88% 7359/8340 [1:51:20<13:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:45,940 >> Initializing global attention on CLS token...\n",
            " 88% 7360/8340 [1:51:21<13:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:46,771 >> Initializing global attention on CLS token...\n",
            " 88% 7361/8340 [1:51:21<13:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:47,605 >> Initializing global attention on CLS token...\n",
            " 88% 7362/8340 [1:51:22<13:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:48,438 >> Initializing global attention on CLS token...\n",
            " 88% 7363/8340 [1:51:23<13:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:49,278 >> Initializing global attention on CLS token...\n",
            " 88% 7364/8340 [1:51:24<13:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:50,110 >> Initializing global attention on CLS token...\n",
            " 88% 7365/8340 [1:51:25<13:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:50,946 >> Initializing global attention on CLS token...\n",
            " 88% 7366/8340 [1:51:26<13:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:51,780 >> Initializing global attention on CLS token...\n",
            " 88% 7367/8340 [1:51:27<13:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:52,619 >> Initializing global attention on CLS token...\n",
            " 88% 7368/8340 [1:51:27<13:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:53,457 >> Initializing global attention on CLS token...\n",
            " 88% 7369/8340 [1:51:28<13:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:54,287 >> Initializing global attention on CLS token...\n",
            " 88% 7370/8340 [1:51:29<13:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:55,121 >> Initializing global attention on CLS token...\n",
            " 88% 7371/8340 [1:51:30<13:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:55,955 >> Initializing global attention on CLS token...\n",
            " 88% 7372/8340 [1:51:31<13:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:56,790 >> Initializing global attention on CLS token...\n",
            " 88% 7373/8340 [1:51:32<13:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:57,626 >> Initializing global attention on CLS token...\n",
            " 88% 7374/8340 [1:51:32<13:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:58,460 >> Initializing global attention on CLS token...\n",
            " 88% 7375/8340 [1:51:33<13:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:54:59,294 >> Initializing global attention on CLS token...\n",
            " 88% 7376/8340 [1:51:34<13:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:00,132 >> Initializing global attention on CLS token...\n",
            " 88% 7377/8340 [1:51:35<13:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:00,968 >> Initializing global attention on CLS token...\n",
            " 88% 7378/8340 [1:51:36<13:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:01,804 >> Initializing global attention on CLS token...\n",
            " 88% 7379/8340 [1:51:37<13:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:02,637 >> Initializing global attention on CLS token...\n",
            " 88% 7380/8340 [1:51:37<13:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:03,478 >> Initializing global attention on CLS token...\n",
            " 89% 7381/8340 [1:51:38<13:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:04,315 >> Initializing global attention on CLS token...\n",
            " 89% 7382/8340 [1:51:39<13:21,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:05,152 >> Initializing global attention on CLS token...\n",
            " 89% 7383/8340 [1:51:40<13:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:05,986 >> Initializing global attention on CLS token...\n",
            " 89% 7384/8340 [1:51:41<13:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:06,820 >> Initializing global attention on CLS token...\n",
            " 89% 7385/8340 [1:51:42<13:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:07,658 >> Initializing global attention on CLS token...\n",
            " 89% 7386/8340 [1:51:42<13:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:08,495 >> Initializing global attention on CLS token...\n",
            " 89% 7387/8340 [1:51:43<13:17,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:09,333 >> Initializing global attention on CLS token...\n",
            " 89% 7388/8340 [1:51:44<13:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:10,169 >> Initializing global attention on CLS token...\n",
            " 89% 7389/8340 [1:51:45<13:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:11,001 >> Initializing global attention on CLS token...\n",
            " 89% 7390/8340 [1:51:46<13:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:11,842 >> Initializing global attention on CLS token...\n",
            " 89% 7391/8340 [1:51:47<13:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:12,679 >> Initializing global attention on CLS token...\n",
            " 89% 7392/8340 [1:51:47<13:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:13,512 >> Initializing global attention on CLS token...\n",
            " 89% 7393/8340 [1:51:48<13:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:14,344 >> Initializing global attention on CLS token...\n",
            " 89% 7394/8340 [1:51:49<13:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:15,181 >> Initializing global attention on CLS token...\n",
            " 89% 7395/8340 [1:51:50<13:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:16,020 >> Initializing global attention on CLS token...\n",
            " 89% 7396/8340 [1:51:51<13:10,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:16,859 >> Initializing global attention on CLS token...\n",
            " 89% 7397/8340 [1:51:52<13:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:17,694 >> Initializing global attention on CLS token...\n",
            " 89% 7398/8340 [1:51:52<13:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:18,536 >> Initializing global attention on CLS token...\n",
            " 89% 7399/8340 [1:51:53<13:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:19,375 >> Initializing global attention on CLS token...\n",
            " 89% 7400/8340 [1:51:54<13:06,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:20,209 >> Initializing global attention on CLS token...\n",
            " 89% 7401/8340 [1:51:55<13:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:21,044 >> Initializing global attention on CLS token...\n",
            " 89% 7402/8340 [1:51:56<13:05,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:21,881 >> Initializing global attention on CLS token...\n",
            " 89% 7403/8340 [1:51:57<13:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:22,720 >> Initializing global attention on CLS token...\n",
            " 89% 7404/8340 [1:51:57<13:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:23,558 >> Initializing global attention on CLS token...\n",
            " 89% 7405/8340 [1:51:58<13:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:24,395 >> Initializing global attention on CLS token...\n",
            " 89% 7406/8340 [1:51:59<13:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:25,229 >> Initializing global attention on CLS token...\n",
            " 89% 7407/8340 [1:52:00<12:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:26,061 >> Initializing global attention on CLS token...\n",
            " 89% 7408/8340 [1:52:01<12:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:26,899 >> Initializing global attention on CLS token...\n",
            " 89% 7409/8340 [1:52:02<12:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:27,735 >> Initializing global attention on CLS token...\n",
            " 89% 7410/8340 [1:52:02<12:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:28,569 >> Initializing global attention on CLS token...\n",
            " 89% 7411/8340 [1:52:03<12:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:29,405 >> Initializing global attention on CLS token...\n",
            " 89% 7412/8340 [1:52:04<12:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:30,239 >> Initializing global attention on CLS token...\n",
            " 89% 7413/8340 [1:52:05<12:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:31,071 >> Initializing global attention on CLS token...\n",
            " 89% 7414/8340 [1:52:06<12:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:31,907 >> Initializing global attention on CLS token...\n",
            " 89% 7415/8340 [1:52:07<12:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:32,743 >> Initializing global attention on CLS token...\n",
            " 89% 7416/8340 [1:52:07<12:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:33,577 >> Initializing global attention on CLS token...\n",
            " 89% 7417/8340 [1:52:08<12:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:34,414 >> Initializing global attention on CLS token...\n",
            " 89% 7418/8340 [1:52:09<12:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:35,252 >> Initializing global attention on CLS token...\n",
            " 89% 7419/8340 [1:52:10<12:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:36,091 >> Initializing global attention on CLS token...\n",
            " 89% 7420/8340 [1:52:11<12:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:36,925 >> Initializing global attention on CLS token...\n",
            " 89% 7421/8340 [1:52:12<12:49,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:37,764 >> Initializing global attention on CLS token...\n",
            " 89% 7422/8340 [1:52:12<12:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:38,604 >> Initializing global attention on CLS token...\n",
            " 89% 7423/8340 [1:52:13<12:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:39,435 >> Initializing global attention on CLS token...\n",
            " 89% 7424/8340 [1:52:14<12:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:40,275 >> Initializing global attention on CLS token...\n",
            " 89% 7425/8340 [1:52:15<12:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:41,110 >> Initializing global attention on CLS token...\n",
            " 89% 7426/8340 [1:52:16<12:45,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:41,947 >> Initializing global attention on CLS token...\n",
            " 89% 7427/8340 [1:52:17<12:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:42,781 >> Initializing global attention on CLS token...\n",
            " 89% 7428/8340 [1:52:18<12:42,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:43,615 >> Initializing global attention on CLS token...\n",
            " 89% 7429/8340 [1:52:18<12:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:44,450 >> Initializing global attention on CLS token...\n",
            " 89% 7430/8340 [1:52:19<12:40,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:45,288 >> Initializing global attention on CLS token...\n",
            " 89% 7431/8340 [1:52:20<12:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:46,122 >> Initializing global attention on CLS token...\n",
            " 89% 7432/8340 [1:52:21<12:37,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:46,952 >> Initializing global attention on CLS token...\n",
            " 89% 7433/8340 [1:52:22<12:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:47,787 >> Initializing global attention on CLS token...\n",
            " 89% 7434/8340 [1:52:23<12:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:48,622 >> Initializing global attention on CLS token...\n",
            " 89% 7435/8340 [1:52:23<12:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:49,459 >> Initializing global attention on CLS token...\n",
            " 89% 7436/8340 [1:52:24<12:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:50,293 >> Initializing global attention on CLS token...\n",
            " 89% 7437/8340 [1:52:25<12:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:51,129 >> Initializing global attention on CLS token...\n",
            " 89% 7438/8340 [1:52:26<12:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:51,965 >> Initializing global attention on CLS token...\n",
            " 89% 7439/8340 [1:52:27<12:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:52,798 >> Initializing global attention on CLS token...\n",
            " 89% 7440/8340 [1:52:28<12:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:53,631 >> Initializing global attention on CLS token...\n",
            " 89% 7441/8340 [1:52:28<12:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:54,465 >> Initializing global attention on CLS token...\n",
            " 89% 7442/8340 [1:52:29<12:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:55,297 >> Initializing global attention on CLS token...\n",
            " 89% 7443/8340 [1:52:30<12:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:56,132 >> Initializing global attention on CLS token...\n",
            " 89% 7444/8340 [1:52:31<12:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:56,965 >> Initializing global attention on CLS token...\n",
            " 89% 7445/8340 [1:52:32<12:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:57,800 >> Initializing global attention on CLS token...\n",
            " 89% 7446/8340 [1:52:33<12:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:58,634 >> Initializing global attention on CLS token...\n",
            " 89% 7447/8340 [1:52:33<12:24,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:55:59,474 >> Initializing global attention on CLS token...\n",
            " 89% 7448/8340 [1:52:34<12:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:00,314 >> Initializing global attention on CLS token...\n",
            " 89% 7449/8340 [1:52:35<12:26,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:01,152 >> Initializing global attention on CLS token...\n",
            " 89% 7450/8340 [1:52:36<12:25,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:01,988 >> Initializing global attention on CLS token...\n",
            " 89% 7451/8340 [1:52:37<12:23,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:02,821 >> Initializing global attention on CLS token...\n",
            " 89% 7452/8340 [1:52:38<12:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:03,655 >> Initializing global attention on CLS token...\n",
            " 89% 7453/8340 [1:52:38<12:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:04,488 >> Initializing global attention on CLS token...\n",
            " 89% 7454/8340 [1:52:39<12:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:05,324 >> Initializing global attention on CLS token...\n",
            " 89% 7455/8340 [1:52:40<12:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:06,162 >> Initializing global attention on CLS token...\n",
            " 89% 7456/8340 [1:52:41<12:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:07,000 >> Initializing global attention on CLS token...\n",
            " 89% 7457/8340 [1:52:42<12:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:07,837 >> Initializing global attention on CLS token...\n",
            " 89% 7458/8340 [1:52:43<12:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:08,682 >> Initializing global attention on CLS token...\n",
            " 89% 7459/8340 [1:52:43<12:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:09,525 >> Initializing global attention on CLS token...\n",
            " 89% 7460/8340 [1:52:44<12:19,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:10,362 >> Initializing global attention on CLS token...\n",
            " 89% 7461/8340 [1:52:45<12:18,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:11,204 >> Initializing global attention on CLS token...\n",
            " 89% 7462/8340 [1:52:46<12:16,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:12,037 >> Initializing global attention on CLS token...\n",
            " 89% 7463/8340 [1:52:47<12:14,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:12,872 >> Initializing global attention on CLS token...\n",
            " 89% 7464/8340 [1:52:48<12:13,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:13,707 >> Initializing global attention on CLS token...\n",
            " 90% 7465/8340 [1:52:48<12:12,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:14,544 >> Initializing global attention on CLS token...\n",
            " 90% 7466/8340 [1:52:49<12:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:15,379 >> Initializing global attention on CLS token...\n",
            " 90% 7467/8340 [1:52:50<12:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:16,214 >> Initializing global attention on CLS token...\n",
            " 90% 7468/8340 [1:52:51<12:08,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:17,049 >> Initializing global attention on CLS token...\n",
            " 90% 7469/8340 [1:52:52<12:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:17,880 >> Initializing global attention on CLS token...\n",
            " 90% 7470/8340 [1:52:53<12:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:18,713 >> Initializing global attention on CLS token...\n",
            " 90% 7471/8340 [1:52:53<12:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:19,547 >> Initializing global attention on CLS token...\n",
            " 90% 7472/8340 [1:52:54<12:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:20,376 >> Initializing global attention on CLS token...\n",
            " 90% 7473/8340 [1:52:55<12:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:21,214 >> Initializing global attention on CLS token...\n",
            " 90% 7474/8340 [1:52:56<12:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:22,048 >> Initializing global attention on CLS token...\n",
            " 90% 7475/8340 [1:52:57<12:02,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:22,890 >> Initializing global attention on CLS token...\n",
            " 90% 7476/8340 [1:52:58<12:03,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:23,728 >> Initializing global attention on CLS token...\n",
            " 90% 7477/8340 [1:52:58<12:01,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:24,562 >> Initializing global attention on CLS token...\n",
            " 90% 7478/8340 [1:52:59<12:00,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:25,395 >> Initializing global attention on CLS token...\n",
            " 90% 7479/8340 [1:53:00<11:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:26,227 >> Initializing global attention on CLS token...\n",
            " 90% 7480/8340 [1:53:01<11:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:27,063 >> Initializing global attention on CLS token...\n",
            " 90% 7481/8340 [1:53:02<11:57,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:27,900 >> Initializing global attention on CLS token...\n",
            " 90% 7482/8340 [1:53:03<11:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:28,736 >> Initializing global attention on CLS token...\n",
            " 90% 7483/8340 [1:53:03<11:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:29,568 >> Initializing global attention on CLS token...\n",
            " 90% 7484/8340 [1:53:04<11:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:30,404 >> Initializing global attention on CLS token...\n",
            " 90% 7485/8340 [1:53:05<11:53,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:31,237 >> Initializing global attention on CLS token...\n",
            " 90% 7486/8340 [1:53:06<11:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:32,073 >> Initializing global attention on CLS token...\n",
            " 90% 7487/8340 [1:53:07<11:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:32,908 >> Initializing global attention on CLS token...\n",
            " 90% 7488/8340 [1:53:08<11:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:33,739 >> Initializing global attention on CLS token...\n",
            " 90% 7489/8340 [1:53:08<11:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:34,575 >> Initializing global attention on CLS token...\n",
            " 90% 7490/8340 [1:53:09<11:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:35,413 >> Initializing global attention on CLS token...\n",
            " 90% 7491/8340 [1:53:10<11:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:36,250 >> Initializing global attention on CLS token...\n",
            " 90% 7492/8340 [1:53:11<11:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:37,086 >> Initializing global attention on CLS token...\n",
            " 90% 7493/8340 [1:53:12<11:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:37,923 >> Initializing global attention on CLS token...\n",
            " 90% 7494/8340 [1:53:13<11:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:38,756 >> Initializing global attention on CLS token...\n",
            " 90% 7495/8340 [1:53:13<11:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:39,594 >> Initializing global attention on CLS token...\n",
            " 90% 7496/8340 [1:53:14<11:45,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:40,430 >> Initializing global attention on CLS token...\n",
            " 90% 7497/8340 [1:53:15<11:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:41,263 >> Initializing global attention on CLS token...\n",
            " 90% 7498/8340 [1:53:16<11:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:42,090 >> Initializing global attention on CLS token...\n",
            " 90% 7499/8340 [1:53:17<11:41,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:42,927 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0382, 'learning_rate': 3.0431654676258995e-06, 'epoch': 8.99}\n",
            " 90% 7500/8340 [1:53:18<12:09,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:43,892 >> Initializing global attention on CLS token...\n",
            " 90% 7501/8340 [1:53:19<12:03,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:44,726 >> Initializing global attention on CLS token...\n",
            " 90% 7502/8340 [1:53:19<11:56,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:45,562 >> Initializing global attention on CLS token...\n",
            " 90% 7503/8340 [1:53:20<11:50,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:46,395 >> Initializing global attention on CLS token...\n",
            " 90% 7504/8340 [1:53:21<11:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:47,229 >> Initializing global attention on CLS token...\n",
            " 90% 7505/8340 [1:53:22<11:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:56:48,044 >> Initializing global attention on CLS token...\n",
            " 90% 7506/8340 [1:53:22<09:27,  1.47it/s][INFO|trainer.py:725] 2022-12-08 17:56:48,339 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-08 17:56:48,341 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-08 17:56:48,341 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-08 17:56:48,342 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:48,372 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:48,625 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:29,  7.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:48,882 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:41,  5.54it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:49,136 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:48,  4.78it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:49,393 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:51,  4.46it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:49,645 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:53,  4.27it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:49,900 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:54,  4.16it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:50,152 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:55,  4.09it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:50,409 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:55,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:50,662 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:55,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:50,921 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:56,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:51,173 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:56,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:51,431 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:56,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:51,687 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:55,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:51,939 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:55,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:52,195 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:55,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:52,449 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:55,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:52,710 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:55,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:52,964 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:54,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:53,230 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:55,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:53,483 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:54,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:53,744 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:54,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:53,996 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:54,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:54,261 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:54,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:54,516 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:53,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:54,774 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:53,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:55,029 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:53,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:55,282 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:52,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:55,536 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:52,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:55,789 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:51,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:56,046 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:51,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:56,299 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:51,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:56,559 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:51,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:56,813 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:51,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:57,066 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:50,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:57,318 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:50,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:57,569 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:49,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:57,820 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:49,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:58,071 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:49,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:58,323 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:48,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:58,575 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:48,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:58,828 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:48,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:59,079 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:48,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:59,333 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:48,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:59,600 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:48,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:56:59,852 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:48,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:00,108 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:47,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:00,361 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:11<00:47,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:00,616 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:47,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:00,868 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:46,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:01,126 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:46,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:01,379 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:13<00:46,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:01,635 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:45,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:01,897 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:46,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:02,152 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:45,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:02,406 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:14<00:45,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:02,657 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:02,924 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:45,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:03,177 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:03,433 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:15<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:03,685 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:43,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:03,935 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:43,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:04,188 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:04,451 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:16<00:43,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:04,703 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:42,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:04,958 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:42,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:05,208 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:42,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:05,460 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:17<00:42,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:05,712 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:41,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:05,963 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:41,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:06,216 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:41,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:06,470 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:18<00:40,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:06,724 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:40,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:06,977 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:40,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:07,233 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:40,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:07,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:19<00:40,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:07,745 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:40,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:07,999 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:39,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:08,257 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:39,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:08,523 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:20<00:39,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:08,782 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:39,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:09,038 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:39,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:09,292 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:38,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:09,547 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:21<00:38,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:09,806 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:38,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:10,065 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:38,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:10,332 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:21<00:38,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:10,589 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:22<00:37,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:10,846 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:37,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:11,100 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:36,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:11,361 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:22<00:36,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:11,615 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:23<00:36,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:11,870 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:36,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:12,123 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:35,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:12,384 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:24<00:35,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:12,638 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:24<00:35,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:12,902 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:35,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:13,156 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:35,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:13,410 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:25<00:34,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:13,661 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:25<00:34,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:13,919 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:33,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:14,172 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:33,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:14,425 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:26<00:33,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:14,680 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:26<00:33,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:14,932 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:32,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:15,183 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:32,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:15,441 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:27<00:32,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:15,695 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:27<00:32,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:15,953 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:31,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:16,207 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:31,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:16,470 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:28<00:31,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:16,727 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:28<00:31,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:16,982 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:31,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:17,255 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:31,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:17,507 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:29<00:30,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:17,758 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:29<00:30,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:18,011 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:29,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:18,261 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:29,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:18,509 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:30<00:29,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:18,763 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:30<00:28,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:19,014 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:28,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:19,270 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:30<00:28,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:19,521 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:31<00:28,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:19,780 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:31<00:27,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:20,031 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:31<00:27,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:20,283 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:31<00:27,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:20,534 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:32<00:27,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:20,789 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:32<00:26,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:21,040 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:32<00:26,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:21,295 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:32<00:26,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:21,548 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:33<00:26,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:21,801 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:33<00:25,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:22,055 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:33<00:25,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:22,308 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:33<00:25,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:22,563 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:34<00:25,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:22,820 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:34<00:24,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:23,074 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:34<00:24,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:23,328 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:34<00:24,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:23,583 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:35<00:24,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:23,836 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:35<00:23,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:24,102 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:35<00:23,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:24,362 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:35<00:23,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:24,614 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:36<00:23,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:24,864 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:36<00:22,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:25,119 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:36<00:22,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:25,369 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:37<00:22,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:25,626 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:37<00:22,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:25,877 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:37<00:21,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:26,138 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:37<00:21,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:26,390 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:38<00:21,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:26,643 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:38<00:21,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:26,895 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:38<00:20,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:27,150 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:38<00:20,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:27,407 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:39<00:20,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:27,665 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:39<00:20,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:27,920 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:39<00:19,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:28,173 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:39<00:19,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:28,439 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:40<00:19,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:28,694 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:40<00:19,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:28,970 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:40<00:19,  3.80it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:29,226 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:40<00:18,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:29,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:41<00:18,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:29,742 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:41<00:18,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:29,992 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:41<00:17,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:30,259 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:41<00:17,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:30,515 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:42<00:17,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:30,769 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:42<00:17,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:31,019 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:42<00:16,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:31,274 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:42<00:16,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:31,526 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:43<00:16,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:31,782 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:43<00:16,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:32,033 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:43<00:15,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:32,287 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:43<00:15,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:32,536 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:44<00:15,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:32,792 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:44<00:14,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:33,042 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:44<00:14,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:33,297 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:44<00:14,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:33,548 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:45<00:14,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:33,810 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:45<00:14,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:34,064 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:45<00:13,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:34,319 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:45<00:13,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:34,573 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:46<00:13,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:34,829 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:46<00:12,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:35,085 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:46<00:12,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:35,341 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:46<00:12,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:35,596 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:47<00:12,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:35,846 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:47<00:11,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:36,104 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:47<00:11,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:36,355 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:47<00:11,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:36,612 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:48<00:11,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:36,863 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:48<00:10,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:37,114 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:48<00:10,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:37,366 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:48<00:10,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:37,618 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:49<00:10,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:37,872 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:49<00:09,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:38,126 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:49<00:09,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:38,379 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:50<00:09,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:38,631 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:50<00:09,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:38,885 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:50<00:08,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:39,138 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:50<00:08,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:39,392 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:51<00:08,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:39,647 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:51<00:08,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:39,901 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:51<00:07,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:40,164 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:51<00:07,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:40,418 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:52<00:07,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:40,672 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:52<00:07,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:40,926 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:52<00:06,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:41,180 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:52<00:06,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:41,432 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:53<00:06,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:41,681 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:53<00:06,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:41,940 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:53<00:05,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:42,193 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:53<00:05,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:42,450 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:54<00:05,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:42,705 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:54<00:05,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:42,970 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:54<00:04,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:43,224 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:54<00:04,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:43,484 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:55<00:04,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:43,739 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:55<00:04,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:43,997 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:55<00:03,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:44,253 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:55<00:03,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:44,504 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:56<00:03,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:44,763 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:56<00:03,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:45,016 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:56<00:02,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:45,271 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:56<00:02,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:45,525 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:57<00:02,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:45,779 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:57<00:02,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:46,034 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:57<00:01,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:46,288 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:57<00:01,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:46,544 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:58<00:01,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:46,797 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:58<00:01,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:47,049 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:58<00:00,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:47,307 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:58<00:00,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:47,561 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:59<00:00,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:47,794 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.6523306369781494, 'eval_f1-micro': 0.7692857142857142, 'eval_f1-macro': 0.6899470484273068, 'eval_runtime': 60.8527, 'eval_samples_per_second': 23.006, 'eval_steps_per_second': 3.845, 'epoch': 9.0}\n",
            " 90% 7506/8340 [1:54:23<09:27,  1.47it/s]\n",
            "100% 234/234 [01:00<00:00,  3.93it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-08 17:57:49,196 >> Saving model checkpoint to logs/output_1/checkpoint-7506\n",
            "[INFO|configuration_utils.py:447] 2022-12-08 17:57:49,197 >> Configuration saved in logs/output_1/checkpoint-7506/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-08 17:57:49,425 >> Model weights saved in logs/output_1/checkpoint-7506/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-08 17:57:49,425 >> tokenizer config file saved in logs/output_1/checkpoint-7506/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-08 17:57:49,426 >> Special tokens file saved in logs/output_1/checkpoint-7506/special_tokens_map.json\n",
            "[INFO|trainer.py:1852] 2022-12-08 17:57:50,143 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1946] 2022-12-08 17:57:50,144 >> Loading best model from logs/output_1/checkpoint-3336 (score: 0.775).\n",
            "{'train_runtime': 6864.6878, 'train_samples_per_second': 7.284, 'train_steps_per_second': 1.215, 'train_loss': 0.35042904912018413, 'epoch': 9.0}\n",
            " 90% 7506/8340 [1:54:24<12:42,  1.09it/s]\n",
            "[INFO|trainer.py:725] 2022-12-08 17:57:50,266 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-08 17:57:50,268 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-08 17:57:50,268 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-08 17:57:50,268 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-08 17:57:50,313 >> Initializing global attention on CLS token...\n",
            "  0% 0/234 [00:00<?, ?it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:50,633 >> Initializing global attention on CLS token...\n",
            "  1% 2/234 [00:00<00:29,  7.97it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:50,884 >> Initializing global attention on CLS token...\n",
            "  1% 3/234 [00:00<00:41,  5.59it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:51,140 >> Initializing global attention on CLS token...\n",
            "  2% 4/234 [00:00<00:47,  4.84it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:51,390 >> Initializing global attention on CLS token...\n",
            "  2% 5/234 [00:01<00:50,  4.50it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:51,647 >> Initializing global attention on CLS token...\n",
            "  3% 6/234 [00:01<00:53,  4.28it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:51,898 >> Initializing global attention on CLS token...\n",
            "  3% 7/234 [00:01<00:54,  4.18it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:52,151 >> Initializing global attention on CLS token...\n",
            "  3% 8/234 [00:01<00:54,  4.11it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:52,401 >> Initializing global attention on CLS token...\n",
            "  4% 9/234 [00:02<00:55,  4.06it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:52,658 >> Initializing global attention on CLS token...\n",
            "  4% 10/234 [00:02<00:55,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:52,910 >> Initializing global attention on CLS token...\n",
            "  5% 11/234 [00:02<00:55,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:53,163 >> Initializing global attention on CLS token...\n",
            "  5% 12/234 [00:02<00:56,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:53,426 >> Initializing global attention on CLS token...\n",
            "  6% 13/234 [00:03<00:56,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:53,678 >> Initializing global attention on CLS token...\n",
            "  6% 14/234 [00:03<00:55,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:53,940 >> Initializing global attention on CLS token...\n",
            "  6% 15/234 [00:03<00:55,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:54,190 >> Initializing global attention on CLS token...\n",
            "  7% 16/234 [00:03<00:55,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:54,449 >> Initializing global attention on CLS token...\n",
            "  7% 17/234 [00:04<00:55,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:54,699 >> Initializing global attention on CLS token...\n",
            "  8% 18/234 [00:04<00:54,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:54,955 >> Initializing global attention on CLS token...\n",
            "  8% 19/234 [00:04<00:54,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:55,206 >> Initializing global attention on CLS token...\n",
            "  9% 20/234 [00:04<00:54,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:55,459 >> Initializing global attention on CLS token...\n",
            "  9% 21/234 [00:05<00:54,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:55,724 >> Initializing global attention on CLS token...\n",
            "  9% 22/234 [00:05<00:54,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:55,997 >> Initializing global attention on CLS token...\n",
            " 10% 23/234 [00:05<00:55,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:56,253 >> Initializing global attention on CLS token...\n",
            " 10% 24/234 [00:05<00:54,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:56,509 >> Initializing global attention on CLS token...\n",
            " 11% 25/234 [00:06<00:54,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:56,763 >> Initializing global attention on CLS token...\n",
            " 11% 26/234 [00:06<00:53,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:57,030 >> Initializing global attention on CLS token...\n",
            " 12% 27/234 [00:06<00:53,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:57,283 >> Initializing global attention on CLS token...\n",
            " 12% 28/234 [00:06<00:53,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:57,540 >> Initializing global attention on CLS token...\n",
            " 12% 29/234 [00:07<00:52,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:57,814 >> Initializing global attention on CLS token...\n",
            " 13% 30/234 [00:07<00:53,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:58,082 >> Initializing global attention on CLS token...\n",
            " 13% 31/234 [00:07<00:53,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:58,334 >> Initializing global attention on CLS token...\n",
            " 14% 32/234 [00:07<00:52,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:58,588 >> Initializing global attention on CLS token...\n",
            " 14% 33/234 [00:08<00:52,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:58,846 >> Initializing global attention on CLS token...\n",
            " 15% 34/234 [00:08<00:51,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:59,102 >> Initializing global attention on CLS token...\n",
            " 15% 35/234 [00:08<00:51,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:59,353 >> Initializing global attention on CLS token...\n",
            " 15% 36/234 [00:08<00:50,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:59,603 >> Initializing global attention on CLS token...\n",
            " 16% 37/234 [00:09<00:49,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:57:59,852 >> Initializing global attention on CLS token...\n",
            " 16% 38/234 [00:09<00:49,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:00,108 >> Initializing global attention on CLS token...\n",
            " 17% 39/234 [00:09<00:49,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:00,360 >> Initializing global attention on CLS token...\n",
            " 17% 40/234 [00:09<00:49,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:00,624 >> Initializing global attention on CLS token...\n",
            " 18% 41/234 [00:10<00:49,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:00,875 >> Initializing global attention on CLS token...\n",
            " 18% 42/234 [00:10<00:48,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:01,132 >> Initializing global attention on CLS token...\n",
            " 18% 43/234 [00:10<00:48,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:01,389 >> Initializing global attention on CLS token...\n",
            " 19% 44/234 [00:11<00:48,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:01,645 >> Initializing global attention on CLS token...\n",
            " 19% 45/234 [00:11<00:48,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:01,898 >> Initializing global attention on CLS token...\n",
            " 20% 46/234 [00:11<00:47,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:02,151 >> Initializing global attention on CLS token...\n",
            " 20% 47/234 [00:11<00:47,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:02,407 >> Initializing global attention on CLS token...\n",
            " 21% 48/234 [00:12<00:47,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:02,661 >> Initializing global attention on CLS token...\n",
            " 21% 49/234 [00:12<00:47,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:02,916 >> Initializing global attention on CLS token...\n",
            " 21% 50/234 [00:12<00:46,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:03,174 >> Initializing global attention on CLS token...\n",
            " 22% 51/234 [00:12<00:46,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:03,428 >> Initializing global attention on CLS token...\n",
            " 22% 52/234 [00:13<00:46,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:03,679 >> Initializing global attention on CLS token...\n",
            " 23% 53/234 [00:13<00:45,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:03,929 >> Initializing global attention on CLS token...\n",
            " 23% 54/234 [00:13<00:45,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:04,182 >> Initializing global attention on CLS token...\n",
            " 24% 55/234 [00:13<00:45,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:04,436 >> Initializing global attention on CLS token...\n",
            " 24% 56/234 [00:14<00:45,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:04,689 >> Initializing global attention on CLS token...\n",
            " 24% 57/234 [00:14<00:44,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:04,951 >> Initializing global attention on CLS token...\n",
            " 25% 58/234 [00:14<00:44,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:05,202 >> Initializing global attention on CLS token...\n",
            " 25% 59/234 [00:14<00:44,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:05,455 >> Initializing global attention on CLS token...\n",
            " 26% 60/234 [00:15<00:44,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:05,707 >> Initializing global attention on CLS token...\n",
            " 26% 61/234 [00:15<00:43,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:05,960 >> Initializing global attention on CLS token...\n",
            " 26% 62/234 [00:15<00:43,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:06,209 >> Initializing global attention on CLS token...\n",
            " 27% 63/234 [00:15<00:43,  3.97it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:06,464 >> Initializing global attention on CLS token...\n",
            " 27% 64/234 [00:16<00:43,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:06,716 >> Initializing global attention on CLS token...\n",
            " 28% 65/234 [00:16<00:42,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:06,967 >> Initializing global attention on CLS token...\n",
            " 28% 66/234 [00:16<00:42,  3.97it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:07,217 >> Initializing global attention on CLS token...\n",
            " 29% 67/234 [00:16<00:42,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:07,472 >> Initializing global attention on CLS token...\n",
            " 29% 68/234 [00:17<00:41,  3.97it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:07,722 >> Initializing global attention on CLS token...\n",
            " 29% 69/234 [00:17<00:41,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:07,978 >> Initializing global attention on CLS token...\n",
            " 30% 70/234 [00:17<00:41,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:08,231 >> Initializing global attention on CLS token...\n",
            " 30% 71/234 [00:17<00:41,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:08,490 >> Initializing global attention on CLS token...\n",
            " 31% 72/234 [00:18<00:41,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:08,741 >> Initializing global attention on CLS token...\n",
            " 31% 73/234 [00:18<00:40,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:08,995 >> Initializing global attention on CLS token...\n",
            " 32% 74/234 [00:18<00:40,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:09,245 >> Initializing global attention on CLS token...\n",
            " 32% 75/234 [00:18<00:40,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:09,506 >> Initializing global attention on CLS token...\n",
            " 32% 76/234 [00:19<00:40,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:09,762 >> Initializing global attention on CLS token...\n",
            " 33% 77/234 [00:19<00:39,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:10,017 >> Initializing global attention on CLS token...\n",
            " 33% 78/234 [00:19<00:39,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:10,273 >> Initializing global attention on CLS token...\n",
            " 34% 79/234 [00:19<00:39,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:10,525 >> Initializing global attention on CLS token...\n",
            " 34% 80/234 [00:20<00:39,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:10,779 >> Initializing global attention on CLS token...\n",
            " 35% 81/234 [00:20<00:39,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:11,033 >> Initializing global attention on CLS token...\n",
            " 35% 82/234 [00:20<00:38,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:11,286 >> Initializing global attention on CLS token...\n",
            " 35% 83/234 [00:20<00:38,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:11,539 >> Initializing global attention on CLS token...\n",
            " 36% 84/234 [00:21<00:38,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:11,792 >> Initializing global attention on CLS token...\n",
            " 36% 85/234 [00:21<00:37,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:12,047 >> Initializing global attention on CLS token...\n",
            " 37% 86/234 [00:21<00:37,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:12,299 >> Initializing global attention on CLS token...\n",
            " 37% 87/234 [00:21<00:37,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:12,554 >> Initializing global attention on CLS token...\n",
            " 38% 88/234 [00:22<00:37,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:12,812 >> Initializing global attention on CLS token...\n",
            " 38% 89/234 [00:22<00:37,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:13,068 >> Initializing global attention on CLS token...\n",
            " 38% 90/234 [00:22<00:36,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:13,323 >> Initializing global attention on CLS token...\n",
            " 39% 91/234 [00:22<00:36,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:13,580 >> Initializing global attention on CLS token...\n",
            " 39% 92/234 [00:23<00:36,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:13,834 >> Initializing global attention on CLS token...\n",
            " 40% 93/234 [00:23<00:35,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:14,088 >> Initializing global attention on CLS token...\n",
            " 40% 94/234 [00:23<00:35,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:14,350 >> Initializing global attention on CLS token...\n",
            " 41% 95/234 [00:23<00:35,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:14,605 >> Initializing global attention on CLS token...\n",
            " 41% 96/234 [00:24<00:35,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:14,859 >> Initializing global attention on CLS token...\n",
            " 41% 97/234 [00:24<00:34,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:15,109 >> Initializing global attention on CLS token...\n",
            " 42% 98/234 [00:24<00:34,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:15,363 >> Initializing global attention on CLS token...\n",
            " 42% 99/234 [00:24<00:34,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:15,626 >> Initializing global attention on CLS token...\n",
            " 43% 100/234 [00:25<00:34,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:15,878 >> Initializing global attention on CLS token...\n",
            " 43% 101/234 [00:25<00:33,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:16,140 >> Initializing global attention on CLS token...\n",
            " 44% 102/234 [00:25<00:33,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:16,393 >> Initializing global attention on CLS token...\n",
            " 44% 103/234 [00:26<00:33,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:16,645 >> Initializing global attention on CLS token...\n",
            " 44% 104/234 [00:26<00:33,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:16,898 >> Initializing global attention on CLS token...\n",
            " 45% 105/234 [00:26<00:32,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:17,151 >> Initializing global attention on CLS token...\n",
            " 45% 106/234 [00:26<00:32,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:17,406 >> Initializing global attention on CLS token...\n",
            " 46% 107/234 [00:27<00:32,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:17,667 >> Initializing global attention on CLS token...\n",
            " 46% 108/234 [00:27<00:32,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:17,919 >> Initializing global attention on CLS token...\n",
            " 47% 109/234 [00:27<00:31,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:18,174 >> Initializing global attention on CLS token...\n",
            " 47% 110/234 [00:27<00:31,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:18,425 >> Initializing global attention on CLS token...\n",
            " 47% 111/234 [00:28<00:31,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:18,676 >> Initializing global attention on CLS token...\n",
            " 48% 112/234 [00:28<00:30,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:18,929 >> Initializing global attention on CLS token...\n",
            " 48% 113/234 [00:28<00:30,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:19,182 >> Initializing global attention on CLS token...\n",
            " 49% 114/234 [00:28<00:30,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:19,437 >> Initializing global attention on CLS token...\n",
            " 49% 115/234 [00:29<00:30,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:19,690 >> Initializing global attention on CLS token...\n",
            " 50% 116/234 [00:29<00:29,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:19,945 >> Initializing global attention on CLS token...\n",
            " 50% 117/234 [00:29<00:29,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:20,199 >> Initializing global attention on CLS token...\n",
            " 50% 118/234 [00:29<00:29,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:20,456 >> Initializing global attention on CLS token...\n",
            " 51% 119/234 [00:30<00:29,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:20,713 >> Initializing global attention on CLS token...\n",
            " 51% 120/234 [00:30<00:29,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:20,972 >> Initializing global attention on CLS token...\n",
            " 52% 121/234 [00:30<00:29,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:21,233 >> Initializing global attention on CLS token...\n",
            " 52% 122/234 [00:30<00:28,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:21,488 >> Initializing global attention on CLS token...\n",
            " 53% 123/234 [00:31<00:28,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:21,740 >> Initializing global attention on CLS token...\n",
            " 53% 124/234 [00:31<00:28,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:21,996 >> Initializing global attention on CLS token...\n",
            " 53% 125/234 [00:31<00:27,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:22,248 >> Initializing global attention on CLS token...\n",
            " 54% 126/234 [00:31<00:27,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:22,501 >> Initializing global attention on CLS token...\n",
            " 54% 127/234 [00:32<00:27,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:22,751 >> Initializing global attention on CLS token...\n",
            " 55% 128/234 [00:32<00:26,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:23,009 >> Initializing global attention on CLS token...\n",
            " 55% 129/234 [00:32<00:26,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:23,265 >> Initializing global attention on CLS token...\n",
            " 56% 130/234 [00:32<00:26,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:23,521 >> Initializing global attention on CLS token...\n",
            " 56% 131/234 [00:33<00:26,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:23,775 >> Initializing global attention on CLS token...\n",
            " 56% 132/234 [00:33<00:26,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:24,032 >> Initializing global attention on CLS token...\n",
            " 57% 133/234 [00:33<00:25,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:24,287 >> Initializing global attention on CLS token...\n",
            " 57% 134/234 [00:33<00:25,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:24,545 >> Initializing global attention on CLS token...\n",
            " 58% 135/234 [00:34<00:25,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:24,801 >> Initializing global attention on CLS token...\n",
            " 58% 136/234 [00:34<00:25,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:25,057 >> Initializing global attention on CLS token...\n",
            " 59% 137/234 [00:34<00:24,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:25,313 >> Initializing global attention on CLS token...\n",
            " 59% 138/234 [00:34<00:24,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:25,568 >> Initializing global attention on CLS token...\n",
            " 59% 139/234 [00:35<00:24,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:25,822 >> Initializing global attention on CLS token...\n",
            " 60% 140/234 [00:35<00:24,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:26,076 >> Initializing global attention on CLS token...\n",
            " 60% 141/234 [00:35<00:23,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:26,338 >> Initializing global attention on CLS token...\n",
            " 61% 142/234 [00:35<00:23,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:26,591 >> Initializing global attention on CLS token...\n",
            " 61% 143/234 [00:36<00:23,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:26,845 >> Initializing global attention on CLS token...\n",
            " 62% 144/234 [00:36<00:22,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:27,099 >> Initializing global attention on CLS token...\n",
            " 62% 145/234 [00:36<00:22,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:27,355 >> Initializing global attention on CLS token...\n",
            " 62% 146/234 [00:36<00:22,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:27,608 >> Initializing global attention on CLS token...\n",
            " 63% 147/234 [00:37<00:22,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:27,865 >> Initializing global attention on CLS token...\n",
            " 63% 148/234 [00:37<00:21,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:28,120 >> Initializing global attention on CLS token...\n",
            " 64% 149/234 [00:37<00:21,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:28,377 >> Initializing global attention on CLS token...\n",
            " 64% 150/234 [00:37<00:21,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:28,633 >> Initializing global attention on CLS token...\n",
            " 65% 151/234 [00:38<00:21,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:28,886 >> Initializing global attention on CLS token...\n",
            " 65% 152/234 [00:38<00:20,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:29,145 >> Initializing global attention on CLS token...\n",
            " 65% 153/234 [00:38<00:20,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:29,396 >> Initializing global attention on CLS token...\n",
            " 66% 154/234 [00:39<00:20,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:29,646 >> Initializing global attention on CLS token...\n",
            " 66% 155/234 [00:39<00:20,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:29,898 >> Initializing global attention on CLS token...\n",
            " 67% 156/234 [00:39<00:19,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:30,151 >> Initializing global attention on CLS token...\n",
            " 67% 157/234 [00:39<00:19,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:30,405 >> Initializing global attention on CLS token...\n",
            " 68% 158/234 [00:40<00:19,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:30,666 >> Initializing global attention on CLS token...\n",
            " 68% 159/234 [00:40<00:19,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:30,922 >> Initializing global attention on CLS token...\n",
            " 68% 160/234 [00:40<00:18,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:31,175 >> Initializing global attention on CLS token...\n",
            " 69% 161/234 [00:40<00:18,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:31,429 >> Initializing global attention on CLS token...\n",
            " 69% 162/234 [00:41<00:18,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:31,685 >> Initializing global attention on CLS token...\n",
            " 70% 163/234 [00:41<00:18,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:31,936 >> Initializing global attention on CLS token...\n",
            " 70% 164/234 [00:41<00:17,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:32,192 >> Initializing global attention on CLS token...\n",
            " 71% 165/234 [00:41<00:17,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:32,444 >> Initializing global attention on CLS token...\n",
            " 71% 166/234 [00:42<00:17,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:32,699 >> Initializing global attention on CLS token...\n",
            " 71% 167/234 [00:42<00:17,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:32,959 >> Initializing global attention on CLS token...\n",
            " 72% 168/234 [00:42<00:16,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:33,214 >> Initializing global attention on CLS token...\n",
            " 72% 169/234 [00:42<00:16,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:33,466 >> Initializing global attention on CLS token...\n",
            " 73% 170/234 [00:43<00:16,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:33,720 >> Initializing global attention on CLS token...\n",
            " 73% 171/234 [00:43<00:15,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:33,972 >> Initializing global attention on CLS token...\n",
            " 74% 172/234 [00:43<00:15,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:34,229 >> Initializing global attention on CLS token...\n",
            " 74% 173/234 [00:43<00:15,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:34,484 >> Initializing global attention on CLS token...\n",
            " 74% 174/234 [00:44<00:15,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:34,738 >> Initializing global attention on CLS token...\n",
            " 75% 175/234 [00:44<00:14,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:34,992 >> Initializing global attention on CLS token...\n",
            " 75% 176/234 [00:44<00:14,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:35,245 >> Initializing global attention on CLS token...\n",
            " 76% 177/234 [00:44<00:14,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:35,503 >> Initializing global attention on CLS token...\n",
            " 76% 178/234 [00:45<00:14,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:35,755 >> Initializing global attention on CLS token...\n",
            " 76% 179/234 [00:45<00:13,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:36,011 >> Initializing global attention on CLS token...\n",
            " 77% 180/234 [00:45<00:13,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:36,263 >> Initializing global attention on CLS token...\n",
            " 77% 181/234 [00:45<00:13,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:36,517 >> Initializing global attention on CLS token...\n",
            " 78% 182/234 [00:46<00:13,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:36,768 >> Initializing global attention on CLS token...\n",
            " 78% 183/234 [00:46<00:12,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:37,021 >> Initializing global attention on CLS token...\n",
            " 79% 184/234 [00:46<00:12,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:37,274 >> Initializing global attention on CLS token...\n",
            " 79% 185/234 [00:46<00:12,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:37,539 >> Initializing global attention on CLS token...\n",
            " 79% 186/234 [00:47<00:12,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:37,793 >> Initializing global attention on CLS token...\n",
            " 80% 187/234 [00:47<00:12,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:38,050 >> Initializing global attention on CLS token...\n",
            " 80% 188/234 [00:47<00:11,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:38,304 >> Initializing global attention on CLS token...\n",
            " 81% 189/234 [00:47<00:11,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:38,557 >> Initializing global attention on CLS token...\n",
            " 81% 190/234 [00:48<00:11,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:38,808 >> Initializing global attention on CLS token...\n",
            " 82% 191/234 [00:48<00:10,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:39,063 >> Initializing global attention on CLS token...\n",
            " 82% 192/234 [00:48<00:10,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:39,318 >> Initializing global attention on CLS token...\n",
            " 82% 193/234 [00:48<00:10,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:39,575 >> Initializing global attention on CLS token...\n",
            " 83% 194/234 [00:49<00:10,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:39,829 >> Initializing global attention on CLS token...\n",
            " 83% 195/234 [00:49<00:09,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:40,079 >> Initializing global attention on CLS token...\n",
            " 84% 196/234 [00:49<00:09,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:40,332 >> Initializing global attention on CLS token...\n",
            " 84% 197/234 [00:49<00:09,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:40,587 >> Initializing global attention on CLS token...\n",
            " 85% 198/234 [00:50<00:09,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:40,845 >> Initializing global attention on CLS token...\n",
            " 85% 199/234 [00:50<00:08,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:41,099 >> Initializing global attention on CLS token...\n",
            " 85% 200/234 [00:50<00:08,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:41,362 >> Initializing global attention on CLS token...\n",
            " 86% 201/234 [00:50<00:08,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:41,613 >> Initializing global attention on CLS token...\n",
            " 86% 202/234 [00:51<00:08,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:41,868 >> Initializing global attention on CLS token...\n",
            " 87% 203/234 [00:51<00:07,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:42,119 >> Initializing global attention on CLS token...\n",
            " 87% 204/234 [00:51<00:07,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:42,371 >> Initializing global attention on CLS token...\n",
            " 88% 205/234 [00:51<00:07,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:42,625 >> Initializing global attention on CLS token...\n",
            " 88% 206/234 [00:52<00:07,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:42,878 >> Initializing global attention on CLS token...\n",
            " 88% 207/234 [00:52<00:06,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:43,129 >> Initializing global attention on CLS token...\n",
            " 89% 208/234 [00:52<00:06,  3.97it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:43,390 >> Initializing global attention on CLS token...\n",
            " 89% 209/234 [00:53<00:06,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:43,647 >> Initializing global attention on CLS token...\n",
            " 90% 210/234 [00:53<00:06,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:43,905 >> Initializing global attention on CLS token...\n",
            " 90% 211/234 [00:53<00:05,  3.91it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:44,160 >> Initializing global attention on CLS token...\n",
            " 91% 212/234 [00:53<00:05,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:44,414 >> Initializing global attention on CLS token...\n",
            " 91% 213/234 [00:54<00:05,  3.92it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:44,675 >> Initializing global attention on CLS token...\n",
            " 91% 214/234 [00:54<00:05,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:44,932 >> Initializing global attention on CLS token...\n",
            " 92% 215/234 [00:54<00:04,  3.89it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:45,190 >> Initializing global attention on CLS token...\n",
            " 92% 216/234 [00:54<00:04,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:45,445 >> Initializing global attention on CLS token...\n",
            " 93% 217/234 [00:55<00:04,  3.90it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:45,715 >> Initializing global attention on CLS token...\n",
            " 93% 218/234 [00:55<00:04,  3.84it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:45,970 >> Initializing global attention on CLS token...\n",
            " 94% 219/234 [00:55<00:03,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:46,242 >> Initializing global attention on CLS token...\n",
            " 94% 220/234 [00:55<00:03,  3.80it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:46,500 >> Initializing global attention on CLS token...\n",
            " 94% 221/234 [00:56<00:03,  3.82it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:46,764 >> Initializing global attention on CLS token...\n",
            " 95% 222/234 [00:56<00:03,  3.82it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:47,035 >> Initializing global attention on CLS token...\n",
            " 95% 223/234 [00:56<00:02,  3.78it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:47,298 >> Initializing global attention on CLS token...\n",
            " 96% 224/234 [00:56<00:02,  3.77it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:47,565 >> Initializing global attention on CLS token...\n",
            " 96% 225/234 [00:57<00:02,  3.77it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:47,822 >> Initializing global attention on CLS token...\n",
            " 97% 226/234 [00:57<00:02,  3.83it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:48,072 >> Initializing global attention on CLS token...\n",
            " 97% 227/234 [00:57<00:01,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:48,336 >> Initializing global attention on CLS token...\n",
            " 97% 228/234 [00:57<00:01,  3.85it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:48,586 >> Initializing global attention on CLS token...\n",
            " 98% 229/234 [00:58<00:01,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:48,850 >> Initializing global attention on CLS token...\n",
            " 98% 230/234 [00:58<00:01,  3.86it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:49,107 >> Initializing global attention on CLS token...\n",
            " 99% 231/234 [00:58<00:00,  3.88it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:49,357 >> Initializing global attention on CLS token...\n",
            " 99% 232/234 [00:58<00:00,  3.93it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:49,604 >> Initializing global attention on CLS token...\n",
            "100% 233/234 [00:59<00:00,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-08 17:58:49,832 >> Initializing global attention on CLS token...\n",
            "100% 234/234 [01:00<00:00,  3.88it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =        9.0\n",
            "  eval_f1-macro           =     0.6426\n",
            "  eval_f1-micro           =     0.7407\n",
            "  eval_loss               =       1.28\n",
            "  eval_runtime            = 0:01:00.61\n",
            "  eval_samples_per_second =     23.095\n",
            "  eval_steps_per_second   =       3.86\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "re"
      ],
      "metadata": {
        "id": "z2d0yLc_allP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}