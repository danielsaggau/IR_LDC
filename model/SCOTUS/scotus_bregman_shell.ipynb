{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/model/SCOTUS/Bregman_shell_command_file_scotus.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "naqIWr56jSUf"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/danielsaggau/IR_LDC.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-rw6QC9ojY5t"
      },
      "outputs": [],
      "source": [
        "%cd IR_LDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ipRGPbTR45u1",
        "outputId": "45f2f97f-a59c-4d2f-abf5-6ead9d90704f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully installed GitPython-3.1.29 datasets-2.3.2 dill-0.3.5.1 docker-pycreds-0.4.0 evaluate-0.2.2 gitdb-4.0.10 huggingface-hub-0.11.1 multiprocess-0.70.13 pathtools-0.1.2 responses-0.18.0 sentence-transformers-2.2.2 sentencepiece-0.1.97 sentry-sdk-1.9.0 setfit-0.4.1 setproctitle-1.3.2 shortuuid-1.0.11 smmap-5.0.0 tokenizers-0.13.2 transformers-4.23.1 urllib3-1.25.11 wandb-0.13.6 xxhash-3.1.0\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPNE-lbQex_N",
        "outputId": "66e0cf7a-5c86-41e0-85c0-6132c48a8aec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "XOCuFbIKgDss",
        "outputId": "4af2c941-a6ca-4f49-a0b9-60180965c9e2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdanielsaggau\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.13.6"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/IR_LDC/wandb/run-20221210_125509-1zinqc4o</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/danielsaggau/IR_LDC/runs/1zinqc4o\" target=\"_blank\">distinctive-glitter-100</a></strong> to <a href=\"https://wandb.ai/danielsaggau/IR_LDC\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "env: WANDB_PROJECT=IR_LDC\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb\n",
        "import wandb\n",
        "#!wandb login XXXX\n",
        "wandb.init(project=\"IR_LDC\")\n",
        "%env WANDB_PROJECT=IR_LDC"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQYL6fodppBA",
        "outputId": "95a41068-ad95-4177-d3b0-09ddf846963c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mDie letzten 5000Â Zeilen der Streamingausgabe wurden abgeschnitten.\u001b[0m\n",
            " 66% 5520/8340 [1:22:23<38:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:04,830 >> Initializing global attention on CLS token...\n",
            " 66% 5521/8340 [1:22:23<38:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:05,655 >> Initializing global attention on CLS token...\n",
            " 66% 5522/8340 [1:22:24<38:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:06,479 >> Initializing global attention on CLS token...\n",
            " 66% 5523/8340 [1:22:25<38:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:07,307 >> Initializing global attention on CLS token...\n",
            " 66% 5524/8340 [1:22:26<38:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:08,133 >> Initializing global attention on CLS token...\n",
            " 66% 5525/8340 [1:22:27<38:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:08,958 >> Initializing global attention on CLS token...\n",
            " 66% 5526/8340 [1:22:28<38:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:09,784 >> Initializing global attention on CLS token...\n",
            " 66% 5527/8340 [1:22:28<38:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:10,608 >> Initializing global attention on CLS token...\n",
            " 66% 5528/8340 [1:22:29<38:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:11,435 >> Initializing global attention on CLS token...\n",
            " 66% 5529/8340 [1:22:30<38:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:12,260 >> Initializing global attention on CLS token...\n",
            " 66% 5530/8340 [1:22:31<38:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:13,084 >> Initializing global attention on CLS token...\n",
            " 66% 5531/8340 [1:22:32<38:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:13,911 >> Initializing global attention on CLS token...\n",
            " 66% 5532/8340 [1:22:33<38:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:14,735 >> Initializing global attention on CLS token...\n",
            " 66% 5533/8340 [1:22:33<38:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:15,559 >> Initializing global attention on CLS token...\n",
            " 66% 5534/8340 [1:22:34<38:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:16,386 >> Initializing global attention on CLS token...\n",
            " 66% 5535/8340 [1:22:35<38:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:17,213 >> Initializing global attention on CLS token...\n",
            " 66% 5536/8340 [1:22:36<38:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:18,043 >> Initializing global attention on CLS token...\n",
            " 66% 5537/8340 [1:22:37<38:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:18,867 >> Initializing global attention on CLS token...\n",
            " 66% 5538/8340 [1:22:38<38:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:19,690 >> Initializing global attention on CLS token...\n",
            " 66% 5539/8340 [1:22:38<38:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:20,518 >> Initializing global attention on CLS token...\n",
            " 66% 5540/8340 [1:22:39<38:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:21,343 >> Initializing global attention on CLS token...\n",
            " 66% 5541/8340 [1:22:40<38:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:22,170 >> Initializing global attention on CLS token...\n",
            " 66% 5542/8340 [1:22:41<38:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:22,993 >> Initializing global attention on CLS token...\n",
            " 66% 5543/8340 [1:22:42<38:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:23,818 >> Initializing global attention on CLS token...\n",
            " 66% 5544/8340 [1:22:42<38:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:24,649 >> Initializing global attention on CLS token...\n",
            " 66% 5545/8340 [1:22:43<38:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:25,474 >> Initializing global attention on CLS token...\n",
            " 66% 5546/8340 [1:22:44<38:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:26,299 >> Initializing global attention on CLS token...\n",
            " 67% 5547/8340 [1:22:45<38:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:27,127 >> Initializing global attention on CLS token...\n",
            " 67% 5548/8340 [1:22:46<38:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:27,949 >> Initializing global attention on CLS token...\n",
            " 67% 5549/8340 [1:22:47<38:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:28,776 >> Initializing global attention on CLS token...\n",
            " 67% 5550/8340 [1:22:47<38:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:29,601 >> Initializing global attention on CLS token...\n",
            " 67% 5551/8340 [1:22:48<38:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:30,426 >> Initializing global attention on CLS token...\n",
            " 67% 5552/8340 [1:22:49<38:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:31,251 >> Initializing global attention on CLS token...\n",
            " 67% 5553/8340 [1:22:50<38:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:32,078 >> Initializing global attention on CLS token...\n",
            " 67% 5554/8340 [1:22:51<38:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:32,903 >> Initializing global attention on CLS token...\n",
            " 67% 5555/8340 [1:22:52<38:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:33,730 >> Initializing global attention on CLS token...\n",
            " 67% 5556/8340 [1:22:52<38:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:34,554 >> Initializing global attention on CLS token...\n",
            " 67% 5557/8340 [1:22:53<38:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:35,383 >> Initializing global attention on CLS token...\n",
            " 67% 5558/8340 [1:22:54<38:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:36,203 >> Initializing global attention on CLS token...\n",
            " 67% 5559/8340 [1:22:55<38:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:37,030 >> Initializing global attention on CLS token...\n",
            " 67% 5560/8340 [1:22:56<38:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:37,861 >> Initializing global attention on CLS token...\n",
            " 67% 5561/8340 [1:22:57<38:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:38,685 >> Initializing global attention on CLS token...\n",
            " 67% 5562/8340 [1:22:57<38:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:39,507 >> Initializing global attention on CLS token...\n",
            " 67% 5563/8340 [1:22:58<38:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:40,335 >> Initializing global attention on CLS token...\n",
            " 67% 5564/8340 [1:22:59<38:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:41,158 >> Initializing global attention on CLS token...\n",
            " 67% 5565/8340 [1:23:00<38:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:41,987 >> Initializing global attention on CLS token...\n",
            " 67% 5566/8340 [1:23:01<38:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:42,812 >> Initializing global attention on CLS token...\n",
            " 67% 5567/8340 [1:23:01<38:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:43,640 >> Initializing global attention on CLS token...\n",
            " 67% 5568/8340 [1:23:02<38:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:44,462 >> Initializing global attention on CLS token...\n",
            " 67% 5569/8340 [1:23:03<38:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:45,287 >> Initializing global attention on CLS token...\n",
            " 67% 5570/8340 [1:23:04<38:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:46,113 >> Initializing global attention on CLS token...\n",
            " 67% 5571/8340 [1:23:05<38:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:46,941 >> Initializing global attention on CLS token...\n",
            " 67% 5572/8340 [1:23:06<38:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:47,767 >> Initializing global attention on CLS token...\n",
            " 67% 5573/8340 [1:23:06<38:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:48,591 >> Initializing global attention on CLS token...\n",
            " 67% 5574/8340 [1:23:07<38:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:49,417 >> Initializing global attention on CLS token...\n",
            " 67% 5575/8340 [1:23:08<38:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:50,241 >> Initializing global attention on CLS token...\n",
            " 67% 5576/8340 [1:23:09<37:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:51,065 >> Initializing global attention on CLS token...\n",
            " 67% 5577/8340 [1:23:10<37:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:51,887 >> Initializing global attention on CLS token...\n",
            " 67% 5578/8340 [1:23:11<37:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:52,709 >> Initializing global attention on CLS token...\n",
            " 67% 5579/8340 [1:23:11<37:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:53,532 >> Initializing global attention on CLS token...\n",
            " 67% 5580/8340 [1:23:12<37:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:54,362 >> Initializing global attention on CLS token...\n",
            " 67% 5581/8340 [1:23:13<37:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:55,187 >> Initializing global attention on CLS token...\n",
            " 67% 5582/8340 [1:23:14<37:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:56,015 >> Initializing global attention on CLS token...\n",
            " 67% 5583/8340 [1:23:15<37:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:56,839 >> Initializing global attention on CLS token...\n",
            " 67% 5584/8340 [1:23:16<37:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:57,665 >> Initializing global attention on CLS token...\n",
            " 67% 5585/8340 [1:23:16<37:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:58,491 >> Initializing global attention on CLS token...\n",
            " 67% 5586/8340 [1:23:17<37:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:23:59,314 >> Initializing global attention on CLS token...\n",
            " 67% 5587/8340 [1:23:18<37:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:00,138 >> Initializing global attention on CLS token...\n",
            " 67% 5588/8340 [1:23:19<37:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:00,965 >> Initializing global attention on CLS token...\n",
            " 67% 5589/8340 [1:23:20<37:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:01,793 >> Initializing global attention on CLS token...\n",
            " 67% 5590/8340 [1:23:20<37:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:02,619 >> Initializing global attention on CLS token...\n",
            " 67% 5591/8340 [1:23:21<37:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:03,447 >> Initializing global attention on CLS token...\n",
            " 67% 5592/8340 [1:23:22<37:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:04,267 >> Initializing global attention on CLS token...\n",
            " 67% 5593/8340 [1:23:23<37:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:05,094 >> Initializing global attention on CLS token...\n",
            " 67% 5594/8340 [1:23:24<37:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:05,918 >> Initializing global attention on CLS token...\n",
            " 67% 5595/8340 [1:23:25<37:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:06,745 >> Initializing global attention on CLS token...\n",
            " 67% 5596/8340 [1:23:25<37:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:07,569 >> Initializing global attention on CLS token...\n",
            " 67% 5597/8340 [1:23:26<37:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:08,395 >> Initializing global attention on CLS token...\n",
            " 67% 5598/8340 [1:23:27<37:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:09,224 >> Initializing global attention on CLS token...\n",
            " 67% 5599/8340 [1:23:28<37:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:10,046 >> Initializing global attention on CLS token...\n",
            " 67% 5600/8340 [1:23:29<37:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:10,866 >> Initializing global attention on CLS token...\n",
            " 67% 5601/8340 [1:23:30<37:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:11,689 >> Initializing global attention on CLS token...\n",
            " 67% 5602/8340 [1:23:30<37:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:12,519 >> Initializing global attention on CLS token...\n",
            " 67% 5603/8340 [1:23:31<37:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:13,343 >> Initializing global attention on CLS token...\n",
            " 67% 5604/8340 [1:23:32<37:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:14,164 >> Initializing global attention on CLS token...\n",
            " 67% 5605/8340 [1:23:33<37:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:14,990 >> Initializing global attention on CLS token...\n",
            " 67% 5606/8340 [1:23:34<37:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:15,816 >> Initializing global attention on CLS token...\n",
            " 67% 5607/8340 [1:23:34<37:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:16,640 >> Initializing global attention on CLS token...\n",
            " 67% 5608/8340 [1:23:35<37:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:17,467 >> Initializing global attention on CLS token...\n",
            " 67% 5609/8340 [1:23:36<37:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:18,307 >> Initializing global attention on CLS token...\n",
            " 67% 5610/8340 [1:23:37<37:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:19,143 >> Initializing global attention on CLS token...\n",
            " 67% 5611/8340 [1:23:38<37:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:19,978 >> Initializing global attention on CLS token...\n",
            " 67% 5612/8340 [1:23:39<37:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:20,827 >> Initializing global attention on CLS token...\n",
            " 67% 5613/8340 [1:23:39<38:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:21,655 >> Initializing global attention on CLS token...\n",
            " 67% 5614/8340 [1:23:40<37:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:22,485 >> Initializing global attention on CLS token...\n",
            " 67% 5615/8340 [1:23:41<37:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:23,308 >> Initializing global attention on CLS token...\n",
            " 67% 5616/8340 [1:23:42<37:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:24,133 >> Initializing global attention on CLS token...\n",
            " 67% 5617/8340 [1:23:43<37:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:24,963 >> Initializing global attention on CLS token...\n",
            " 67% 5618/8340 [1:23:44<37:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:25,785 >> Initializing global attention on CLS token...\n",
            " 67% 5619/8340 [1:23:44<37:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:26,609 >> Initializing global attention on CLS token...\n",
            " 67% 5620/8340 [1:23:45<37:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:27,433 >> Initializing global attention on CLS token...\n",
            " 67% 5621/8340 [1:23:46<37:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:28,259 >> Initializing global attention on CLS token...\n",
            " 67% 5622/8340 [1:23:47<37:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:29,086 >> Initializing global attention on CLS token...\n",
            " 67% 5623/8340 [1:23:48<37:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:29,913 >> Initializing global attention on CLS token...\n",
            " 67% 5624/8340 [1:23:49<37:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:30,746 >> Initializing global attention on CLS token...\n",
            " 67% 5625/8340 [1:23:49<37:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:31,578 >> Initializing global attention on CLS token...\n",
            " 67% 5626/8340 [1:23:50<37:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:32,408 >> Initializing global attention on CLS token...\n",
            " 67% 5627/8340 [1:23:51<37:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:33,234 >> Initializing global attention on CLS token...\n",
            " 67% 5628/8340 [1:23:52<37:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:34,064 >> Initializing global attention on CLS token...\n",
            " 67% 5629/8340 [1:23:53<37:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:34,886 >> Initializing global attention on CLS token...\n",
            " 68% 5630/8340 [1:23:54<37:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:35,710 >> Initializing global attention on CLS token...\n",
            " 68% 5631/8340 [1:23:54<37:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:36,535 >> Initializing global attention on CLS token...\n",
            " 68% 5632/8340 [1:23:55<37:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:37,362 >> Initializing global attention on CLS token...\n",
            " 68% 5633/8340 [1:23:56<37:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:38,191 >> Initializing global attention on CLS token...\n",
            " 68% 5634/8340 [1:23:57<37:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:39,019 >> Initializing global attention on CLS token...\n",
            " 68% 5635/8340 [1:23:58<37:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:39,845 >> Initializing global attention on CLS token...\n",
            " 68% 5636/8340 [1:23:59<37:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:40,674 >> Initializing global attention on CLS token...\n",
            " 68% 5637/8340 [1:23:59<37:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:41,496 >> Initializing global attention on CLS token...\n",
            " 68% 5638/8340 [1:24:00<37:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:42,320 >> Initializing global attention on CLS token...\n",
            " 68% 5639/8340 [1:24:01<37:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:43,145 >> Initializing global attention on CLS token...\n",
            " 68% 5640/8340 [1:24:02<37:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:43,972 >> Initializing global attention on CLS token...\n",
            " 68% 5641/8340 [1:24:03<37:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:44,798 >> Initializing global attention on CLS token...\n",
            " 68% 5642/8340 [1:24:03<37:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:45,623 >> Initializing global attention on CLS token...\n",
            " 68% 5643/8340 [1:24:04<37:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:46,447 >> Initializing global attention on CLS token...\n",
            " 68% 5644/8340 [1:24:05<37:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:47,279 >> Initializing global attention on CLS token...\n",
            " 68% 5645/8340 [1:24:06<37:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:48,105 >> Initializing global attention on CLS token...\n",
            " 68% 5646/8340 [1:24:07<37:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:48,931 >> Initializing global attention on CLS token...\n",
            " 68% 5647/8340 [1:24:08<37:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:49,755 >> Initializing global attention on CLS token...\n",
            " 68% 5648/8340 [1:24:08<37:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:50,582 >> Initializing global attention on CLS token...\n",
            " 68% 5649/8340 [1:24:09<37:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:51,406 >> Initializing global attention on CLS token...\n",
            " 68% 5650/8340 [1:24:10<37:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:52,237 >> Initializing global attention on CLS token...\n",
            " 68% 5651/8340 [1:24:11<37:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:53,068 >> Initializing global attention on CLS token...\n",
            " 68% 5652/8340 [1:24:12<37:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:53,894 >> Initializing global attention on CLS token...\n",
            " 68% 5653/8340 [1:24:13<37:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:54,722 >> Initializing global attention on CLS token...\n",
            " 68% 5654/8340 [1:24:13<37:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:55,547 >> Initializing global attention on CLS token...\n",
            " 68% 5655/8340 [1:24:14<36:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:56,371 >> Initializing global attention on CLS token...\n",
            " 68% 5656/8340 [1:24:15<36:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:57,197 >> Initializing global attention on CLS token...\n",
            " 68% 5657/8340 [1:24:16<36:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:58,020 >> Initializing global attention on CLS token...\n",
            " 68% 5658/8340 [1:24:17<36:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:58,849 >> Initializing global attention on CLS token...\n",
            " 68% 5659/8340 [1:24:18<36:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:24:59,672 >> Initializing global attention on CLS token...\n",
            " 68% 5660/8340 [1:24:18<36:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:00,496 >> Initializing global attention on CLS token...\n",
            " 68% 5661/8340 [1:24:19<36:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:01,319 >> Initializing global attention on CLS token...\n",
            " 68% 5662/8340 [1:24:20<36:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:02,145 >> Initializing global attention on CLS token...\n",
            " 68% 5663/8340 [1:24:21<36:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:02,965 >> Initializing global attention on CLS token...\n",
            " 68% 5664/8340 [1:24:22<36:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:03,790 >> Initializing global attention on CLS token...\n",
            " 68% 5665/8340 [1:24:22<36:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:04,623 >> Initializing global attention on CLS token...\n",
            " 68% 5666/8340 [1:24:23<36:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:05,448 >> Initializing global attention on CLS token...\n",
            " 68% 5667/8340 [1:24:24<36:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:06,273 >> Initializing global attention on CLS token...\n",
            " 68% 5668/8340 [1:24:25<36:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:07,104 >> Initializing global attention on CLS token...\n",
            " 68% 5669/8340 [1:24:26<36:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:07,928 >> Initializing global attention on CLS token...\n",
            " 68% 5670/8340 [1:24:27<36:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:08,750 >> Initializing global attention on CLS token...\n",
            " 68% 5671/8340 [1:24:27<36:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:09,579 >> Initializing global attention on CLS token...\n",
            " 68% 5672/8340 [1:24:28<36:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:10,405 >> Initializing global attention on CLS token...\n",
            " 68% 5673/8340 [1:24:29<36:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:11,231 >> Initializing global attention on CLS token...\n",
            " 68% 5674/8340 [1:24:30<36:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:12,054 >> Initializing global attention on CLS token...\n",
            " 68% 5675/8340 [1:24:31<36:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:12,881 >> Initializing global attention on CLS token...\n",
            " 68% 5676/8340 [1:24:32<36:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:13,704 >> Initializing global attention on CLS token...\n",
            " 68% 5677/8340 [1:24:32<36:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:14,528 >> Initializing global attention on CLS token...\n",
            " 68% 5678/8340 [1:24:33<36:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:15,358 >> Initializing global attention on CLS token...\n",
            " 68% 5679/8340 [1:24:34<36:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:16,184 >> Initializing global attention on CLS token...\n",
            " 68% 5680/8340 [1:24:35<36:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:17,010 >> Initializing global attention on CLS token...\n",
            " 68% 5681/8340 [1:24:36<36:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:17,835 >> Initializing global attention on CLS token...\n",
            " 68% 5682/8340 [1:24:36<36:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:18,657 >> Initializing global attention on CLS token...\n",
            " 68% 5683/8340 [1:24:37<36:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:19,484 >> Initializing global attention on CLS token...\n",
            " 68% 5684/8340 [1:24:38<36:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:20,304 >> Initializing global attention on CLS token...\n",
            " 68% 5685/8340 [1:24:39<36:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:21,128 >> Initializing global attention on CLS token...\n",
            " 68% 5686/8340 [1:24:40<36:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:21,954 >> Initializing global attention on CLS token...\n",
            " 68% 5687/8340 [1:24:41<36:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:22,780 >> Initializing global attention on CLS token...\n",
            " 68% 5688/8340 [1:24:41<36:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:23,602 >> Initializing global attention on CLS token...\n",
            " 68% 5689/8340 [1:24:42<36:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:24,430 >> Initializing global attention on CLS token...\n",
            " 68% 5690/8340 [1:24:43<36:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:25,259 >> Initializing global attention on CLS token...\n",
            " 68% 5691/8340 [1:24:44<36:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:26,082 >> Initializing global attention on CLS token...\n",
            " 68% 5692/8340 [1:24:45<36:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:26,910 >> Initializing global attention on CLS token...\n",
            " 68% 5693/8340 [1:24:46<36:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:27,732 >> Initializing global attention on CLS token...\n",
            " 68% 5694/8340 [1:24:46<36:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:28,561 >> Initializing global attention on CLS token...\n",
            " 68% 5695/8340 [1:24:47<36:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:29,387 >> Initializing global attention on CLS token...\n",
            " 68% 5696/8340 [1:24:48<36:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:30,212 >> Initializing global attention on CLS token...\n",
            " 68% 5697/8340 [1:24:49<36:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:31,041 >> Initializing global attention on CLS token...\n",
            " 68% 5698/8340 [1:24:50<36:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:31,865 >> Initializing global attention on CLS token...\n",
            " 68% 5699/8340 [1:24:51<36:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:32,686 >> Initializing global attention on CLS token...\n",
            " 68% 5700/8340 [1:24:51<36:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:33,512 >> Initializing global attention on CLS token...\n",
            " 68% 5701/8340 [1:24:52<36:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:34,338 >> Initializing global attention on CLS token...\n",
            " 68% 5702/8340 [1:24:53<36:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:35,166 >> Initializing global attention on CLS token...\n",
            " 68% 5703/8340 [1:24:54<36:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:35,989 >> Initializing global attention on CLS token...\n",
            " 68% 5704/8340 [1:24:55<36:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:36,815 >> Initializing global attention on CLS token...\n",
            " 68% 5705/8340 [1:24:55<36:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:37,645 >> Initializing global attention on CLS token...\n",
            " 68% 5706/8340 [1:24:56<36:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:38,471 >> Initializing global attention on CLS token...\n",
            " 68% 5707/8340 [1:24:57<36:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:39,301 >> Initializing global attention on CLS token...\n",
            " 68% 5708/8340 [1:24:58<36:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:40,126 >> Initializing global attention on CLS token...\n",
            " 68% 5709/8340 [1:24:59<36:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:40,952 >> Initializing global attention on CLS token...\n",
            " 68% 5710/8340 [1:25:00<36:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:41,778 >> Initializing global attention on CLS token...\n",
            " 68% 5711/8340 [1:25:00<36:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:42,603 >> Initializing global attention on CLS token...\n",
            " 68% 5712/8340 [1:25:01<36:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:43,431 >> Initializing global attention on CLS token...\n",
            " 69% 5713/8340 [1:25:02<36:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:44,252 >> Initializing global attention on CLS token...\n",
            " 69% 5714/8340 [1:25:03<36:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:45,080 >> Initializing global attention on CLS token...\n",
            " 69% 5715/8340 [1:25:04<36:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:45,905 >> Initializing global attention on CLS token...\n",
            " 69% 5716/8340 [1:25:05<36:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:46,732 >> Initializing global attention on CLS token...\n",
            " 69% 5717/8340 [1:25:05<36:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:47,560 >> Initializing global attention on CLS token...\n",
            " 69% 5718/8340 [1:25:06<36:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:48,390 >> Initializing global attention on CLS token...\n",
            " 69% 5719/8340 [1:25:07<36:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:49,214 >> Initializing global attention on CLS token...\n",
            " 69% 5720/8340 [1:25:08<36:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:50,044 >> Initializing global attention on CLS token...\n",
            " 69% 5721/8340 [1:25:09<36:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:50,867 >> Initializing global attention on CLS token...\n",
            " 69% 5722/8340 [1:25:10<36:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:51,689 >> Initializing global attention on CLS token...\n",
            " 69% 5723/8340 [1:25:10<36:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:52,516 >> Initializing global attention on CLS token...\n",
            " 69% 5724/8340 [1:25:11<35:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:53,344 >> Initializing global attention on CLS token...\n",
            " 69% 5725/8340 [1:25:12<36:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:54,168 >> Initializing global attention on CLS token...\n",
            " 69% 5726/8340 [1:25:13<35:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:54,995 >> Initializing global attention on CLS token...\n",
            " 69% 5727/8340 [1:25:14<36:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:55,823 >> Initializing global attention on CLS token...\n",
            " 69% 5728/8340 [1:25:14<36:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:56,651 >> Initializing global attention on CLS token...\n",
            " 69% 5729/8340 [1:25:15<35:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:57,475 >> Initializing global attention on CLS token...\n",
            " 69% 5730/8340 [1:25:16<35:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:58,298 >> Initializing global attention on CLS token...\n",
            " 69% 5731/8340 [1:25:17<35:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:59,125 >> Initializing global attention on CLS token...\n",
            " 69% 5732/8340 [1:25:18<35:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:25:59,951 >> Initializing global attention on CLS token...\n",
            " 69% 5733/8340 [1:25:19<35:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:00,778 >> Initializing global attention on CLS token...\n",
            " 69% 5734/8340 [1:25:19<35:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:01,603 >> Initializing global attention on CLS token...\n",
            " 69% 5735/8340 [1:25:20<35:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:02,427 >> Initializing global attention on CLS token...\n",
            " 69% 5736/8340 [1:25:21<35:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:03,253 >> Initializing global attention on CLS token...\n",
            " 69% 5737/8340 [1:25:22<35:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:04,077 >> Initializing global attention on CLS token...\n",
            " 69% 5738/8340 [1:25:23<35:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:04,900 >> Initializing global attention on CLS token...\n",
            " 69% 5739/8340 [1:25:24<35:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:05,726 >> Initializing global attention on CLS token...\n",
            " 69% 5740/8340 [1:25:24<35:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:06,547 >> Initializing global attention on CLS token...\n",
            " 69% 5741/8340 [1:25:25<35:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:07,371 >> Initializing global attention on CLS token...\n",
            " 69% 5742/8340 [1:25:26<35:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:08,197 >> Initializing global attention on CLS token...\n",
            " 69% 5743/8340 [1:25:27<35:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:09,021 >> Initializing global attention on CLS token...\n",
            " 69% 5744/8340 [1:25:28<35:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:09,849 >> Initializing global attention on CLS token...\n",
            " 69% 5745/8340 [1:25:29<35:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:10,673 >> Initializing global attention on CLS token...\n",
            " 69% 5746/8340 [1:25:29<35:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:11,497 >> Initializing global attention on CLS token...\n",
            " 69% 5747/8340 [1:25:30<35:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:12,324 >> Initializing global attention on CLS token...\n",
            " 69% 5748/8340 [1:25:31<35:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:13,152 >> Initializing global attention on CLS token...\n",
            " 69% 5749/8340 [1:25:32<35:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:13,978 >> Initializing global attention on CLS token...\n",
            " 69% 5750/8340 [1:25:33<35:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:14,804 >> Initializing global attention on CLS token...\n",
            " 69% 5751/8340 [1:25:33<35:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:15,631 >> Initializing global attention on CLS token...\n",
            " 69% 5752/8340 [1:25:34<35:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:16,455 >> Initializing global attention on CLS token...\n",
            " 69% 5753/8340 [1:25:35<35:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:17,285 >> Initializing global attention on CLS token...\n",
            " 69% 5754/8340 [1:25:36<35:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:18,114 >> Initializing global attention on CLS token...\n",
            " 69% 5755/8340 [1:25:37<35:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:18,940 >> Initializing global attention on CLS token...\n",
            " 69% 5756/8340 [1:25:38<35:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:19,765 >> Initializing global attention on CLS token...\n",
            " 69% 5757/8340 [1:25:38<35:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:20,589 >> Initializing global attention on CLS token...\n",
            " 69% 5758/8340 [1:25:39<35:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:21,413 >> Initializing global attention on CLS token...\n",
            " 69% 5759/8340 [1:25:40<35:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:22,236 >> Initializing global attention on CLS token...\n",
            " 69% 5760/8340 [1:25:41<35:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:23,061 >> Initializing global attention on CLS token...\n",
            " 69% 5761/8340 [1:25:42<35:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:23,885 >> Initializing global attention on CLS token...\n",
            " 69% 5762/8340 [1:25:43<35:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:24,715 >> Initializing global attention on CLS token...\n",
            " 69% 5763/8340 [1:25:43<35:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:25,541 >> Initializing global attention on CLS token...\n",
            " 69% 5764/8340 [1:25:44<35:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:26,364 >> Initializing global attention on CLS token...\n",
            " 69% 5765/8340 [1:25:45<35:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:27,192 >> Initializing global attention on CLS token...\n",
            " 69% 5766/8340 [1:25:46<35:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:28,017 >> Initializing global attention on CLS token...\n",
            " 69% 5767/8340 [1:25:47<35:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:28,843 >> Initializing global attention on CLS token...\n",
            " 69% 5768/8340 [1:25:48<35:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:29,668 >> Initializing global attention on CLS token...\n",
            " 69% 5769/8340 [1:25:48<35:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:30,492 >> Initializing global attention on CLS token...\n",
            " 69% 5770/8340 [1:25:49<35:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:31,317 >> Initializing global attention on CLS token...\n",
            " 69% 5771/8340 [1:25:50<35:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:32,144 >> Initializing global attention on CLS token...\n",
            " 69% 5772/8340 [1:25:51<35:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:32,970 >> Initializing global attention on CLS token...\n",
            " 69% 5773/8340 [1:25:52<35:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:33,798 >> Initializing global attention on CLS token...\n",
            " 69% 5774/8340 [1:25:52<35:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:34,625 >> Initializing global attention on CLS token...\n",
            " 69% 5775/8340 [1:25:53<35:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:35,453 >> Initializing global attention on CLS token...\n",
            " 69% 5776/8340 [1:25:54<35:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:36,283 >> Initializing global attention on CLS token...\n",
            " 69% 5777/8340 [1:25:55<35:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:37,106 >> Initializing global attention on CLS token...\n",
            " 69% 5778/8340 [1:25:56<35:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:37,928 >> Initializing global attention on CLS token...\n",
            " 69% 5779/8340 [1:25:57<35:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:38,752 >> Initializing global attention on CLS token...\n",
            " 69% 5780/8340 [1:25:57<35:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:39,574 >> Initializing global attention on CLS token...\n",
            " 69% 5781/8340 [1:25:58<35:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:40,404 >> Initializing global attention on CLS token...\n",
            " 69% 5782/8340 [1:25:59<35:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:41,228 >> Initializing global attention on CLS token...\n",
            " 69% 5783/8340 [1:26:00<35:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:42,052 >> Initializing global attention on CLS token...\n",
            " 69% 5784/8340 [1:26:01<35:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:42,878 >> Initializing global attention on CLS token...\n",
            " 69% 5785/8340 [1:26:02<35:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:43,703 >> Initializing global attention on CLS token...\n",
            " 69% 5786/8340 [1:26:02<35:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:44,530 >> Initializing global attention on CLS token...\n",
            " 69% 5787/8340 [1:26:03<35:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:45,359 >> Initializing global attention on CLS token...\n",
            " 69% 5788/8340 [1:26:04<35:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:46,186 >> Initializing global attention on CLS token...\n",
            " 69% 5789/8340 [1:26:05<35:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:47,011 >> Initializing global attention on CLS token...\n",
            " 69% 5790/8340 [1:26:06<35:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:47,835 >> Initializing global attention on CLS token...\n",
            " 69% 5791/8340 [1:26:07<35:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:48,666 >> Initializing global attention on CLS token...\n",
            " 69% 5792/8340 [1:26:07<35:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:49,494 >> Initializing global attention on CLS token...\n",
            " 69% 5793/8340 [1:26:08<35:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:50,324 >> Initializing global attention on CLS token...\n",
            " 69% 5794/8340 [1:26:09<35:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:51,150 >> Initializing global attention on CLS token...\n",
            " 69% 5795/8340 [1:26:10<35:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:51,989 >> Initializing global attention on CLS token...\n",
            " 69% 5796/8340 [1:26:11<35:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:52,814 >> Initializing global attention on CLS token...\n",
            " 70% 5797/8340 [1:26:11<35:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:53,647 >> Initializing global attention on CLS token...\n",
            " 70% 5798/8340 [1:26:12<35:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:54,473 >> Initializing global attention on CLS token...\n",
            " 70% 5799/8340 [1:26:13<35:09,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:55,303 >> Initializing global attention on CLS token...\n",
            " 70% 5800/8340 [1:26:14<35:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:56,132 >> Initializing global attention on CLS token...\n",
            " 70% 5801/8340 [1:26:15<35:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:56,956 >> Initializing global attention on CLS token...\n",
            " 70% 5802/8340 [1:26:16<34:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:57,781 >> Initializing global attention on CLS token...\n",
            " 70% 5803/8340 [1:26:16<34:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:58,605 >> Initializing global attention on CLS token...\n",
            " 70% 5804/8340 [1:26:17<34:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:26:59,434 >> Initializing global attention on CLS token...\n",
            " 70% 5805/8340 [1:26:18<34:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:00,259 >> Initializing global attention on CLS token...\n",
            " 70% 5806/8340 [1:26:19<34:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:01,079 >> Initializing global attention on CLS token...\n",
            " 70% 5807/8340 [1:26:20<34:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:01,905 >> Initializing global attention on CLS token...\n",
            " 70% 5808/8340 [1:26:21<34:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:02,731 >> Initializing global attention on CLS token...\n",
            " 70% 5809/8340 [1:26:21<34:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:03,557 >> Initializing global attention on CLS token...\n",
            " 70% 5810/8340 [1:26:22<34:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:04,383 >> Initializing global attention on CLS token...\n",
            " 70% 5811/8340 [1:26:23<34:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:05,211 >> Initializing global attention on CLS token...\n",
            " 70% 5812/8340 [1:26:24<34:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:06,037 >> Initializing global attention on CLS token...\n",
            " 70% 5813/8340 [1:26:25<34:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:06,866 >> Initializing global attention on CLS token...\n",
            " 70% 5814/8340 [1:26:26<34:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:07,688 >> Initializing global attention on CLS token...\n",
            " 70% 5815/8340 [1:26:26<34:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:08,515 >> Initializing global attention on CLS token...\n",
            " 70% 5816/8340 [1:26:27<34:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:09,340 >> Initializing global attention on CLS token...\n",
            " 70% 5817/8340 [1:26:28<34:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:10,167 >> Initializing global attention on CLS token...\n",
            " 70% 5818/8340 [1:26:29<34:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:10,991 >> Initializing global attention on CLS token...\n",
            " 70% 5819/8340 [1:26:30<34:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:11,818 >> Initializing global attention on CLS token...\n",
            " 70% 5820/8340 [1:26:30<34:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:12,645 >> Initializing global attention on CLS token...\n",
            " 70% 5821/8340 [1:26:31<34:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:13,469 >> Initializing global attention on CLS token...\n",
            " 70% 5822/8340 [1:26:32<34:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:14,293 >> Initializing global attention on CLS token...\n",
            " 70% 5823/8340 [1:26:33<34:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:15,120 >> Initializing global attention on CLS token...\n",
            " 70% 5824/8340 [1:26:34<34:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:15,943 >> Initializing global attention on CLS token...\n",
            " 70% 5825/8340 [1:26:35<34:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:16,767 >> Initializing global attention on CLS token...\n",
            " 70% 5826/8340 [1:26:35<34:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:17,595 >> Initializing global attention on CLS token...\n",
            " 70% 5827/8340 [1:26:36<34:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:18,420 >> Initializing global attention on CLS token...\n",
            " 70% 5828/8340 [1:26:37<34:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:19,244 >> Initializing global attention on CLS token...\n",
            " 70% 5829/8340 [1:26:38<34:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:20,069 >> Initializing global attention on CLS token...\n",
            " 70% 5830/8340 [1:26:39<34:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:20,896 >> Initializing global attention on CLS token...\n",
            " 70% 5831/8340 [1:26:40<34:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:21,723 >> Initializing global attention on CLS token...\n",
            " 70% 5832/8340 [1:26:40<34:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:22,548 >> Initializing global attention on CLS token...\n",
            " 70% 5833/8340 [1:26:41<34:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:23,374 >> Initializing global attention on CLS token...\n",
            " 70% 5834/8340 [1:26:42<34:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:24,198 >> Initializing global attention on CLS token...\n",
            " 70% 5835/8340 [1:26:43<34:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:25,026 >> Initializing global attention on CLS token...\n",
            " 70% 5836/8340 [1:26:44<34:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:25,855 >> Initializing global attention on CLS token...\n",
            " 70% 5837/8340 [1:26:45<34:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:27:26,661 >> Initializing global attention on CLS token...\n",
            " 70% 5838/8340 [1:26:45<27:56,  1.49it/s][INFO|trainer.py:725] 2022-12-10 16:27:26,955 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 16:27:26,958 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 16:27:26,958 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 16:27:26,958 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:26,989 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:27,236 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:28,  8.09it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:27,482 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:40,  5.72it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:27,732 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:46,  4.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:27,982 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:00<00:49,  4.58it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:28,239 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:52,  4.31it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:28,489 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:53,  4.21it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:28,739 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:54,  4.15it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:28,985 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:01<00:54,  4.12it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:29,236 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:54,  4.08it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:29,486 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:54,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:29,733 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:54,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:29,987 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:02<00:54,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:30,236 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:54,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:30,488 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:54,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:30,736 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:54,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:30,989 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:03<00:54,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:31,234 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:53,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:31,489 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:53,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:31,736 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:53,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:31,983 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:04<00:52,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:32,229 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:52,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:32,478 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:52,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:32,726 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:52,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:32,975 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:05<00:51,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:33,226 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:51,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:33,473 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:51,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:33,725 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:51,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:33,978 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:06<00:51,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:34,223 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:50,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:34,472 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:50,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:34,720 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:50,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:34,967 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:07<00:49,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:35,215 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:49,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:35,462 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:49,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:35,719 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:49,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:35,963 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:08<00:49,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:36,212 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:48,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:36,456 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:48,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:36,703 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:48,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:36,955 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:09<00:48,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:37,204 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:47,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:37,450 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:47,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:37,696 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:47,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:37,947 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:10<00:46,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:38,194 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:46,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:38,447 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:46,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:38,691 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:11<00:46,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:38,939 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:11<00:45,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:39,190 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:45,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:39,438 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:45,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:39,684 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:12<00:45,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:39,940 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:12<00:45,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:40,187 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:44,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:40,436 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:44,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:40,686 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:13<00:44,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:40,941 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:13<00:44,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:41,196 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:44,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:41,447 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:44,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:41,696 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:14<00:43,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:41,951 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:14<00:43,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:42,204 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:43,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:42,454 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:42,702 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:15<00:42,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:42,950 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:15<00:42,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:43,195 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:41,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:43,437 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:41,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:43,682 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:16<00:40,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:43,929 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:16<00:40,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:44,181 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:40,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:44,434 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:40,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:44,681 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:17<00:40,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:44,929 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:17<00:40,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:45,180 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:39,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:45,428 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:39,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:45,676 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:18<00:39,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:45,928 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:18<00:39,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:46,174 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:38,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:46,424 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:38,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:46,671 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:19<00:38,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:46,917 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:19<00:37,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:47,163 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:37,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:47,409 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:37,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:47,657 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:20<00:37,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:47,907 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:20<00:36,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:48,159 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:36,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:48,409 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:21<00:36,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:48,661 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:21<00:36,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:48,911 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:21<00:36,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:49,159 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:35,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:49,406 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:22<00:35,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:49,657 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:22<00:35,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:49,901 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:22<00:35,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:50,151 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:34,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:50,398 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:23<00:34,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:50,657 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:23<00:34,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:50,902 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:23<00:34,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:51,157 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:34,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:51,403 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:24<00:33,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:51,652 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:24<00:33,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:51,901 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:24<00:33,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:52,154 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:33,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:52,404 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:25<00:32,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:52,660 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:25<00:32,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:52,906 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:25<00:32,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:53,154 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:32,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:53,404 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:26<00:31,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:53,652 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:26<00:31,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:53,899 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:26<00:31,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:54,144 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:30,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:54,390 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:27<00:30,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:54,640 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:27<00:30,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:54,887 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:27<00:29,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:55,135 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:29,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:55,393 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:28<00:29,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:55,643 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:28<00:29,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:55,900 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:28<00:29,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:56,145 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:28,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:56,398 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:29<00:28,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:56,645 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:29<00:28,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:56,896 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:29<00:28,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:57,145 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:30<00:28,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:57,395 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:30<00:27,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:57,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:30<00:27,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:57,896 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:30<00:27,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:58,146 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:31<00:26,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:58,393 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:31<00:26,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:58,642 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:31<00:26,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:58,888 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:31<00:26,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:59,141 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:32<00:25,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:59,387 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:32<00:25,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:59,639 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:32<00:25,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:27:59,885 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:32<00:25,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:00,133 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:33<00:24,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:00,381 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:33<00:24,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:00,635 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:33<00:24,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:00,881 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:33<00:24,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:01,127 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:34<00:23,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:01,376 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:34<00:23,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:01,620 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:34<00:23,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:01,871 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:34<00:23,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:02,123 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:35<00:22,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:02,368 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:35<00:22,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:02,614 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:35<00:22,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:02,861 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:35<00:22,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:03,106 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:36<00:21,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:03,360 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:36<00:21,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:03,606 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:36<00:21,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:03,854 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:36<00:21,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:04,100 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:37<00:20,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:04,350 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:37<00:20,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:04,601 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:37<00:20,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:04,846 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:37<00:20,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:05,095 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:38<00:19,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:05,343 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:38<00:19,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:05,593 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:38<00:19,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:05,840 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:38<00:19,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:06,087 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:39<00:18,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:06,334 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:39<00:18,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:06,595 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:39<00:18,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:06,841 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:39<00:18,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:07,091 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:40<00:18,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:07,342 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:40<00:17,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:07,597 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:40<00:17,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:07,848 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:40<00:17,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:08,095 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:41<00:17,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:08,342 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:41<00:16,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:08,591 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:41<00:16,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:08,842 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:41<00:16,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:09,090 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:42<00:15,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:09,341 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:42<00:15,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:09,587 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:42<00:15,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:09,834 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:42<00:15,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:10,079 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:43<00:14,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:10,328 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:43<00:14,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:10,574 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:43<00:14,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:10,828 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:43<00:14,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:11,076 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:44<00:13,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:11,325 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:44<00:13,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:11,573 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:44<00:13,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:11,834 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:44<00:13,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:12,085 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:45<00:13,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:12,343 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:45<00:12,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:12,596 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:45<00:12,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:12,846 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:45<00:12,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:13,093 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:46<00:12,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:13,341 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:46<00:11,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:13,588 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:46<00:11,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:13,841 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:46<00:11,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:14,093 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:47<00:11,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:14,341 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:47<00:10,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:14,594 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:47<00:10,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:14,840 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:47<00:10,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:15,091 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:48<00:09,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:15,339 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:48<00:09,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:15,589 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:48<00:09,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:15,839 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:48<00:09,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:16,088 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:49<00:08,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:16,335 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:49<00:08,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:16,583 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:49<00:08,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:16,833 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:49<00:08,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:17,093 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:50<00:08,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:17,341 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:50<00:07,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:17,590 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:50<00:07,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:17,841 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:50<00:07,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:18,098 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:51<00:07,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:18,345 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:51<00:06,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:18,593 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:51<00:06,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:18,844 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:51<00:06,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:19,090 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:52<00:05,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:19,335 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:52<00:05,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:19,582 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:52<00:05,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:19,831 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:52<00:05,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:20,075 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:53<00:04,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:20,321 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:53<00:04,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:20,569 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:53<00:04,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:20,819 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:53<00:04,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:21,066 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:54<00:03,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:21,317 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:54<00:03,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:21,568 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:54<00:03,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:21,818 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:54<00:03,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:22,066 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:55<00:02,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:22,315 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:55<00:02,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:22,564 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:55<00:02,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:22,811 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:55<00:02,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:23,061 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:56<00:01,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:23,310 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:56<00:01,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:23,563 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:56<00:01,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:23,811 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:56<00:01,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:24,057 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:57<00:00,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:24,303 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:57<00:00,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:24,560 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:57<00:00,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:24,806 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:57<00:00,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:25,036 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.4768788814544678, 'eval_f1-micro': 0.7714285714285715, 'eval_f1-macro': 0.6941050920361911, 'eval_runtime': 59.3428, 'eval_samples_per_second': 23.592, 'eval_steps_per_second': 3.943, 'epoch': 7.0}\n",
            " 70% 5838/8340 [1:27:44<27:56,  1.49it/s]\n",
            "100% 234/234 [00:59<00:00,  4.01it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-10 16:28:26,303 >> Saving model checkpoint to logs/output_1/checkpoint-5838\n",
            "[INFO|configuration_utils.py:447] 2022-12-10 16:28:26,304 >> Configuration saved in logs/output_1/checkpoint-5838/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-10 16:28:26,633 >> Model weights saved in logs/output_1/checkpoint-5838/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-10 16:28:26,634 >> tokenizer config file saved in logs/output_1/checkpoint-5838/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-10 16:28:26,635 >> Special tokens file saved in logs/output_1/checkpoint-5838/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 16:28:27,299 >> Initializing global attention on CLS token...\n",
            " 70% 5839/8340 [1:27:46<13:05:00, 18.83s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:28,197 >> Initializing global attention on CLS token...\n",
            " 70% 5840/8340 [1:27:47<9:19:37, 13.43s/it] [INFO|modeling_longformer.py:1932] 2022-12-10 16:28:29,022 >> Initializing global attention on CLS token...\n",
            " 70% 5841/8340 [1:27:48<6:41:51,  9.65s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:29,846 >> Initializing global attention on CLS token...\n",
            " 70% 5842/8340 [1:27:49<4:51:30,  7.00s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:30,673 >> Initializing global attention on CLS token...\n",
            " 70% 5843/8340 [1:27:49<3:34:15,  5.15s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:31,497 >> Initializing global attention on CLS token...\n",
            " 70% 5844/8340 [1:27:50<2:40:13,  3.85s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:32,322 >> Initializing global attention on CLS token...\n",
            " 70% 5845/8340 [1:27:51<2:02:24,  2.94s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:33,146 >> Initializing global attention on CLS token...\n",
            " 70% 5846/8340 [1:27:52<1:35:54,  2.31s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:33,970 >> Initializing global attention on CLS token...\n",
            " 70% 5847/8340 [1:27:53<1:17:23,  1.86s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:34,795 >> Initializing global attention on CLS token...\n",
            " 70% 5848/8340 [1:27:53<1:04:26,  1.55s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:35,622 >> Initializing global attention on CLS token...\n",
            " 70% 5849/8340 [1:27:54<55:22,  1.33s/it]  [INFO|modeling_longformer.py:1932] 2022-12-10 16:28:36,445 >> Initializing global attention on CLS token...\n",
            " 70% 5850/8340 [1:27:55<48:59,  1.18s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:37,269 >> Initializing global attention on CLS token...\n",
            " 70% 5851/8340 [1:27:56<44:32,  1.07s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:38,094 >> Initializing global attention on CLS token...\n",
            " 70% 5852/8340 [1:27:57<41:25,  1.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:38,918 >> Initializing global attention on CLS token...\n",
            " 70% 5853/8340 [1:27:58<39:14,  1.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:39,746 >> Initializing global attention on CLS token...\n",
            " 70% 5854/8340 [1:27:58<37:45,  1.10it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:40,572 >> Initializing global attention on CLS token...\n",
            " 70% 5855/8340 [1:27:59<36:38,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:41,395 >> Initializing global attention on CLS token...\n",
            " 70% 5856/8340 [1:28:00<35:57,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:42,228 >> Initializing global attention on CLS token...\n",
            " 70% 5857/8340 [1:28:01<35:26,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:43,056 >> Initializing global attention on CLS token...\n",
            " 70% 5858/8340 [1:28:02<35:04,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:43,880 >> Initializing global attention on CLS token...\n",
            " 70% 5859/8340 [1:28:03<34:46,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:44,706 >> Initializing global attention on CLS token...\n",
            " 70% 5860/8340 [1:28:03<34:37,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:45,537 >> Initializing global attention on CLS token...\n",
            " 70% 5861/8340 [1:28:04<34:28,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:46,363 >> Initializing global attention on CLS token...\n",
            " 70% 5862/8340 [1:28:05<34:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:47,189 >> Initializing global attention on CLS token...\n",
            " 70% 5863/8340 [1:28:06<34:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:48,023 >> Initializing global attention on CLS token...\n",
            " 70% 5864/8340 [1:28:07<34:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:48,849 >> Initializing global attention on CLS token...\n",
            " 70% 5865/8340 [1:28:08<34:14,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:49,676 >> Initializing global attention on CLS token...\n",
            " 70% 5866/8340 [1:28:08<34:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:50,502 >> Initializing global attention on CLS token...\n",
            " 70% 5867/8340 [1:28:09<34:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:51,326 >> Initializing global attention on CLS token...\n",
            " 70% 5868/8340 [1:28:10<34:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:52,151 >> Initializing global attention on CLS token...\n",
            " 70% 5869/8340 [1:28:11<34:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:52,977 >> Initializing global attention on CLS token...\n",
            " 70% 5870/8340 [1:28:12<33:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:53,800 >> Initializing global attention on CLS token...\n",
            " 70% 5871/8340 [1:28:12<34:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:54,632 >> Initializing global attention on CLS token...\n",
            " 70% 5872/8340 [1:28:13<34:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:55,458 >> Initializing global attention on CLS token...\n",
            " 70% 5873/8340 [1:28:14<33:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:56,287 >> Initializing global attention on CLS token...\n",
            " 70% 5874/8340 [1:28:15<34:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:57,114 >> Initializing global attention on CLS token...\n",
            " 70% 5875/8340 [1:28:16<34:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:57,949 >> Initializing global attention on CLS token...\n",
            " 70% 5876/8340 [1:28:17<34:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:58,778 >> Initializing global attention on CLS token...\n",
            " 70% 5877/8340 [1:28:17<34:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:28:59,603 >> Initializing global attention on CLS token...\n",
            " 70% 5878/8340 [1:28:18<33:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:00,424 >> Initializing global attention on CLS token...\n",
            " 70% 5879/8340 [1:28:19<33:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:01,254 >> Initializing global attention on CLS token...\n",
            " 71% 5880/8340 [1:28:20<33:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:02,081 >> Initializing global attention on CLS token...\n",
            " 71% 5881/8340 [1:28:21<33:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:02,909 >> Initializing global attention on CLS token...\n",
            " 71% 5882/8340 [1:28:22<33:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:03,736 >> Initializing global attention on CLS token...\n",
            " 71% 5883/8340 [1:28:22<33:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:04,560 >> Initializing global attention on CLS token...\n",
            " 71% 5884/8340 [1:28:23<33:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:05,388 >> Initializing global attention on CLS token...\n",
            " 71% 5885/8340 [1:28:24<33:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:06,217 >> Initializing global attention on CLS token...\n",
            " 71% 5886/8340 [1:28:25<33:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:07,050 >> Initializing global attention on CLS token...\n",
            " 71% 5887/8340 [1:28:26<33:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:07,876 >> Initializing global attention on CLS token...\n",
            " 71% 5888/8340 [1:28:27<33:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:08,701 >> Initializing global attention on CLS token...\n",
            " 71% 5889/8340 [1:28:27<33:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:09,527 >> Initializing global attention on CLS token...\n",
            " 71% 5890/8340 [1:28:28<33:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:10,356 >> Initializing global attention on CLS token...\n",
            " 71% 5891/8340 [1:28:29<33:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:11,183 >> Initializing global attention on CLS token...\n",
            " 71% 5892/8340 [1:28:30<33:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:12,008 >> Initializing global attention on CLS token...\n",
            " 71% 5893/8340 [1:28:31<33:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:12,836 >> Initializing global attention on CLS token...\n",
            " 71% 5894/8340 [1:28:31<33:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:13,661 >> Initializing global attention on CLS token...\n",
            " 71% 5895/8340 [1:28:32<33:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:14,488 >> Initializing global attention on CLS token...\n",
            " 71% 5896/8340 [1:28:33<33:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:15,314 >> Initializing global attention on CLS token...\n",
            " 71% 5897/8340 [1:28:34<33:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:16,146 >> Initializing global attention on CLS token...\n",
            " 71% 5898/8340 [1:28:35<33:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:16,985 >> Initializing global attention on CLS token...\n",
            " 71% 5899/8340 [1:28:36<33:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:17,815 >> Initializing global attention on CLS token...\n",
            " 71% 5900/8340 [1:28:36<33:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:18,653 >> Initializing global attention on CLS token...\n",
            " 71% 5901/8340 [1:28:37<33:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:19,481 >> Initializing global attention on CLS token...\n",
            " 71% 5902/8340 [1:28:38<33:47,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:20,307 >> Initializing global attention on CLS token...\n",
            " 71% 5903/8340 [1:28:39<33:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:21,131 >> Initializing global attention on CLS token...\n",
            " 71% 5904/8340 [1:28:40<33:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:21,960 >> Initializing global attention on CLS token...\n",
            " 71% 5905/8340 [1:28:41<33:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:22,782 >> Initializing global attention on CLS token...\n",
            " 71% 5906/8340 [1:28:41<33:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:23,606 >> Initializing global attention on CLS token...\n",
            " 71% 5907/8340 [1:28:42<33:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:24,429 >> Initializing global attention on CLS token...\n",
            " 71% 5908/8340 [1:28:43<33:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:25,260 >> Initializing global attention on CLS token...\n",
            " 71% 5909/8340 [1:28:44<33:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:26,086 >> Initializing global attention on CLS token...\n",
            " 71% 5910/8340 [1:28:45<33:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:26,911 >> Initializing global attention on CLS token...\n",
            " 71% 5911/8340 [1:28:46<33:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:27,740 >> Initializing global attention on CLS token...\n",
            " 71% 5912/8340 [1:28:46<33:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:28,564 >> Initializing global attention on CLS token...\n",
            " 71% 5913/8340 [1:28:47<33:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:29,391 >> Initializing global attention on CLS token...\n",
            " 71% 5914/8340 [1:28:48<33:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:30,219 >> Initializing global attention on CLS token...\n",
            " 71% 5915/8340 [1:28:49<33:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:31,046 >> Initializing global attention on CLS token...\n",
            " 71% 5916/8340 [1:28:50<33:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:31,875 >> Initializing global attention on CLS token...\n",
            " 71% 5917/8340 [1:28:51<33:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:32,700 >> Initializing global attention on CLS token...\n",
            " 71% 5918/8340 [1:28:51<33:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:33,526 >> Initializing global attention on CLS token...\n",
            " 71% 5919/8340 [1:28:52<33:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:34,354 >> Initializing global attention on CLS token...\n",
            " 71% 5920/8340 [1:28:53<33:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:35,180 >> Initializing global attention on CLS token...\n",
            " 71% 5921/8340 [1:28:54<33:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:36,010 >> Initializing global attention on CLS token...\n",
            " 71% 5922/8340 [1:28:55<33:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:36,836 >> Initializing global attention on CLS token...\n",
            " 71% 5923/8340 [1:28:55<33:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:37,660 >> Initializing global attention on CLS token...\n",
            " 71% 5924/8340 [1:28:56<33:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:38,486 >> Initializing global attention on CLS token...\n",
            " 71% 5925/8340 [1:28:57<33:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:39,306 >> Initializing global attention on CLS token...\n",
            " 71% 5926/8340 [1:28:58<33:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:40,128 >> Initializing global attention on CLS token...\n",
            " 71% 5927/8340 [1:28:59<33:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:40,954 >> Initializing global attention on CLS token...\n",
            " 71% 5928/8340 [1:29:00<33:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:41,778 >> Initializing global attention on CLS token...\n",
            " 71% 5929/8340 [1:29:00<33:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:42,607 >> Initializing global attention on CLS token...\n",
            " 71% 5930/8340 [1:29:01<33:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:43,438 >> Initializing global attention on CLS token...\n",
            " 71% 5931/8340 [1:29:02<33:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:44,262 >> Initializing global attention on CLS token...\n",
            " 71% 5932/8340 [1:29:03<33:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:45,087 >> Initializing global attention on CLS token...\n",
            " 71% 5933/8340 [1:29:04<33:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:45,920 >> Initializing global attention on CLS token...\n",
            " 71% 5934/8340 [1:29:05<33:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:46,755 >> Initializing global attention on CLS token...\n",
            " 71% 5935/8340 [1:29:05<33:17,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:47,583 >> Initializing global attention on CLS token...\n",
            " 71% 5936/8340 [1:29:06<33:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:48,409 >> Initializing global attention on CLS token...\n",
            " 71% 5937/8340 [1:29:07<33:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:49,234 >> Initializing global attention on CLS token...\n",
            " 71% 5938/8340 [1:29:08<33:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:50,060 >> Initializing global attention on CLS token...\n",
            " 71% 5939/8340 [1:29:09<33:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:50,883 >> Initializing global attention on CLS token...\n",
            " 71% 5940/8340 [1:29:10<33:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:51,708 >> Initializing global attention on CLS token...\n",
            " 71% 5941/8340 [1:29:10<33:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:52,533 >> Initializing global attention on CLS token...\n",
            " 71% 5942/8340 [1:29:11<33:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:53,361 >> Initializing global attention on CLS token...\n",
            " 71% 5943/8340 [1:29:12<32:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:54,183 >> Initializing global attention on CLS token...\n",
            " 71% 5944/8340 [1:29:13<32:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:55,008 >> Initializing global attention on CLS token...\n",
            " 71% 5945/8340 [1:29:14<32:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:55,833 >> Initializing global attention on CLS token...\n",
            " 71% 5946/8340 [1:29:14<32:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:56,660 >> Initializing global attention on CLS token...\n",
            " 71% 5947/8340 [1:29:15<32:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:57,486 >> Initializing global attention on CLS token...\n",
            " 71% 5948/8340 [1:29:16<32:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:58,312 >> Initializing global attention on CLS token...\n",
            " 71% 5949/8340 [1:29:17<32:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:59,139 >> Initializing global attention on CLS token...\n",
            " 71% 5950/8340 [1:29:18<32:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:29:59,972 >> Initializing global attention on CLS token...\n",
            " 71% 5951/8340 [1:29:19<32:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:00,803 >> Initializing global attention on CLS token...\n",
            " 71% 5952/8340 [1:29:19<33:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:01,652 >> Initializing global attention on CLS token...\n",
            " 71% 5953/8340 [1:29:20<33:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:02,499 >> Initializing global attention on CLS token...\n",
            " 71% 5954/8340 [1:29:21<33:20,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:03,330 >> Initializing global attention on CLS token...\n",
            " 71% 5955/8340 [1:29:22<33:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:04,155 >> Initializing global attention on CLS token...\n",
            " 71% 5956/8340 [1:29:23<33:03,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:04,979 >> Initializing global attention on CLS token...\n",
            " 71% 5957/8340 [1:29:24<32:58,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:05,806 >> Initializing global attention on CLS token...\n",
            " 71% 5958/8340 [1:29:24<32:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:06,632 >> Initializing global attention on CLS token...\n",
            " 71% 5959/8340 [1:29:25<32:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:07,458 >> Initializing global attention on CLS token...\n",
            " 71% 5960/8340 [1:29:26<32:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:08,285 >> Initializing global attention on CLS token...\n",
            " 71% 5961/8340 [1:29:27<32:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:09,109 >> Initializing global attention on CLS token...\n",
            " 71% 5962/8340 [1:29:28<32:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:09,938 >> Initializing global attention on CLS token...\n",
            " 71% 5963/8340 [1:29:29<32:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:10,759 >> Initializing global attention on CLS token...\n",
            " 72% 5964/8340 [1:29:29<32:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:11,582 >> Initializing global attention on CLS token...\n",
            " 72% 5965/8340 [1:29:30<32:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:12,409 >> Initializing global attention on CLS token...\n",
            " 72% 5966/8340 [1:29:31<32:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:13,233 >> Initializing global attention on CLS token...\n",
            " 72% 5967/8340 [1:29:32<32:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:14,058 >> Initializing global attention on CLS token...\n",
            " 72% 5968/8340 [1:29:33<32:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:14,879 >> Initializing global attention on CLS token...\n",
            " 72% 5969/8340 [1:29:34<32:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:15,705 >> Initializing global attention on CLS token...\n",
            " 72% 5970/8340 [1:29:34<32:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:16,527 >> Initializing global attention on CLS token...\n",
            " 72% 5971/8340 [1:29:35<32:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:17,354 >> Initializing global attention on CLS token...\n",
            " 72% 5972/8340 [1:29:36<32:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:18,179 >> Initializing global attention on CLS token...\n",
            " 72% 5973/8340 [1:29:37<32:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:19,003 >> Initializing global attention on CLS token...\n",
            " 72% 5974/8340 [1:29:38<32:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:19,824 >> Initializing global attention on CLS token...\n",
            " 72% 5975/8340 [1:29:38<32:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:20,652 >> Initializing global attention on CLS token...\n",
            " 72% 5976/8340 [1:29:39<32:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:21,480 >> Initializing global attention on CLS token...\n",
            " 72% 5977/8340 [1:29:40<32:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:22,302 >> Initializing global attention on CLS token...\n",
            " 72% 5978/8340 [1:29:41<32:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:23,126 >> Initializing global attention on CLS token...\n",
            " 72% 5979/8340 [1:29:42<32:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:23,950 >> Initializing global attention on CLS token...\n",
            " 72% 5980/8340 [1:29:43<32:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:24,773 >> Initializing global attention on CLS token...\n",
            " 72% 5981/8340 [1:29:43<32:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:25,598 >> Initializing global attention on CLS token...\n",
            " 72% 5982/8340 [1:29:44<32:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:26,426 >> Initializing global attention on CLS token...\n",
            " 72% 5983/8340 [1:29:45<32:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:27,252 >> Initializing global attention on CLS token...\n",
            " 72% 5984/8340 [1:29:46<32:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:28,072 >> Initializing global attention on CLS token...\n",
            " 72% 5985/8340 [1:29:47<32:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:28,898 >> Initializing global attention on CLS token...\n",
            " 72% 5986/8340 [1:29:48<32:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:29,722 >> Initializing global attention on CLS token...\n",
            " 72% 5987/8340 [1:29:48<32:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:30,547 >> Initializing global attention on CLS token...\n",
            " 72% 5988/8340 [1:29:49<32:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:31,375 >> Initializing global attention on CLS token...\n",
            " 72% 5989/8340 [1:29:50<32:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:32,199 >> Initializing global attention on CLS token...\n",
            " 72% 5990/8340 [1:29:51<32:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:33,025 >> Initializing global attention on CLS token...\n",
            " 72% 5991/8340 [1:29:52<32:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:33,850 >> Initializing global attention on CLS token...\n",
            " 72% 5992/8340 [1:29:53<32:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:34,680 >> Initializing global attention on CLS token...\n",
            " 72% 5993/8340 [1:29:53<32:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:35,502 >> Initializing global attention on CLS token...\n",
            " 72% 5994/8340 [1:29:54<32:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:36,329 >> Initializing global attention on CLS token...\n",
            " 72% 5995/8340 [1:29:55<32:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:37,149 >> Initializing global attention on CLS token...\n",
            " 72% 5996/8340 [1:29:56<32:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:37,976 >> Initializing global attention on CLS token...\n",
            " 72% 5997/8340 [1:29:57<32:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:38,799 >> Initializing global attention on CLS token...\n",
            " 72% 5998/8340 [1:29:57<32:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:39,626 >> Initializing global attention on CLS token...\n",
            " 72% 5999/8340 [1:29:58<32:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:40,450 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0676, 'learning_rate': 8.43884892086331e-06, 'epoch': 7.19}\n",
            " 72% 6000/8340 [1:29:59<33:34,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:41,397 >> Initializing global attention on CLS token...\n",
            " 72% 6001/8340 [1:30:00<33:09,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:42,221 >> Initializing global attention on CLS token...\n",
            " 72% 6002/8340 [1:30:01<32:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:43,046 >> Initializing global attention on CLS token...\n",
            " 72% 6003/8340 [1:30:02<32:36,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:43,875 >> Initializing global attention on CLS token...\n",
            " 72% 6004/8340 [1:30:03<32:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:44,705 >> Initializing global attention on CLS token...\n",
            " 72% 6005/8340 [1:30:03<32:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:45,532 >> Initializing global attention on CLS token...\n",
            " 72% 6006/8340 [1:30:04<32:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:46,357 >> Initializing global attention on CLS token...\n",
            " 72% 6007/8340 [1:30:05<32:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:47,182 >> Initializing global attention on CLS token...\n",
            " 72% 6008/8340 [1:30:06<32:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:48,012 >> Initializing global attention on CLS token...\n",
            " 72% 6009/8340 [1:30:07<32:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:48,834 >> Initializing global attention on CLS token...\n",
            " 72% 6010/8340 [1:30:08<32:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:49,662 >> Initializing global attention on CLS token...\n",
            " 72% 6011/8340 [1:30:08<32:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:50,485 >> Initializing global attention on CLS token...\n",
            " 72% 6012/8340 [1:30:09<32:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:51,308 >> Initializing global attention on CLS token...\n",
            " 72% 6013/8340 [1:30:10<32:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:52,132 >> Initializing global attention on CLS token...\n",
            " 72% 6014/8340 [1:30:11<31:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:52,958 >> Initializing global attention on CLS token...\n",
            " 72% 6015/8340 [1:30:12<31:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:53,779 >> Initializing global attention on CLS token...\n",
            " 72% 6016/8340 [1:30:12<31:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:54,604 >> Initializing global attention on CLS token...\n",
            " 72% 6017/8340 [1:30:13<31:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:55,426 >> Initializing global attention on CLS token...\n",
            " 72% 6018/8340 [1:30:14<31:49,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:56,246 >> Initializing global attention on CLS token...\n",
            " 72% 6019/8340 [1:30:15<31:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:57,071 >> Initializing global attention on CLS token...\n",
            " 72% 6020/8340 [1:30:16<31:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:57,897 >> Initializing global attention on CLS token...\n",
            " 72% 6021/8340 [1:30:17<31:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:58,720 >> Initializing global attention on CLS token...\n",
            " 72% 6022/8340 [1:30:17<31:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:30:59,551 >> Initializing global attention on CLS token...\n",
            " 72% 6023/8340 [1:30:18<31:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:00,375 >> Initializing global attention on CLS token...\n",
            " 72% 6024/8340 [1:30:19<31:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:01,201 >> Initializing global attention on CLS token...\n",
            " 72% 6025/8340 [1:30:20<31:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:02,027 >> Initializing global attention on CLS token...\n",
            " 72% 6026/8340 [1:30:21<31:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:02,852 >> Initializing global attention on CLS token...\n",
            " 72% 6027/8340 [1:30:22<31:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:03,676 >> Initializing global attention on CLS token...\n",
            " 72% 6028/8340 [1:30:22<31:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:04,502 >> Initializing global attention on CLS token...\n",
            " 72% 6029/8340 [1:30:23<31:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:05,328 >> Initializing global attention on CLS token...\n",
            " 72% 6030/8340 [1:30:24<31:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:06,156 >> Initializing global attention on CLS token...\n",
            " 72% 6031/8340 [1:30:25<31:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:06,979 >> Initializing global attention on CLS token...\n",
            " 72% 6032/8340 [1:30:26<31:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:07,804 >> Initializing global attention on CLS token...\n",
            " 72% 6033/8340 [1:30:26<31:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:08,629 >> Initializing global attention on CLS token...\n",
            " 72% 6034/8340 [1:30:27<31:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:09,452 >> Initializing global attention on CLS token...\n",
            " 72% 6035/8340 [1:30:28<31:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:10,283 >> Initializing global attention on CLS token...\n",
            " 72% 6036/8340 [1:30:29<31:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:11,107 >> Initializing global attention on CLS token...\n",
            " 72% 6037/8340 [1:30:30<31:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:11,937 >> Initializing global attention on CLS token...\n",
            " 72% 6038/8340 [1:30:31<31:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:12,763 >> Initializing global attention on CLS token...\n",
            " 72% 6039/8340 [1:30:31<31:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:13,589 >> Initializing global attention on CLS token...\n",
            " 72% 6040/8340 [1:30:32<31:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:14,418 >> Initializing global attention on CLS token...\n",
            " 72% 6041/8340 [1:30:33<31:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:15,242 >> Initializing global attention on CLS token...\n",
            " 72% 6042/8340 [1:30:34<31:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:16,063 >> Initializing global attention on CLS token...\n",
            " 72% 6043/8340 [1:30:35<31:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:16,889 >> Initializing global attention on CLS token...\n",
            " 72% 6044/8340 [1:30:36<31:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:17,717 >> Initializing global attention on CLS token...\n",
            " 72% 6045/8340 [1:30:36<31:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:18,539 >> Initializing global attention on CLS token...\n",
            " 72% 6046/8340 [1:30:37<31:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:19,366 >> Initializing global attention on CLS token...\n",
            " 73% 6047/8340 [1:30:38<31:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:20,191 >> Initializing global attention on CLS token...\n",
            " 73% 6048/8340 [1:30:39<31:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:21,016 >> Initializing global attention on CLS token...\n",
            " 73% 6049/8340 [1:30:40<31:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:21,845 >> Initializing global attention on CLS token...\n",
            " 73% 6050/8340 [1:30:41<31:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:22,670 >> Initializing global attention on CLS token...\n",
            " 73% 6051/8340 [1:30:41<31:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:23,494 >> Initializing global attention on CLS token...\n",
            " 73% 6052/8340 [1:30:42<31:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:24,320 >> Initializing global attention on CLS token...\n",
            " 73% 6053/8340 [1:30:43<31:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:25,149 >> Initializing global attention on CLS token...\n",
            " 73% 6054/8340 [1:30:44<31:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:25,973 >> Initializing global attention on CLS token...\n",
            " 73% 6055/8340 [1:30:45<31:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:26,799 >> Initializing global attention on CLS token...\n",
            " 73% 6056/8340 [1:30:45<31:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:27,628 >> Initializing global attention on CLS token...\n",
            " 73% 6057/8340 [1:30:46<31:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:28,451 >> Initializing global attention on CLS token...\n",
            " 73% 6058/8340 [1:30:47<31:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:29,275 >> Initializing global attention on CLS token...\n",
            " 73% 6059/8340 [1:30:48<31:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:30,098 >> Initializing global attention on CLS token...\n",
            " 73% 6060/8340 [1:30:49<31:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:30,923 >> Initializing global attention on CLS token...\n",
            " 73% 6061/8340 [1:30:50<31:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:31,742 >> Initializing global attention on CLS token...\n",
            " 73% 6062/8340 [1:30:50<31:13,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:32,563 >> Initializing global attention on CLS token...\n",
            " 73% 6063/8340 [1:30:51<31:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:33,394 >> Initializing global attention on CLS token...\n",
            " 73% 6064/8340 [1:30:52<31:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:34,219 >> Initializing global attention on CLS token...\n",
            " 73% 6065/8340 [1:30:53<31:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:35,040 >> Initializing global attention on CLS token...\n",
            " 73% 6066/8340 [1:30:54<31:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:35,866 >> Initializing global attention on CLS token...\n",
            " 73% 6067/8340 [1:30:55<31:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:36,692 >> Initializing global attention on CLS token...\n",
            " 73% 6068/8340 [1:30:55<31:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:37,523 >> Initializing global attention on CLS token...\n",
            " 73% 6069/8340 [1:30:56<31:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:38,345 >> Initializing global attention on CLS token...\n",
            " 73% 6070/8340 [1:30:57<31:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:39,168 >> Initializing global attention on CLS token...\n",
            " 73% 6071/8340 [1:30:58<31:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:39,990 >> Initializing global attention on CLS token...\n",
            " 73% 6072/8340 [1:30:59<31:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:40,815 >> Initializing global attention on CLS token...\n",
            " 73% 6073/8340 [1:30:59<31:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:41,643 >> Initializing global attention on CLS token...\n",
            " 73% 6074/8340 [1:31:00<31:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:42,468 >> Initializing global attention on CLS token...\n",
            " 73% 6075/8340 [1:31:01<31:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:43,293 >> Initializing global attention on CLS token...\n",
            " 73% 6076/8340 [1:31:02<31:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:44,119 >> Initializing global attention on CLS token...\n",
            " 73% 6077/8340 [1:31:03<31:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:44,947 >> Initializing global attention on CLS token...\n",
            " 73% 6078/8340 [1:31:04<31:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:45,769 >> Initializing global attention on CLS token...\n",
            " 73% 6079/8340 [1:31:04<31:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:46,595 >> Initializing global attention on CLS token...\n",
            " 73% 6080/8340 [1:31:05<31:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:47,421 >> Initializing global attention on CLS token...\n",
            " 73% 6081/8340 [1:31:06<31:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:48,251 >> Initializing global attention on CLS token...\n",
            " 73% 6082/8340 [1:31:07<31:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:49,075 >> Initializing global attention on CLS token...\n",
            " 73% 6083/8340 [1:31:08<31:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:49,896 >> Initializing global attention on CLS token...\n",
            " 73% 6084/8340 [1:31:09<30:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:50,719 >> Initializing global attention on CLS token...\n",
            " 73% 6085/8340 [1:31:09<30:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:51,541 >> Initializing global attention on CLS token...\n",
            " 73% 6086/8340 [1:31:10<30:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:52,364 >> Initializing global attention on CLS token...\n",
            " 73% 6087/8340 [1:31:11<30:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:53,190 >> Initializing global attention on CLS token...\n",
            " 73% 6088/8340 [1:31:12<30:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:54,012 >> Initializing global attention on CLS token...\n",
            " 73% 6089/8340 [1:31:13<30:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:54,838 >> Initializing global attention on CLS token...\n",
            " 73% 6090/8340 [1:31:14<30:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:55,664 >> Initializing global attention on CLS token...\n",
            " 73% 6091/8340 [1:31:14<30:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:56,491 >> Initializing global attention on CLS token...\n",
            " 73% 6092/8340 [1:31:15<30:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:57,312 >> Initializing global attention on CLS token...\n",
            " 73% 6093/8340 [1:31:16<30:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:58,139 >> Initializing global attention on CLS token...\n",
            " 73% 6094/8340 [1:31:17<30:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:58,964 >> Initializing global attention on CLS token...\n",
            " 73% 6095/8340 [1:31:18<30:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:31:59,791 >> Initializing global attention on CLS token...\n",
            " 73% 6096/8340 [1:31:18<30:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:00,617 >> Initializing global attention on CLS token...\n",
            " 73% 6097/8340 [1:31:19<30:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:01,444 >> Initializing global attention on CLS token...\n",
            " 73% 6098/8340 [1:31:20<30:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:02,272 >> Initializing global attention on CLS token...\n",
            " 73% 6099/8340 [1:31:21<30:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:03,092 >> Initializing global attention on CLS token...\n",
            " 73% 6100/8340 [1:31:22<30:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:03,920 >> Initializing global attention on CLS token...\n",
            " 73% 6101/8340 [1:31:23<30:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:04,746 >> Initializing global attention on CLS token...\n",
            " 73% 6102/8340 [1:31:23<30:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:05,570 >> Initializing global attention on CLS token...\n",
            " 73% 6103/8340 [1:31:24<30:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:06,398 >> Initializing global attention on CLS token...\n",
            " 73% 6104/8340 [1:31:25<30:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:07,222 >> Initializing global attention on CLS token...\n",
            " 73% 6105/8340 [1:31:26<30:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:08,050 >> Initializing global attention on CLS token...\n",
            " 73% 6106/8340 [1:31:27<30:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:08,874 >> Initializing global attention on CLS token...\n",
            " 73% 6107/8340 [1:31:28<30:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:09,703 >> Initializing global attention on CLS token...\n",
            " 73% 6108/8340 [1:31:28<30:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:10,531 >> Initializing global attention on CLS token...\n",
            " 73% 6109/8340 [1:31:29<30:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:11,357 >> Initializing global attention on CLS token...\n",
            " 73% 6110/8340 [1:31:30<30:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:12,180 >> Initializing global attention on CLS token...\n",
            " 73% 6111/8340 [1:31:31<30:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:13,006 >> Initializing global attention on CLS token...\n",
            " 73% 6112/8340 [1:31:32<30:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:13,829 >> Initializing global attention on CLS token...\n",
            " 73% 6113/8340 [1:31:32<30:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:14,655 >> Initializing global attention on CLS token...\n",
            " 73% 6114/8340 [1:31:33<30:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:15,479 >> Initializing global attention on CLS token...\n",
            " 73% 6115/8340 [1:31:34<30:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:16,301 >> Initializing global attention on CLS token...\n",
            " 73% 6116/8340 [1:31:35<30:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:17,129 >> Initializing global attention on CLS token...\n",
            " 73% 6117/8340 [1:31:36<30:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:17,955 >> Initializing global attention on CLS token...\n",
            " 73% 6118/8340 [1:31:37<30:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:18,783 >> Initializing global attention on CLS token...\n",
            " 73% 6119/8340 [1:31:37<30:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:19,610 >> Initializing global attention on CLS token...\n",
            " 73% 6120/8340 [1:31:38<30:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:20,438 >> Initializing global attention on CLS token...\n",
            " 73% 6121/8340 [1:31:39<30:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:21,264 >> Initializing global attention on CLS token...\n",
            " 73% 6122/8340 [1:31:40<30:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:22,088 >> Initializing global attention on CLS token...\n",
            " 73% 6123/8340 [1:31:41<30:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:22,912 >> Initializing global attention on CLS token...\n",
            " 73% 6124/8340 [1:31:42<30:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:23,738 >> Initializing global attention on CLS token...\n",
            " 73% 6125/8340 [1:31:42<30:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:24,563 >> Initializing global attention on CLS token...\n",
            " 73% 6126/8340 [1:31:43<30:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:25,389 >> Initializing global attention on CLS token...\n",
            " 73% 6127/8340 [1:31:44<30:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:26,216 >> Initializing global attention on CLS token...\n",
            " 73% 6128/8340 [1:31:45<30:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:27,041 >> Initializing global attention on CLS token...\n",
            " 73% 6129/8340 [1:31:46<30:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:27,866 >> Initializing global attention on CLS token...\n",
            " 74% 6130/8340 [1:31:47<30:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:28,692 >> Initializing global attention on CLS token...\n",
            " 74% 6131/8340 [1:31:47<30:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:29,515 >> Initializing global attention on CLS token...\n",
            " 74% 6132/8340 [1:31:48<30:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:30,340 >> Initializing global attention on CLS token...\n",
            " 74% 6133/8340 [1:31:49<30:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:31,164 >> Initializing global attention on CLS token...\n",
            " 74% 6134/8340 [1:31:50<30:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:31,987 >> Initializing global attention on CLS token...\n",
            " 74% 6135/8340 [1:31:51<30:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:32,813 >> Initializing global attention on CLS token...\n",
            " 74% 6136/8340 [1:31:51<30:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:33,636 >> Initializing global attention on CLS token...\n",
            " 74% 6137/8340 [1:31:52<30:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:34,460 >> Initializing global attention on CLS token...\n",
            " 74% 6138/8340 [1:31:53<30:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:35,286 >> Initializing global attention on CLS token...\n",
            " 74% 6139/8340 [1:31:54<30:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:36,110 >> Initializing global attention on CLS token...\n",
            " 74% 6140/8340 [1:31:55<30:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:36,933 >> Initializing global attention on CLS token...\n",
            " 74% 6141/8340 [1:31:56<30:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:37,758 >> Initializing global attention on CLS token...\n",
            " 74% 6142/8340 [1:31:56<30:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:38,581 >> Initializing global attention on CLS token...\n",
            " 74% 6143/8340 [1:31:57<30:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:39,411 >> Initializing global attention on CLS token...\n",
            " 74% 6144/8340 [1:31:58<30:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:40,232 >> Initializing global attention on CLS token...\n",
            " 74% 6145/8340 [1:31:59<30:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:41,061 >> Initializing global attention on CLS token...\n",
            " 74% 6146/8340 [1:32:00<30:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:41,886 >> Initializing global attention on CLS token...\n",
            " 74% 6147/8340 [1:32:01<30:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:42,711 >> Initializing global attention on CLS token...\n",
            " 74% 6148/8340 [1:32:01<30:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:43,535 >> Initializing global attention on CLS token...\n",
            " 74% 6149/8340 [1:32:02<30:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:44,359 >> Initializing global attention on CLS token...\n",
            " 74% 6150/8340 [1:32:03<30:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:45,188 >> Initializing global attention on CLS token...\n",
            " 74% 6151/8340 [1:32:04<30:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:46,010 >> Initializing global attention on CLS token...\n",
            " 74% 6152/8340 [1:32:05<30:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:46,835 >> Initializing global attention on CLS token...\n",
            " 74% 6153/8340 [1:32:05<30:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:47,660 >> Initializing global attention on CLS token...\n",
            " 74% 6154/8340 [1:32:06<30:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:48,491 >> Initializing global attention on CLS token...\n",
            " 74% 6155/8340 [1:32:07<30:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:49,315 >> Initializing global attention on CLS token...\n",
            " 74% 6156/8340 [1:32:08<30:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:50,137 >> Initializing global attention on CLS token...\n",
            " 74% 6157/8340 [1:32:09<30:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:50,965 >> Initializing global attention on CLS token...\n",
            " 74% 6158/8340 [1:32:10<30:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:51,795 >> Initializing global attention on CLS token...\n",
            " 74% 6159/8340 [1:32:10<30:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:52,621 >> Initializing global attention on CLS token...\n",
            " 74% 6160/8340 [1:32:11<30:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:53,446 >> Initializing global attention on CLS token...\n",
            " 74% 6161/8340 [1:32:12<29:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:54,269 >> Initializing global attention on CLS token...\n",
            " 74% 6162/8340 [1:32:13<29:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:55,090 >> Initializing global attention on CLS token...\n",
            " 74% 6163/8340 [1:32:14<29:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:55,913 >> Initializing global attention on CLS token...\n",
            " 74% 6164/8340 [1:32:15<29:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:56,737 >> Initializing global attention on CLS token...\n",
            " 74% 6165/8340 [1:32:15<29:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:57,560 >> Initializing global attention on CLS token...\n",
            " 74% 6166/8340 [1:32:16<29:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:58,387 >> Initializing global attention on CLS token...\n",
            " 74% 6167/8340 [1:32:17<29:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:32:59,209 >> Initializing global attention on CLS token...\n",
            " 74% 6168/8340 [1:32:18<29:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:00,034 >> Initializing global attention on CLS token...\n",
            " 74% 6169/8340 [1:32:19<29:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:00,860 >> Initializing global attention on CLS token...\n",
            " 74% 6170/8340 [1:32:20<29:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:01,687 >> Initializing global attention on CLS token...\n",
            " 74% 6171/8340 [1:32:20<29:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:02,510 >> Initializing global attention on CLS token...\n",
            " 74% 6172/8340 [1:32:21<29:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:03,340 >> Initializing global attention on CLS token...\n",
            " 74% 6173/8340 [1:32:22<29:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:04,163 >> Initializing global attention on CLS token...\n",
            " 74% 6174/8340 [1:32:23<29:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:04,987 >> Initializing global attention on CLS token...\n",
            " 74% 6175/8340 [1:32:24<29:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:05,813 >> Initializing global attention on CLS token...\n",
            " 74% 6176/8340 [1:32:24<29:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:06,637 >> Initializing global attention on CLS token...\n",
            " 74% 6177/8340 [1:32:25<29:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:07,459 >> Initializing global attention on CLS token...\n",
            " 74% 6178/8340 [1:32:26<29:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:08,285 >> Initializing global attention on CLS token...\n",
            " 74% 6179/8340 [1:32:27<29:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:09,108 >> Initializing global attention on CLS token...\n",
            " 74% 6180/8340 [1:32:28<29:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:09,939 >> Initializing global attention on CLS token...\n",
            " 74% 6181/8340 [1:32:29<29:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:10,764 >> Initializing global attention on CLS token...\n",
            " 74% 6182/8340 [1:32:29<29:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:11,587 >> Initializing global attention on CLS token...\n",
            " 74% 6183/8340 [1:32:30<29:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:12,414 >> Initializing global attention on CLS token...\n",
            " 74% 6184/8340 [1:32:31<29:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:13,240 >> Initializing global attention on CLS token...\n",
            " 74% 6185/8340 [1:32:32<29:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:14,064 >> Initializing global attention on CLS token...\n",
            " 74% 6186/8340 [1:32:33<29:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:14,888 >> Initializing global attention on CLS token...\n",
            " 74% 6187/8340 [1:32:34<29:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:15,715 >> Initializing global attention on CLS token...\n",
            " 74% 6188/8340 [1:32:34<29:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:16,539 >> Initializing global attention on CLS token...\n",
            " 74% 6189/8340 [1:32:35<29:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:17,363 >> Initializing global attention on CLS token...\n",
            " 74% 6190/8340 [1:32:36<29:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:18,190 >> Initializing global attention on CLS token...\n",
            " 74% 6191/8340 [1:32:37<29:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:19,018 >> Initializing global attention on CLS token...\n",
            " 74% 6192/8340 [1:32:38<29:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:19,845 >> Initializing global attention on CLS token...\n",
            " 74% 6193/8340 [1:32:39<29:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:20,674 >> Initializing global attention on CLS token...\n",
            " 74% 6194/8340 [1:32:39<29:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:21,496 >> Initializing global attention on CLS token...\n",
            " 74% 6195/8340 [1:32:40<29:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:22,324 >> Initializing global attention on CLS token...\n",
            " 74% 6196/8340 [1:32:41<29:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:23,148 >> Initializing global attention on CLS token...\n",
            " 74% 6197/8340 [1:32:42<29:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:23,973 >> Initializing global attention on CLS token...\n",
            " 74% 6198/8340 [1:32:43<29:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:24,813 >> Initializing global attention on CLS token...\n",
            " 74% 6199/8340 [1:32:43<29:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:25,638 >> Initializing global attention on CLS token...\n",
            " 74% 6200/8340 [1:32:44<29:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:26,463 >> Initializing global attention on CLS token...\n",
            " 74% 6201/8340 [1:32:45<29:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:27,285 >> Initializing global attention on CLS token...\n",
            " 74% 6202/8340 [1:32:46<29:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:28,113 >> Initializing global attention on CLS token...\n",
            " 74% 6203/8340 [1:32:47<29:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:28,935 >> Initializing global attention on CLS token...\n",
            " 74% 6204/8340 [1:32:48<29:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:29,765 >> Initializing global attention on CLS token...\n",
            " 74% 6205/8340 [1:32:48<29:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:30,590 >> Initializing global attention on CLS token...\n",
            " 74% 6206/8340 [1:32:49<29:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:31,416 >> Initializing global attention on CLS token...\n",
            " 74% 6207/8340 [1:32:50<29:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:32,247 >> Initializing global attention on CLS token...\n",
            " 74% 6208/8340 [1:32:51<29:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:33,073 >> Initializing global attention on CLS token...\n",
            " 74% 6209/8340 [1:32:52<29:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:33,894 >> Initializing global attention on CLS token...\n",
            " 74% 6210/8340 [1:32:53<29:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:34,719 >> Initializing global attention on CLS token...\n",
            " 74% 6211/8340 [1:32:53<29:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:35,546 >> Initializing global attention on CLS token...\n",
            " 74% 6212/8340 [1:32:54<29:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:36,371 >> Initializing global attention on CLS token...\n",
            " 74% 6213/8340 [1:32:55<29:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:37,196 >> Initializing global attention on CLS token...\n",
            " 75% 6214/8340 [1:32:56<29:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:38,020 >> Initializing global attention on CLS token...\n",
            " 75% 6215/8340 [1:32:57<29:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:38,848 >> Initializing global attention on CLS token...\n",
            " 75% 6216/8340 [1:32:58<29:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:39,678 >> Initializing global attention on CLS token...\n",
            " 75% 6217/8340 [1:32:58<29:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:40,508 >> Initializing global attention on CLS token...\n",
            " 75% 6218/8340 [1:32:59<29:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:41,342 >> Initializing global attention on CLS token...\n",
            " 75% 6219/8340 [1:33:00<29:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:42,165 >> Initializing global attention on CLS token...\n",
            " 75% 6220/8340 [1:33:01<29:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:42,990 >> Initializing global attention on CLS token...\n",
            " 75% 6221/8340 [1:33:02<29:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:43,819 >> Initializing global attention on CLS token...\n",
            " 75% 6222/8340 [1:33:02<29:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:44,644 >> Initializing global attention on CLS token...\n",
            " 75% 6223/8340 [1:33:03<29:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:45,473 >> Initializing global attention on CLS token...\n",
            " 75% 6224/8340 [1:33:04<29:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:46,300 >> Initializing global attention on CLS token...\n",
            " 75% 6225/8340 [1:33:05<29:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:47,122 >> Initializing global attention on CLS token...\n",
            " 75% 6226/8340 [1:33:06<29:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:47,948 >> Initializing global attention on CLS token...\n",
            " 75% 6227/8340 [1:33:07<29:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:48,774 >> Initializing global attention on CLS token...\n",
            " 75% 6228/8340 [1:33:07<29:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:49,604 >> Initializing global attention on CLS token...\n",
            " 75% 6229/8340 [1:33:08<29:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:50,429 >> Initializing global attention on CLS token...\n",
            " 75% 6230/8340 [1:33:09<29:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:51,256 >> Initializing global attention on CLS token...\n",
            " 75% 6231/8340 [1:33:10<29:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:52,080 >> Initializing global attention on CLS token...\n",
            " 75% 6232/8340 [1:33:11<29:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:52,907 >> Initializing global attention on CLS token...\n",
            " 75% 6233/8340 [1:33:12<28:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:53,731 >> Initializing global attention on CLS token...\n",
            " 75% 6234/8340 [1:33:12<28:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:54,556 >> Initializing global attention on CLS token...\n",
            " 75% 6235/8340 [1:33:13<28:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:55,380 >> Initializing global attention on CLS token...\n",
            " 75% 6236/8340 [1:33:14<28:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:56,207 >> Initializing global attention on CLS token...\n",
            " 75% 6237/8340 [1:33:15<28:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:57,032 >> Initializing global attention on CLS token...\n",
            " 75% 6238/8340 [1:33:16<28:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:57,861 >> Initializing global attention on CLS token...\n",
            " 75% 6239/8340 [1:33:17<28:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:58,686 >> Initializing global attention on CLS token...\n",
            " 75% 6240/8340 [1:33:17<28:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:33:59,513 >> Initializing global attention on CLS token...\n",
            " 75% 6241/8340 [1:33:18<28:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:00,343 >> Initializing global attention on CLS token...\n",
            " 75% 6242/8340 [1:33:19<28:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:01,169 >> Initializing global attention on CLS token...\n",
            " 75% 6243/8340 [1:33:20<28:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:01,992 >> Initializing global attention on CLS token...\n",
            " 75% 6244/8340 [1:33:21<28:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:02,822 >> Initializing global attention on CLS token...\n",
            " 75% 6245/8340 [1:33:21<28:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:03,647 >> Initializing global attention on CLS token...\n",
            " 75% 6246/8340 [1:33:22<28:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:04,470 >> Initializing global attention on CLS token...\n",
            " 75% 6247/8340 [1:33:23<28:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:05,294 >> Initializing global attention on CLS token...\n",
            " 75% 6248/8340 [1:33:24<28:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:06,120 >> Initializing global attention on CLS token...\n",
            " 75% 6249/8340 [1:33:25<28:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:06,940 >> Initializing global attention on CLS token...\n",
            " 75% 6250/8340 [1:33:26<28:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:07,766 >> Initializing global attention on CLS token...\n",
            " 75% 6251/8340 [1:33:26<28:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:08,589 >> Initializing global attention on CLS token...\n",
            " 75% 6252/8340 [1:33:27<28:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:09,416 >> Initializing global attention on CLS token...\n",
            " 75% 6253/8340 [1:33:28<28:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:10,239 >> Initializing global attention on CLS token...\n",
            " 75% 6254/8340 [1:33:29<28:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:11,062 >> Initializing global attention on CLS token...\n",
            " 75% 6255/8340 [1:33:30<28:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:11,888 >> Initializing global attention on CLS token...\n",
            " 75% 6256/8340 [1:33:31<28:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:12,716 >> Initializing global attention on CLS token...\n",
            " 75% 6257/8340 [1:33:31<28:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:13,539 >> Initializing global attention on CLS token...\n",
            " 75% 6258/8340 [1:33:32<28:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:14,368 >> Initializing global attention on CLS token...\n",
            " 75% 6259/8340 [1:33:33<28:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:15,194 >> Initializing global attention on CLS token...\n",
            " 75% 6260/8340 [1:33:34<28:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:16,020 >> Initializing global attention on CLS token...\n",
            " 75% 6261/8340 [1:33:35<28:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:16,845 >> Initializing global attention on CLS token...\n",
            " 75% 6262/8340 [1:33:36<28:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:17,669 >> Initializing global attention on CLS token...\n",
            " 75% 6263/8340 [1:33:36<28:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:18,496 >> Initializing global attention on CLS token...\n",
            " 75% 6264/8340 [1:33:37<28:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:19,320 >> Initializing global attention on CLS token...\n",
            " 75% 6265/8340 [1:33:38<28:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:20,147 >> Initializing global attention on CLS token...\n",
            " 75% 6266/8340 [1:33:39<28:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:20,974 >> Initializing global attention on CLS token...\n",
            " 75% 6267/8340 [1:33:40<28:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:21,795 >> Initializing global attention on CLS token...\n",
            " 75% 6268/8340 [1:33:40<28:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:22,619 >> Initializing global attention on CLS token...\n",
            " 75% 6269/8340 [1:33:41<28:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:23,442 >> Initializing global attention on CLS token...\n",
            " 75% 6270/8340 [1:33:42<28:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:24,270 >> Initializing global attention on CLS token...\n",
            " 75% 6271/8340 [1:33:43<28:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:25,093 >> Initializing global attention on CLS token...\n",
            " 75% 6272/8340 [1:33:44<28:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:25,925 >> Initializing global attention on CLS token...\n",
            " 75% 6273/8340 [1:33:45<28:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:26,748 >> Initializing global attention on CLS token...\n",
            " 75% 6274/8340 [1:33:45<28:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:27,574 >> Initializing global attention on CLS token...\n",
            " 75% 6275/8340 [1:33:46<28:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:28,398 >> Initializing global attention on CLS token...\n",
            " 75% 6276/8340 [1:33:47<28:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:29,222 >> Initializing global attention on CLS token...\n",
            " 75% 6277/8340 [1:33:48<28:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:30,047 >> Initializing global attention on CLS token...\n",
            " 75% 6278/8340 [1:33:49<28:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:30,871 >> Initializing global attention on CLS token...\n",
            " 75% 6279/8340 [1:33:50<28:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:31,693 >> Initializing global attention on CLS token...\n",
            " 75% 6280/8340 [1:33:50<28:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:32,519 >> Initializing global attention on CLS token...\n",
            " 75% 6281/8340 [1:33:51<28:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:33,343 >> Initializing global attention on CLS token...\n",
            " 75% 6282/8340 [1:33:52<28:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:34,169 >> Initializing global attention on CLS token...\n",
            " 75% 6283/8340 [1:33:53<28:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:34,995 >> Initializing global attention on CLS token...\n",
            " 75% 6284/8340 [1:33:54<28:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:35,821 >> Initializing global attention on CLS token...\n",
            " 75% 6285/8340 [1:33:54<28:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:36,646 >> Initializing global attention on CLS token...\n",
            " 75% 6286/8340 [1:33:55<28:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:37,471 >> Initializing global attention on CLS token...\n",
            " 75% 6287/8340 [1:33:56<28:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:38,296 >> Initializing global attention on CLS token...\n",
            " 75% 6288/8340 [1:33:57<28:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:39,120 >> Initializing global attention on CLS token...\n",
            " 75% 6289/8340 [1:33:58<28:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:39,945 >> Initializing global attention on CLS token...\n",
            " 75% 6290/8340 [1:33:59<28:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:40,768 >> Initializing global attention on CLS token...\n",
            " 75% 6291/8340 [1:33:59<28:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:41,591 >> Initializing global attention on CLS token...\n",
            " 75% 6292/8340 [1:34:00<28:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:42,417 >> Initializing global attention on CLS token...\n",
            " 75% 6293/8340 [1:34:01<28:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:43,242 >> Initializing global attention on CLS token...\n",
            " 75% 6294/8340 [1:34:02<28:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:44,067 >> Initializing global attention on CLS token...\n",
            " 75% 6295/8340 [1:34:03<28:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:44,897 >> Initializing global attention on CLS token...\n",
            " 75% 6296/8340 [1:34:04<28:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:45,722 >> Initializing global attention on CLS token...\n",
            " 76% 6297/8340 [1:34:04<28:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:46,551 >> Initializing global attention on CLS token...\n",
            " 76% 6298/8340 [1:34:05<28:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:47,376 >> Initializing global attention on CLS token...\n",
            " 76% 6299/8340 [1:34:06<28:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:48,202 >> Initializing global attention on CLS token...\n",
            " 76% 6300/8340 [1:34:07<28:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:49,026 >> Initializing global attention on CLS token...\n",
            " 76% 6301/8340 [1:34:08<28:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:49,849 >> Initializing global attention on CLS token...\n",
            " 76% 6302/8340 [1:34:09<28:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:50,675 >> Initializing global attention on CLS token...\n",
            " 76% 6303/8340 [1:34:09<28:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:51,503 >> Initializing global attention on CLS token...\n",
            " 76% 6304/8340 [1:34:10<28:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:52,329 >> Initializing global attention on CLS token...\n",
            " 76% 6305/8340 [1:34:11<28:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:53,158 >> Initializing global attention on CLS token...\n",
            " 76% 6306/8340 [1:34:12<28:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:53,990 >> Initializing global attention on CLS token...\n",
            " 76% 6307/8340 [1:34:13<28:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:54,820 >> Initializing global attention on CLS token...\n",
            " 76% 6308/8340 [1:34:13<28:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:55,648 >> Initializing global attention on CLS token...\n",
            " 76% 6309/8340 [1:34:14<28:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:56,479 >> Initializing global attention on CLS token...\n",
            " 76% 6310/8340 [1:34:15<28:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:57,312 >> Initializing global attention on CLS token...\n",
            " 76% 6311/8340 [1:34:16<28:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:58,143 >> Initializing global attention on CLS token...\n",
            " 76% 6312/8340 [1:34:17<28:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:58,972 >> Initializing global attention on CLS token...\n",
            " 76% 6313/8340 [1:34:18<28:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:34:59,812 >> Initializing global attention on CLS token...\n",
            " 76% 6314/8340 [1:34:18<28:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:00,676 >> Initializing global attention on CLS token...\n",
            " 76% 6315/8340 [1:34:19<28:28,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:01,544 >> Initializing global attention on CLS token...\n",
            " 76% 6316/8340 [1:34:20<28:42,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:02,405 >> Initializing global attention on CLS token...\n",
            " 76% 6317/8340 [1:34:21<28:46,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:03,254 >> Initializing global attention on CLS token...\n",
            " 76% 6318/8340 [1:34:22<28:40,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:04,098 >> Initializing global attention on CLS token...\n",
            " 76% 6319/8340 [1:34:23<28:36,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:04,935 >> Initializing global attention on CLS token...\n",
            " 76% 6320/8340 [1:34:24<28:26,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:05,764 >> Initializing global attention on CLS token...\n",
            " 76% 6321/8340 [1:34:24<28:13,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:06,589 >> Initializing global attention on CLS token...\n",
            " 76% 6322/8340 [1:34:25<28:07,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:07,418 >> Initializing global attention on CLS token...\n",
            " 76% 6323/8340 [1:34:26<27:59,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:08,245 >> Initializing global attention on CLS token...\n",
            " 76% 6324/8340 [1:34:27<27:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:09,069 >> Initializing global attention on CLS token...\n",
            " 76% 6325/8340 [1:34:28<27:52,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:09,897 >> Initializing global attention on CLS token...\n",
            " 76% 6326/8340 [1:34:29<27:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:10,722 >> Initializing global attention on CLS token...\n",
            " 76% 6327/8340 [1:34:29<27:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:11,550 >> Initializing global attention on CLS token...\n",
            " 76% 6328/8340 [1:34:30<27:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:12,373 >> Initializing global attention on CLS token...\n",
            " 76% 6329/8340 [1:34:31<27:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:13,197 >> Initializing global attention on CLS token...\n",
            " 76% 6330/8340 [1:34:32<27:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:14,023 >> Initializing global attention on CLS token...\n",
            " 76% 6331/8340 [1:34:33<27:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:14,845 >> Initializing global attention on CLS token...\n",
            " 76% 6332/8340 [1:34:34<27:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:15,671 >> Initializing global attention on CLS token...\n",
            " 76% 6333/8340 [1:34:34<27:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:16,495 >> Initializing global attention on CLS token...\n",
            " 76% 6334/8340 [1:34:35<27:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:17,317 >> Initializing global attention on CLS token...\n",
            " 76% 6335/8340 [1:34:36<27:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:18,149 >> Initializing global attention on CLS token...\n",
            " 76% 6336/8340 [1:34:37<27:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:18,975 >> Initializing global attention on CLS token...\n",
            " 76% 6337/8340 [1:34:38<27:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:19,799 >> Initializing global attention on CLS token...\n",
            " 76% 6338/8340 [1:34:38<27:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:20,628 >> Initializing global attention on CLS token...\n",
            " 76% 6339/8340 [1:34:39<27:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:21,453 >> Initializing global attention on CLS token...\n",
            " 76% 6340/8340 [1:34:40<27:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:22,285 >> Initializing global attention on CLS token...\n",
            " 76% 6341/8340 [1:34:41<27:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:23,107 >> Initializing global attention on CLS token...\n",
            " 76% 6342/8340 [1:34:42<27:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:23,931 >> Initializing global attention on CLS token...\n",
            " 76% 6343/8340 [1:34:43<27:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:24,758 >> Initializing global attention on CLS token...\n",
            " 76% 6344/8340 [1:34:43<27:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:25,593 >> Initializing global attention on CLS token...\n",
            " 76% 6345/8340 [1:34:44<27:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:26,418 >> Initializing global attention on CLS token...\n",
            " 76% 6346/8340 [1:34:45<27:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:27,241 >> Initializing global attention on CLS token...\n",
            " 76% 6347/8340 [1:34:46<27:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:28,067 >> Initializing global attention on CLS token...\n",
            " 76% 6348/8340 [1:34:47<27:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:28,896 >> Initializing global attention on CLS token...\n",
            " 76% 6349/8340 [1:34:48<27:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:29,723 >> Initializing global attention on CLS token...\n",
            " 76% 6350/8340 [1:34:48<27:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:30,552 >> Initializing global attention on CLS token...\n",
            " 76% 6351/8340 [1:34:49<27:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:31,380 >> Initializing global attention on CLS token...\n",
            " 76% 6352/8340 [1:34:50<27:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:32,209 >> Initializing global attention on CLS token...\n",
            " 76% 6353/8340 [1:34:51<27:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:33,034 >> Initializing global attention on CLS token...\n",
            " 76% 6354/8340 [1:34:52<27:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:33,860 >> Initializing global attention on CLS token...\n",
            " 76% 6355/8340 [1:34:53<27:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:34,687 >> Initializing global attention on CLS token...\n",
            " 76% 6356/8340 [1:34:53<27:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:35,518 >> Initializing global attention on CLS token...\n",
            " 76% 6357/8340 [1:34:54<27:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:36,343 >> Initializing global attention on CLS token...\n",
            " 76% 6358/8340 [1:34:55<27:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:37,168 >> Initializing global attention on CLS token...\n",
            " 76% 6359/8340 [1:34:56<27:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:37,996 >> Initializing global attention on CLS token...\n",
            " 76% 6360/8340 [1:34:57<27:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:38,823 >> Initializing global attention on CLS token...\n",
            " 76% 6361/8340 [1:34:57<27:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:39,650 >> Initializing global attention on CLS token...\n",
            " 76% 6362/8340 [1:34:58<27:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:40,473 >> Initializing global attention on CLS token...\n",
            " 76% 6363/8340 [1:34:59<27:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:41,298 >> Initializing global attention on CLS token...\n",
            " 76% 6364/8340 [1:35:00<27:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:42,124 >> Initializing global attention on CLS token...\n",
            " 76% 6365/8340 [1:35:01<27:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:42,947 >> Initializing global attention on CLS token...\n",
            " 76% 6366/8340 [1:35:02<27:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:43,774 >> Initializing global attention on CLS token...\n",
            " 76% 6367/8340 [1:35:02<27:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:44,595 >> Initializing global attention on CLS token...\n",
            " 76% 6368/8340 [1:35:03<27:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:45,422 >> Initializing global attention on CLS token...\n",
            " 76% 6369/8340 [1:35:04<27:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:46,251 >> Initializing global attention on CLS token...\n",
            " 76% 6370/8340 [1:35:05<27:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:47,079 >> Initializing global attention on CLS token...\n",
            " 76% 6371/8340 [1:35:06<27:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:47,906 >> Initializing global attention on CLS token...\n",
            " 76% 6372/8340 [1:35:07<27:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:48,734 >> Initializing global attention on CLS token...\n",
            " 76% 6373/8340 [1:35:07<27:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:49,558 >> Initializing global attention on CLS token...\n",
            " 76% 6374/8340 [1:35:08<27:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:50,383 >> Initializing global attention on CLS token...\n",
            " 76% 6375/8340 [1:35:09<27:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:51,215 >> Initializing global attention on CLS token...\n",
            " 76% 6376/8340 [1:35:10<27:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:52,041 >> Initializing global attention on CLS token...\n",
            " 76% 6377/8340 [1:35:11<27:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:52,865 >> Initializing global attention on CLS token...\n",
            " 76% 6378/8340 [1:35:12<27:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:53,691 >> Initializing global attention on CLS token...\n",
            " 76% 6379/8340 [1:35:12<27:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:54,518 >> Initializing global attention on CLS token...\n",
            " 76% 6380/8340 [1:35:13<26:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:55,342 >> Initializing global attention on CLS token...\n",
            " 77% 6381/8340 [1:35:14<26:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:56,169 >> Initializing global attention on CLS token...\n",
            " 77% 6382/8340 [1:35:15<26:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:56,994 >> Initializing global attention on CLS token...\n",
            " 77% 6383/8340 [1:35:16<26:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:57,819 >> Initializing global attention on CLS token...\n",
            " 77% 6384/8340 [1:35:16<26:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:58,644 >> Initializing global attention on CLS token...\n",
            " 77% 6385/8340 [1:35:17<26:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:35:59,465 >> Initializing global attention on CLS token...\n",
            " 77% 6386/8340 [1:35:18<26:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:00,292 >> Initializing global attention on CLS token...\n",
            " 77% 6387/8340 [1:35:19<26:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:01,117 >> Initializing global attention on CLS token...\n",
            " 77% 6388/8340 [1:35:20<26:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:01,942 >> Initializing global attention on CLS token...\n",
            " 77% 6389/8340 [1:35:21<26:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:02,770 >> Initializing global attention on CLS token...\n",
            " 77% 6390/8340 [1:35:21<26:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:03,593 >> Initializing global attention on CLS token...\n",
            " 77% 6391/8340 [1:35:22<26:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:04,423 >> Initializing global attention on CLS token...\n",
            " 77% 6392/8340 [1:35:23<26:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:05,244 >> Initializing global attention on CLS token...\n",
            " 77% 6393/8340 [1:35:24<26:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:06,068 >> Initializing global attention on CLS token...\n",
            " 77% 6394/8340 [1:35:25<26:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:06,889 >> Initializing global attention on CLS token...\n",
            " 77% 6395/8340 [1:35:26<26:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:07,716 >> Initializing global attention on CLS token...\n",
            " 77% 6396/8340 [1:35:26<26:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:08,543 >> Initializing global attention on CLS token...\n",
            " 77% 6397/8340 [1:35:27<26:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:09,371 >> Initializing global attention on CLS token...\n",
            " 77% 6398/8340 [1:35:28<26:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:10,195 >> Initializing global attention on CLS token...\n",
            " 77% 6399/8340 [1:35:29<26:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:11,021 >> Initializing global attention on CLS token...\n",
            " 77% 6400/8340 [1:35:30<26:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:11,846 >> Initializing global attention on CLS token...\n",
            " 77% 6401/8340 [1:35:31<26:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:12,674 >> Initializing global attention on CLS token...\n",
            " 77% 6402/8340 [1:35:31<26:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:13,499 >> Initializing global attention on CLS token...\n",
            " 77% 6403/8340 [1:35:32<26:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:14,323 >> Initializing global attention on CLS token...\n",
            " 77% 6404/8340 [1:35:33<26:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:15,152 >> Initializing global attention on CLS token...\n",
            " 77% 6405/8340 [1:35:34<26:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:15,978 >> Initializing global attention on CLS token...\n",
            " 77% 6406/8340 [1:35:35<26:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:16,802 >> Initializing global attention on CLS token...\n",
            " 77% 6407/8340 [1:35:35<26:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:17,627 >> Initializing global attention on CLS token...\n",
            " 77% 6408/8340 [1:35:36<26:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:18,453 >> Initializing global attention on CLS token...\n",
            " 77% 6409/8340 [1:35:37<26:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:19,281 >> Initializing global attention on CLS token...\n",
            " 77% 6410/8340 [1:35:38<26:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:20,106 >> Initializing global attention on CLS token...\n",
            " 77% 6411/8340 [1:35:39<26:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:20,935 >> Initializing global attention on CLS token...\n",
            " 77% 6412/8340 [1:35:40<26:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:21,763 >> Initializing global attention on CLS token...\n",
            " 77% 6413/8340 [1:35:40<26:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:22,584 >> Initializing global attention on CLS token...\n",
            " 77% 6414/8340 [1:35:41<26:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:23,409 >> Initializing global attention on CLS token...\n",
            " 77% 6415/8340 [1:35:42<26:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:24,240 >> Initializing global attention on CLS token...\n",
            " 77% 6416/8340 [1:35:43<26:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:25,069 >> Initializing global attention on CLS token...\n",
            " 77% 6417/8340 [1:35:44<26:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:25,896 >> Initializing global attention on CLS token...\n",
            " 77% 6418/8340 [1:35:45<26:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:26,723 >> Initializing global attention on CLS token...\n",
            " 77% 6419/8340 [1:35:45<26:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:27,551 >> Initializing global attention on CLS token...\n",
            " 77% 6420/8340 [1:35:46<26:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:28,374 >> Initializing global attention on CLS token...\n",
            " 77% 6421/8340 [1:35:47<26:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:29,202 >> Initializing global attention on CLS token...\n",
            " 77% 6422/8340 [1:35:48<26:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:30,027 >> Initializing global attention on CLS token...\n",
            " 77% 6423/8340 [1:35:49<26:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:30,857 >> Initializing global attention on CLS token...\n",
            " 77% 6424/8340 [1:35:50<26:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:31,684 >> Initializing global attention on CLS token...\n",
            " 77% 6425/8340 [1:35:50<26:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:32,509 >> Initializing global attention on CLS token...\n",
            " 77% 6426/8340 [1:35:51<26:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:33,337 >> Initializing global attention on CLS token...\n",
            " 77% 6427/8340 [1:35:52<26:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:34,166 >> Initializing global attention on CLS token...\n",
            " 77% 6428/8340 [1:35:53<26:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:34,992 >> Initializing global attention on CLS token...\n",
            " 77% 6429/8340 [1:35:54<26:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:35,820 >> Initializing global attention on CLS token...\n",
            " 77% 6430/8340 [1:35:54<26:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:36,644 >> Initializing global attention on CLS token...\n",
            " 77% 6431/8340 [1:35:55<26:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:37,470 >> Initializing global attention on CLS token...\n",
            " 77% 6432/8340 [1:35:56<26:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:38,298 >> Initializing global attention on CLS token...\n",
            " 77% 6433/8340 [1:35:57<26:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:39,124 >> Initializing global attention on CLS token...\n",
            " 77% 6434/8340 [1:35:58<26:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:39,950 >> Initializing global attention on CLS token...\n",
            " 77% 6435/8340 [1:35:59<26:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:40,781 >> Initializing global attention on CLS token...\n",
            " 77% 6436/8340 [1:35:59<26:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:41,609 >> Initializing global attention on CLS token...\n",
            " 77% 6437/8340 [1:36:00<26:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:42,433 >> Initializing global attention on CLS token...\n",
            " 77% 6438/8340 [1:36:01<26:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:43,262 >> Initializing global attention on CLS token...\n",
            " 77% 6439/8340 [1:36:02<26:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:44,088 >> Initializing global attention on CLS token...\n",
            " 77% 6440/8340 [1:36:03<26:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:44,913 >> Initializing global attention on CLS token...\n",
            " 77% 6441/8340 [1:36:04<26:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:45,738 >> Initializing global attention on CLS token...\n",
            " 77% 6442/8340 [1:36:04<26:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:46,566 >> Initializing global attention on CLS token...\n",
            " 77% 6443/8340 [1:36:05<26:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:47,394 >> Initializing global attention on CLS token...\n",
            " 77% 6444/8340 [1:36:06<26:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:48,228 >> Initializing global attention on CLS token...\n",
            " 77% 6445/8340 [1:36:07<26:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:49,051 >> Initializing global attention on CLS token...\n",
            " 77% 6446/8340 [1:36:08<26:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:49,876 >> Initializing global attention on CLS token...\n",
            " 77% 6447/8340 [1:36:09<26:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:50,702 >> Initializing global attention on CLS token...\n",
            " 77% 6448/8340 [1:36:09<26:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:51,527 >> Initializing global attention on CLS token...\n",
            " 77% 6449/8340 [1:36:10<26:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:52,354 >> Initializing global attention on CLS token...\n",
            " 77% 6450/8340 [1:36:11<26:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:53,179 >> Initializing global attention on CLS token...\n",
            " 77% 6451/8340 [1:36:12<25:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:54,003 >> Initializing global attention on CLS token...\n",
            " 77% 6452/8340 [1:36:13<25:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:54,826 >> Initializing global attention on CLS token...\n",
            " 77% 6453/8340 [1:36:13<25:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:55,653 >> Initializing global attention on CLS token...\n",
            " 77% 6454/8340 [1:36:14<25:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:56,481 >> Initializing global attention on CLS token...\n",
            " 77% 6455/8340 [1:36:15<25:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:57,305 >> Initializing global attention on CLS token...\n",
            " 77% 6456/8340 [1:36:16<25:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:58,132 >> Initializing global attention on CLS token...\n",
            " 77% 6457/8340 [1:36:17<25:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:58,962 >> Initializing global attention on CLS token...\n",
            " 77% 6458/8340 [1:36:18<25:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:36:59,784 >> Initializing global attention on CLS token...\n",
            " 77% 6459/8340 [1:36:18<25:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:00,612 >> Initializing global attention on CLS token...\n",
            " 77% 6460/8340 [1:36:19<25:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:01,440 >> Initializing global attention on CLS token...\n",
            " 77% 6461/8340 [1:36:20<25:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:02,266 >> Initializing global attention on CLS token...\n",
            " 77% 6462/8340 [1:36:21<25:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:03,093 >> Initializing global attention on CLS token...\n",
            " 77% 6463/8340 [1:36:22<25:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:03,920 >> Initializing global attention on CLS token...\n",
            " 78% 6464/8340 [1:36:23<25:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:04,745 >> Initializing global attention on CLS token...\n",
            " 78% 6465/8340 [1:36:23<25:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:05,576 >> Initializing global attention on CLS token...\n",
            " 78% 6466/8340 [1:36:24<25:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:06,402 >> Initializing global attention on CLS token...\n",
            " 78% 6467/8340 [1:36:25<25:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:07,228 >> Initializing global attention on CLS token...\n",
            " 78% 6468/8340 [1:36:26<25:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:08,053 >> Initializing global attention on CLS token...\n",
            " 78% 6469/8340 [1:36:27<25:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:08,881 >> Initializing global attention on CLS token...\n",
            " 78% 6470/8340 [1:36:28<25:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:09,704 >> Initializing global attention on CLS token...\n",
            " 78% 6471/8340 [1:36:28<25:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:10,531 >> Initializing global attention on CLS token...\n",
            " 78% 6472/8340 [1:36:29<25:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:11,352 >> Initializing global attention on CLS token...\n",
            " 78% 6473/8340 [1:36:30<25:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:12,181 >> Initializing global attention on CLS token...\n",
            " 78% 6474/8340 [1:36:31<25:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:13,009 >> Initializing global attention on CLS token...\n",
            " 78% 6475/8340 [1:36:32<25:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:13,833 >> Initializing global attention on CLS token...\n",
            " 78% 6476/8340 [1:36:32<25:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:14,660 >> Initializing global attention on CLS token...\n",
            " 78% 6477/8340 [1:36:33<25:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:15,485 >> Initializing global attention on CLS token...\n",
            " 78% 6478/8340 [1:36:34<25:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:16,314 >> Initializing global attention on CLS token...\n",
            " 78% 6479/8340 [1:36:35<25:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:17,145 >> Initializing global attention on CLS token...\n",
            " 78% 6480/8340 [1:36:36<25:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:17,973 >> Initializing global attention on CLS token...\n",
            " 78% 6481/8340 [1:36:37<25:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:18,802 >> Initializing global attention on CLS token...\n",
            " 78% 6482/8340 [1:36:37<25:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:19,629 >> Initializing global attention on CLS token...\n",
            " 78% 6483/8340 [1:36:38<25:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:20,458 >> Initializing global attention on CLS token...\n",
            " 78% 6484/8340 [1:36:39<25:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:21,286 >> Initializing global attention on CLS token...\n",
            " 78% 6485/8340 [1:36:40<25:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:22,112 >> Initializing global attention on CLS token...\n",
            " 78% 6486/8340 [1:36:41<25:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:22,942 >> Initializing global attention on CLS token...\n",
            " 78% 6487/8340 [1:36:42<25:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:23,771 >> Initializing global attention on CLS token...\n",
            " 78% 6488/8340 [1:36:42<25:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:24,597 >> Initializing global attention on CLS token...\n",
            " 78% 6489/8340 [1:36:43<25:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:25,423 >> Initializing global attention on CLS token...\n",
            " 78% 6490/8340 [1:36:44<25:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:26,246 >> Initializing global attention on CLS token...\n",
            " 78% 6491/8340 [1:36:45<25:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:27,075 >> Initializing global attention on CLS token...\n",
            " 78% 6492/8340 [1:36:46<25:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:27,903 >> Initializing global attention on CLS token...\n",
            " 78% 6493/8340 [1:36:47<25:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:28,728 >> Initializing global attention on CLS token...\n",
            " 78% 6494/8340 [1:36:47<25:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:29,554 >> Initializing global attention on CLS token...\n",
            " 78% 6495/8340 [1:36:48<25:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:30,379 >> Initializing global attention on CLS token...\n",
            " 78% 6496/8340 [1:36:49<25:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:31,203 >> Initializing global attention on CLS token...\n",
            " 78% 6497/8340 [1:36:50<25:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:32,031 >> Initializing global attention on CLS token...\n",
            " 78% 6498/8340 [1:36:51<25:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:32,858 >> Initializing global attention on CLS token...\n",
            " 78% 6499/8340 [1:36:52<25:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:33,685 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0547, 'learning_rate': 6.640287769784173e-06, 'epoch': 7.79}\n",
            " 78% 6500/8340 [1:36:52<26:24,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:34,631 >> Initializing global attention on CLS token...\n",
            " 78% 6501/8340 [1:36:53<26:06,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:35,457 >> Initializing global attention on CLS token...\n",
            " 78% 6502/8340 [1:36:54<25:50,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:36,282 >> Initializing global attention on CLS token...\n",
            " 78% 6503/8340 [1:36:55<25:41,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:37,111 >> Initializing global attention on CLS token...\n",
            " 78% 6504/8340 [1:36:56<25:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:37,939 >> Initializing global attention on CLS token...\n",
            " 78% 6505/8340 [1:36:57<25:29,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:38,766 >> Initializing global attention on CLS token...\n",
            " 78% 6506/8340 [1:36:57<25:26,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:39,600 >> Initializing global attention on CLS token...\n",
            " 78% 6507/8340 [1:36:58<25:25,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:40,427 >> Initializing global attention on CLS token...\n",
            " 78% 6508/8340 [1:36:59<25:21,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:41,254 >> Initializing global attention on CLS token...\n",
            " 78% 6509/8340 [1:37:00<25:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:42,083 >> Initializing global attention on CLS token...\n",
            " 78% 6510/8340 [1:37:01<25:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:42,911 >> Initializing global attention on CLS token...\n",
            " 78% 6511/8340 [1:37:02<25:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:43,739 >> Initializing global attention on CLS token...\n",
            " 78% 6512/8340 [1:37:02<25:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:44,561 >> Initializing global attention on CLS token...\n",
            " 78% 6513/8340 [1:37:03<25:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:45,387 >> Initializing global attention on CLS token...\n",
            " 78% 6514/8340 [1:37:04<25:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:46,215 >> Initializing global attention on CLS token...\n",
            " 78% 6515/8340 [1:37:05<25:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:47,042 >> Initializing global attention on CLS token...\n",
            " 78% 6516/8340 [1:37:06<25:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:47,866 >> Initializing global attention on CLS token...\n",
            " 78% 6517/8340 [1:37:07<25:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:48,701 >> Initializing global attention on CLS token...\n",
            " 78% 6518/8340 [1:37:07<25:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:49,532 >> Initializing global attention on CLS token...\n",
            " 78% 6519/8340 [1:37:08<25:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:50,363 >> Initializing global attention on CLS token...\n",
            " 78% 6520/8340 [1:37:09<25:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:51,195 >> Initializing global attention on CLS token...\n",
            " 78% 6521/8340 [1:37:10<25:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:52,026 >> Initializing global attention on CLS token...\n",
            " 78% 6522/8340 [1:37:11<25:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:52,851 >> Initializing global attention on CLS token...\n",
            " 78% 6523/8340 [1:37:12<25:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:53,679 >> Initializing global attention on CLS token...\n",
            " 78% 6524/8340 [1:37:12<25:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:54,503 >> Initializing global attention on CLS token...\n",
            " 78% 6525/8340 [1:37:13<25:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:55,328 >> Initializing global attention on CLS token...\n",
            " 78% 6526/8340 [1:37:14<24:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:56,153 >> Initializing global attention on CLS token...\n",
            " 78% 6527/8340 [1:37:15<24:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:56,979 >> Initializing global attention on CLS token...\n",
            " 78% 6528/8340 [1:37:16<24:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:57,809 >> Initializing global attention on CLS token...\n",
            " 78% 6529/8340 [1:37:16<24:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:58,637 >> Initializing global attention on CLS token...\n",
            " 78% 6530/8340 [1:37:17<24:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:37:59,465 >> Initializing global attention on CLS token...\n",
            " 78% 6531/8340 [1:37:18<24:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:00,296 >> Initializing global attention on CLS token...\n",
            " 78% 6532/8340 [1:37:19<24:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:01,124 >> Initializing global attention on CLS token...\n",
            " 78% 6533/8340 [1:37:20<24:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:01,949 >> Initializing global attention on CLS token...\n",
            " 78% 6534/8340 [1:37:21<24:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:02,774 >> Initializing global attention on CLS token...\n",
            " 78% 6535/8340 [1:37:21<24:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:03,602 >> Initializing global attention on CLS token...\n",
            " 78% 6536/8340 [1:37:22<24:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:04,429 >> Initializing global attention on CLS token...\n",
            " 78% 6537/8340 [1:37:23<24:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:05,256 >> Initializing global attention on CLS token...\n",
            " 78% 6538/8340 [1:37:24<24:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:06,082 >> Initializing global attention on CLS token...\n",
            " 78% 6539/8340 [1:37:25<24:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:06,911 >> Initializing global attention on CLS token...\n",
            " 78% 6540/8340 [1:37:26<24:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:07,738 >> Initializing global attention on CLS token...\n",
            " 78% 6541/8340 [1:37:26<24:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:08,565 >> Initializing global attention on CLS token...\n",
            " 78% 6542/8340 [1:37:27<24:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:09,390 >> Initializing global attention on CLS token...\n",
            " 78% 6543/8340 [1:37:28<24:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:10,217 >> Initializing global attention on CLS token...\n",
            " 78% 6544/8340 [1:37:29<24:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:11,046 >> Initializing global attention on CLS token...\n",
            " 78% 6545/8340 [1:37:30<24:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:11,869 >> Initializing global attention on CLS token...\n",
            " 78% 6546/8340 [1:37:31<24:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:12,696 >> Initializing global attention on CLS token...\n",
            " 79% 6547/8340 [1:37:31<24:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:13,520 >> Initializing global attention on CLS token...\n",
            " 79% 6548/8340 [1:37:32<24:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:14,346 >> Initializing global attention on CLS token...\n",
            " 79% 6549/8340 [1:37:33<24:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:15,173 >> Initializing global attention on CLS token...\n",
            " 79% 6550/8340 [1:37:34<24:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:16,000 >> Initializing global attention on CLS token...\n",
            " 79% 6551/8340 [1:37:35<24:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:16,828 >> Initializing global attention on CLS token...\n",
            " 79% 6552/8340 [1:37:35<24:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:17,653 >> Initializing global attention on CLS token...\n",
            " 79% 6553/8340 [1:37:36<24:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:18,483 >> Initializing global attention on CLS token...\n",
            " 79% 6554/8340 [1:37:37<24:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:19,313 >> Initializing global attention on CLS token...\n",
            " 79% 6555/8340 [1:37:38<24:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:20,140 >> Initializing global attention on CLS token...\n",
            " 79% 6556/8340 [1:37:39<24:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:20,963 >> Initializing global attention on CLS token...\n",
            " 79% 6557/8340 [1:37:40<24:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:21,788 >> Initializing global attention on CLS token...\n",
            " 79% 6558/8340 [1:37:40<24:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:22,612 >> Initializing global attention on CLS token...\n",
            " 79% 6559/8340 [1:37:41<24:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:23,440 >> Initializing global attention on CLS token...\n",
            " 79% 6560/8340 [1:37:42<24:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:24,268 >> Initializing global attention on CLS token...\n",
            " 79% 6561/8340 [1:37:43<24:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:25,092 >> Initializing global attention on CLS token...\n",
            " 79% 6562/8340 [1:37:44<24:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:25,930 >> Initializing global attention on CLS token...\n",
            " 79% 6563/8340 [1:37:45<24:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:26,757 >> Initializing global attention on CLS token...\n",
            " 79% 6564/8340 [1:37:45<24:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:27,588 >> Initializing global attention on CLS token...\n",
            " 79% 6565/8340 [1:37:46<24:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:28,416 >> Initializing global attention on CLS token...\n",
            " 79% 6566/8340 [1:37:47<24:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:29,239 >> Initializing global attention on CLS token...\n",
            " 79% 6567/8340 [1:37:48<24:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:30,068 >> Initializing global attention on CLS token...\n",
            " 79% 6568/8340 [1:37:49<24:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:30,894 >> Initializing global attention on CLS token...\n",
            " 79% 6569/8340 [1:37:50<24:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:31,725 >> Initializing global attention on CLS token...\n",
            " 79% 6570/8340 [1:37:50<24:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:32,553 >> Initializing global attention on CLS token...\n",
            " 79% 6571/8340 [1:37:51<24:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:33,377 >> Initializing global attention on CLS token...\n",
            " 79% 6572/8340 [1:37:52<24:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:34,206 >> Initializing global attention on CLS token...\n",
            " 79% 6573/8340 [1:37:53<24:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:35,028 >> Initializing global attention on CLS token...\n",
            " 79% 6574/8340 [1:37:54<24:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:35,858 >> Initializing global attention on CLS token...\n",
            " 79% 6575/8340 [1:37:55<24:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:36,687 >> Initializing global attention on CLS token...\n",
            " 79% 6576/8340 [1:37:55<24:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:37,516 >> Initializing global attention on CLS token...\n",
            " 79% 6577/8340 [1:37:56<24:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:38,346 >> Initializing global attention on CLS token...\n",
            " 79% 6578/8340 [1:37:57<24:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:39,171 >> Initializing global attention on CLS token...\n",
            " 79% 6579/8340 [1:37:58<24:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:40,000 >> Initializing global attention on CLS token...\n",
            " 79% 6580/8340 [1:37:59<24:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:40,829 >> Initializing global attention on CLS token...\n",
            " 79% 6581/8340 [1:37:59<24:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:41,655 >> Initializing global attention on CLS token...\n",
            " 79% 6582/8340 [1:38:00<24:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:42,480 >> Initializing global attention on CLS token...\n",
            " 79% 6583/8340 [1:38:01<24:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:43,306 >> Initializing global attention on CLS token...\n",
            " 79% 6584/8340 [1:38:02<24:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:44,133 >> Initializing global attention on CLS token...\n",
            " 79% 6585/8340 [1:38:03<24:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:44,963 >> Initializing global attention on CLS token...\n",
            " 79% 6586/8340 [1:38:04<24:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:45,789 >> Initializing global attention on CLS token...\n",
            " 79% 6587/8340 [1:38:04<24:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:46,614 >> Initializing global attention on CLS token...\n",
            " 79% 6588/8340 [1:38:05<24:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:47,446 >> Initializing global attention on CLS token...\n",
            " 79% 6589/8340 [1:38:06<24:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:48,277 >> Initializing global attention on CLS token...\n",
            " 79% 6590/8340 [1:38:07<24:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:49,103 >> Initializing global attention on CLS token...\n",
            " 79% 6591/8340 [1:38:08<24:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:49,929 >> Initializing global attention on CLS token...\n",
            " 79% 6592/8340 [1:38:09<24:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:50,758 >> Initializing global attention on CLS token...\n",
            " 79% 6593/8340 [1:38:09<24:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:51,586 >> Initializing global attention on CLS token...\n",
            " 79% 6594/8340 [1:38:10<24:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:52,412 >> Initializing global attention on CLS token...\n",
            " 79% 6595/8340 [1:38:11<24:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:53,238 >> Initializing global attention on CLS token...\n",
            " 79% 6596/8340 [1:38:12<24:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:54,067 >> Initializing global attention on CLS token...\n",
            " 79% 6597/8340 [1:38:13<24:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:54,893 >> Initializing global attention on CLS token...\n",
            " 79% 6598/8340 [1:38:14<24:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:55,721 >> Initializing global attention on CLS token...\n",
            " 79% 6599/8340 [1:38:14<24:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:56,552 >> Initializing global attention on CLS token...\n",
            " 79% 6600/8340 [1:38:15<24:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:57,380 >> Initializing global attention on CLS token...\n",
            " 79% 6601/8340 [1:38:16<23:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:58,207 >> Initializing global attention on CLS token...\n",
            " 79% 6602/8340 [1:38:17<23:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:59,035 >> Initializing global attention on CLS token...\n",
            " 79% 6603/8340 [1:38:18<23:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:38:59,860 >> Initializing global attention on CLS token...\n",
            " 79% 6604/8340 [1:38:19<23:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:00,689 >> Initializing global attention on CLS token...\n",
            " 79% 6605/8340 [1:38:19<23:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:01,517 >> Initializing global attention on CLS token...\n",
            " 79% 6606/8340 [1:38:20<23:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:02,347 >> Initializing global attention on CLS token...\n",
            " 79% 6607/8340 [1:38:21<23:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:03,171 >> Initializing global attention on CLS token...\n",
            " 79% 6608/8340 [1:38:22<23:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:03,997 >> Initializing global attention on CLS token...\n",
            " 79% 6609/8340 [1:38:23<23:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:04,824 >> Initializing global attention on CLS token...\n",
            " 79% 6610/8340 [1:38:23<23:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:05,652 >> Initializing global attention on CLS token...\n",
            " 79% 6611/8340 [1:38:24<23:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:06,475 >> Initializing global attention on CLS token...\n",
            " 79% 6612/8340 [1:38:25<23:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:07,301 >> Initializing global attention on CLS token...\n",
            " 79% 6613/8340 [1:38:26<23:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:08,127 >> Initializing global attention on CLS token...\n",
            " 79% 6614/8340 [1:38:27<23:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:08,952 >> Initializing global attention on CLS token...\n",
            " 79% 6615/8340 [1:38:28<23:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:09,780 >> Initializing global attention on CLS token...\n",
            " 79% 6616/8340 [1:38:28<23:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:10,605 >> Initializing global attention on CLS token...\n",
            " 79% 6617/8340 [1:38:29<23:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:11,431 >> Initializing global attention on CLS token...\n",
            " 79% 6618/8340 [1:38:30<23:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:12,255 >> Initializing global attention on CLS token...\n",
            " 79% 6619/8340 [1:38:31<23:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:13,083 >> Initializing global attention on CLS token...\n",
            " 79% 6620/8340 [1:38:32<23:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:13,909 >> Initializing global attention on CLS token...\n",
            " 79% 6621/8340 [1:38:33<23:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:14,735 >> Initializing global attention on CLS token...\n",
            " 79% 6622/8340 [1:38:33<23:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:15,559 >> Initializing global attention on CLS token...\n",
            " 79% 6623/8340 [1:38:34<23:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:16,388 >> Initializing global attention on CLS token...\n",
            " 79% 6624/8340 [1:38:35<23:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:17,217 >> Initializing global attention on CLS token...\n",
            " 79% 6625/8340 [1:38:36<23:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:18,043 >> Initializing global attention on CLS token...\n",
            " 79% 6626/8340 [1:38:37<23:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:18,867 >> Initializing global attention on CLS token...\n",
            " 79% 6627/8340 [1:38:38<23:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:19,693 >> Initializing global attention on CLS token...\n",
            " 79% 6628/8340 [1:38:38<23:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:20,520 >> Initializing global attention on CLS token...\n",
            " 79% 6629/8340 [1:38:39<23:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:21,352 >> Initializing global attention on CLS token...\n",
            " 79% 6630/8340 [1:38:40<23:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:22,178 >> Initializing global attention on CLS token...\n",
            " 80% 6631/8340 [1:38:41<23:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:23,007 >> Initializing global attention on CLS token...\n",
            " 80% 6632/8340 [1:38:42<23:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:23,835 >> Initializing global attention on CLS token...\n",
            " 80% 6633/8340 [1:38:43<23:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:24,664 >> Initializing global attention on CLS token...\n",
            " 80% 6634/8340 [1:38:43<23:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:25,491 >> Initializing global attention on CLS token...\n",
            " 80% 6635/8340 [1:38:44<23:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:26,317 >> Initializing global attention on CLS token...\n",
            " 80% 6636/8340 [1:38:45<23:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:27,146 >> Initializing global attention on CLS token...\n",
            " 80% 6637/8340 [1:38:46<23:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:27,976 >> Initializing global attention on CLS token...\n",
            " 80% 6638/8340 [1:38:47<23:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:28,802 >> Initializing global attention on CLS token...\n",
            " 80% 6639/8340 [1:38:47<23:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:29,627 >> Initializing global attention on CLS token...\n",
            " 80% 6640/8340 [1:38:48<23:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:30,453 >> Initializing global attention on CLS token...\n",
            " 80% 6641/8340 [1:38:49<23:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:31,281 >> Initializing global attention on CLS token...\n",
            " 80% 6642/8340 [1:38:50<23:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:32,108 >> Initializing global attention on CLS token...\n",
            " 80% 6643/8340 [1:38:51<23:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:32,937 >> Initializing global attention on CLS token...\n",
            " 80% 6644/8340 [1:38:52<23:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:33,763 >> Initializing global attention on CLS token...\n",
            " 80% 6645/8340 [1:38:52<23:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:34,589 >> Initializing global attention on CLS token...\n",
            " 80% 6646/8340 [1:38:53<23:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:35,417 >> Initializing global attention on CLS token...\n",
            " 80% 6647/8340 [1:38:54<23:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:36,241 >> Initializing global attention on CLS token...\n",
            " 80% 6648/8340 [1:38:55<23:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:37,066 >> Initializing global attention on CLS token...\n",
            " 80% 6649/8340 [1:38:56<23:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:37,890 >> Initializing global attention on CLS token...\n",
            " 80% 6650/8340 [1:38:57<23:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:38,715 >> Initializing global attention on CLS token...\n",
            " 80% 6651/8340 [1:38:57<23:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:39,541 >> Initializing global attention on CLS token...\n",
            " 80% 6652/8340 [1:38:58<23:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:40,363 >> Initializing global attention on CLS token...\n",
            " 80% 6653/8340 [1:38:59<23:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:41,188 >> Initializing global attention on CLS token...\n",
            " 80% 6654/8340 [1:39:00<23:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:42,014 >> Initializing global attention on CLS token...\n",
            " 80% 6655/8340 [1:39:01<23:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:42,843 >> Initializing global attention on CLS token...\n",
            " 80% 6656/8340 [1:39:02<23:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:43,672 >> Initializing global attention on CLS token...\n",
            " 80% 6657/8340 [1:39:02<23:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:44,494 >> Initializing global attention on CLS token...\n",
            " 80% 6658/8340 [1:39:03<23:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:45,324 >> Initializing global attention on CLS token...\n",
            " 80% 6659/8340 [1:39:04<23:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:46,152 >> Initializing global attention on CLS token...\n",
            " 80% 6660/8340 [1:39:05<23:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:46,976 >> Initializing global attention on CLS token...\n",
            " 80% 6661/8340 [1:39:06<23:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:47,800 >> Initializing global attention on CLS token...\n",
            " 80% 6662/8340 [1:39:06<23:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:48,627 >> Initializing global attention on CLS token...\n",
            " 80% 6663/8340 [1:39:07<23:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:49,453 >> Initializing global attention on CLS token...\n",
            " 80% 6664/8340 [1:39:08<23:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:50,278 >> Initializing global attention on CLS token...\n",
            " 80% 6665/8340 [1:39:09<23:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:51,102 >> Initializing global attention on CLS token...\n",
            " 80% 6666/8340 [1:39:10<23:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:51,928 >> Initializing global attention on CLS token...\n",
            " 80% 6667/8340 [1:39:11<23:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:52,755 >> Initializing global attention on CLS token...\n",
            " 80% 6668/8340 [1:39:11<23:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:53,580 >> Initializing global attention on CLS token...\n",
            " 80% 6669/8340 [1:39:12<22:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:54,404 >> Initializing global attention on CLS token...\n",
            " 80% 6670/8340 [1:39:13<22:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:55,231 >> Initializing global attention on CLS token...\n",
            " 80% 6671/8340 [1:39:14<23:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:39:56,042 >> Initializing global attention on CLS token...\n",
            " 80% 6672/8340 [1:39:14<18:39,  1.49it/s][INFO|trainer.py:725] 2022-12-10 16:39:56,338 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 16:39:56,340 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 16:39:56,340 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 16:39:56,341 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:56,371 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:56,620 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:28,  8.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:56,871 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:40,  5.64it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:57,127 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:47,  4.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:57,377 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:50,  4.52it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:57,628 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:52,  4.31it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:57,877 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:53,  4.22it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:58,128 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:54,  4.15it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:58,375 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:54,  4.11it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:58,628 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:55,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:58,875 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:54,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:59,122 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:54,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:59,368 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:02<00:54,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:59,619 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:54,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:39:59,872 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:54,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:00,123 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:54,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:00,373 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:54,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:00,621 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:53,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:00,871 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:53,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:01,122 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:53,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:01,374 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:05<00:53,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:01,622 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:53,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:01,876 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:53,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:02,132 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:52,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:02,384 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:52,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:02,635 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:52,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:02,885 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:52,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:03,138 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:51,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:03,393 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:51,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:03,643 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:51,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:03,894 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:51,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:04,145 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:50,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:04,394 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:50,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:04,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:50,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:04,894 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:49,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:05,141 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:49,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:05,390 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:49,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:05,645 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:49,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:05,894 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:48,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:06,139 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:48,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:06,388 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:10<00:48,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:06,640 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:47,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:06,892 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:47,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:07,140 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:47,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:07,388 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:47,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:07,640 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:46,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:07,900 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:47,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:08,147 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:11<00:46,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:08,397 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:46,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:08,652 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:46,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:08,910 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:46,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:09,160 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:12<00:45,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:09,410 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:45,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:09,659 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:45,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:09,918 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:45,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:10,169 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:13<00:44,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:10,423 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:44,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:10,677 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:44,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:10,926 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:44,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:11,175 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:14<00:43,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:11,426 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:43,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:11,680 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:43,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:11,929 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:42,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:12,179 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:15<00:42,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:12,426 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:42,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:12,670 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:41,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:12,915 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:41,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:13,164 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:16<00:41,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:13,412 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:40,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:13,661 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:40,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:13,914 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:40,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:14,171 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:17<00:40,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:14,418 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:40,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:14,667 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:39,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:14,915 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:39,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:15,166 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:18<00:39,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:15,414 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:39,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:15,664 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:38,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:15,917 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:38,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:16,174 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:19<00:38,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:16,431 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:38,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:16,680 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:38,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:16,927 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:37,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:17,175 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:20<00:37,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:17,427 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:37,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:17,676 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:37,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:17,932 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:21<00:36,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:18,187 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:21<00:36,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:18,440 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:36,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:18,693 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:36,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:18,943 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:22<00:36,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:19,195 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:22<00:35,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:19,442 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:35,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:19,692 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:35,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:19,943 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:23<00:34,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:20,191 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:23<00:34,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:20,442 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:34,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:20,691 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:33,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:20,944 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:24<00:33,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:21,191 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:24<00:33,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:21,441 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:33,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:21,689 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:32,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:21,948 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:25<00:33,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:22,196 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:25<00:32,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:22,447 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:32,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:22,694 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:31,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:22,944 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:26<00:31,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:23,197 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:26<00:31,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:23,448 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:31,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:23,695 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:30,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:23,945 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:27<00:30,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:24,193 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:27<00:30,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:24,445 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:30,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:24,696 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:30,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:24,950 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:28<00:29,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:25,205 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:28<00:29,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:25,455 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:29,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:25,710 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:29,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:25,969 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:29<00:29,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:26,222 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:29<00:28,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:26,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:28,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:26,730 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:30<00:28,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:26,978 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:30<00:27,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:27,230 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:30<00:27,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:27,486 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:31<00:27,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:27,733 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:31<00:27,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:27,984 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:31<00:26,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:28,233 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:31<00:26,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:28,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:32<00:26,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:28,737 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:32<00:26,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:28,993 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:32<00:26,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:29,247 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:32<00:25,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:29,505 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:33<00:25,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:29,754 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:33<00:25,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:30,016 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:33<00:25,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:30,264 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:33<00:24,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:30,512 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:34<00:24,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:30,761 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:34<00:24,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:31,013 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:34<00:23,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:31,261 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:34<00:23,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:31,511 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:35<00:23,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:31,761 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:35<00:23,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:32,011 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:35<00:22,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:32,261 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:35<00:22,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:32,511 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:36<00:22,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:32,759 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:36<00:21,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:33,010 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:36<00:21,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:33,257 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:36<00:21,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:33,506 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:37<00:21,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:33,757 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:37<00:20,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:34,005 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:37<00:20,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:34,254 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:37<00:20,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:34,504 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:38<00:20,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:34,759 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:38<00:20,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:35,011 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:38<00:19,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:35,260 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:38<00:19,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:35,509 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:39<00:19,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:35,762 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:39<00:19,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:36,017 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:39<00:18,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:36,271 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:39<00:18,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:36,518 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:40<00:18,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:36,775 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:40<00:18,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:37,025 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:40<00:17,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:37,275 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:40<00:17,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:37,524 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:41<00:17,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:37,779 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:41<00:17,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:38,032 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:41<00:16,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:38,283 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:41<00:16,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:38,530 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:42<00:16,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:38,790 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:42<00:16,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:39,039 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:42<00:15,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:39,290 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:42<00:15,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:39,538 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:43<00:15,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:39,800 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:43<00:15,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:40,057 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:43<00:15,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:40,313 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:43<00:14,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:40,561 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:44<00:14,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:40,813 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:44<00:14,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:41,061 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:44<00:13,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:41,331 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:44<00:13,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:41,579 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:45<00:13,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:41,828 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:45<00:13,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:42,082 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:45<00:12,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:42,338 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:45<00:12,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:42,593 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:46<00:12,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:42,861 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:46<00:12,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:43,127 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:46<00:12,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:43,384 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:47<00:11,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:43,640 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:47<00:11,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:43,891 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:47<00:11,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:44,142 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:47<00:10,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:44,391 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:48<00:10,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:44,640 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:48<00:10,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:44,888 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:48<00:10,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:45,145 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:48<00:09,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:45,394 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:49<00:09,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:45,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:49<00:09,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:45,892 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:49<00:09,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:46,143 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:49<00:08,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:46,392 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:50<00:08,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:46,643 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:50<00:08,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:46,892 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:50<00:08,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:47,144 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:50<00:07,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:47,393 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:51<00:07,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:47,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:51<00:07,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:47,893 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:51<00:07,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:48,148 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:51<00:06,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:48,396 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:52<00:06,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:48,641 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:52<00:06,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:48,885 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:52<00:05,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:49,130 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:52<00:05,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:49,381 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:53<00:05,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:49,628 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:53<00:05,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:49,881 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:53<00:04,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:50,127 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:53<00:04,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:50,384 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:54<00:04,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:50,632 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:54<00:04,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:50,881 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:54<00:03,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:51,132 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:54<00:03,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:51,383 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:55<00:03,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:51,629 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:55<00:03,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:51,880 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:55<00:02,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:52,129 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:55<00:02,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:52,377 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:56<00:02,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:52,625 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:56<00:02,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:52,877 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:56<00:02,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:53,127 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:56<00:01,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:53,375 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:57<00:01,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:53,631 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:57<00:01,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:53,879 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:57<00:00,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:54,128 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:57<00:00,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:54,374 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:58<00:00,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:54,624 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:58<00:00,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:54,853 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.5027014017105103, 'eval_f1-micro': 0.7678571428571429, 'eval_f1-macro': 0.6875144495288958, 'eval_runtime': 59.7556, 'eval_samples_per_second': 23.429, 'eval_steps_per_second': 3.916, 'epoch': 8.0}\n",
            " 80% 6672/8340 [1:40:14<18:39,  1.49it/s]\n",
            "100% 234/234 [00:59<00:00,  4.01it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-10 16:40:56,098 >> Saving model checkpoint to logs/output_1/checkpoint-6672\n",
            "[INFO|configuration_utils.py:447] 2022-12-10 16:40:56,099 >> Configuration saved in logs/output_1/checkpoint-6672/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-10 16:40:56,426 >> Model weights saved in logs/output_1/checkpoint-6672/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-10 16:40:56,427 >> tokenizer config file saved in logs/output_1/checkpoint-6672/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-10 16:40:56,427 >> Special tokens file saved in logs/output_1/checkpoint-6672/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 16:40:57,255 >> Initializing global attention on CLS token...\n",
            " 80% 6673/8340 [1:40:16<8:47:59, 19.00s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:40:58,151 >> Initializing global attention on CLS token...\n",
            " 80% 6674/8340 [1:40:17<6:16:16, 13.55s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:40:58,978 >> Initializing global attention on CLS token...\n",
            " 80% 6675/8340 [1:40:18<4:30:05,  9.73s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:40:59,802 >> Initializing global attention on CLS token...\n",
            " 80% 6676/8340 [1:40:18<3:15:49,  7.06s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:00,629 >> Initializing global attention on CLS token...\n",
            " 80% 6677/8340 [1:40:19<2:23:53,  5.19s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:01,456 >> Initializing global attention on CLS token...\n",
            " 80% 6678/8340 [1:40:20<1:47:31,  3.88s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:02,282 >> Initializing global attention on CLS token...\n",
            " 80% 6679/8340 [1:40:21<1:22:04,  2.97s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:03,107 >> Initializing global attention on CLS token...\n",
            " 80% 6680/8340 [1:40:22<1:04:14,  2.32s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:03,930 >> Initializing global attention on CLS token...\n",
            " 80% 6681/8340 [1:40:23<51:46,  1.87s/it]  [INFO|modeling_longformer.py:1932] 2022-12-10 16:41:04,753 >> Initializing global attention on CLS token...\n",
            " 80% 6682/8340 [1:40:23<43:03,  1.56s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:05,578 >> Initializing global attention on CLS token...\n",
            " 80% 6683/8340 [1:40:24<36:58,  1.34s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:06,404 >> Initializing global attention on CLS token...\n",
            " 80% 6684/8340 [1:40:25<32:43,  1.19s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:07,231 >> Initializing global attention on CLS token...\n",
            " 80% 6685/8340 [1:40:26<29:41,  1.08s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:08,054 >> Initializing global attention on CLS token...\n",
            " 80% 6686/8340 [1:40:27<27:35,  1.00s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:08,879 >> Initializing global attention on CLS token...\n",
            " 80% 6687/8340 [1:40:28<26:06,  1.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:09,702 >> Initializing global attention on CLS token...\n",
            " 80% 6688/8340 [1:40:28<25:05,  1.10it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:10,528 >> Initializing global attention on CLS token...\n",
            " 80% 6689/8340 [1:40:29<24:19,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:11,350 >> Initializing global attention on CLS token...\n",
            " 80% 6690/8340 [1:40:30<23:50,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:12,177 >> Initializing global attention on CLS token...\n",
            " 80% 6691/8340 [1:40:31<23:29,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:13,002 >> Initializing global attention on CLS token...\n",
            " 80% 6692/8340 [1:40:32<23:15,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:13,831 >> Initializing global attention on CLS token...\n",
            " 80% 6693/8340 [1:40:32<23:04,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:14,659 >> Initializing global attention on CLS token...\n",
            " 80% 6694/8340 [1:40:33<22:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:15,483 >> Initializing global attention on CLS token...\n",
            " 80% 6695/8340 [1:40:34<22:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:16,306 >> Initializing global attention on CLS token...\n",
            " 80% 6696/8340 [1:40:35<22:44,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:17,132 >> Initializing global attention on CLS token...\n",
            " 80% 6697/8340 [1:40:36<22:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:17,957 >> Initializing global attention on CLS token...\n",
            " 80% 6698/8340 [1:40:37<22:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:18,786 >> Initializing global attention on CLS token...\n",
            " 80% 6699/8340 [1:40:37<22:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:19,613 >> Initializing global attention on CLS token...\n",
            " 80% 6700/8340 [1:40:38<22:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:20,437 >> Initializing global attention on CLS token...\n",
            " 80% 6701/8340 [1:40:39<22:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:21,264 >> Initializing global attention on CLS token...\n",
            " 80% 6702/8340 [1:40:40<22:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:22,092 >> Initializing global attention on CLS token...\n",
            " 80% 6703/8340 [1:40:41<22:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:22,921 >> Initializing global attention on CLS token...\n",
            " 80% 6704/8340 [1:40:42<22:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:23,750 >> Initializing global attention on CLS token...\n",
            " 80% 6705/8340 [1:40:42<22:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:24,577 >> Initializing global attention on CLS token...\n",
            " 80% 6706/8340 [1:40:43<22:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:25,403 >> Initializing global attention on CLS token...\n",
            " 80% 6707/8340 [1:40:44<22:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:26,235 >> Initializing global attention on CLS token...\n",
            " 80% 6708/8340 [1:40:45<22:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:27,064 >> Initializing global attention on CLS token...\n",
            " 80% 6709/8340 [1:40:46<22:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:27,913 >> Initializing global attention on CLS token...\n",
            " 80% 6710/8340 [1:40:47<22:43,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:28,746 >> Initializing global attention on CLS token...\n",
            " 80% 6711/8340 [1:40:47<22:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:29,601 >> Initializing global attention on CLS token...\n",
            " 80% 6712/8340 [1:40:48<22:48,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:30,451 >> Initializing global attention on CLS token...\n",
            " 80% 6713/8340 [1:40:49<22:53,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:31,297 >> Initializing global attention on CLS token...\n",
            " 81% 6714/8340 [1:40:50<22:51,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:32,131 >> Initializing global attention on CLS token...\n",
            " 81% 6715/8340 [1:40:51<22:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:32,955 >> Initializing global attention on CLS token...\n",
            " 81% 6716/8340 [1:40:52<22:34,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:33,777 >> Initializing global attention on CLS token...\n",
            " 81% 6717/8340 [1:40:52<22:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:34,606 >> Initializing global attention on CLS token...\n",
            " 81% 6718/8340 [1:40:53<22:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:35,433 >> Initializing global attention on CLS token...\n",
            " 81% 6719/8340 [1:40:54<22:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:36,261 >> Initializing global attention on CLS token...\n",
            " 81% 6720/8340 [1:40:55<22:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:37,089 >> Initializing global attention on CLS token...\n",
            " 81% 6721/8340 [1:40:56<22:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:37,915 >> Initializing global attention on CLS token...\n",
            " 81% 6722/8340 [1:40:57<22:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:38,742 >> Initializing global attention on CLS token...\n",
            " 81% 6723/8340 [1:40:57<22:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:39,569 >> Initializing global attention on CLS token...\n",
            " 81% 6724/8340 [1:40:58<22:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:40,395 >> Initializing global attention on CLS token...\n",
            " 81% 6725/8340 [1:40:59<22:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:41,223 >> Initializing global attention on CLS token...\n",
            " 81% 6726/8340 [1:41:00<22:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:42,048 >> Initializing global attention on CLS token...\n",
            " 81% 6727/8340 [1:41:01<22:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:42,878 >> Initializing global attention on CLS token...\n",
            " 81% 6728/8340 [1:41:02<22:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:43,706 >> Initializing global attention on CLS token...\n",
            " 81% 6729/8340 [1:41:02<22:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:44,533 >> Initializing global attention on CLS token...\n",
            " 81% 6730/8340 [1:41:03<22:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:45,358 >> Initializing global attention on CLS token...\n",
            " 81% 6731/8340 [1:41:04<22:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:46,182 >> Initializing global attention on CLS token...\n",
            " 81% 6732/8340 [1:41:05<22:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:47,012 >> Initializing global attention on CLS token...\n",
            " 81% 6733/8340 [1:41:06<22:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:47,837 >> Initializing global attention on CLS token...\n",
            " 81% 6734/8340 [1:41:07<22:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:48,669 >> Initializing global attention on CLS token...\n",
            " 81% 6735/8340 [1:41:07<22:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:49,494 >> Initializing global attention on CLS token...\n",
            " 81% 6736/8340 [1:41:08<22:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:50,320 >> Initializing global attention on CLS token...\n",
            " 81% 6737/8340 [1:41:09<22:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:51,146 >> Initializing global attention on CLS token...\n",
            " 81% 6738/8340 [1:41:10<22:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:51,974 >> Initializing global attention on CLS token...\n",
            " 81% 6739/8340 [1:41:11<22:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:52,828 >> Initializing global attention on CLS token...\n",
            " 81% 6740/8340 [1:41:11<22:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:53,654 >> Initializing global attention on CLS token...\n",
            " 81% 6741/8340 [1:41:12<22:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:54,484 >> Initializing global attention on CLS token...\n",
            " 81% 6742/8340 [1:41:13<22:10,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:55,314 >> Initializing global attention on CLS token...\n",
            " 81% 6743/8340 [1:41:14<22:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:56,137 >> Initializing global attention on CLS token...\n",
            " 81% 6744/8340 [1:41:15<22:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:56,961 >> Initializing global attention on CLS token...\n",
            " 81% 6745/8340 [1:41:16<21:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:57,782 >> Initializing global attention on CLS token...\n",
            " 81% 6746/8340 [1:41:16<21:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:58,609 >> Initializing global attention on CLS token...\n",
            " 81% 6747/8340 [1:41:17<21:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:41:59,432 >> Initializing global attention on CLS token...\n",
            " 81% 6748/8340 [1:41:18<21:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:00,256 >> Initializing global attention on CLS token...\n",
            " 81% 6749/8340 [1:41:19<21:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:01,083 >> Initializing global attention on CLS token...\n",
            " 81% 6750/8340 [1:41:20<21:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:01,910 >> Initializing global attention on CLS token...\n",
            " 81% 6751/8340 [1:41:21<21:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:02,738 >> Initializing global attention on CLS token...\n",
            " 81% 6752/8340 [1:41:21<21:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:03,569 >> Initializing global attention on CLS token...\n",
            " 81% 6753/8340 [1:41:22<21:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:04,394 >> Initializing global attention on CLS token...\n",
            " 81% 6754/8340 [1:41:23<21:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:05,218 >> Initializing global attention on CLS token...\n",
            " 81% 6755/8340 [1:41:24<21:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:06,043 >> Initializing global attention on CLS token...\n",
            " 81% 6756/8340 [1:41:25<21:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:06,869 >> Initializing global attention on CLS token...\n",
            " 81% 6757/8340 [1:41:26<21:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:07,689 >> Initializing global attention on CLS token...\n",
            " 81% 6758/8340 [1:41:26<21:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:08,511 >> Initializing global attention on CLS token...\n",
            " 81% 6759/8340 [1:41:27<21:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:09,333 >> Initializing global attention on CLS token...\n",
            " 81% 6760/8340 [1:41:28<21:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:10,158 >> Initializing global attention on CLS token...\n",
            " 81% 6761/8340 [1:41:29<21:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:10,988 >> Initializing global attention on CLS token...\n",
            " 81% 6762/8340 [1:41:30<21:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:11,814 >> Initializing global attention on CLS token...\n",
            " 81% 6763/8340 [1:41:30<21:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:12,638 >> Initializing global attention on CLS token...\n",
            " 81% 6764/8340 [1:41:31<21:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:13,466 >> Initializing global attention on CLS token...\n",
            " 81% 6765/8340 [1:41:32<21:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:14,290 >> Initializing global attention on CLS token...\n",
            " 81% 6766/8340 [1:41:33<21:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:15,113 >> Initializing global attention on CLS token...\n",
            " 81% 6767/8340 [1:41:34<21:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:15,943 >> Initializing global attention on CLS token...\n",
            " 81% 6768/8340 [1:41:35<21:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:16,769 >> Initializing global attention on CLS token...\n",
            " 81% 6769/8340 [1:41:35<21:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:17,595 >> Initializing global attention on CLS token...\n",
            " 81% 6770/8340 [1:41:36<21:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:18,422 >> Initializing global attention on CLS token...\n",
            " 81% 6771/8340 [1:41:37<21:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:19,245 >> Initializing global attention on CLS token...\n",
            " 81% 6772/8340 [1:41:38<21:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:20,071 >> Initializing global attention on CLS token...\n",
            " 81% 6773/8340 [1:41:39<21:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:20,894 >> Initializing global attention on CLS token...\n",
            " 81% 6774/8340 [1:41:40<21:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:21,721 >> Initializing global attention on CLS token...\n",
            " 81% 6775/8340 [1:41:40<21:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:22,547 >> Initializing global attention on CLS token...\n",
            " 81% 6776/8340 [1:41:41<21:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:23,369 >> Initializing global attention on CLS token...\n",
            " 81% 6777/8340 [1:41:42<21:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:24,193 >> Initializing global attention on CLS token...\n",
            " 81% 6778/8340 [1:41:43<21:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:25,017 >> Initializing global attention on CLS token...\n",
            " 81% 6779/8340 [1:41:44<21:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:25,843 >> Initializing global attention on CLS token...\n",
            " 81% 6780/8340 [1:41:45<21:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:26,669 >> Initializing global attention on CLS token...\n",
            " 81% 6781/8340 [1:41:45<21:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:27,497 >> Initializing global attention on CLS token...\n",
            " 81% 6782/8340 [1:41:46<21:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:28,325 >> Initializing global attention on CLS token...\n",
            " 81% 6783/8340 [1:41:47<21:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:29,150 >> Initializing global attention on CLS token...\n",
            " 81% 6784/8340 [1:41:48<21:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:29,981 >> Initializing global attention on CLS token...\n",
            " 81% 6785/8340 [1:41:49<21:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:30,806 >> Initializing global attention on CLS token...\n",
            " 81% 6786/8340 [1:41:49<21:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:31,633 >> Initializing global attention on CLS token...\n",
            " 81% 6787/8340 [1:41:50<21:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:32,456 >> Initializing global attention on CLS token...\n",
            " 81% 6788/8340 [1:41:51<21:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:33,280 >> Initializing global attention on CLS token...\n",
            " 81% 6789/8340 [1:41:52<21:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:34,106 >> Initializing global attention on CLS token...\n",
            " 81% 6790/8340 [1:41:53<21:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:34,930 >> Initializing global attention on CLS token...\n",
            " 81% 6791/8340 [1:41:54<21:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:35,760 >> Initializing global attention on CLS token...\n",
            " 81% 6792/8340 [1:41:54<21:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:36,586 >> Initializing global attention on CLS token...\n",
            " 81% 6793/8340 [1:41:55<21:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:37,410 >> Initializing global attention on CLS token...\n",
            " 81% 6794/8340 [1:41:56<21:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:38,235 >> Initializing global attention on CLS token...\n",
            " 81% 6795/8340 [1:41:57<21:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:39,057 >> Initializing global attention on CLS token...\n",
            " 81% 6796/8340 [1:41:58<21:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:39,879 >> Initializing global attention on CLS token...\n",
            " 81% 6797/8340 [1:41:59<21:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:40,707 >> Initializing global attention on CLS token...\n",
            " 82% 6798/8340 [1:41:59<21:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:41,533 >> Initializing global attention on CLS token...\n",
            " 82% 6799/8340 [1:42:00<21:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:42,361 >> Initializing global attention on CLS token...\n",
            " 82% 6800/8340 [1:42:01<21:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:43,185 >> Initializing global attention on CLS token...\n",
            " 82% 6801/8340 [1:42:02<21:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:44,011 >> Initializing global attention on CLS token...\n",
            " 82% 6802/8340 [1:42:03<21:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:44,836 >> Initializing global attention on CLS token...\n",
            " 82% 6803/8340 [1:42:03<21:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:45,659 >> Initializing global attention on CLS token...\n",
            " 82% 6804/8340 [1:42:04<21:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:46,490 >> Initializing global attention on CLS token...\n",
            " 82% 6805/8340 [1:42:05<21:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:47,317 >> Initializing global attention on CLS token...\n",
            " 82% 6806/8340 [1:42:06<21:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:48,145 >> Initializing global attention on CLS token...\n",
            " 82% 6807/8340 [1:42:07<21:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:48,970 >> Initializing global attention on CLS token...\n",
            " 82% 6808/8340 [1:42:08<21:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:49,794 >> Initializing global attention on CLS token...\n",
            " 82% 6809/8340 [1:42:08<21:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:50,616 >> Initializing global attention on CLS token...\n",
            " 82% 6810/8340 [1:42:09<21:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:51,439 >> Initializing global attention on CLS token...\n",
            " 82% 6811/8340 [1:42:10<20:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:52,262 >> Initializing global attention on CLS token...\n",
            " 82% 6812/8340 [1:42:11<20:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:53,087 >> Initializing global attention on CLS token...\n",
            " 82% 6813/8340 [1:42:12<20:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:53,912 >> Initializing global attention on CLS token...\n",
            " 82% 6814/8340 [1:42:13<20:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:54,741 >> Initializing global attention on CLS token...\n",
            " 82% 6815/8340 [1:42:13<20:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:55,565 >> Initializing global attention on CLS token...\n",
            " 82% 6816/8340 [1:42:14<20:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:56,391 >> Initializing global attention on CLS token...\n",
            " 82% 6817/8340 [1:42:15<20:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:57,218 >> Initializing global attention on CLS token...\n",
            " 82% 6818/8340 [1:42:16<20:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:58,042 >> Initializing global attention on CLS token...\n",
            " 82% 6819/8340 [1:42:17<20:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:58,870 >> Initializing global attention on CLS token...\n",
            " 82% 6820/8340 [1:42:18<20:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:42:59,697 >> Initializing global attention on CLS token...\n",
            " 82% 6821/8340 [1:42:18<20:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:00,522 >> Initializing global attention on CLS token...\n",
            " 82% 6822/8340 [1:42:19<20:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:01,345 >> Initializing global attention on CLS token...\n",
            " 82% 6823/8340 [1:42:20<20:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:02,179 >> Initializing global attention on CLS token...\n",
            " 82% 6824/8340 [1:42:21<20:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:03,004 >> Initializing global attention on CLS token...\n",
            " 82% 6825/8340 [1:42:22<20:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:03,832 >> Initializing global attention on CLS token...\n",
            " 82% 6826/8340 [1:42:22<20:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:04,657 >> Initializing global attention on CLS token...\n",
            " 82% 6827/8340 [1:42:23<20:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:05,483 >> Initializing global attention on CLS token...\n",
            " 82% 6828/8340 [1:42:24<20:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:06,312 >> Initializing global attention on CLS token...\n",
            " 82% 6829/8340 [1:42:25<20:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:07,137 >> Initializing global attention on CLS token...\n",
            " 82% 6830/8340 [1:42:26<20:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:07,963 >> Initializing global attention on CLS token...\n",
            " 82% 6831/8340 [1:42:27<20:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:08,791 >> Initializing global attention on CLS token...\n",
            " 82% 6832/8340 [1:42:27<20:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:09,621 >> Initializing global attention on CLS token...\n",
            " 82% 6833/8340 [1:42:28<20:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:10,447 >> Initializing global attention on CLS token...\n",
            " 82% 6834/8340 [1:42:29<20:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:11,273 >> Initializing global attention on CLS token...\n",
            " 82% 6835/8340 [1:42:30<20:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:12,100 >> Initializing global attention on CLS token...\n",
            " 82% 6836/8340 [1:42:31<20:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:12,927 >> Initializing global attention on CLS token...\n",
            " 82% 6837/8340 [1:42:32<20:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:13,752 >> Initializing global attention on CLS token...\n",
            " 82% 6838/8340 [1:42:32<20:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:14,579 >> Initializing global attention on CLS token...\n",
            " 82% 6839/8340 [1:42:33<20:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:15,404 >> Initializing global attention on CLS token...\n",
            " 82% 6840/8340 [1:42:34<20:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:16,231 >> Initializing global attention on CLS token...\n",
            " 82% 6841/8340 [1:42:35<20:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:17,055 >> Initializing global attention on CLS token...\n",
            " 82% 6842/8340 [1:42:36<20:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:17,880 >> Initializing global attention on CLS token...\n",
            " 82% 6843/8340 [1:42:37<20:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:18,706 >> Initializing global attention on CLS token...\n",
            " 82% 6844/8340 [1:42:37<20:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:19,529 >> Initializing global attention on CLS token...\n",
            " 82% 6845/8340 [1:42:38<20:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:20,355 >> Initializing global attention on CLS token...\n",
            " 82% 6846/8340 [1:42:39<20:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:21,179 >> Initializing global attention on CLS token...\n",
            " 82% 6847/8340 [1:42:40<20:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:22,005 >> Initializing global attention on CLS token...\n",
            " 82% 6848/8340 [1:42:41<20:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:22,835 >> Initializing global attention on CLS token...\n",
            " 82% 6849/8340 [1:42:42<20:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:23,662 >> Initializing global attention on CLS token...\n",
            " 82% 6850/8340 [1:42:42<20:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:24,488 >> Initializing global attention on CLS token...\n",
            " 82% 6851/8340 [1:42:43<20:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:25,314 >> Initializing global attention on CLS token...\n",
            " 82% 6852/8340 [1:42:44<20:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:26,138 >> Initializing global attention on CLS token...\n",
            " 82% 6853/8340 [1:42:45<20:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:26,962 >> Initializing global attention on CLS token...\n",
            " 82% 6854/8340 [1:42:46<20:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:27,788 >> Initializing global attention on CLS token...\n",
            " 82% 6855/8340 [1:42:46<20:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:28,611 >> Initializing global attention on CLS token...\n",
            " 82% 6856/8340 [1:42:47<20:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:29,438 >> Initializing global attention on CLS token...\n",
            " 82% 6857/8340 [1:42:48<20:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:30,268 >> Initializing global attention on CLS token...\n",
            " 82% 6858/8340 [1:42:49<20:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:31,091 >> Initializing global attention on CLS token...\n",
            " 82% 6859/8340 [1:42:50<20:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:31,916 >> Initializing global attention on CLS token...\n",
            " 82% 6860/8340 [1:42:51<20:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:32,742 >> Initializing global attention on CLS token...\n",
            " 82% 6861/8340 [1:42:51<20:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:33,570 >> Initializing global attention on CLS token...\n",
            " 82% 6862/8340 [1:42:52<20:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:34,394 >> Initializing global attention on CLS token...\n",
            " 82% 6863/8340 [1:42:53<20:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:35,218 >> Initializing global attention on CLS token...\n",
            " 82% 6864/8340 [1:42:54<20:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:36,041 >> Initializing global attention on CLS token...\n",
            " 82% 6865/8340 [1:42:55<20:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:36,868 >> Initializing global attention on CLS token...\n",
            " 82% 6866/8340 [1:42:56<20:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:37,695 >> Initializing global attention on CLS token...\n",
            " 82% 6867/8340 [1:42:56<20:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:38,518 >> Initializing global attention on CLS token...\n",
            " 82% 6868/8340 [1:42:57<20:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:39,341 >> Initializing global attention on CLS token...\n",
            " 82% 6869/8340 [1:42:58<20:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:40,168 >> Initializing global attention on CLS token...\n",
            " 82% 6870/8340 [1:42:59<20:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:40,993 >> Initializing global attention on CLS token...\n",
            " 82% 6871/8340 [1:43:00<20:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:41,817 >> Initializing global attention on CLS token...\n",
            " 82% 6872/8340 [1:43:00<20:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:42,642 >> Initializing global attention on CLS token...\n",
            " 82% 6873/8340 [1:43:01<20:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:43,463 >> Initializing global attention on CLS token...\n",
            " 82% 6874/8340 [1:43:02<20:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:44,289 >> Initializing global attention on CLS token...\n",
            " 82% 6875/8340 [1:43:03<20:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:45,117 >> Initializing global attention on CLS token...\n",
            " 82% 6876/8340 [1:43:04<20:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:45,945 >> Initializing global attention on CLS token...\n",
            " 82% 6877/8340 [1:43:05<20:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:46,771 >> Initializing global attention on CLS token...\n",
            " 82% 6878/8340 [1:43:05<20:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:47,596 >> Initializing global attention on CLS token...\n",
            " 82% 6879/8340 [1:43:06<20:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:48,423 >> Initializing global attention on CLS token...\n",
            " 82% 6880/8340 [1:43:07<20:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:49,248 >> Initializing global attention on CLS token...\n",
            " 83% 6881/8340 [1:43:08<20:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:50,071 >> Initializing global attention on CLS token...\n",
            " 83% 6882/8340 [1:43:09<20:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:50,898 >> Initializing global attention on CLS token...\n",
            " 83% 6883/8340 [1:43:10<20:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:51,724 >> Initializing global attention on CLS token...\n",
            " 83% 6884/8340 [1:43:10<20:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:52,549 >> Initializing global attention on CLS token...\n",
            " 83% 6885/8340 [1:43:11<19:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:53,371 >> Initializing global attention on CLS token...\n",
            " 83% 6886/8340 [1:43:12<19:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:54,198 >> Initializing global attention on CLS token...\n",
            " 83% 6887/8340 [1:43:13<19:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:55,026 >> Initializing global attention on CLS token...\n",
            " 83% 6888/8340 [1:43:14<19:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:55,850 >> Initializing global attention on CLS token...\n",
            " 83% 6889/8340 [1:43:15<19:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:56,676 >> Initializing global attention on CLS token...\n",
            " 83% 6890/8340 [1:43:15<19:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:57,503 >> Initializing global attention on CLS token...\n",
            " 83% 6891/8340 [1:43:16<19:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:58,329 >> Initializing global attention on CLS token...\n",
            " 83% 6892/8340 [1:43:17<19:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:59,154 >> Initializing global attention on CLS token...\n",
            " 83% 6893/8340 [1:43:18<19:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:43:59,980 >> Initializing global attention on CLS token...\n",
            " 83% 6894/8340 [1:43:19<19:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:00,803 >> Initializing global attention on CLS token...\n",
            " 83% 6895/8340 [1:43:19<19:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:01,632 >> Initializing global attention on CLS token...\n",
            " 83% 6896/8340 [1:43:20<19:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:02,459 >> Initializing global attention on CLS token...\n",
            " 83% 6897/8340 [1:43:21<19:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:03,285 >> Initializing global attention on CLS token...\n",
            " 83% 6898/8340 [1:43:22<19:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:04,111 >> Initializing global attention on CLS token...\n",
            " 83% 6899/8340 [1:43:23<19:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:04,939 >> Initializing global attention on CLS token...\n",
            " 83% 6900/8340 [1:43:24<19:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:05,770 >> Initializing global attention on CLS token...\n",
            " 83% 6901/8340 [1:43:24<19:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:06,597 >> Initializing global attention on CLS token...\n",
            " 83% 6902/8340 [1:43:25<19:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:07,423 >> Initializing global attention on CLS token...\n",
            " 83% 6903/8340 [1:43:26<19:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:08,248 >> Initializing global attention on CLS token...\n",
            " 83% 6904/8340 [1:43:27<19:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:09,076 >> Initializing global attention on CLS token...\n",
            " 83% 6905/8340 [1:43:28<19:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:09,900 >> Initializing global attention on CLS token...\n",
            " 83% 6906/8340 [1:43:29<19:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:10,726 >> Initializing global attention on CLS token...\n",
            " 83% 6907/8340 [1:43:29<19:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:11,549 >> Initializing global attention on CLS token...\n",
            " 83% 6908/8340 [1:43:30<19:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:12,376 >> Initializing global attention on CLS token...\n",
            " 83% 6909/8340 [1:43:31<19:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:13,195 >> Initializing global attention on CLS token...\n",
            " 83% 6910/8340 [1:43:32<19:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:14,019 >> Initializing global attention on CLS token...\n",
            " 83% 6911/8340 [1:43:33<19:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:14,842 >> Initializing global attention on CLS token...\n",
            " 83% 6912/8340 [1:43:34<19:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:15,669 >> Initializing global attention on CLS token...\n",
            " 83% 6913/8340 [1:43:34<19:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:16,492 >> Initializing global attention on CLS token...\n",
            " 83% 6914/8340 [1:43:35<19:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:17,317 >> Initializing global attention on CLS token...\n",
            " 83% 6915/8340 [1:43:36<19:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:18,143 >> Initializing global attention on CLS token...\n",
            " 83% 6916/8340 [1:43:37<19:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:18,966 >> Initializing global attention on CLS token...\n",
            " 83% 6917/8340 [1:43:38<19:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:19,788 >> Initializing global attention on CLS token...\n",
            " 83% 6918/8340 [1:43:38<19:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:20,610 >> Initializing global attention on CLS token...\n",
            " 83% 6919/8340 [1:43:39<19:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:21,435 >> Initializing global attention on CLS token...\n",
            " 83% 6920/8340 [1:43:40<19:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:22,265 >> Initializing global attention on CLS token...\n",
            " 83% 6921/8340 [1:43:41<19:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:23,093 >> Initializing global attention on CLS token...\n",
            " 83% 6922/8340 [1:43:42<19:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:23,922 >> Initializing global attention on CLS token...\n",
            " 83% 6923/8340 [1:43:43<19:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:24,749 >> Initializing global attention on CLS token...\n",
            " 83% 6924/8340 [1:43:43<19:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:25,573 >> Initializing global attention on CLS token...\n",
            " 83% 6925/8340 [1:43:44<19:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:26,398 >> Initializing global attention on CLS token...\n",
            " 83% 6926/8340 [1:43:45<19:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:27,222 >> Initializing global attention on CLS token...\n",
            " 83% 6927/8340 [1:43:46<19:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:28,046 >> Initializing global attention on CLS token...\n",
            " 83% 6928/8340 [1:43:47<19:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:28,870 >> Initializing global attention on CLS token...\n",
            " 83% 6929/8340 [1:43:48<19:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:29,696 >> Initializing global attention on CLS token...\n",
            " 83% 6930/8340 [1:43:48<19:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:30,517 >> Initializing global attention on CLS token...\n",
            " 83% 6931/8340 [1:43:49<19:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:31,343 >> Initializing global attention on CLS token...\n",
            " 83% 6932/8340 [1:43:50<19:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:32,174 >> Initializing global attention on CLS token...\n",
            " 83% 6933/8340 [1:43:51<19:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:33,001 >> Initializing global attention on CLS token...\n",
            " 83% 6934/8340 [1:43:52<19:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:33,828 >> Initializing global attention on CLS token...\n",
            " 83% 6935/8340 [1:43:52<19:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:34,654 >> Initializing global attention on CLS token...\n",
            " 83% 6936/8340 [1:43:53<19:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:35,475 >> Initializing global attention on CLS token...\n",
            " 83% 6937/8340 [1:43:54<19:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:36,299 >> Initializing global attention on CLS token...\n",
            " 83% 6938/8340 [1:43:55<19:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:37,126 >> Initializing global attention on CLS token...\n",
            " 83% 6939/8340 [1:43:56<19:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:37,950 >> Initializing global attention on CLS token...\n",
            " 83% 6940/8340 [1:43:57<19:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:38,771 >> Initializing global attention on CLS token...\n",
            " 83% 6941/8340 [1:43:57<19:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:39,596 >> Initializing global attention on CLS token...\n",
            " 83% 6942/8340 [1:43:58<19:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:40,429 >> Initializing global attention on CLS token...\n",
            " 83% 6943/8340 [1:43:59<19:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:41,251 >> Initializing global attention on CLS token...\n",
            " 83% 6944/8340 [1:44:00<19:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:42,082 >> Initializing global attention on CLS token...\n",
            " 83% 6945/8340 [1:44:01<19:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:42,908 >> Initializing global attention on CLS token...\n",
            " 83% 6946/8340 [1:44:02<19:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:43,732 >> Initializing global attention on CLS token...\n",
            " 83% 6947/8340 [1:44:02<19:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:44,560 >> Initializing global attention on CLS token...\n",
            " 83% 6948/8340 [1:44:03<19:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:45,384 >> Initializing global attention on CLS token...\n",
            " 83% 6949/8340 [1:44:04<19:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:46,212 >> Initializing global attention on CLS token...\n",
            " 83% 6950/8340 [1:44:05<19:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:47,037 >> Initializing global attention on CLS token...\n",
            " 83% 6951/8340 [1:44:06<19:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:47,863 >> Initializing global attention on CLS token...\n",
            " 83% 6952/8340 [1:44:07<19:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:48,691 >> Initializing global attention on CLS token...\n",
            " 83% 6953/8340 [1:44:07<19:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:49,520 >> Initializing global attention on CLS token...\n",
            " 83% 6954/8340 [1:44:08<19:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:50,351 >> Initializing global attention on CLS token...\n",
            " 83% 6955/8340 [1:44:09<19:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:51,182 >> Initializing global attention on CLS token...\n",
            " 83% 6956/8340 [1:44:10<19:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:52,010 >> Initializing global attention on CLS token...\n",
            " 83% 6957/8340 [1:44:11<19:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:52,839 >> Initializing global attention on CLS token...\n",
            " 83% 6958/8340 [1:44:12<19:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:53,664 >> Initializing global attention on CLS token...\n",
            " 83% 6959/8340 [1:44:12<19:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:54,494 >> Initializing global attention on CLS token...\n",
            " 83% 6960/8340 [1:44:13<19:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:55,319 >> Initializing global attention on CLS token...\n",
            " 83% 6961/8340 [1:44:14<19:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:56,147 >> Initializing global attention on CLS token...\n",
            " 83% 6962/8340 [1:44:15<19:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:56,972 >> Initializing global attention on CLS token...\n",
            " 83% 6963/8340 [1:44:16<18:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:57,799 >> Initializing global attention on CLS token...\n",
            " 84% 6964/8340 [1:44:16<18:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:58,631 >> Initializing global attention on CLS token...\n",
            " 84% 6965/8340 [1:44:17<18:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:44:59,455 >> Initializing global attention on CLS token...\n",
            " 84% 6966/8340 [1:44:18<18:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:00,281 >> Initializing global attention on CLS token...\n",
            " 84% 6967/8340 [1:44:19<18:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:01,110 >> Initializing global attention on CLS token...\n",
            " 84% 6968/8340 [1:44:20<18:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:01,936 >> Initializing global attention on CLS token...\n",
            " 84% 6969/8340 [1:44:21<18:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:02,761 >> Initializing global attention on CLS token...\n",
            " 84% 6970/8340 [1:44:21<18:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:03,586 >> Initializing global attention on CLS token...\n",
            " 84% 6971/8340 [1:44:22<18:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:04,414 >> Initializing global attention on CLS token...\n",
            " 84% 6972/8340 [1:44:23<18:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:05,242 >> Initializing global attention on CLS token...\n",
            " 84% 6973/8340 [1:44:24<18:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:06,066 >> Initializing global attention on CLS token...\n",
            " 84% 6974/8340 [1:44:25<18:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:06,890 >> Initializing global attention on CLS token...\n",
            " 84% 6975/8340 [1:44:26<18:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:07,716 >> Initializing global attention on CLS token...\n",
            " 84% 6976/8340 [1:44:26<18:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:08,542 >> Initializing global attention on CLS token...\n",
            " 84% 6977/8340 [1:44:27<18:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:09,367 >> Initializing global attention on CLS token...\n",
            " 84% 6978/8340 [1:44:28<18:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:10,191 >> Initializing global attention on CLS token...\n",
            " 84% 6979/8340 [1:44:29<18:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:11,015 >> Initializing global attention on CLS token...\n",
            " 84% 6980/8340 [1:44:30<18:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:11,842 >> Initializing global attention on CLS token...\n",
            " 84% 6981/8340 [1:44:31<18:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:12,666 >> Initializing global attention on CLS token...\n",
            " 84% 6982/8340 [1:44:31<18:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:13,493 >> Initializing global attention on CLS token...\n",
            " 84% 6983/8340 [1:44:32<18:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:14,319 >> Initializing global attention on CLS token...\n",
            " 84% 6984/8340 [1:44:33<18:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:15,143 >> Initializing global attention on CLS token...\n",
            " 84% 6985/8340 [1:44:34<18:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:15,972 >> Initializing global attention on CLS token...\n",
            " 84% 6986/8340 [1:44:35<18:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:16,797 >> Initializing global attention on CLS token...\n",
            " 84% 6987/8340 [1:44:35<18:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:17,622 >> Initializing global attention on CLS token...\n",
            " 84% 6988/8340 [1:44:36<18:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:18,447 >> Initializing global attention on CLS token...\n",
            " 84% 6989/8340 [1:44:37<18:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:19,274 >> Initializing global attention on CLS token...\n",
            " 84% 6990/8340 [1:44:38<18:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:20,101 >> Initializing global attention on CLS token...\n",
            " 84% 6991/8340 [1:44:39<18:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:20,929 >> Initializing global attention on CLS token...\n",
            " 84% 6992/8340 [1:44:40<18:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:21,755 >> Initializing global attention on CLS token...\n",
            " 84% 6993/8340 [1:44:40<18:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:22,583 >> Initializing global attention on CLS token...\n",
            " 84% 6994/8340 [1:44:41<18:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:23,410 >> Initializing global attention on CLS token...\n",
            " 84% 6995/8340 [1:44:42<18:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:24,235 >> Initializing global attention on CLS token...\n",
            " 84% 6996/8340 [1:44:43<18:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:25,062 >> Initializing global attention on CLS token...\n",
            " 84% 6997/8340 [1:44:44<18:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:25,890 >> Initializing global attention on CLS token...\n",
            " 84% 6998/8340 [1:44:45<18:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:26,715 >> Initializing global attention on CLS token...\n",
            " 84% 6999/8340 [1:44:45<18:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:27,541 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.053, 'learning_rate': 4.841726618705037e-06, 'epoch': 8.39}\n",
            " 84% 7000/8340 [1:44:46<19:14,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:28,486 >> Initializing global attention on CLS token...\n",
            " 84% 7001/8340 [1:44:47<19:01,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:29,314 >> Initializing global attention on CLS token...\n",
            " 84% 7002/8340 [1:44:48<18:49,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:30,141 >> Initializing global attention on CLS token...\n",
            " 84% 7003/8340 [1:44:49<18:40,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:30,966 >> Initializing global attention on CLS token...\n",
            " 84% 7004/8340 [1:44:50<18:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:31,792 >> Initializing global attention on CLS token...\n",
            " 84% 7005/8340 [1:44:50<18:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:32,616 >> Initializing global attention on CLS token...\n",
            " 84% 7006/8340 [1:44:51<18:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:33,444 >> Initializing global attention on CLS token...\n",
            " 84% 7007/8340 [1:44:52<18:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:34,272 >> Initializing global attention on CLS token...\n",
            " 84% 7008/8340 [1:44:53<18:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:35,098 >> Initializing global attention on CLS token...\n",
            " 84% 7009/8340 [1:44:54<18:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:35,927 >> Initializing global attention on CLS token...\n",
            " 84% 7010/8340 [1:44:55<18:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:36,754 >> Initializing global attention on CLS token...\n",
            " 84% 7011/8340 [1:44:55<18:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:37,574 >> Initializing global attention on CLS token...\n",
            " 84% 7012/8340 [1:44:56<18:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:38,402 >> Initializing global attention on CLS token...\n",
            " 84% 7013/8340 [1:44:57<18:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:39,224 >> Initializing global attention on CLS token...\n",
            " 84% 7014/8340 [1:44:58<18:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:40,053 >> Initializing global attention on CLS token...\n",
            " 84% 7015/8340 [1:44:59<18:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:40,881 >> Initializing global attention on CLS token...\n",
            " 84% 7016/8340 [1:45:00<18:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:41,708 >> Initializing global attention on CLS token...\n",
            " 84% 7017/8340 [1:45:00<18:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:42,539 >> Initializing global attention on CLS token...\n",
            " 84% 7018/8340 [1:45:01<18:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:43,363 >> Initializing global attention on CLS token...\n",
            " 84% 7019/8340 [1:45:02<18:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:44,183 >> Initializing global attention on CLS token...\n",
            " 84% 7020/8340 [1:45:03<18:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:45,010 >> Initializing global attention on CLS token...\n",
            " 84% 7021/8340 [1:45:04<18:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:45,837 >> Initializing global attention on CLS token...\n",
            " 84% 7022/8340 [1:45:05<18:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:46,664 >> Initializing global attention on CLS token...\n",
            " 84% 7023/8340 [1:45:05<18:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:47,490 >> Initializing global attention on CLS token...\n",
            " 84% 7024/8340 [1:45:06<18:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:48,319 >> Initializing global attention on CLS token...\n",
            " 84% 7025/8340 [1:45:07<18:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:49,142 >> Initializing global attention on CLS token...\n",
            " 84% 7026/8340 [1:45:08<18:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:49,967 >> Initializing global attention on CLS token...\n",
            " 84% 7027/8340 [1:45:09<18:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:50,795 >> Initializing global attention on CLS token...\n",
            " 84% 7028/8340 [1:45:09<18:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:51,618 >> Initializing global attention on CLS token...\n",
            " 84% 7029/8340 [1:45:10<18:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:52,443 >> Initializing global attention on CLS token...\n",
            " 84% 7030/8340 [1:45:11<18:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:53,270 >> Initializing global attention on CLS token...\n",
            " 84% 7031/8340 [1:45:12<18:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:54,098 >> Initializing global attention on CLS token...\n",
            " 84% 7032/8340 [1:45:13<18:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:54,926 >> Initializing global attention on CLS token...\n",
            " 84% 7033/8340 [1:45:14<17:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:55,752 >> Initializing global attention on CLS token...\n",
            " 84% 7034/8340 [1:45:14<17:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:56,579 >> Initializing global attention on CLS token...\n",
            " 84% 7035/8340 [1:45:15<17:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:57,405 >> Initializing global attention on CLS token...\n",
            " 84% 7036/8340 [1:45:16<17:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:58,230 >> Initializing global attention on CLS token...\n",
            " 84% 7037/8340 [1:45:17<17:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:59,056 >> Initializing global attention on CLS token...\n",
            " 84% 7038/8340 [1:45:18<17:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:45:59,884 >> Initializing global attention on CLS token...\n",
            " 84% 7039/8340 [1:45:19<17:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:00,710 >> Initializing global attention on CLS token...\n",
            " 84% 7040/8340 [1:45:19<17:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:01,541 >> Initializing global attention on CLS token...\n",
            " 84% 7041/8340 [1:45:20<17:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:02,367 >> Initializing global attention on CLS token...\n",
            " 84% 7042/8340 [1:45:21<17:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:03,192 >> Initializing global attention on CLS token...\n",
            " 84% 7043/8340 [1:45:22<17:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:04,017 >> Initializing global attention on CLS token...\n",
            " 84% 7044/8340 [1:45:23<17:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:04,841 >> Initializing global attention on CLS token...\n",
            " 84% 7045/8340 [1:45:24<17:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:05,665 >> Initializing global attention on CLS token...\n",
            " 84% 7046/8340 [1:45:24<17:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:06,491 >> Initializing global attention on CLS token...\n",
            " 84% 7047/8340 [1:45:25<17:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:07,314 >> Initializing global attention on CLS token...\n",
            " 85% 7048/8340 [1:45:26<17:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:08,140 >> Initializing global attention on CLS token...\n",
            " 85% 7049/8340 [1:45:27<17:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:08,960 >> Initializing global attention on CLS token...\n",
            " 85% 7050/8340 [1:45:28<17:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:09,784 >> Initializing global attention on CLS token...\n",
            " 85% 7051/8340 [1:45:28<17:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:10,610 >> Initializing global attention on CLS token...\n",
            " 85% 7052/8340 [1:45:29<17:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:11,435 >> Initializing global attention on CLS token...\n",
            " 85% 7053/8340 [1:45:30<17:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:12,264 >> Initializing global attention on CLS token...\n",
            " 85% 7054/8340 [1:45:31<17:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:13,092 >> Initializing global attention on CLS token...\n",
            " 85% 7055/8340 [1:45:32<17:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:13,924 >> Initializing global attention on CLS token...\n",
            " 85% 7056/8340 [1:45:33<17:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:14,756 >> Initializing global attention on CLS token...\n",
            " 85% 7057/8340 [1:45:33<17:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:15,587 >> Initializing global attention on CLS token...\n",
            " 85% 7058/8340 [1:45:34<17:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:16,413 >> Initializing global attention on CLS token...\n",
            " 85% 7059/8340 [1:45:35<17:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:17,237 >> Initializing global attention on CLS token...\n",
            " 85% 7060/8340 [1:45:36<17:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:18,065 >> Initializing global attention on CLS token...\n",
            " 85% 7061/8340 [1:45:37<17:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:18,894 >> Initializing global attention on CLS token...\n",
            " 85% 7062/8340 [1:45:38<17:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:19,719 >> Initializing global attention on CLS token...\n",
            " 85% 7063/8340 [1:45:38<17:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:20,545 >> Initializing global attention on CLS token...\n",
            " 85% 7064/8340 [1:45:39<17:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:21,370 >> Initializing global attention on CLS token...\n",
            " 85% 7065/8340 [1:45:40<17:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:22,195 >> Initializing global attention on CLS token...\n",
            " 85% 7066/8340 [1:45:41<17:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:23,018 >> Initializing global attention on CLS token...\n",
            " 85% 7067/8340 [1:45:42<17:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:23,844 >> Initializing global attention on CLS token...\n",
            " 85% 7068/8340 [1:45:43<17:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:24,669 >> Initializing global attention on CLS token...\n",
            " 85% 7069/8340 [1:45:43<17:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:25,494 >> Initializing global attention on CLS token...\n",
            " 85% 7070/8340 [1:45:44<17:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:26,320 >> Initializing global attention on CLS token...\n",
            " 85% 7071/8340 [1:45:45<17:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:27,151 >> Initializing global attention on CLS token...\n",
            " 85% 7072/8340 [1:45:46<17:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:27,987 >> Initializing global attention on CLS token...\n",
            " 85% 7073/8340 [1:45:47<17:31,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:28,843 >> Initializing global attention on CLS token...\n",
            " 85% 7074/8340 [1:45:48<17:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:29,693 >> Initializing global attention on CLS token...\n",
            " 85% 7075/8340 [1:45:48<17:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:30,518 >> Initializing global attention on CLS token...\n",
            " 85% 7076/8340 [1:45:49<17:35,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:31,343 >> Initializing global attention on CLS token...\n",
            " 85% 7077/8340 [1:45:50<17:32,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:32,174 >> Initializing global attention on CLS token...\n",
            " 85% 7078/8340 [1:45:51<17:30,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:33,005 >> Initializing global attention on CLS token...\n",
            " 85% 7079/8340 [1:45:52<17:27,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:33,830 >> Initializing global attention on CLS token...\n",
            " 85% 7080/8340 [1:45:52<17:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:34,655 >> Initializing global attention on CLS token...\n",
            " 85% 7081/8340 [1:45:53<17:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:35,482 >> Initializing global attention on CLS token...\n",
            " 85% 7082/8340 [1:45:54<17:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:36,308 >> Initializing global attention on CLS token...\n",
            " 85% 7083/8340 [1:45:55<17:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:37,131 >> Initializing global attention on CLS token...\n",
            " 85% 7084/8340 [1:45:56<17:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:37,958 >> Initializing global attention on CLS token...\n",
            " 85% 7085/8340 [1:45:57<17:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:38,782 >> Initializing global attention on CLS token...\n",
            " 85% 7086/8340 [1:45:57<17:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:39,607 >> Initializing global attention on CLS token...\n",
            " 85% 7087/8340 [1:45:58<17:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:40,434 >> Initializing global attention on CLS token...\n",
            " 85% 7088/8340 [1:45:59<17:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:41,260 >> Initializing global attention on CLS token...\n",
            " 85% 7089/8340 [1:46:00<17:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:42,090 >> Initializing global attention on CLS token...\n",
            " 85% 7090/8340 [1:46:01<17:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:42,915 >> Initializing global attention on CLS token...\n",
            " 85% 7091/8340 [1:46:02<17:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:43,742 >> Initializing global attention on CLS token...\n",
            " 85% 7092/8340 [1:46:02<17:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:44,570 >> Initializing global attention on CLS token...\n",
            " 85% 7093/8340 [1:46:03<17:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:45,396 >> Initializing global attention on CLS token...\n",
            " 85% 7094/8340 [1:46:04<17:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:46,226 >> Initializing global attention on CLS token...\n",
            " 85% 7095/8340 [1:46:05<17:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:47,050 >> Initializing global attention on CLS token...\n",
            " 85% 7096/8340 [1:46:06<17:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:47,878 >> Initializing global attention on CLS token...\n",
            " 85% 7097/8340 [1:46:07<17:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:48,704 >> Initializing global attention on CLS token...\n",
            " 85% 7098/8340 [1:46:07<17:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:49,531 >> Initializing global attention on CLS token...\n",
            " 85% 7099/8340 [1:46:08<17:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:50,357 >> Initializing global attention on CLS token...\n",
            " 85% 7100/8340 [1:46:09<17:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:51,181 >> Initializing global attention on CLS token...\n",
            " 85% 7101/8340 [1:46:10<17:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:52,006 >> Initializing global attention on CLS token...\n",
            " 85% 7102/8340 [1:46:11<17:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:52,829 >> Initializing global attention on CLS token...\n",
            " 85% 7103/8340 [1:46:11<17:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:53,662 >> Initializing global attention on CLS token...\n",
            " 85% 7104/8340 [1:46:12<17:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:54,485 >> Initializing global attention on CLS token...\n",
            " 85% 7105/8340 [1:46:13<17:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:55,310 >> Initializing global attention on CLS token...\n",
            " 85% 7106/8340 [1:46:14<16:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:56,136 >> Initializing global attention on CLS token...\n",
            " 85% 7107/8340 [1:46:15<16:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:56,964 >> Initializing global attention on CLS token...\n",
            " 85% 7108/8340 [1:46:16<16:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:57,784 >> Initializing global attention on CLS token...\n",
            " 85% 7109/8340 [1:46:16<16:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:58,616 >> Initializing global attention on CLS token...\n",
            " 85% 7110/8340 [1:46:17<16:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:46:59,440 >> Initializing global attention on CLS token...\n",
            " 85% 7111/8340 [1:46:18<16:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:00,265 >> Initializing global attention on CLS token...\n",
            " 85% 7112/8340 [1:46:19<16:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:01,089 >> Initializing global attention on CLS token...\n",
            " 85% 7113/8340 [1:46:20<16:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:01,914 >> Initializing global attention on CLS token...\n",
            " 85% 7114/8340 [1:46:21<16:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:02,741 >> Initializing global attention on CLS token...\n",
            " 85% 7115/8340 [1:46:21<16:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:03,569 >> Initializing global attention on CLS token...\n",
            " 85% 7116/8340 [1:46:22<16:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:04,395 >> Initializing global attention on CLS token...\n",
            " 85% 7117/8340 [1:46:23<16:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:05,218 >> Initializing global attention on CLS token...\n",
            " 85% 7118/8340 [1:46:24<16:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:06,041 >> Initializing global attention on CLS token...\n",
            " 85% 7119/8340 [1:46:25<16:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:06,868 >> Initializing global attention on CLS token...\n",
            " 85% 7120/8340 [1:46:26<16:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:07,692 >> Initializing global attention on CLS token...\n",
            " 85% 7121/8340 [1:46:26<16:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:08,517 >> Initializing global attention on CLS token...\n",
            " 85% 7122/8340 [1:46:27<16:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:09,340 >> Initializing global attention on CLS token...\n",
            " 85% 7123/8340 [1:46:28<16:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:10,168 >> Initializing global attention on CLS token...\n",
            " 85% 7124/8340 [1:46:29<16:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:10,991 >> Initializing global attention on CLS token...\n",
            " 85% 7125/8340 [1:46:30<16:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:11,818 >> Initializing global attention on CLS token...\n",
            " 85% 7126/8340 [1:46:30<16:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:12,642 >> Initializing global attention on CLS token...\n",
            " 85% 7127/8340 [1:46:31<16:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:13,467 >> Initializing global attention on CLS token...\n",
            " 85% 7128/8340 [1:46:32<16:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:14,292 >> Initializing global attention on CLS token...\n",
            " 85% 7129/8340 [1:46:33<16:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:15,114 >> Initializing global attention on CLS token...\n",
            " 85% 7130/8340 [1:46:34<16:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:15,943 >> Initializing global attention on CLS token...\n",
            " 86% 7131/8340 [1:46:35<16:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:16,773 >> Initializing global attention on CLS token...\n",
            " 86% 7132/8340 [1:46:35<16:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:17,599 >> Initializing global attention on CLS token...\n",
            " 86% 7133/8340 [1:46:36<16:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:18,420 >> Initializing global attention on CLS token...\n",
            " 86% 7134/8340 [1:46:37<16:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:19,249 >> Initializing global attention on CLS token...\n",
            " 86% 7135/8340 [1:46:38<16:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:20,073 >> Initializing global attention on CLS token...\n",
            " 86% 7136/8340 [1:46:39<16:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:20,898 >> Initializing global attention on CLS token...\n",
            " 86% 7137/8340 [1:46:40<16:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:21,726 >> Initializing global attention on CLS token...\n",
            " 86% 7138/8340 [1:46:40<16:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:22,547 >> Initializing global attention on CLS token...\n",
            " 86% 7139/8340 [1:46:41<16:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:23,375 >> Initializing global attention on CLS token...\n",
            " 86% 7140/8340 [1:46:42<16:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:24,199 >> Initializing global attention on CLS token...\n",
            " 86% 7141/8340 [1:46:43<16:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:25,032 >> Initializing global attention on CLS token...\n",
            " 86% 7142/8340 [1:46:44<16:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:25,857 >> Initializing global attention on CLS token...\n",
            " 86% 7143/8340 [1:46:45<16:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:26,680 >> Initializing global attention on CLS token...\n",
            " 86% 7144/8340 [1:46:45<16:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:27,511 >> Initializing global attention on CLS token...\n",
            " 86% 7145/8340 [1:46:46<16:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:28,335 >> Initializing global attention on CLS token...\n",
            " 86% 7146/8340 [1:46:47<16:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:29,160 >> Initializing global attention on CLS token...\n",
            " 86% 7147/8340 [1:46:48<16:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:29,984 >> Initializing global attention on CLS token...\n",
            " 86% 7148/8340 [1:46:49<16:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:30,813 >> Initializing global attention on CLS token...\n",
            " 86% 7149/8340 [1:46:49<16:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:31,634 >> Initializing global attention on CLS token...\n",
            " 86% 7150/8340 [1:46:50<16:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:32,463 >> Initializing global attention on CLS token...\n",
            " 86% 7151/8340 [1:46:51<16:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:33,288 >> Initializing global attention on CLS token...\n",
            " 86% 7152/8340 [1:46:52<16:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:34,123 >> Initializing global attention on CLS token...\n",
            " 86% 7153/8340 [1:46:53<16:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:34,948 >> Initializing global attention on CLS token...\n",
            " 86% 7154/8340 [1:46:54<16:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:35,773 >> Initializing global attention on CLS token...\n",
            " 86% 7155/8340 [1:46:54<16:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:36,600 >> Initializing global attention on CLS token...\n",
            " 86% 7156/8340 [1:46:55<16:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:37,423 >> Initializing global attention on CLS token...\n",
            " 86% 7157/8340 [1:46:56<16:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:38,246 >> Initializing global attention on CLS token...\n",
            " 86% 7158/8340 [1:46:57<16:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:39,070 >> Initializing global attention on CLS token...\n",
            " 86% 7159/8340 [1:46:58<16:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:39,894 >> Initializing global attention on CLS token...\n",
            " 86% 7160/8340 [1:46:59<16:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:40,723 >> Initializing global attention on CLS token...\n",
            " 86% 7161/8340 [1:46:59<16:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:41,551 >> Initializing global attention on CLS token...\n",
            " 86% 7162/8340 [1:47:00<16:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:42,379 >> Initializing global attention on CLS token...\n",
            " 86% 7163/8340 [1:47:01<16:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:43,201 >> Initializing global attention on CLS token...\n",
            " 86% 7164/8340 [1:47:02<16:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:44,029 >> Initializing global attention on CLS token...\n",
            " 86% 7165/8340 [1:47:03<16:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:44,858 >> Initializing global attention on CLS token...\n",
            " 86% 7166/8340 [1:47:04<16:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:45,681 >> Initializing global attention on CLS token...\n",
            " 86% 7167/8340 [1:47:04<16:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:46,509 >> Initializing global attention on CLS token...\n",
            " 86% 7168/8340 [1:47:05<16:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:47,335 >> Initializing global attention on CLS token...\n",
            " 86% 7169/8340 [1:47:06<16:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:48,162 >> Initializing global attention on CLS token...\n",
            " 86% 7170/8340 [1:47:07<16:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:48,984 >> Initializing global attention on CLS token...\n",
            " 86% 7171/8340 [1:47:08<16:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:49,814 >> Initializing global attention on CLS token...\n",
            " 86% 7172/8340 [1:47:08<16:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:50,643 >> Initializing global attention on CLS token...\n",
            " 86% 7173/8340 [1:47:09<16:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:51,464 >> Initializing global attention on CLS token...\n",
            " 86% 7174/8340 [1:47:10<16:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:52,287 >> Initializing global attention on CLS token...\n",
            " 86% 7175/8340 [1:47:11<16:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:53,111 >> Initializing global attention on CLS token...\n",
            " 86% 7176/8340 [1:47:12<16:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:53,939 >> Initializing global attention on CLS token...\n",
            " 86% 7177/8340 [1:47:13<16:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:54,765 >> Initializing global attention on CLS token...\n",
            " 86% 7178/8340 [1:47:13<15:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:55,586 >> Initializing global attention on CLS token...\n",
            " 86% 7179/8340 [1:47:14<15:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:56,413 >> Initializing global attention on CLS token...\n",
            " 86% 7180/8340 [1:47:15<15:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:57,241 >> Initializing global attention on CLS token...\n",
            " 86% 7181/8340 [1:47:16<15:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:58,068 >> Initializing global attention on CLS token...\n",
            " 86% 7182/8340 [1:47:17<15:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:58,893 >> Initializing global attention on CLS token...\n",
            " 86% 7183/8340 [1:47:18<15:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:47:59,714 >> Initializing global attention on CLS token...\n",
            " 86% 7184/8340 [1:47:18<15:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:00,540 >> Initializing global attention on CLS token...\n",
            " 86% 7185/8340 [1:47:19<15:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:01,365 >> Initializing global attention on CLS token...\n",
            " 86% 7186/8340 [1:47:20<15:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:02,195 >> Initializing global attention on CLS token...\n",
            " 86% 7187/8340 [1:47:21<15:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:03,025 >> Initializing global attention on CLS token...\n",
            " 86% 7188/8340 [1:47:22<15:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:03,849 >> Initializing global attention on CLS token...\n",
            " 86% 7189/8340 [1:47:23<15:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:04,677 >> Initializing global attention on CLS token...\n",
            " 86% 7190/8340 [1:47:23<15:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:05,504 >> Initializing global attention on CLS token...\n",
            " 86% 7191/8340 [1:47:24<15:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:06,332 >> Initializing global attention on CLS token...\n",
            " 86% 7192/8340 [1:47:25<15:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:07,158 >> Initializing global attention on CLS token...\n",
            " 86% 7193/8340 [1:47:26<15:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:07,983 >> Initializing global attention on CLS token...\n",
            " 86% 7194/8340 [1:47:27<15:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:08,803 >> Initializing global attention on CLS token...\n",
            " 86% 7195/8340 [1:47:27<15:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:09,633 >> Initializing global attention on CLS token...\n",
            " 86% 7196/8340 [1:47:28<15:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:10,460 >> Initializing global attention on CLS token...\n",
            " 86% 7197/8340 [1:47:29<15:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:11,292 >> Initializing global attention on CLS token...\n",
            " 86% 7198/8340 [1:47:30<15:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:12,115 >> Initializing global attention on CLS token...\n",
            " 86% 7199/8340 [1:47:31<15:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:12,942 >> Initializing global attention on CLS token...\n",
            " 86% 7200/8340 [1:47:32<15:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:13,770 >> Initializing global attention on CLS token...\n",
            " 86% 7201/8340 [1:47:32<15:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:14,597 >> Initializing global attention on CLS token...\n",
            " 86% 7202/8340 [1:47:33<15:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:15,423 >> Initializing global attention on CLS token...\n",
            " 86% 7203/8340 [1:47:34<15:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:16,248 >> Initializing global attention on CLS token...\n",
            " 86% 7204/8340 [1:47:35<15:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:17,075 >> Initializing global attention on CLS token...\n",
            " 86% 7205/8340 [1:47:36<15:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:17,899 >> Initializing global attention on CLS token...\n",
            " 86% 7206/8340 [1:47:37<15:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:18,727 >> Initializing global attention on CLS token...\n",
            " 86% 7207/8340 [1:47:37<15:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:19,554 >> Initializing global attention on CLS token...\n",
            " 86% 7208/8340 [1:47:38<15:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:20,379 >> Initializing global attention on CLS token...\n",
            " 86% 7209/8340 [1:47:39<15:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:21,204 >> Initializing global attention on CLS token...\n",
            " 86% 7210/8340 [1:47:40<15:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:22,027 >> Initializing global attention on CLS token...\n",
            " 86% 7211/8340 [1:47:41<15:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:22,853 >> Initializing global attention on CLS token...\n",
            " 86% 7212/8340 [1:47:42<15:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:23,678 >> Initializing global attention on CLS token...\n",
            " 86% 7213/8340 [1:47:42<15:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:24,502 >> Initializing global attention on CLS token...\n",
            " 86% 7214/8340 [1:47:43<15:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:25,329 >> Initializing global attention on CLS token...\n",
            " 87% 7215/8340 [1:47:44<15:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:26,154 >> Initializing global attention on CLS token...\n",
            " 87% 7216/8340 [1:47:45<15:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:26,980 >> Initializing global attention on CLS token...\n",
            " 87% 7217/8340 [1:47:46<15:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:27,808 >> Initializing global attention on CLS token...\n",
            " 87% 7218/8340 [1:47:46<15:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:28,630 >> Initializing global attention on CLS token...\n",
            " 87% 7219/8340 [1:47:47<15:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:29,455 >> Initializing global attention on CLS token...\n",
            " 87% 7220/8340 [1:47:48<15:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:30,276 >> Initializing global attention on CLS token...\n",
            " 87% 7221/8340 [1:47:49<15:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:31,102 >> Initializing global attention on CLS token...\n",
            " 87% 7222/8340 [1:47:50<15:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:31,926 >> Initializing global attention on CLS token...\n",
            " 87% 7223/8340 [1:47:51<15:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:32,756 >> Initializing global attention on CLS token...\n",
            " 87% 7224/8340 [1:47:51<15:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:33,582 >> Initializing global attention on CLS token...\n",
            " 87% 7225/8340 [1:47:52<15:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:34,404 >> Initializing global attention on CLS token...\n",
            " 87% 7226/8340 [1:47:53<15:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:35,233 >> Initializing global attention on CLS token...\n",
            " 87% 7227/8340 [1:47:54<15:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:36,054 >> Initializing global attention on CLS token...\n",
            " 87% 7228/8340 [1:47:55<15:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:36,881 >> Initializing global attention on CLS token...\n",
            " 87% 7229/8340 [1:47:56<15:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:37,706 >> Initializing global attention on CLS token...\n",
            " 87% 7230/8340 [1:47:56<15:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:38,531 >> Initializing global attention on CLS token...\n",
            " 87% 7231/8340 [1:47:57<15:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:39,358 >> Initializing global attention on CLS token...\n",
            " 87% 7232/8340 [1:47:58<15:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:40,180 >> Initializing global attention on CLS token...\n",
            " 87% 7233/8340 [1:47:59<15:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:41,006 >> Initializing global attention on CLS token...\n",
            " 87% 7234/8340 [1:48:00<15:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:41,832 >> Initializing global attention on CLS token...\n",
            " 87% 7235/8340 [1:48:00<15:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:42,658 >> Initializing global attention on CLS token...\n",
            " 87% 7236/8340 [1:48:01<15:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:43,483 >> Initializing global attention on CLS token...\n",
            " 87% 7237/8340 [1:48:02<15:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:44,311 >> Initializing global attention on CLS token...\n",
            " 87% 7238/8340 [1:48:03<15:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:45,136 >> Initializing global attention on CLS token...\n",
            " 87% 7239/8340 [1:48:04<15:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:45,963 >> Initializing global attention on CLS token...\n",
            " 87% 7240/8340 [1:48:05<15:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:46,789 >> Initializing global attention on CLS token...\n",
            " 87% 7241/8340 [1:48:05<15:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:47,622 >> Initializing global attention on CLS token...\n",
            " 87% 7242/8340 [1:48:06<15:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:48,450 >> Initializing global attention on CLS token...\n",
            " 87% 7243/8340 [1:48:07<15:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:49,277 >> Initializing global attention on CLS token...\n",
            " 87% 7244/8340 [1:48:08<15:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:50,101 >> Initializing global attention on CLS token...\n",
            " 87% 7245/8340 [1:48:09<15:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:50,926 >> Initializing global attention on CLS token...\n",
            " 87% 7246/8340 [1:48:10<15:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:51,750 >> Initializing global attention on CLS token...\n",
            " 87% 7247/8340 [1:48:10<15:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:52,575 >> Initializing global attention on CLS token...\n",
            " 87% 7248/8340 [1:48:11<15:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:53,400 >> Initializing global attention on CLS token...\n",
            " 87% 7249/8340 [1:48:12<15:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:54,227 >> Initializing global attention on CLS token...\n",
            " 87% 7250/8340 [1:48:13<15:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:55,054 >> Initializing global attention on CLS token...\n",
            " 87% 7251/8340 [1:48:14<14:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:55,879 >> Initializing global attention on CLS token...\n",
            " 87% 7252/8340 [1:48:15<14:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:56,708 >> Initializing global attention on CLS token...\n",
            " 87% 7253/8340 [1:48:15<14:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:57,533 >> Initializing global attention on CLS token...\n",
            " 87% 7254/8340 [1:48:16<14:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:58,359 >> Initializing global attention on CLS token...\n",
            " 87% 7255/8340 [1:48:17<14:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:48:59,188 >> Initializing global attention on CLS token...\n",
            " 87% 7256/8340 [1:48:18<14:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:00,014 >> Initializing global attention on CLS token...\n",
            " 87% 7257/8340 [1:48:19<14:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:00,836 >> Initializing global attention on CLS token...\n",
            " 87% 7258/8340 [1:48:20<14:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:01,660 >> Initializing global attention on CLS token...\n",
            " 87% 7259/8340 [1:48:20<14:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:02,483 >> Initializing global attention on CLS token...\n",
            " 87% 7260/8340 [1:48:21<14:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:03,314 >> Initializing global attention on CLS token...\n",
            " 87% 7261/8340 [1:48:22<14:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:04,141 >> Initializing global attention on CLS token...\n",
            " 87% 7262/8340 [1:48:23<14:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:04,965 >> Initializing global attention on CLS token...\n",
            " 87% 7263/8340 [1:48:24<14:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:05,796 >> Initializing global attention on CLS token...\n",
            " 87% 7264/8340 [1:48:24<14:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:06,623 >> Initializing global attention on CLS token...\n",
            " 87% 7265/8340 [1:48:25<14:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:07,451 >> Initializing global attention on CLS token...\n",
            " 87% 7266/8340 [1:48:26<14:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:08,279 >> Initializing global attention on CLS token...\n",
            " 87% 7267/8340 [1:48:27<14:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:09,105 >> Initializing global attention on CLS token...\n",
            " 87% 7268/8340 [1:48:28<14:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:09,928 >> Initializing global attention on CLS token...\n",
            " 87% 7269/8340 [1:48:29<14:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:10,755 >> Initializing global attention on CLS token...\n",
            " 87% 7270/8340 [1:48:29<14:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:11,577 >> Initializing global attention on CLS token...\n",
            " 87% 7271/8340 [1:48:30<14:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:12,406 >> Initializing global attention on CLS token...\n",
            " 87% 7272/8340 [1:48:31<14:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:13,230 >> Initializing global attention on CLS token...\n",
            " 87% 7273/8340 [1:48:32<14:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:14,051 >> Initializing global attention on CLS token...\n",
            " 87% 7274/8340 [1:48:33<14:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:14,876 >> Initializing global attention on CLS token...\n",
            " 87% 7275/8340 [1:48:34<14:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:15,702 >> Initializing global attention on CLS token...\n",
            " 87% 7276/8340 [1:48:34<14:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:16,527 >> Initializing global attention on CLS token...\n",
            " 87% 7277/8340 [1:48:35<14:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:17,348 >> Initializing global attention on CLS token...\n",
            " 87% 7278/8340 [1:48:36<14:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:18,171 >> Initializing global attention on CLS token...\n",
            " 87% 7279/8340 [1:48:37<14:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:18,997 >> Initializing global attention on CLS token...\n",
            " 87% 7280/8340 [1:48:38<14:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:19,820 >> Initializing global attention on CLS token...\n",
            " 87% 7281/8340 [1:48:38<14:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:20,647 >> Initializing global attention on CLS token...\n",
            " 87% 7282/8340 [1:48:39<14:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:21,473 >> Initializing global attention on CLS token...\n",
            " 87% 7283/8340 [1:48:40<14:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:22,300 >> Initializing global attention on CLS token...\n",
            " 87% 7284/8340 [1:48:41<14:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:23,124 >> Initializing global attention on CLS token...\n",
            " 87% 7285/8340 [1:48:42<14:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:23,948 >> Initializing global attention on CLS token...\n",
            " 87% 7286/8340 [1:48:43<14:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:24,772 >> Initializing global attention on CLS token...\n",
            " 87% 7287/8340 [1:48:43<14:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:25,602 >> Initializing global attention on CLS token...\n",
            " 87% 7288/8340 [1:48:44<14:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:26,432 >> Initializing global attention on CLS token...\n",
            " 87% 7289/8340 [1:48:45<14:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:27,255 >> Initializing global attention on CLS token...\n",
            " 87% 7290/8340 [1:48:46<14:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:28,082 >> Initializing global attention on CLS token...\n",
            " 87% 7291/8340 [1:48:47<14:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:28,908 >> Initializing global attention on CLS token...\n",
            " 87% 7292/8340 [1:48:48<14:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:29,737 >> Initializing global attention on CLS token...\n",
            " 87% 7293/8340 [1:48:48<14:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:30,564 >> Initializing global attention on CLS token...\n",
            " 87% 7294/8340 [1:48:49<14:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:31,390 >> Initializing global attention on CLS token...\n",
            " 87% 7295/8340 [1:48:50<14:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:32,217 >> Initializing global attention on CLS token...\n",
            " 87% 7296/8340 [1:48:51<14:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:33,040 >> Initializing global attention on CLS token...\n",
            " 87% 7297/8340 [1:48:52<14:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:33,868 >> Initializing global attention on CLS token...\n",
            " 88% 7298/8340 [1:48:53<14:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:34,693 >> Initializing global attention on CLS token...\n",
            " 88% 7299/8340 [1:48:53<14:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:35,520 >> Initializing global attention on CLS token...\n",
            " 88% 7300/8340 [1:48:54<14:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:36,348 >> Initializing global attention on CLS token...\n",
            " 88% 7301/8340 [1:48:55<14:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:37,170 >> Initializing global attention on CLS token...\n",
            " 88% 7302/8340 [1:48:56<14:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:37,995 >> Initializing global attention on CLS token...\n",
            " 88% 7303/8340 [1:48:57<14:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:38,819 >> Initializing global attention on CLS token...\n",
            " 88% 7304/8340 [1:48:57<14:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:39,648 >> Initializing global attention on CLS token...\n",
            " 88% 7305/8340 [1:48:58<14:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:40,473 >> Initializing global attention on CLS token...\n",
            " 88% 7306/8340 [1:48:59<14:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:41,301 >> Initializing global attention on CLS token...\n",
            " 88% 7307/8340 [1:49:00<14:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:42,130 >> Initializing global attention on CLS token...\n",
            " 88% 7308/8340 [1:49:01<14:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:42,954 >> Initializing global attention on CLS token...\n",
            " 88% 7309/8340 [1:49:02<14:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:43,779 >> Initializing global attention on CLS token...\n",
            " 88% 7310/8340 [1:49:02<14:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:44,612 >> Initializing global attention on CLS token...\n",
            " 88% 7311/8340 [1:49:03<14:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:45,435 >> Initializing global attention on CLS token...\n",
            " 88% 7312/8340 [1:49:04<14:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:46,259 >> Initializing global attention on CLS token...\n",
            " 88% 7313/8340 [1:49:05<14:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:47,085 >> Initializing global attention on CLS token...\n",
            " 88% 7314/8340 [1:49:06<14:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:47,912 >> Initializing global attention on CLS token...\n",
            " 88% 7315/8340 [1:49:07<14:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:48,736 >> Initializing global attention on CLS token...\n",
            " 88% 7316/8340 [1:49:07<14:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:49,562 >> Initializing global attention on CLS token...\n",
            " 88% 7317/8340 [1:49:08<14:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:50,388 >> Initializing global attention on CLS token...\n",
            " 88% 7318/8340 [1:49:09<14:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:51,213 >> Initializing global attention on CLS token...\n",
            " 88% 7319/8340 [1:49:10<14:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:52,037 >> Initializing global attention on CLS token...\n",
            " 88% 7320/8340 [1:49:11<14:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:52,866 >> Initializing global attention on CLS token...\n",
            " 88% 7321/8340 [1:49:12<14:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:53,690 >> Initializing global attention on CLS token...\n",
            " 88% 7322/8340 [1:49:12<13:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:54,513 >> Initializing global attention on CLS token...\n",
            " 88% 7323/8340 [1:49:13<13:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:55,338 >> Initializing global attention on CLS token...\n",
            " 88% 7324/8340 [1:49:14<13:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:56,165 >> Initializing global attention on CLS token...\n",
            " 88% 7325/8340 [1:49:15<13:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:56,991 >> Initializing global attention on CLS token...\n",
            " 88% 7326/8340 [1:49:16<13:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:57,816 >> Initializing global attention on CLS token...\n",
            " 88% 7327/8340 [1:49:16<13:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:58,641 >> Initializing global attention on CLS token...\n",
            " 88% 7328/8340 [1:49:17<13:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:49:59,465 >> Initializing global attention on CLS token...\n",
            " 88% 7329/8340 [1:49:18<13:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:00,289 >> Initializing global attention on CLS token...\n",
            " 88% 7330/8340 [1:49:19<13:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:01,111 >> Initializing global attention on CLS token...\n",
            " 88% 7331/8340 [1:49:20<13:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:01,938 >> Initializing global attention on CLS token...\n",
            " 88% 7332/8340 [1:49:21<13:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:02,765 >> Initializing global attention on CLS token...\n",
            " 88% 7333/8340 [1:49:21<13:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:03,589 >> Initializing global attention on CLS token...\n",
            " 88% 7334/8340 [1:49:22<13:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:04,418 >> Initializing global attention on CLS token...\n",
            " 88% 7335/8340 [1:49:23<13:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:05,239 >> Initializing global attention on CLS token...\n",
            " 88% 7336/8340 [1:49:24<13:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:06,068 >> Initializing global attention on CLS token...\n",
            " 88% 7337/8340 [1:49:25<13:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:06,895 >> Initializing global attention on CLS token...\n",
            " 88% 7338/8340 [1:49:26<13:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:07,719 >> Initializing global attention on CLS token...\n",
            " 88% 7339/8340 [1:49:26<13:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:08,548 >> Initializing global attention on CLS token...\n",
            " 88% 7340/8340 [1:49:27<13:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:09,373 >> Initializing global attention on CLS token...\n",
            " 88% 7341/8340 [1:49:28<13:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:10,197 >> Initializing global attention on CLS token...\n",
            " 88% 7342/8340 [1:49:29<13:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:11,024 >> Initializing global attention on CLS token...\n",
            " 88% 7343/8340 [1:49:30<13:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:11,847 >> Initializing global attention on CLS token...\n",
            " 88% 7344/8340 [1:49:31<13:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:12,671 >> Initializing global attention on CLS token...\n",
            " 88% 7345/8340 [1:49:31<13:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:13,497 >> Initializing global attention on CLS token...\n",
            " 88% 7346/8340 [1:49:32<13:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:14,322 >> Initializing global attention on CLS token...\n",
            " 88% 7347/8340 [1:49:33<13:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:15,152 >> Initializing global attention on CLS token...\n",
            " 88% 7348/8340 [1:49:34<13:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:15,977 >> Initializing global attention on CLS token...\n",
            " 88% 7349/8340 [1:49:35<13:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:16,805 >> Initializing global attention on CLS token...\n",
            " 88% 7350/8340 [1:49:35<13:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:17,631 >> Initializing global attention on CLS token...\n",
            " 88% 7351/8340 [1:49:36<13:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:18,464 >> Initializing global attention on CLS token...\n",
            " 88% 7352/8340 [1:49:37<13:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:19,298 >> Initializing global attention on CLS token...\n",
            " 88% 7353/8340 [1:49:38<13:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:20,128 >> Initializing global attention on CLS token...\n",
            " 88% 7354/8340 [1:49:39<13:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:20,953 >> Initializing global attention on CLS token...\n",
            " 88% 7355/8340 [1:49:40<13:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:21,778 >> Initializing global attention on CLS token...\n",
            " 88% 7356/8340 [1:49:40<13:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:22,606 >> Initializing global attention on CLS token...\n",
            " 88% 7357/8340 [1:49:41<13:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:23,431 >> Initializing global attention on CLS token...\n",
            " 88% 7358/8340 [1:49:42<13:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:24,257 >> Initializing global attention on CLS token...\n",
            " 88% 7359/8340 [1:49:43<13:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:25,080 >> Initializing global attention on CLS token...\n",
            " 88% 7360/8340 [1:49:44<13:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:25,904 >> Initializing global attention on CLS token...\n",
            " 88% 7361/8340 [1:49:45<13:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:26,729 >> Initializing global attention on CLS token...\n",
            " 88% 7362/8340 [1:49:45<13:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:27,555 >> Initializing global attention on CLS token...\n",
            " 88% 7363/8340 [1:49:46<13:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:28,386 >> Initializing global attention on CLS token...\n",
            " 88% 7364/8340 [1:49:47<13:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:29,210 >> Initializing global attention on CLS token...\n",
            " 88% 7365/8340 [1:49:48<13:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:30,041 >> Initializing global attention on CLS token...\n",
            " 88% 7366/8340 [1:49:49<13:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:30,861 >> Initializing global attention on CLS token...\n",
            " 88% 7367/8340 [1:49:50<13:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:31,690 >> Initializing global attention on CLS token...\n",
            " 88% 7368/8340 [1:49:50<13:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:32,516 >> Initializing global attention on CLS token...\n",
            " 88% 7369/8340 [1:49:51<13:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:33,340 >> Initializing global attention on CLS token...\n",
            " 88% 7370/8340 [1:49:52<13:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:34,161 >> Initializing global attention on CLS token...\n",
            " 88% 7371/8340 [1:49:53<13:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:34,986 >> Initializing global attention on CLS token...\n",
            " 88% 7372/8340 [1:49:54<13:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:35,815 >> Initializing global attention on CLS token...\n",
            " 88% 7373/8340 [1:49:54<13:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:36,648 >> Initializing global attention on CLS token...\n",
            " 88% 7374/8340 [1:49:55<13:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:37,474 >> Initializing global attention on CLS token...\n",
            " 88% 7375/8340 [1:49:56<13:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:38,298 >> Initializing global attention on CLS token...\n",
            " 88% 7376/8340 [1:49:57<13:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:39,126 >> Initializing global attention on CLS token...\n",
            " 88% 7377/8340 [1:49:58<13:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:39,955 >> Initializing global attention on CLS token...\n",
            " 88% 7378/8340 [1:49:59<13:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:40,782 >> Initializing global attention on CLS token...\n",
            " 88% 7379/8340 [1:49:59<13:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:41,608 >> Initializing global attention on CLS token...\n",
            " 88% 7380/8340 [1:50:00<13:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:42,436 >> Initializing global attention on CLS token...\n",
            " 89% 7381/8340 [1:50:01<13:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:43,260 >> Initializing global attention on CLS token...\n",
            " 89% 7382/8340 [1:50:02<13:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:44,091 >> Initializing global attention on CLS token...\n",
            " 89% 7383/8340 [1:50:03<13:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:44,917 >> Initializing global attention on CLS token...\n",
            " 89% 7384/8340 [1:50:04<13:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:45,743 >> Initializing global attention on CLS token...\n",
            " 89% 7385/8340 [1:50:04<13:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:46,573 >> Initializing global attention on CLS token...\n",
            " 89% 7386/8340 [1:50:05<13:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:47,402 >> Initializing global attention on CLS token...\n",
            " 89% 7387/8340 [1:50:06<13:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:48,227 >> Initializing global attention on CLS token...\n",
            " 89% 7388/8340 [1:50:07<13:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:49,051 >> Initializing global attention on CLS token...\n",
            " 89% 7389/8340 [1:50:08<13:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:49,876 >> Initializing global attention on CLS token...\n",
            " 89% 7390/8340 [1:50:09<13:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:50,704 >> Initializing global attention on CLS token...\n",
            " 89% 7391/8340 [1:50:09<13:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:51,531 >> Initializing global attention on CLS token...\n",
            " 89% 7392/8340 [1:50:10<13:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:52,358 >> Initializing global attention on CLS token...\n",
            " 89% 7393/8340 [1:50:11<13:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:53,189 >> Initializing global attention on CLS token...\n",
            " 89% 7394/8340 [1:50:12<13:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:54,015 >> Initializing global attention on CLS token...\n",
            " 89% 7395/8340 [1:50:13<13:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:54,839 >> Initializing global attention on CLS token...\n",
            " 89% 7396/8340 [1:50:14<12:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:55,666 >> Initializing global attention on CLS token...\n",
            " 89% 7397/8340 [1:50:14<12:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:56,494 >> Initializing global attention on CLS token...\n",
            " 89% 7398/8340 [1:50:15<12:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:57,317 >> Initializing global attention on CLS token...\n",
            " 89% 7399/8340 [1:50:16<12:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:58,146 >> Initializing global attention on CLS token...\n",
            " 89% 7400/8340 [1:50:17<12:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:58,967 >> Initializing global attention on CLS token...\n",
            " 89% 7401/8340 [1:50:18<12:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:50:59,796 >> Initializing global attention on CLS token...\n",
            " 89% 7402/8340 [1:50:18<12:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:00,623 >> Initializing global attention on CLS token...\n",
            " 89% 7403/8340 [1:50:19<12:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:01,447 >> Initializing global attention on CLS token...\n",
            " 89% 7404/8340 [1:50:20<12:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:02,281 >> Initializing global attention on CLS token...\n",
            " 89% 7405/8340 [1:50:21<12:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:03,104 >> Initializing global attention on CLS token...\n",
            " 89% 7406/8340 [1:50:22<12:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:03,929 >> Initializing global attention on CLS token...\n",
            " 89% 7407/8340 [1:50:23<12:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:04,755 >> Initializing global attention on CLS token...\n",
            " 89% 7408/8340 [1:50:23<12:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:05,582 >> Initializing global attention on CLS token...\n",
            " 89% 7409/8340 [1:50:24<12:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:06,407 >> Initializing global attention on CLS token...\n",
            " 89% 7410/8340 [1:50:25<12:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:07,231 >> Initializing global attention on CLS token...\n",
            " 89% 7411/8340 [1:50:26<12:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:08,062 >> Initializing global attention on CLS token...\n",
            " 89% 7412/8340 [1:50:27<12:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:08,886 >> Initializing global attention on CLS token...\n",
            " 89% 7413/8340 [1:50:28<12:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:09,710 >> Initializing global attention on CLS token...\n",
            " 89% 7414/8340 [1:50:28<12:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:10,536 >> Initializing global attention on CLS token...\n",
            " 89% 7415/8340 [1:50:29<12:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:11,362 >> Initializing global attention on CLS token...\n",
            " 89% 7416/8340 [1:50:30<12:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:12,189 >> Initializing global attention on CLS token...\n",
            " 89% 7417/8340 [1:50:31<12:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:13,014 >> Initializing global attention on CLS token...\n",
            " 89% 7418/8340 [1:50:32<12:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:13,844 >> Initializing global attention on CLS token...\n",
            " 89% 7419/8340 [1:50:33<12:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:14,669 >> Initializing global attention on CLS token...\n",
            " 89% 7420/8340 [1:50:33<12:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:15,496 >> Initializing global attention on CLS token...\n",
            " 89% 7421/8340 [1:50:34<12:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:16,327 >> Initializing global attention on CLS token...\n",
            " 89% 7422/8340 [1:50:35<12:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:17,152 >> Initializing global attention on CLS token...\n",
            " 89% 7423/8340 [1:50:36<12:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:17,976 >> Initializing global attention on CLS token...\n",
            " 89% 7424/8340 [1:50:37<12:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:18,809 >> Initializing global attention on CLS token...\n",
            " 89% 7425/8340 [1:50:37<12:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:19,635 >> Initializing global attention on CLS token...\n",
            " 89% 7426/8340 [1:50:38<12:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:20,461 >> Initializing global attention on CLS token...\n",
            " 89% 7427/8340 [1:50:39<12:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:21,285 >> Initializing global attention on CLS token...\n",
            " 89% 7428/8340 [1:50:40<12:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:22,116 >> Initializing global attention on CLS token...\n",
            " 89% 7429/8340 [1:50:41<12:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:22,937 >> Initializing global attention on CLS token...\n",
            " 89% 7430/8340 [1:50:42<12:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:23,763 >> Initializing global attention on CLS token...\n",
            " 89% 7431/8340 [1:50:42<12:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:24,592 >> Initializing global attention on CLS token...\n",
            " 89% 7432/8340 [1:50:43<12:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:25,416 >> Initializing global attention on CLS token...\n",
            " 89% 7433/8340 [1:50:44<12:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:26,241 >> Initializing global attention on CLS token...\n",
            " 89% 7434/8340 [1:50:45<12:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:27,065 >> Initializing global attention on CLS token...\n",
            " 89% 7435/8340 [1:50:46<12:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:27,894 >> Initializing global attention on CLS token...\n",
            " 89% 7436/8340 [1:50:47<12:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:28,716 >> Initializing global attention on CLS token...\n",
            " 89% 7437/8340 [1:50:47<12:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:29,542 >> Initializing global attention on CLS token...\n",
            " 89% 7438/8340 [1:50:48<12:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:30,365 >> Initializing global attention on CLS token...\n",
            " 89% 7439/8340 [1:50:49<12:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:31,189 >> Initializing global attention on CLS token...\n",
            " 89% 7440/8340 [1:50:50<12:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:32,017 >> Initializing global attention on CLS token...\n",
            " 89% 7441/8340 [1:50:51<12:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:32,844 >> Initializing global attention on CLS token...\n",
            " 89% 7442/8340 [1:50:52<12:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:33,666 >> Initializing global attention on CLS token...\n",
            " 89% 7443/8340 [1:50:52<12:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:34,487 >> Initializing global attention on CLS token...\n",
            " 89% 7444/8340 [1:50:53<12:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:35,314 >> Initializing global attention on CLS token...\n",
            " 89% 7445/8340 [1:50:54<12:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:36,137 >> Initializing global attention on CLS token...\n",
            " 89% 7446/8340 [1:50:55<12:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:36,966 >> Initializing global attention on CLS token...\n",
            " 89% 7447/8340 [1:50:56<12:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:37,797 >> Initializing global attention on CLS token...\n",
            " 89% 7448/8340 [1:50:56<12:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:38,625 >> Initializing global attention on CLS token...\n",
            " 89% 7449/8340 [1:50:57<12:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:39,450 >> Initializing global attention on CLS token...\n",
            " 89% 7450/8340 [1:50:58<12:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:40,278 >> Initializing global attention on CLS token...\n",
            " 89% 7451/8340 [1:50:59<12:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:41,102 >> Initializing global attention on CLS token...\n",
            " 89% 7452/8340 [1:51:00<12:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:41,928 >> Initializing global attention on CLS token...\n",
            " 89% 7453/8340 [1:51:01<12:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:42,756 >> Initializing global attention on CLS token...\n",
            " 89% 7454/8340 [1:51:01<12:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:43,579 >> Initializing global attention on CLS token...\n",
            " 89% 7455/8340 [1:51:02<12:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:44,411 >> Initializing global attention on CLS token...\n",
            " 89% 7456/8340 [1:51:03<12:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:45,241 >> Initializing global attention on CLS token...\n",
            " 89% 7457/8340 [1:51:04<12:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:46,066 >> Initializing global attention on CLS token...\n",
            " 89% 7458/8340 [1:51:05<12:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:46,892 >> Initializing global attention on CLS token...\n",
            " 89% 7459/8340 [1:51:06<12:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:47,720 >> Initializing global attention on CLS token...\n",
            " 89% 7460/8340 [1:51:06<12:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:48,556 >> Initializing global attention on CLS token...\n",
            " 89% 7461/8340 [1:51:07<12:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:49,385 >> Initializing global attention on CLS token...\n",
            " 89% 7462/8340 [1:51:08<12:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:50,207 >> Initializing global attention on CLS token...\n",
            " 89% 7463/8340 [1:51:09<12:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:51,035 >> Initializing global attention on CLS token...\n",
            " 89% 7464/8340 [1:51:10<12:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:51,860 >> Initializing global attention on CLS token...\n",
            " 90% 7465/8340 [1:51:11<12:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:52,685 >> Initializing global attention on CLS token...\n",
            " 90% 7466/8340 [1:51:11<12:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:53,513 >> Initializing global attention on CLS token...\n",
            " 90% 7467/8340 [1:51:12<12:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:54,340 >> Initializing global attention on CLS token...\n",
            " 90% 7468/8340 [1:51:13<11:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:55,162 >> Initializing global attention on CLS token...\n",
            " 90% 7469/8340 [1:51:14<11:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:55,989 >> Initializing global attention on CLS token...\n",
            " 90% 7470/8340 [1:51:15<11:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:56,813 >> Initializing global attention on CLS token...\n",
            " 90% 7471/8340 [1:51:15<11:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:57,640 >> Initializing global attention on CLS token...\n",
            " 90% 7472/8340 [1:51:16<11:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:58,460 >> Initializing global attention on CLS token...\n",
            " 90% 7473/8340 [1:51:17<11:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:51:59,286 >> Initializing global attention on CLS token...\n",
            " 90% 7474/8340 [1:51:18<11:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:00,115 >> Initializing global attention on CLS token...\n",
            " 90% 7475/8340 [1:51:19<11:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:00,940 >> Initializing global attention on CLS token...\n",
            " 90% 7476/8340 [1:51:20<11:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:01,766 >> Initializing global attention on CLS token...\n",
            " 90% 7477/8340 [1:51:20<11:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:02,598 >> Initializing global attention on CLS token...\n",
            " 90% 7478/8340 [1:51:21<11:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:03,423 >> Initializing global attention on CLS token...\n",
            " 90% 7479/8340 [1:51:22<11:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:04,261 >> Initializing global attention on CLS token...\n",
            " 90% 7480/8340 [1:51:23<11:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:05,113 >> Initializing global attention on CLS token...\n",
            " 90% 7481/8340 [1:51:24<11:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:05,970 >> Initializing global attention on CLS token...\n",
            " 90% 7482/8340 [1:51:25<12:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:06,812 >> Initializing global attention on CLS token...\n",
            " 90% 7483/8340 [1:51:25<12:02,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:07,646 >> Initializing global attention on CLS token...\n",
            " 90% 7484/8340 [1:51:26<11:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:08,475 >> Initializing global attention on CLS token...\n",
            " 90% 7485/8340 [1:51:27<11:54,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:09,298 >> Initializing global attention on CLS token...\n",
            " 90% 7486/8340 [1:51:28<11:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:10,127 >> Initializing global attention on CLS token...\n",
            " 90% 7487/8340 [1:51:29<11:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:10,954 >> Initializing global attention on CLS token...\n",
            " 90% 7488/8340 [1:51:30<11:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:11,781 >> Initializing global attention on CLS token...\n",
            " 90% 7489/8340 [1:51:30<11:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:12,605 >> Initializing global attention on CLS token...\n",
            " 90% 7490/8340 [1:51:31<11:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:13,431 >> Initializing global attention on CLS token...\n",
            " 90% 7491/8340 [1:51:32<11:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:14,257 >> Initializing global attention on CLS token...\n",
            " 90% 7492/8340 [1:51:33<11:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:15,085 >> Initializing global attention on CLS token...\n",
            " 90% 7493/8340 [1:51:34<11:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:15,912 >> Initializing global attention on CLS token...\n",
            " 90% 7494/8340 [1:51:35<11:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:16,737 >> Initializing global attention on CLS token...\n",
            " 90% 7495/8340 [1:51:35<11:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:17,561 >> Initializing global attention on CLS token...\n",
            " 90% 7496/8340 [1:51:36<11:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:18,390 >> Initializing global attention on CLS token...\n",
            " 90% 7497/8340 [1:51:37<11:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:19,213 >> Initializing global attention on CLS token...\n",
            " 90% 7498/8340 [1:51:38<11:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:20,035 >> Initializing global attention on CLS token...\n",
            " 90% 7499/8340 [1:51:39<11:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:20,861 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0422, 'learning_rate': 3.0431654676258995e-06, 'epoch': 8.99}\n",
            " 90% 7500/8340 [1:51:40<12:01,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:21,801 >> Initializing global attention on CLS token...\n",
            " 90% 7501/8340 [1:51:40<11:51,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:22,622 >> Initializing global attention on CLS token...\n",
            " 90% 7502/8340 [1:51:41<11:44,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:23,447 >> Initializing global attention on CLS token...\n",
            " 90% 7503/8340 [1:51:42<11:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:24,272 >> Initializing global attention on CLS token...\n",
            " 90% 7504/8340 [1:51:43<11:36,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:25,099 >> Initializing global attention on CLS token...\n",
            " 90% 7505/8340 [1:51:44<11:33,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:52:25,904 >> Initializing global attention on CLS token...\n",
            " 90% 7506/8340 [1:51:44<09:21,  1.49it/s][INFO|trainer.py:725] 2022-12-10 16:52:26,198 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 16:52:26,201 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 16:52:26,201 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 16:52:26,201 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:26,237 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:26,489 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:29,  7.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:26,740 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:41,  5.62it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:26,992 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:47,  4.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:27,241 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:01<00:50,  4.53it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:27,495 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:52,  4.32it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:27,749 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:54,  4.18it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:27,997 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:54,  4.13it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:28,251 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:02<00:55,  4.07it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:28,499 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:55,  4.07it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:28,748 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:55,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:28,996 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:54,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:29,244 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:03<00:54,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:29,493 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:54,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:29,742 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:54,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:29,993 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:54,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:30,241 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:04<00:53,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:30,490 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:53,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:30,739 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:53,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:30,987 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:53,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:31,234 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:04<00:52,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:31,491 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:53,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:31,738 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:52,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:31,989 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:52,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:32,238 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:06<00:52,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:32,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:51,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:32,735 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:51,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:32,988 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:51,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:33,240 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:07<00:51,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:33,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:50,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:33,740 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:50,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:33,988 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:50,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:34,245 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:08<00:50,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:34,493 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:50,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:34,742 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:49,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:34,988 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:49,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:35,240 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:09<00:49,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:35,492 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:48,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:35,737 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:48,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:35,983 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:48,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:36,234 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:09<00:48,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:36,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:47,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:36,739 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:47,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:36,987 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:47,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:37,238 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:11<00:47,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:37,490 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:47,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:37,754 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:47,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:38,003 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:11<00:47,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:38,272 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:12<00:47,  3.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:38,521 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:47,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:38,791 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:47,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:39,042 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:12<00:46,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:39,299 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:13<00:46,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:39,557 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:46,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:39,810 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:45,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:40,070 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:13<00:45,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:40,322 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:14<00:45,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:40,573 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:44,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:40,830 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:44,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:41,096 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:14<00:45,  3.86it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:41,355 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:15<00:44,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:41,608 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:44,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:41,859 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:43,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:42,115 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:15<00:43,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:42,361 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:16<00:42,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:42,609 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:42,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:42,853 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:41,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:43,101 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:16<00:41,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:43,350 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:17<00:41,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:43,608 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:41,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:43,858 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:40,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:44,113 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:17<00:40,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:44,362 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:18<00:40,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:44,618 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:40,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:44,865 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:39,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:45,127 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:18<00:40,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:45,378 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:19<00:39,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:45,635 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:39,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:45,881 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:39,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:46,141 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:19<00:39,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:46,391 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:20<00:38,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:46,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:38,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:46,888 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:37,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:47,137 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:20<00:37,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:47,385 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:21<00:37,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:47,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:37,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:47,892 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:21<00:36,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:48,143 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:21<00:36,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:48,395 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:22<00:36,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:48,644 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:36,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:48,894 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:22<00:35,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:49,153 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:22<00:35,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:49,407 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:23<00:35,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:49,662 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:35,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:49,912 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:23<00:35,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:50,163 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:23<00:34,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:50,412 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:24<00:34,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:50,666 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:34,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:50,918 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:24<00:33,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:51,166 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:24<00:33,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:51,418 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:25<00:33,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:51,668 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:33,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:51,917 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:25<00:32,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:52,169 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:25<00:32,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:52,418 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:26<00:32,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:52,670 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:32,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:52,920 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:26<00:31,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:53,172 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:26<00:31,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:53,422 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:27<00:31,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:53,672 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:31,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:53,920 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:27<00:30,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:54,167 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:27<00:30,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:54,415 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:28<00:30,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:54,664 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:29,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:54,914 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:28<00:29,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:55,161 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:28<00:29,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:55,411 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:29<00:29,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:55,659 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:28,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:55,906 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:29<00:28,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:56,155 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:29<00:28,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:56,404 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:30<00:28,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:56,651 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:30<00:27,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:56,901 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:30<00:27,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:57,148 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:30<00:27,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:57,394 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:31<00:26,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:57,641 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:31<00:26,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:57,888 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:31<00:26,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:58,147 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:31<00:26,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:58,395 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:32<00:26,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:58,643 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:32<00:25,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:58,891 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:32<00:25,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:59,146 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:32<00:25,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:59,399 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:33<00:25,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:59,654 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:33<00:25,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:52:59,903 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:33<00:24,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:00,155 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:33<00:24,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:00,404 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:34<00:24,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:00,651 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:34<00:23,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:00,901 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:34<00:23,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:01,151 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:34<00:23,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:01,399 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:35<00:23,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:01,652 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:35<00:23,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:01,900 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:35<00:22,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:02,152 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:35<00:22,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:02,412 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:36<00:22,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:02,660 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:36<00:22,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:02,912 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:36<00:21,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:03,163 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:36<00:21,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:03,417 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:37<00:21,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:03,667 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:37<00:21,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:03,919 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:37<00:20,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:04,166 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:37<00:20,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:04,418 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:38<00:20,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:04,666 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:38<00:20,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:04,920 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:38<00:19,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:05,168 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:38<00:19,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:05,422 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:39<00:19,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:05,670 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:39<00:19,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:05,937 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:39<00:19,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:06,186 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:39<00:18,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:06,450 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:40<00:18,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:06,703 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:40<00:18,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:06,956 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:40<00:18,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:07,205 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:40<00:17,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:07,455 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:41<00:17,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:07,704 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:41<00:17,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:07,956 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:41<00:16,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:08,207 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:41<00:16,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:08,457 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:42<00:16,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:08,704 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:42<00:16,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:08,955 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:42<00:15,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:09,201 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:42<00:15,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:09,463 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:43<00:15,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:09,709 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:43<00:15,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:09,969 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:43<00:14,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:10,217 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:43<00:14,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:10,476 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:44<00:14,  3.94it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:10,722 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:44<00:14,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:10,970 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:44<00:13,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:11,217 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:44<00:13,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:11,465 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:45<00:13,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:11,713 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:45<00:12,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:11,971 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:45<00:12,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:12,223 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:45<00:12,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:12,479 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:46<00:12,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:12,727 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:46<00:12,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:12,975 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:46<00:11,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:13,223 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:46<00:11,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:13,479 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:47<00:11,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:13,728 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:47<00:11,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:13,977 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:47<00:10,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:14,225 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:47<00:10,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:14,475 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:48<00:10,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:14,727 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:48<00:10,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:14,978 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:48<00:09,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:15,225 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:48<00:09,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:15,477 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:49<00:09,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:15,726 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:49<00:09,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:15,979 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:49<00:08,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:16,227 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:49<00:08,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:16,475 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:50<00:08,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:16,726 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:50<00:07,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:16,974 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:50<00:07,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:17,235 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:50<00:07,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:17,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:51<00:07,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:17,732 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:51<00:07,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:17,980 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:51<00:06,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:18,229 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:51<00:06,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:18,474 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:52<00:06,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:18,721 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:52<00:05,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:18,973 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:52<00:05,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:19,229 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:52<00:05,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:19,477 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:53<00:05,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:19,724 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:53<00:04,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:19,979 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:53<00:04,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:20,229 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:53<00:04,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:20,482 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:54<00:04,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:20,731 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:54<00:04,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:20,990 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:54<00:03,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:21,239 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:55<00:03,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:21,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:55<00:03,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:21,737 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:55<00:03,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:21,987 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:55<00:02,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:22,238 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:56<00:02,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:22,487 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:56<00:02,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:22,736 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:56<00:01,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:22,983 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:56<00:01,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:23,232 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:56<00:01,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:23,484 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:57<00:01,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:23,735 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:57<00:01,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:23,992 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:57<00:00,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:24,238 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:58<00:00,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:24,486 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:58<00:00,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:24,714 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.5327558517456055, 'eval_f1-micro': 0.7721428571428571, 'eval_f1-macro': 0.6936794453993467, 'eval_runtime': 59.7938, 'eval_samples_per_second': 23.414, 'eval_steps_per_second': 3.913, 'epoch': 9.0}\n",
            " 90% 7506/8340 [1:52:44<09:21,  1.49it/s]\n",
            "100% 234/234 [00:59<00:00,  4.01it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-10 16:53:25,997 >> Saving model checkpoint to logs/output_1/checkpoint-7506\n",
            "[INFO|configuration_utils.py:447] 2022-12-10 16:53:25,998 >> Configuration saved in logs/output_1/checkpoint-7506/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-10 16:53:26,317 >> Model weights saved in logs/output_1/checkpoint-7506/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-10 16:53:26,332 >> tokenizer config file saved in logs/output_1/checkpoint-7506/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-10 16:53:26,333 >> Special tokens file saved in logs/output_1/checkpoint-7506/special_tokens_map.json\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 16:53:28,352 >> Initializing global attention on CLS token...\n",
            " 90% 7507/8340 [1:52:47<4:28:56, 19.37s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:29,231 >> Initializing global attention on CLS token...\n",
            " 90% 7508/8340 [1:52:48<3:11:27, 13.81s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:30,054 >> Initializing global attention on CLS token...\n",
            " 90% 7509/8340 [1:52:49<2:17:16,  9.91s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:30,877 >> Initializing global attention on CLS token...\n",
            " 90% 7510/8340 [1:52:50<1:39:24,  7.19s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:31,701 >> Initializing global attention on CLS token...\n",
            " 90% 7511/8340 [1:52:50<1:12:54,  5.28s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:32,524 >> Initializing global attention on CLS token...\n",
            " 90% 7512/8340 [1:52:51<54:23,  3.94s/it]  [INFO|modeling_longformer.py:1932] 2022-12-10 16:53:33,352 >> Initializing global attention on CLS token...\n",
            " 90% 7513/8340 [1:52:52<41:26,  3.01s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:34,174 >> Initializing global attention on CLS token...\n",
            " 90% 7514/8340 [1:52:53<32:22,  2.35s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:34,997 >> Initializing global attention on CLS token...\n",
            " 90% 7515/8340 [1:52:54<26:00,  1.89s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:35,816 >> Initializing global attention on CLS token...\n",
            " 90% 7516/8340 [1:52:54<21:35,  1.57s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:36,643 >> Initializing global attention on CLS token...\n",
            " 90% 7517/8340 [1:52:55<18:29,  1.35s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:37,466 >> Initializing global attention on CLS token...\n",
            " 90% 7518/8340 [1:52:56<16:19,  1.19s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:38,292 >> Initializing global attention on CLS token...\n",
            " 90% 7519/8340 [1:52:57<14:47,  1.08s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:39,114 >> Initializing global attention on CLS token...\n",
            " 90% 7520/8340 [1:52:58<13:44,  1.01s/it][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:39,944 >> Initializing global attention on CLS token...\n",
            " 90% 7521/8340 [1:52:59<12:58,  1.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:40,768 >> Initializing global attention on CLS token...\n",
            " 90% 7522/8340 [1:52:59<12:26,  1.10it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:41,593 >> Initializing global attention on CLS token...\n",
            " 90% 7523/8340 [1:53:00<12:04,  1.13it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:42,424 >> Initializing global attention on CLS token...\n",
            " 90% 7524/8340 [1:53:01<11:50,  1.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:43,253 >> Initializing global attention on CLS token...\n",
            " 90% 7525/8340 [1:53:02<11:38,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:44,077 >> Initializing global attention on CLS token...\n",
            " 90% 7526/8340 [1:53:03<11:30,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:44,903 >> Initializing global attention on CLS token...\n",
            " 90% 7527/8340 [1:53:04<11:23,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:45,726 >> Initializing global attention on CLS token...\n",
            " 90% 7528/8340 [1:53:04<11:18,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:46,553 >> Initializing global attention on CLS token...\n",
            " 90% 7529/8340 [1:53:05<11:15,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:47,379 >> Initializing global attention on CLS token...\n",
            " 90% 7530/8340 [1:53:06<11:12,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:48,203 >> Initializing global attention on CLS token...\n",
            " 90% 7531/8340 [1:53:07<11:11,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:49,031 >> Initializing global attention on CLS token...\n",
            " 90% 7532/8340 [1:53:08<11:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:49,858 >> Initializing global attention on CLS token...\n",
            " 90% 7533/8340 [1:53:09<11:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:50,682 >> Initializing global attention on CLS token...\n",
            " 90% 7534/8340 [1:53:09<11:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:51,513 >> Initializing global attention on CLS token...\n",
            " 90% 7535/8340 [1:53:10<11:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:52,336 >> Initializing global attention on CLS token...\n",
            " 90% 7536/8340 [1:53:11<11:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:53,162 >> Initializing global attention on CLS token...\n",
            " 90% 7537/8340 [1:53:12<11:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:53,988 >> Initializing global attention on CLS token...\n",
            " 90% 7538/8340 [1:53:13<11:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:54,812 >> Initializing global attention on CLS token...\n",
            " 90% 7539/8340 [1:53:13<11:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:55,640 >> Initializing global attention on CLS token...\n",
            " 90% 7540/8340 [1:53:14<11:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:56,466 >> Initializing global attention on CLS token...\n",
            " 90% 7541/8340 [1:53:15<10:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:57,289 >> Initializing global attention on CLS token...\n",
            " 90% 7542/8340 [1:53:16<11:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:58,121 >> Initializing global attention on CLS token...\n",
            " 90% 7543/8340 [1:53:17<10:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:58,946 >> Initializing global attention on CLS token...\n",
            " 90% 7544/8340 [1:53:18<10:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:53:59,770 >> Initializing global attention on CLS token...\n",
            " 90% 7545/8340 [1:53:18<10:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:00,594 >> Initializing global attention on CLS token...\n",
            " 90% 7546/8340 [1:53:19<10:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:01,419 >> Initializing global attention on CLS token...\n",
            " 90% 7547/8340 [1:53:20<10:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:02,247 >> Initializing global attention on CLS token...\n",
            " 91% 7548/8340 [1:53:21<10:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:03,079 >> Initializing global attention on CLS token...\n",
            " 91% 7549/8340 [1:53:22<10:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:03,907 >> Initializing global attention on CLS token...\n",
            " 91% 7550/8340 [1:53:23<10:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:04,738 >> Initializing global attention on CLS token...\n",
            " 91% 7551/8340 [1:53:23<10:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:05,567 >> Initializing global attention on CLS token...\n",
            " 91% 7552/8340 [1:53:24<10:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:06,397 >> Initializing global attention on CLS token...\n",
            " 91% 7553/8340 [1:53:25<10:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:07,223 >> Initializing global attention on CLS token...\n",
            " 91% 7554/8340 [1:53:26<10:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:08,053 >> Initializing global attention on CLS token...\n",
            " 91% 7555/8340 [1:53:27<11:28,  1.14it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:09,041 >> Initializing global attention on CLS token...\n",
            " 91% 7556/8340 [1:53:28<11:15,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:09,866 >> Initializing global attention on CLS token...\n",
            " 91% 7557/8340 [1:53:29<11:06,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:10,692 >> Initializing global attention on CLS token...\n",
            " 91% 7558/8340 [1:53:29<10:59,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:11,519 >> Initializing global attention on CLS token...\n",
            " 91% 7559/8340 [1:53:30<10:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:12,346 >> Initializing global attention on CLS token...\n",
            " 91% 7560/8340 [1:53:31<10:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:13,174 >> Initializing global attention on CLS token...\n",
            " 91% 7561/8340 [1:53:32<10:48,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:14,002 >> Initializing global attention on CLS token...\n",
            " 91% 7562/8340 [1:53:33<10:46,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:14,826 >> Initializing global attention on CLS token...\n",
            " 91% 7563/8340 [1:53:33<10:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:15,652 >> Initializing global attention on CLS token...\n",
            " 91% 7564/8340 [1:53:34<10:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:16,477 >> Initializing global attention on CLS token...\n",
            " 91% 7565/8340 [1:53:35<10:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:17,304 >> Initializing global attention on CLS token...\n",
            " 91% 7566/8340 [1:53:36<10:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:18,134 >> Initializing global attention on CLS token...\n",
            " 91% 7567/8340 [1:53:37<10:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:18,962 >> Initializing global attention on CLS token...\n",
            " 91% 7568/8340 [1:53:38<10:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:19,786 >> Initializing global attention on CLS token...\n",
            " 91% 7569/8340 [1:53:38<10:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:20,613 >> Initializing global attention on CLS token...\n",
            " 91% 7570/8340 [1:53:39<10:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:21,440 >> Initializing global attention on CLS token...\n",
            " 91% 7571/8340 [1:53:40<10:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:22,264 >> Initializing global attention on CLS token...\n",
            " 91% 7572/8340 [1:53:41<10:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:23,089 >> Initializing global attention on CLS token...\n",
            " 91% 7573/8340 [1:53:42<10:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:23,916 >> Initializing global attention on CLS token...\n",
            " 91% 7574/8340 [1:53:43<10:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:24,741 >> Initializing global attention on CLS token...\n",
            " 91% 7575/8340 [1:53:43<10:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:25,567 >> Initializing global attention on CLS token...\n",
            " 91% 7576/8340 [1:53:44<10:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:26,388 >> Initializing global attention on CLS token...\n",
            " 91% 7577/8340 [1:53:45<10:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:27,214 >> Initializing global attention on CLS token...\n",
            " 91% 7578/8340 [1:53:46<10:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:28,038 >> Initializing global attention on CLS token...\n",
            " 91% 7579/8340 [1:53:47<10:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:28,864 >> Initializing global attention on CLS token...\n",
            " 91% 7580/8340 [1:53:48<10:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:29,690 >> Initializing global attention on CLS token...\n",
            " 91% 7581/8340 [1:53:48<10:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:30,519 >> Initializing global attention on CLS token...\n",
            " 91% 7582/8340 [1:53:49<10:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:31,341 >> Initializing global attention on CLS token...\n",
            " 91% 7583/8340 [1:53:50<10:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:32,168 >> Initializing global attention on CLS token...\n",
            " 91% 7584/8340 [1:53:51<10:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:32,991 >> Initializing global attention on CLS token...\n",
            " 91% 7585/8340 [1:53:52<10:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:33,815 >> Initializing global attention on CLS token...\n",
            " 91% 7586/8340 [1:53:52<10:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:34,635 >> Initializing global attention on CLS token...\n",
            " 91% 7587/8340 [1:53:53<10:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:35,457 >> Initializing global attention on CLS token...\n",
            " 91% 7588/8340 [1:53:54<10:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:36,282 >> Initializing global attention on CLS token...\n",
            " 91% 7589/8340 [1:53:55<10:18,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:37,104 >> Initializing global attention on CLS token...\n",
            " 91% 7590/8340 [1:53:56<10:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:37,931 >> Initializing global attention on CLS token...\n",
            " 91% 7591/8340 [1:53:57<10:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:38,759 >> Initializing global attention on CLS token...\n",
            " 91% 7592/8340 [1:53:57<10:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:39,585 >> Initializing global attention on CLS token...\n",
            " 91% 7593/8340 [1:53:58<10:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:40,408 >> Initializing global attention on CLS token...\n",
            " 91% 7594/8340 [1:53:59<10:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:41,236 >> Initializing global attention on CLS token...\n",
            " 91% 7595/8340 [1:54:00<10:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:42,057 >> Initializing global attention on CLS token...\n",
            " 91% 7596/8340 [1:54:01<10:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:42,883 >> Initializing global attention on CLS token...\n",
            " 91% 7597/8340 [1:54:02<10:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:43,710 >> Initializing global attention on CLS token...\n",
            " 91% 7598/8340 [1:54:02<10:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:44,535 >> Initializing global attention on CLS token...\n",
            " 91% 7599/8340 [1:54:03<10:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:45,358 >> Initializing global attention on CLS token...\n",
            " 91% 7600/8340 [1:54:04<10:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:46,180 >> Initializing global attention on CLS token...\n",
            " 91% 7601/8340 [1:54:05<10:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:47,005 >> Initializing global attention on CLS token...\n",
            " 91% 7602/8340 [1:54:06<10:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:47,828 >> Initializing global attention on CLS token...\n",
            " 91% 7603/8340 [1:54:06<10:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:48,653 >> Initializing global attention on CLS token...\n",
            " 91% 7604/8340 [1:54:07<10:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:49,475 >> Initializing global attention on CLS token...\n",
            " 91% 7605/8340 [1:54:08<10:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:50,302 >> Initializing global attention on CLS token...\n",
            " 91% 7606/8340 [1:54:09<10:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:51,125 >> Initializing global attention on CLS token...\n",
            " 91% 7607/8340 [1:54:10<10:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:51,949 >> Initializing global attention on CLS token...\n",
            " 91% 7608/8340 [1:54:11<10:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:52,775 >> Initializing global attention on CLS token...\n",
            " 91% 7609/8340 [1:54:11<10:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:53,599 >> Initializing global attention on CLS token...\n",
            " 91% 7610/8340 [1:54:12<10:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:54,422 >> Initializing global attention on CLS token...\n",
            " 91% 7611/8340 [1:54:13<10:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:55,245 >> Initializing global attention on CLS token...\n",
            " 91% 7612/8340 [1:54:14<10:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:56,083 >> Initializing global attention on CLS token...\n",
            " 91% 7613/8340 [1:54:15<10:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:56,908 >> Initializing global attention on CLS token...\n",
            " 91% 7614/8340 [1:54:16<09:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:57,729 >> Initializing global attention on CLS token...\n",
            " 91% 7615/8340 [1:54:16<09:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:58,557 >> Initializing global attention on CLS token...\n",
            " 91% 7616/8340 [1:54:17<09:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:54:59,381 >> Initializing global attention on CLS token...\n",
            " 91% 7617/8340 [1:54:18<09:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:00,208 >> Initializing global attention on CLS token...\n",
            " 91% 7618/8340 [1:54:19<09:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:01,038 >> Initializing global attention on CLS token...\n",
            " 91% 7619/8340 [1:54:20<09:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:01,868 >> Initializing global attention on CLS token...\n",
            " 91% 7620/8340 [1:54:21<09:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:02,692 >> Initializing global attention on CLS token...\n",
            " 91% 7621/8340 [1:54:21<09:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:03,517 >> Initializing global attention on CLS token...\n",
            " 91% 7622/8340 [1:54:22<09:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:04,344 >> Initializing global attention on CLS token...\n",
            " 91% 7623/8340 [1:54:23<09:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:05,175 >> Initializing global attention on CLS token...\n",
            " 91% 7624/8340 [1:54:24<09:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:06,002 >> Initializing global attention on CLS token...\n",
            " 91% 7625/8340 [1:54:25<09:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:06,828 >> Initializing global attention on CLS token...\n",
            " 91% 7626/8340 [1:54:25<09:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:07,651 >> Initializing global attention on CLS token...\n",
            " 91% 7627/8340 [1:54:26<09:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:08,474 >> Initializing global attention on CLS token...\n",
            " 91% 7628/8340 [1:54:27<09:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:09,297 >> Initializing global attention on CLS token...\n",
            " 91% 7629/8340 [1:54:28<09:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:10,129 >> Initializing global attention on CLS token...\n",
            " 91% 7630/8340 [1:54:29<09:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:10,954 >> Initializing global attention on CLS token...\n",
            " 91% 7631/8340 [1:54:30<09:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:11,780 >> Initializing global attention on CLS token...\n",
            " 92% 7632/8340 [1:54:30<09:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:12,608 >> Initializing global attention on CLS token...\n",
            " 92% 7633/8340 [1:54:31<09:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:13,436 >> Initializing global attention on CLS token...\n",
            " 92% 7634/8340 [1:54:32<09:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:14,262 >> Initializing global attention on CLS token...\n",
            " 92% 7635/8340 [1:54:33<09:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:15,089 >> Initializing global attention on CLS token...\n",
            " 92% 7636/8340 [1:54:34<09:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:15,915 >> Initializing global attention on CLS token...\n",
            " 92% 7637/8340 [1:54:35<09:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:16,738 >> Initializing global attention on CLS token...\n",
            " 92% 7638/8340 [1:54:35<09:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:17,567 >> Initializing global attention on CLS token...\n",
            " 92% 7639/8340 [1:54:36<09:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:18,395 >> Initializing global attention on CLS token...\n",
            " 92% 7640/8340 [1:54:37<09:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:19,218 >> Initializing global attention on CLS token...\n",
            " 92% 7641/8340 [1:54:38<09:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:20,041 >> Initializing global attention on CLS token...\n",
            " 92% 7642/8340 [1:54:39<09:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:20,864 >> Initializing global attention on CLS token...\n",
            " 92% 7643/8340 [1:54:40<09:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:21,693 >> Initializing global attention on CLS token...\n",
            " 92% 7644/8340 [1:54:40<09:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:22,520 >> Initializing global attention on CLS token...\n",
            " 92% 7645/8340 [1:54:41<09:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:23,346 >> Initializing global attention on CLS token...\n",
            " 92% 7646/8340 [1:54:42<09:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:24,169 >> Initializing global attention on CLS token...\n",
            " 92% 7647/8340 [1:54:43<09:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:24,991 >> Initializing global attention on CLS token...\n",
            " 92% 7648/8340 [1:54:44<09:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:25,817 >> Initializing global attention on CLS token...\n",
            " 92% 7649/8340 [1:54:44<09:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:26,642 >> Initializing global attention on CLS token...\n",
            " 92% 7650/8340 [1:54:45<09:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:27,465 >> Initializing global attention on CLS token...\n",
            " 92% 7651/8340 [1:54:46<09:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:28,286 >> Initializing global attention on CLS token...\n",
            " 92% 7652/8340 [1:54:47<09:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:29,111 >> Initializing global attention on CLS token...\n",
            " 92% 7653/8340 [1:54:48<09:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:29,935 >> Initializing global attention on CLS token...\n",
            " 92% 7654/8340 [1:54:49<09:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:30,766 >> Initializing global attention on CLS token...\n",
            " 92% 7655/8340 [1:54:49<09:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:31,591 >> Initializing global attention on CLS token...\n",
            " 92% 7656/8340 [1:54:50<09:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:32,415 >> Initializing global attention on CLS token...\n",
            " 92% 7657/8340 [1:54:51<09:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:33,239 >> Initializing global attention on CLS token...\n",
            " 92% 7658/8340 [1:54:52<09:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:34,061 >> Initializing global attention on CLS token...\n",
            " 92% 7659/8340 [1:54:53<09:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:34,884 >> Initializing global attention on CLS token...\n",
            " 92% 7660/8340 [1:54:54<09:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:35,710 >> Initializing global attention on CLS token...\n",
            " 92% 7661/8340 [1:54:54<09:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:36,534 >> Initializing global attention on CLS token...\n",
            " 92% 7662/8340 [1:54:55<09:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:37,361 >> Initializing global attention on CLS token...\n",
            " 92% 7663/8340 [1:54:56<09:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:38,187 >> Initializing global attention on CLS token...\n",
            " 92% 7664/8340 [1:54:57<09:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:39,011 >> Initializing global attention on CLS token...\n",
            " 92% 7665/8340 [1:54:58<09:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:39,837 >> Initializing global attention on CLS token...\n",
            " 92% 7666/8340 [1:54:59<09:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:40,661 >> Initializing global attention on CLS token...\n",
            " 92% 7667/8340 [1:54:59<09:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:41,492 >> Initializing global attention on CLS token...\n",
            " 92% 7668/8340 [1:55:00<09:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:42,320 >> Initializing global attention on CLS token...\n",
            " 92% 7669/8340 [1:55:01<09:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:43,149 >> Initializing global attention on CLS token...\n",
            " 92% 7670/8340 [1:55:02<09:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:43,975 >> Initializing global attention on CLS token...\n",
            " 92% 7671/8340 [1:55:03<09:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:44,802 >> Initializing global attention on CLS token...\n",
            " 92% 7672/8340 [1:55:03<09:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:45,626 >> Initializing global attention on CLS token...\n",
            " 92% 7673/8340 [1:55:04<09:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:46,449 >> Initializing global attention on CLS token...\n",
            " 92% 7674/8340 [1:55:05<09:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:47,276 >> Initializing global attention on CLS token...\n",
            " 92% 7675/8340 [1:55:06<09:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:48,103 >> Initializing global attention on CLS token...\n",
            " 92% 7676/8340 [1:55:07<09:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:48,932 >> Initializing global attention on CLS token...\n",
            " 92% 7677/8340 [1:55:08<09:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:49,753 >> Initializing global attention on CLS token...\n",
            " 92% 7678/8340 [1:55:08<09:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:50,578 >> Initializing global attention on CLS token...\n",
            " 92% 7679/8340 [1:55:09<09:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:51,403 >> Initializing global attention on CLS token...\n",
            " 92% 7680/8340 [1:55:10<09:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:52,232 >> Initializing global attention on CLS token...\n",
            " 92% 7681/8340 [1:55:11<09:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:53,058 >> Initializing global attention on CLS token...\n",
            " 92% 7682/8340 [1:55:12<09:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:53,882 >> Initializing global attention on CLS token...\n",
            " 92% 7683/8340 [1:55:13<09:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:54,707 >> Initializing global attention on CLS token...\n",
            " 92% 7684/8340 [1:55:13<09:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:55,532 >> Initializing global attention on CLS token...\n",
            " 92% 7685/8340 [1:55:14<09:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:56,358 >> Initializing global attention on CLS token...\n",
            " 92% 7686/8340 [1:55:15<08:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:57,182 >> Initializing global attention on CLS token...\n",
            " 92% 7687/8340 [1:55:16<08:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:58,010 >> Initializing global attention on CLS token...\n",
            " 92% 7688/8340 [1:55:17<08:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:58,834 >> Initializing global attention on CLS token...\n",
            " 92% 7689/8340 [1:55:17<08:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:55:59,661 >> Initializing global attention on CLS token...\n",
            " 92% 7690/8340 [1:55:18<08:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:00,492 >> Initializing global attention on CLS token...\n",
            " 92% 7691/8340 [1:55:19<08:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:01,316 >> Initializing global attention on CLS token...\n",
            " 92% 7692/8340 [1:55:20<08:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:02,143 >> Initializing global attention on CLS token...\n",
            " 92% 7693/8340 [1:55:21<08:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:02,970 >> Initializing global attention on CLS token...\n",
            " 92% 7694/8340 [1:55:22<08:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:03,793 >> Initializing global attention on CLS token...\n",
            " 92% 7695/8340 [1:55:22<08:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:04,619 >> Initializing global attention on CLS token...\n",
            " 92% 7696/8340 [1:55:23<08:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:05,446 >> Initializing global attention on CLS token...\n",
            " 92% 7697/8340 [1:55:24<08:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:06,272 >> Initializing global attention on CLS token...\n",
            " 92% 7698/8340 [1:55:25<08:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:07,098 >> Initializing global attention on CLS token...\n",
            " 92% 7699/8340 [1:55:26<08:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:07,924 >> Initializing global attention on CLS token...\n",
            " 92% 7700/8340 [1:55:27<08:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:08,752 >> Initializing global attention on CLS token...\n",
            " 92% 7701/8340 [1:55:27<08:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:09,580 >> Initializing global attention on CLS token...\n",
            " 92% 7702/8340 [1:55:28<08:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:10,408 >> Initializing global attention on CLS token...\n",
            " 92% 7703/8340 [1:55:29<08:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:11,233 >> Initializing global attention on CLS token...\n",
            " 92% 7704/8340 [1:55:30<08:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:12,058 >> Initializing global attention on CLS token...\n",
            " 92% 7705/8340 [1:55:31<08:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:12,885 >> Initializing global attention on CLS token...\n",
            " 92% 7706/8340 [1:55:32<08:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:13,711 >> Initializing global attention on CLS token...\n",
            " 92% 7707/8340 [1:55:32<08:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:14,537 >> Initializing global attention on CLS token...\n",
            " 92% 7708/8340 [1:55:33<08:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:15,361 >> Initializing global attention on CLS token...\n",
            " 92% 7709/8340 [1:55:34<08:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:16,189 >> Initializing global attention on CLS token...\n",
            " 92% 7710/8340 [1:55:35<08:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:17,018 >> Initializing global attention on CLS token...\n",
            " 92% 7711/8340 [1:55:36<08:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:17,843 >> Initializing global attention on CLS token...\n",
            " 92% 7712/8340 [1:55:37<08:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:18,666 >> Initializing global attention on CLS token...\n",
            " 92% 7713/8340 [1:55:37<08:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:19,494 >> Initializing global attention on CLS token...\n",
            " 92% 7714/8340 [1:55:38<08:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:20,320 >> Initializing global attention on CLS token...\n",
            " 93% 7715/8340 [1:55:39<08:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:21,147 >> Initializing global attention on CLS token...\n",
            " 93% 7716/8340 [1:55:40<08:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:21,977 >> Initializing global attention on CLS token...\n",
            " 93% 7717/8340 [1:55:41<08:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:22,801 >> Initializing global attention on CLS token...\n",
            " 93% 7718/8340 [1:55:41<08:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:23,626 >> Initializing global attention on CLS token...\n",
            " 93% 7719/8340 [1:55:42<08:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:24,454 >> Initializing global attention on CLS token...\n",
            " 93% 7720/8340 [1:55:43<08:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:25,273 >> Initializing global attention on CLS token...\n",
            " 93% 7721/8340 [1:55:44<08:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:26,098 >> Initializing global attention on CLS token...\n",
            " 93% 7722/8340 [1:55:45<08:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:26,922 >> Initializing global attention on CLS token...\n",
            " 93% 7723/8340 [1:55:46<08:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:27,746 >> Initializing global attention on CLS token...\n",
            " 93% 7724/8340 [1:55:46<08:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:28,571 >> Initializing global attention on CLS token...\n",
            " 93% 7725/8340 [1:55:47<08:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:29,396 >> Initializing global attention on CLS token...\n",
            " 93% 7726/8340 [1:55:48<08:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:30,219 >> Initializing global attention on CLS token...\n",
            " 93% 7727/8340 [1:55:49<08:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:31,043 >> Initializing global attention on CLS token...\n",
            " 93% 7728/8340 [1:55:50<08:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:31,865 >> Initializing global attention on CLS token...\n",
            " 93% 7729/8340 [1:55:51<08:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:32,691 >> Initializing global attention on CLS token...\n",
            " 93% 7730/8340 [1:55:51<08:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:33,515 >> Initializing global attention on CLS token...\n",
            " 93% 7731/8340 [1:55:52<08:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:34,342 >> Initializing global attention on CLS token...\n",
            " 93% 7732/8340 [1:55:53<08:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:35,175 >> Initializing global attention on CLS token...\n",
            " 93% 7733/8340 [1:55:54<08:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:36,004 >> Initializing global attention on CLS token...\n",
            " 93% 7734/8340 [1:55:55<08:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:36,840 >> Initializing global attention on CLS token...\n",
            " 93% 7735/8340 [1:55:56<08:22,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:37,667 >> Initializing global attention on CLS token...\n",
            " 93% 7736/8340 [1:55:56<08:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:38,494 >> Initializing global attention on CLS token...\n",
            " 93% 7737/8340 [1:55:57<08:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:39,321 >> Initializing global attention on CLS token...\n",
            " 93% 7738/8340 [1:55:58<08:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:40,141 >> Initializing global attention on CLS token...\n",
            " 93% 7739/8340 [1:55:59<08:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:40,969 >> Initializing global attention on CLS token...\n",
            " 93% 7740/8340 [1:56:00<08:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:41,794 >> Initializing global attention on CLS token...\n",
            " 93% 7741/8340 [1:56:00<08:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:42,624 >> Initializing global attention on CLS token...\n",
            " 93% 7742/8340 [1:56:01<08:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:43,448 >> Initializing global attention on CLS token...\n",
            " 93% 7743/8340 [1:56:02<08:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:44,270 >> Initializing global attention on CLS token...\n",
            " 93% 7744/8340 [1:56:03<08:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:45,098 >> Initializing global attention on CLS token...\n",
            " 93% 7745/8340 [1:56:04<08:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:45,926 >> Initializing global attention on CLS token...\n",
            " 93% 7746/8340 [1:56:05<08:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:46,755 >> Initializing global attention on CLS token...\n",
            " 93% 7747/8340 [1:56:05<08:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:47,583 >> Initializing global attention on CLS token...\n",
            " 93% 7748/8340 [1:56:06<08:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:48,409 >> Initializing global attention on CLS token...\n",
            " 93% 7749/8340 [1:56:07<08:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:49,237 >> Initializing global attention on CLS token...\n",
            " 93% 7750/8340 [1:56:08<08:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:50,059 >> Initializing global attention on CLS token...\n",
            " 93% 7751/8340 [1:56:09<08:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:50,883 >> Initializing global attention on CLS token...\n",
            " 93% 7752/8340 [1:56:10<08:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:51,705 >> Initializing global attention on CLS token...\n",
            " 93% 7753/8340 [1:56:10<08:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:52,530 >> Initializing global attention on CLS token...\n",
            " 93% 7754/8340 [1:56:11<08:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:53,356 >> Initializing global attention on CLS token...\n",
            " 93% 7755/8340 [1:56:12<08:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:54,180 >> Initializing global attention on CLS token...\n",
            " 93% 7756/8340 [1:56:13<08:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:55,001 >> Initializing global attention on CLS token...\n",
            " 93% 7757/8340 [1:56:14<08:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:55,835 >> Initializing global attention on CLS token...\n",
            " 93% 7758/8340 [1:56:14<08:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:56,658 >> Initializing global attention on CLS token...\n",
            " 93% 7759/8340 [1:56:15<07:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:57,486 >> Initializing global attention on CLS token...\n",
            " 93% 7760/8340 [1:56:16<07:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:58,316 >> Initializing global attention on CLS token...\n",
            " 93% 7761/8340 [1:56:17<07:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:59,141 >> Initializing global attention on CLS token...\n",
            " 93% 7762/8340 [1:56:18<07:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:56:59,967 >> Initializing global attention on CLS token...\n",
            " 93% 7763/8340 [1:56:19<07:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:00,793 >> Initializing global attention on CLS token...\n",
            " 93% 7764/8340 [1:56:19<07:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:01,621 >> Initializing global attention on CLS token...\n",
            " 93% 7765/8340 [1:56:20<07:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:02,446 >> Initializing global attention on CLS token...\n",
            " 93% 7766/8340 [1:56:21<07:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:03,272 >> Initializing global attention on CLS token...\n",
            " 93% 7767/8340 [1:56:22<07:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:04,096 >> Initializing global attention on CLS token...\n",
            " 93% 7768/8340 [1:56:23<07:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:04,920 >> Initializing global attention on CLS token...\n",
            " 93% 7769/8340 [1:56:24<07:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:05,746 >> Initializing global attention on CLS token...\n",
            " 93% 7770/8340 [1:56:24<07:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:06,575 >> Initializing global attention on CLS token...\n",
            " 93% 7771/8340 [1:56:25<07:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:07,399 >> Initializing global attention on CLS token...\n",
            " 93% 7772/8340 [1:56:26<07:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:08,226 >> Initializing global attention on CLS token...\n",
            " 93% 7773/8340 [1:56:27<07:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:09,046 >> Initializing global attention on CLS token...\n",
            " 93% 7774/8340 [1:56:28<07:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:09,874 >> Initializing global attention on CLS token...\n",
            " 93% 7775/8340 [1:56:29<07:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:10,697 >> Initializing global attention on CLS token...\n",
            " 93% 7776/8340 [1:56:29<07:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:11,523 >> Initializing global attention on CLS token...\n",
            " 93% 7777/8340 [1:56:30<07:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:12,349 >> Initializing global attention on CLS token...\n",
            " 93% 7778/8340 [1:56:31<07:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:13,173 >> Initializing global attention on CLS token...\n",
            " 93% 7779/8340 [1:56:32<07:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:13,997 >> Initializing global attention on CLS token...\n",
            " 93% 7780/8340 [1:56:33<07:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:14,821 >> Initializing global attention on CLS token...\n",
            " 93% 7781/8340 [1:56:33<07:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:15,651 >> Initializing global attention on CLS token...\n",
            " 93% 7782/8340 [1:56:34<07:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:16,474 >> Initializing global attention on CLS token...\n",
            " 93% 7783/8340 [1:56:35<07:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:17,297 >> Initializing global attention on CLS token...\n",
            " 93% 7784/8340 [1:56:36<07:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:18,127 >> Initializing global attention on CLS token...\n",
            " 93% 7785/8340 [1:56:37<07:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:18,952 >> Initializing global attention on CLS token...\n",
            " 93% 7786/8340 [1:56:38<07:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:19,780 >> Initializing global attention on CLS token...\n",
            " 93% 7787/8340 [1:56:38<07:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:20,605 >> Initializing global attention on CLS token...\n",
            " 93% 7788/8340 [1:56:39<07:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:21,431 >> Initializing global attention on CLS token...\n",
            " 93% 7789/8340 [1:56:40<07:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:22,258 >> Initializing global attention on CLS token...\n",
            " 93% 7790/8340 [1:56:41<07:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:23,084 >> Initializing global attention on CLS token...\n",
            " 93% 7791/8340 [1:56:42<07:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:23,907 >> Initializing global attention on CLS token...\n",
            " 93% 7792/8340 [1:56:43<07:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:24,736 >> Initializing global attention on CLS token...\n",
            " 93% 7793/8340 [1:56:43<07:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:25,558 >> Initializing global attention on CLS token...\n",
            " 93% 7794/8340 [1:56:44<07:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:26,383 >> Initializing global attention on CLS token...\n",
            " 93% 7795/8340 [1:56:45<07:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:27,204 >> Initializing global attention on CLS token...\n",
            " 93% 7796/8340 [1:56:46<07:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:28,030 >> Initializing global attention on CLS token...\n",
            " 93% 7797/8340 [1:56:47<07:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:28,857 >> Initializing global attention on CLS token...\n",
            " 94% 7798/8340 [1:56:48<07:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:29,685 >> Initializing global attention on CLS token...\n",
            " 94% 7799/8340 [1:56:48<07:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:30,508 >> Initializing global attention on CLS token...\n",
            " 94% 7800/8340 [1:56:49<07:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:31,332 >> Initializing global attention on CLS token...\n",
            " 94% 7801/8340 [1:56:50<07:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:32,160 >> Initializing global attention on CLS token...\n",
            " 94% 7802/8340 [1:56:51<07:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:32,985 >> Initializing global attention on CLS token...\n",
            " 94% 7803/8340 [1:56:52<07:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:33,808 >> Initializing global attention on CLS token...\n",
            " 94% 7804/8340 [1:56:52<07:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:34,638 >> Initializing global attention on CLS token...\n",
            " 94% 7805/8340 [1:56:53<07:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:35,463 >> Initializing global attention on CLS token...\n",
            " 94% 7806/8340 [1:56:54<07:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:36,287 >> Initializing global attention on CLS token...\n",
            " 94% 7807/8340 [1:56:55<07:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:37,117 >> Initializing global attention on CLS token...\n",
            " 94% 7808/8340 [1:56:56<07:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:37,944 >> Initializing global attention on CLS token...\n",
            " 94% 7809/8340 [1:56:57<07:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:38,773 >> Initializing global attention on CLS token...\n",
            " 94% 7810/8340 [1:56:57<07:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:39,630 >> Initializing global attention on CLS token...\n",
            " 94% 7811/8340 [1:56:58<07:22,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:40,466 >> Initializing global attention on CLS token...\n",
            " 94% 7812/8340 [1:56:59<07:20,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:41,293 >> Initializing global attention on CLS token...\n",
            " 94% 7813/8340 [1:57:00<07:19,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:42,119 >> Initializing global attention on CLS token...\n",
            " 94% 7814/8340 [1:57:01<07:16,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:42,945 >> Initializing global attention on CLS token...\n",
            " 94% 7815/8340 [1:57:02<07:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:43,769 >> Initializing global attention on CLS token...\n",
            " 94% 7816/8340 [1:57:02<07:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:44,598 >> Initializing global attention on CLS token...\n",
            " 94% 7817/8340 [1:57:03<07:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:45,423 >> Initializing global attention on CLS token...\n",
            " 94% 7818/8340 [1:57:04<07:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:46,249 >> Initializing global attention on CLS token...\n",
            " 94% 7819/8340 [1:57:05<07:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:47,075 >> Initializing global attention on CLS token...\n",
            " 94% 7820/8340 [1:57:06<07:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:47,897 >> Initializing global attention on CLS token...\n",
            " 94% 7821/8340 [1:57:07<07:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:48,722 >> Initializing global attention on CLS token...\n",
            " 94% 7822/8340 [1:57:07<07:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:49,545 >> Initializing global attention on CLS token...\n",
            " 94% 7823/8340 [1:57:08<07:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:50,373 >> Initializing global attention on CLS token...\n",
            " 94% 7824/8340 [1:57:09<07:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:51,202 >> Initializing global attention on CLS token...\n",
            " 94% 7825/8340 [1:57:10<07:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:52,026 >> Initializing global attention on CLS token...\n",
            " 94% 7826/8340 [1:57:11<07:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:52,859 >> Initializing global attention on CLS token...\n",
            " 94% 7827/8340 [1:57:12<07:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:53,698 >> Initializing global attention on CLS token...\n",
            " 94% 7828/8340 [1:57:12<07:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:54,525 >> Initializing global attention on CLS token...\n",
            " 94% 7829/8340 [1:57:13<07:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:55,349 >> Initializing global attention on CLS token...\n",
            " 94% 7830/8340 [1:57:14<07:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:56,174 >> Initializing global attention on CLS token...\n",
            " 94% 7831/8340 [1:57:15<07:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:57,000 >> Initializing global attention on CLS token...\n",
            " 94% 7832/8340 [1:57:16<07:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:57,829 >> Initializing global attention on CLS token...\n",
            " 94% 7833/8340 [1:57:16<06:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:58,653 >> Initializing global attention on CLS token...\n",
            " 94% 7834/8340 [1:57:17<06:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:57:59,477 >> Initializing global attention on CLS token...\n",
            " 94% 7835/8340 [1:57:18<06:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:00,300 >> Initializing global attention on CLS token...\n",
            " 94% 7836/8340 [1:57:19<06:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:01,130 >> Initializing global attention on CLS token...\n",
            " 94% 7837/8340 [1:57:20<06:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:01,959 >> Initializing global attention on CLS token...\n",
            " 94% 7838/8340 [1:57:21<06:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:02,784 >> Initializing global attention on CLS token...\n",
            " 94% 7839/8340 [1:57:21<06:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:03,607 >> Initializing global attention on CLS token...\n",
            " 94% 7840/8340 [1:57:22<06:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:04,433 >> Initializing global attention on CLS token...\n",
            " 94% 7841/8340 [1:57:23<06:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:05,255 >> Initializing global attention on CLS token...\n",
            " 94% 7842/8340 [1:57:24<06:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:06,081 >> Initializing global attention on CLS token...\n",
            " 94% 7843/8340 [1:57:25<06:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:06,904 >> Initializing global attention on CLS token...\n",
            " 94% 7844/8340 [1:57:26<06:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:07,735 >> Initializing global attention on CLS token...\n",
            " 94% 7845/8340 [1:57:26<06:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:08,557 >> Initializing global attention on CLS token...\n",
            " 94% 7846/8340 [1:57:27<06:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:09,380 >> Initializing global attention on CLS token...\n",
            " 94% 7847/8340 [1:57:28<06:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:10,205 >> Initializing global attention on CLS token...\n",
            " 94% 7848/8340 [1:57:29<06:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:11,027 >> Initializing global attention on CLS token...\n",
            " 94% 7849/8340 [1:57:30<06:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:11,851 >> Initializing global attention on CLS token...\n",
            " 94% 7850/8340 [1:57:31<06:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:12,674 >> Initializing global attention on CLS token...\n",
            " 94% 7851/8340 [1:57:31<06:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:13,498 >> Initializing global attention on CLS token...\n",
            " 94% 7852/8340 [1:57:32<06:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:14,324 >> Initializing global attention on CLS token...\n",
            " 94% 7853/8340 [1:57:33<06:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:15,148 >> Initializing global attention on CLS token...\n",
            " 94% 7854/8340 [1:57:34<06:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:15,971 >> Initializing global attention on CLS token...\n",
            " 94% 7855/8340 [1:57:35<06:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:16,805 >> Initializing global attention on CLS token...\n",
            " 94% 7856/8340 [1:57:35<06:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:17,630 >> Initializing global attention on CLS token...\n",
            " 94% 7857/8340 [1:57:36<06:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:18,454 >> Initializing global attention on CLS token...\n",
            " 94% 7858/8340 [1:57:37<06:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:19,276 >> Initializing global attention on CLS token...\n",
            " 94% 7859/8340 [1:57:38<06:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:20,101 >> Initializing global attention on CLS token...\n",
            " 94% 7860/8340 [1:57:39<06:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:20,932 >> Initializing global attention on CLS token...\n",
            " 94% 7861/8340 [1:57:40<06:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:21,753 >> Initializing global attention on CLS token...\n",
            " 94% 7862/8340 [1:57:40<06:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:22,576 >> Initializing global attention on CLS token...\n",
            " 94% 7863/8340 [1:57:41<06:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:23,402 >> Initializing global attention on CLS token...\n",
            " 94% 7864/8340 [1:57:42<06:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:24,228 >> Initializing global attention on CLS token...\n",
            " 94% 7865/8340 [1:57:43<06:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:25,053 >> Initializing global attention on CLS token...\n",
            " 94% 7866/8340 [1:57:44<06:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:25,879 >> Initializing global attention on CLS token...\n",
            " 94% 7867/8340 [1:57:45<06:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:26,702 >> Initializing global attention on CLS token...\n",
            " 94% 7868/8340 [1:57:45<06:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:27,530 >> Initializing global attention on CLS token...\n",
            " 94% 7869/8340 [1:57:46<06:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:28,353 >> Initializing global attention on CLS token...\n",
            " 94% 7870/8340 [1:57:47<06:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:29,178 >> Initializing global attention on CLS token...\n",
            " 94% 7871/8340 [1:57:48<06:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:30,001 >> Initializing global attention on CLS token...\n",
            " 94% 7872/8340 [1:57:49<06:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:30,828 >> Initializing global attention on CLS token...\n",
            " 94% 7873/8340 [1:57:49<06:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:31,653 >> Initializing global attention on CLS token...\n",
            " 94% 7874/8340 [1:57:50<06:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:32,480 >> Initializing global attention on CLS token...\n",
            " 94% 7875/8340 [1:57:51<06:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:33,311 >> Initializing global attention on CLS token...\n",
            " 94% 7876/8340 [1:57:52<06:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:34,138 >> Initializing global attention on CLS token...\n",
            " 94% 7877/8340 [1:57:53<06:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:34,966 >> Initializing global attention on CLS token...\n",
            " 94% 7878/8340 [1:57:54<06:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:35,790 >> Initializing global attention on CLS token...\n",
            " 94% 7879/8340 [1:57:54<06:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:36,616 >> Initializing global attention on CLS token...\n",
            " 94% 7880/8340 [1:57:55<06:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:37,435 >> Initializing global attention on CLS token...\n",
            " 94% 7881/8340 [1:57:56<06:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:38,267 >> Initializing global attention on CLS token...\n",
            " 95% 7882/8340 [1:57:57<06:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:39,097 >> Initializing global attention on CLS token...\n",
            " 95% 7883/8340 [1:57:58<06:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:39,920 >> Initializing global attention on CLS token...\n",
            " 95% 7884/8340 [1:57:59<06:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:40,743 >> Initializing global attention on CLS token...\n",
            " 95% 7885/8340 [1:57:59<06:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:41,569 >> Initializing global attention on CLS token...\n",
            " 95% 7886/8340 [1:58:00<06:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:42,395 >> Initializing global attention on CLS token...\n",
            " 95% 7887/8340 [1:58:01<06:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:43,221 >> Initializing global attention on CLS token...\n",
            " 95% 7888/8340 [1:58:02<06:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:44,044 >> Initializing global attention on CLS token...\n",
            " 95% 7889/8340 [1:58:03<06:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:44,866 >> Initializing global attention on CLS token...\n",
            " 95% 7890/8340 [1:58:04<06:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:45,694 >> Initializing global attention on CLS token...\n",
            " 95% 7891/8340 [1:58:04<06:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:46,520 >> Initializing global attention on CLS token...\n",
            " 95% 7892/8340 [1:58:05<06:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:47,348 >> Initializing global attention on CLS token...\n",
            " 95% 7893/8340 [1:58:06<06:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:48,177 >> Initializing global attention on CLS token...\n",
            " 95% 7894/8340 [1:58:07<06:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:48,999 >> Initializing global attention on CLS token...\n",
            " 95% 7895/8340 [1:58:08<06:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:49,827 >> Initializing global attention on CLS token...\n",
            " 95% 7896/8340 [1:58:08<06:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:50,656 >> Initializing global attention on CLS token...\n",
            " 95% 7897/8340 [1:58:09<06:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:51,480 >> Initializing global attention on CLS token...\n",
            " 95% 7898/8340 [1:58:10<06:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:52,305 >> Initializing global attention on CLS token...\n",
            " 95% 7899/8340 [1:58:11<06:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:53,127 >> Initializing global attention on CLS token...\n",
            " 95% 7900/8340 [1:58:12<06:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:53,955 >> Initializing global attention on CLS token...\n",
            " 95% 7901/8340 [1:58:13<06:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:54,779 >> Initializing global attention on CLS token...\n",
            " 95% 7902/8340 [1:58:13<06:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:55,603 >> Initializing global attention on CLS token...\n",
            " 95% 7903/8340 [1:58:14<05:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:56,423 >> Initializing global attention on CLS token...\n",
            " 95% 7904/8340 [1:58:15<05:58,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:57,243 >> Initializing global attention on CLS token...\n",
            " 95% 7905/8340 [1:58:16<05:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:58,069 >> Initializing global attention on CLS token...\n",
            " 95% 7906/8340 [1:58:17<05:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:58,897 >> Initializing global attention on CLS token...\n",
            " 95% 7907/8340 [1:58:18<05:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:58:59,722 >> Initializing global attention on CLS token...\n",
            " 95% 7908/8340 [1:58:18<05:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:00,547 >> Initializing global attention on CLS token...\n",
            " 95% 7909/8340 [1:58:19<05:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:01,373 >> Initializing global attention on CLS token...\n",
            " 95% 7910/8340 [1:58:20<05:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:02,200 >> Initializing global attention on CLS token...\n",
            " 95% 7911/8340 [1:58:21<05:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:03,023 >> Initializing global attention on CLS token...\n",
            " 95% 7912/8340 [1:58:22<05:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:03,846 >> Initializing global attention on CLS token...\n",
            " 95% 7913/8340 [1:58:23<05:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:04,678 >> Initializing global attention on CLS token...\n",
            " 95% 7914/8340 [1:58:23<05:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:05,501 >> Initializing global attention on CLS token...\n",
            " 95% 7915/8340 [1:58:24<05:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:06,326 >> Initializing global attention on CLS token...\n",
            " 95% 7916/8340 [1:58:25<05:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:07,152 >> Initializing global attention on CLS token...\n",
            " 95% 7917/8340 [1:58:26<05:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:07,976 >> Initializing global attention on CLS token...\n",
            " 95% 7918/8340 [1:58:27<05:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:08,800 >> Initializing global attention on CLS token...\n",
            " 95% 7919/8340 [1:58:27<05:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:09,622 >> Initializing global attention on CLS token...\n",
            " 95% 7920/8340 [1:58:28<05:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:10,446 >> Initializing global attention on CLS token...\n",
            " 95% 7921/8340 [1:58:29<05:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:11,268 >> Initializing global attention on CLS token...\n",
            " 95% 7922/8340 [1:58:30<05:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:12,090 >> Initializing global attention on CLS token...\n",
            " 95% 7923/8340 [1:58:31<05:43,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:12,917 >> Initializing global attention on CLS token...\n",
            " 95% 7924/8340 [1:58:32<05:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:13,743 >> Initializing global attention on CLS token...\n",
            " 95% 7925/8340 [1:58:32<05:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:14,563 >> Initializing global attention on CLS token...\n",
            " 95% 7926/8340 [1:58:33<05:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:15,389 >> Initializing global attention on CLS token...\n",
            " 95% 7927/8340 [1:58:34<05:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:16,213 >> Initializing global attention on CLS token...\n",
            " 95% 7928/8340 [1:58:35<05:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:17,034 >> Initializing global attention on CLS token...\n",
            " 95% 7929/8340 [1:58:36<05:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:17,866 >> Initializing global attention on CLS token...\n",
            " 95% 7930/8340 [1:58:37<05:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:18,693 >> Initializing global attention on CLS token...\n",
            " 95% 7931/8340 [1:58:37<05:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:19,515 >> Initializing global attention on CLS token...\n",
            " 95% 7932/8340 [1:58:38<05:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:20,342 >> Initializing global attention on CLS token...\n",
            " 95% 7933/8340 [1:58:39<05:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:21,167 >> Initializing global attention on CLS token...\n",
            " 95% 7934/8340 [1:58:40<05:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:21,991 >> Initializing global attention on CLS token...\n",
            " 95% 7935/8340 [1:58:41<05:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:22,812 >> Initializing global attention on CLS token...\n",
            " 95% 7936/8340 [1:58:41<05:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:23,637 >> Initializing global attention on CLS token...\n",
            " 95% 7937/8340 [1:58:42<05:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:24,461 >> Initializing global attention on CLS token...\n",
            " 95% 7938/8340 [1:58:43<05:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:25,291 >> Initializing global attention on CLS token...\n",
            " 95% 7939/8340 [1:58:44<05:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:26,118 >> Initializing global attention on CLS token...\n",
            " 95% 7940/8340 [1:58:45<05:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:26,948 >> Initializing global attention on CLS token...\n",
            " 95% 7941/8340 [1:58:46<05:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:27,773 >> Initializing global attention on CLS token...\n",
            " 95% 7942/8340 [1:58:46<05:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:28,598 >> Initializing global attention on CLS token...\n",
            " 95% 7943/8340 [1:58:47<05:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:29,422 >> Initializing global attention on CLS token...\n",
            " 95% 7944/8340 [1:58:48<05:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:30,247 >> Initializing global attention on CLS token...\n",
            " 95% 7945/8340 [1:58:49<05:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:31,073 >> Initializing global attention on CLS token...\n",
            " 95% 7946/8340 [1:58:50<05:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:31,894 >> Initializing global attention on CLS token...\n",
            " 95% 7947/8340 [1:58:51<05:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:32,722 >> Initializing global attention on CLS token...\n",
            " 95% 7948/8340 [1:58:51<05:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:33,547 >> Initializing global attention on CLS token...\n",
            " 95% 7949/8340 [1:58:52<05:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:34,367 >> Initializing global attention on CLS token...\n",
            " 95% 7950/8340 [1:58:53<05:20,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:35,189 >> Initializing global attention on CLS token...\n",
            " 95% 7951/8340 [1:58:54<05:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:36,018 >> Initializing global attention on CLS token...\n",
            " 95% 7952/8340 [1:58:55<05:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:36,847 >> Initializing global attention on CLS token...\n",
            " 95% 7953/8340 [1:58:56<05:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:37,670 >> Initializing global attention on CLS token...\n",
            " 95% 7954/8340 [1:58:56<05:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:38,500 >> Initializing global attention on CLS token...\n",
            " 95% 7955/8340 [1:58:57<05:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:39,323 >> Initializing global attention on CLS token...\n",
            " 95% 7956/8340 [1:58:58<05:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:40,148 >> Initializing global attention on CLS token...\n",
            " 95% 7957/8340 [1:58:59<05:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:40,980 >> Initializing global attention on CLS token...\n",
            " 95% 7958/8340 [1:59:00<05:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:41,806 >> Initializing global attention on CLS token...\n",
            " 95% 7959/8340 [1:59:00<05:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:42,630 >> Initializing global attention on CLS token...\n",
            " 95% 7960/8340 [1:59:01<05:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:43,456 >> Initializing global attention on CLS token...\n",
            " 95% 7961/8340 [1:59:02<05:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:44,282 >> Initializing global attention on CLS token...\n",
            " 95% 7962/8340 [1:59:03<05:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:45,110 >> Initializing global attention on CLS token...\n",
            " 95% 7963/8340 [1:59:04<05:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:45,931 >> Initializing global attention on CLS token...\n",
            " 95% 7964/8340 [1:59:05<05:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:46,757 >> Initializing global attention on CLS token...\n",
            " 96% 7965/8340 [1:59:05<05:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:47,581 >> Initializing global attention on CLS token...\n",
            " 96% 7966/8340 [1:59:06<05:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:48,410 >> Initializing global attention on CLS token...\n",
            " 96% 7967/8340 [1:59:07<05:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:49,239 >> Initializing global attention on CLS token...\n",
            " 96% 7968/8340 [1:59:08<05:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:50,067 >> Initializing global attention on CLS token...\n",
            " 96% 7969/8340 [1:59:09<05:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:50,890 >> Initializing global attention on CLS token...\n",
            " 96% 7970/8340 [1:59:10<05:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:51,715 >> Initializing global attention on CLS token...\n",
            " 96% 7971/8340 [1:59:10<05:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:52,536 >> Initializing global attention on CLS token...\n",
            " 96% 7972/8340 [1:59:11<05:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:53,360 >> Initializing global attention on CLS token...\n",
            " 96% 7973/8340 [1:59:12<05:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:54,185 >> Initializing global attention on CLS token...\n",
            " 96% 7974/8340 [1:59:13<05:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:55,009 >> Initializing global attention on CLS token...\n",
            " 96% 7975/8340 [1:59:14<05:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:55,836 >> Initializing global attention on CLS token...\n",
            " 96% 7976/8340 [1:59:14<05:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:56,660 >> Initializing global attention on CLS token...\n",
            " 96% 7977/8340 [1:59:15<04:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:57,483 >> Initializing global attention on CLS token...\n",
            " 96% 7978/8340 [1:59:16<04:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:58,307 >> Initializing global attention on CLS token...\n",
            " 96% 7979/8340 [1:59:17<04:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:59,132 >> Initializing global attention on CLS token...\n",
            " 96% 7980/8340 [1:59:18<04:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 16:59:59,955 >> Initializing global attention on CLS token...\n",
            " 96% 7981/8340 [1:59:19<04:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:00,783 >> Initializing global attention on CLS token...\n",
            " 96% 7982/8340 [1:59:19<04:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:01,605 >> Initializing global attention on CLS token...\n",
            " 96% 7983/8340 [1:59:20<04:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:02,432 >> Initializing global attention on CLS token...\n",
            " 96% 7984/8340 [1:59:21<04:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:03,256 >> Initializing global attention on CLS token...\n",
            " 96% 7985/8340 [1:59:22<04:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:04,081 >> Initializing global attention on CLS token...\n",
            " 96% 7986/8340 [1:59:23<04:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:04,905 >> Initializing global attention on CLS token...\n",
            " 96% 7987/8340 [1:59:24<04:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:05,731 >> Initializing global attention on CLS token...\n",
            " 96% 7988/8340 [1:59:24<04:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:06,555 >> Initializing global attention on CLS token...\n",
            " 96% 7989/8340 [1:59:25<04:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:07,381 >> Initializing global attention on CLS token...\n",
            " 96% 7990/8340 [1:59:26<04:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:08,203 >> Initializing global attention on CLS token...\n",
            " 96% 7991/8340 [1:59:27<04:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:09,031 >> Initializing global attention on CLS token...\n",
            " 96% 7992/8340 [1:59:28<04:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:09,856 >> Initializing global attention on CLS token...\n",
            " 96% 7993/8340 [1:59:29<04:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:10,684 >> Initializing global attention on CLS token...\n",
            " 96% 7994/8340 [1:59:29<04:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:11,508 >> Initializing global attention on CLS token...\n",
            " 96% 7995/8340 [1:59:30<04:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:12,332 >> Initializing global attention on CLS token...\n",
            " 96% 7996/8340 [1:59:31<04:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:13,156 >> Initializing global attention on CLS token...\n",
            " 96% 7997/8340 [1:59:32<04:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:13,981 >> Initializing global attention on CLS token...\n",
            " 96% 7998/8340 [1:59:33<04:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:14,807 >> Initializing global attention on CLS token...\n",
            " 96% 7999/8340 [1:59:33<04:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:15,632 >> Initializing global attention on CLS token...\n",
            "{'loss': 0.0207, 'learning_rate': 1.2446043165467626e-06, 'epoch': 9.59}\n",
            " 96% 8000/8340 [1:59:34<04:53,  1.16it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:16,588 >> Initializing global attention on CLS token...\n",
            " 96% 8001/8340 [1:59:35<04:49,  1.17it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:17,414 >> Initializing global attention on CLS token...\n",
            " 96% 8002/8340 [1:59:36<04:45,  1.18it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:18,239 >> Initializing global attention on CLS token...\n",
            " 96% 8003/8340 [1:59:37<04:42,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:19,061 >> Initializing global attention on CLS token...\n",
            " 96% 8004/8340 [1:59:38<04:39,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:19,882 >> Initializing global attention on CLS token...\n",
            " 96% 8005/8340 [1:59:39<04:38,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:20,708 >> Initializing global attention on CLS token...\n",
            " 96% 8006/8340 [1:59:39<04:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:21,530 >> Initializing global attention on CLS token...\n",
            " 96% 8007/8340 [1:59:40<04:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:22,354 >> Initializing global attention on CLS token...\n",
            " 96% 8008/8340 [1:59:41<04:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:23,181 >> Initializing global attention on CLS token...\n",
            " 96% 8009/8340 [1:59:42<04:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:24,009 >> Initializing global attention on CLS token...\n",
            " 96% 8010/8340 [1:59:43<04:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:24,837 >> Initializing global attention on CLS token...\n",
            " 96% 8011/8340 [1:59:44<04:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:25,664 >> Initializing global attention on CLS token...\n",
            " 96% 8012/8340 [1:59:44<04:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:26,488 >> Initializing global attention on CLS token...\n",
            " 96% 8013/8340 [1:59:45<04:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:27,315 >> Initializing global attention on CLS token...\n",
            " 96% 8014/8340 [1:59:46<04:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:28,137 >> Initializing global attention on CLS token...\n",
            " 96% 8015/8340 [1:59:47<04:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:28,963 >> Initializing global attention on CLS token...\n",
            " 96% 8016/8340 [1:59:48<04:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:29,786 >> Initializing global attention on CLS token...\n",
            " 96% 8017/8340 [1:59:48<04:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:30,610 >> Initializing global attention on CLS token...\n",
            " 96% 8018/8340 [1:59:49<04:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:31,430 >> Initializing global attention on CLS token...\n",
            " 96% 8019/8340 [1:59:50<04:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:32,261 >> Initializing global attention on CLS token...\n",
            " 96% 8020/8340 [1:59:51<04:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:33,085 >> Initializing global attention on CLS token...\n",
            " 96% 8021/8340 [1:59:52<04:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:33,911 >> Initializing global attention on CLS token...\n",
            " 96% 8022/8340 [1:59:53<04:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:34,737 >> Initializing global attention on CLS token...\n",
            " 96% 8023/8340 [1:59:53<04:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:35,562 >> Initializing global attention on CLS token...\n",
            " 96% 8024/8340 [1:59:54<04:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:36,387 >> Initializing global attention on CLS token...\n",
            " 96% 8025/8340 [1:59:55<04:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:37,210 >> Initializing global attention on CLS token...\n",
            " 96% 8026/8340 [1:59:56<04:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:38,029 >> Initializing global attention on CLS token...\n",
            " 96% 8027/8340 [1:59:57<04:17,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:38,851 >> Initializing global attention on CLS token...\n",
            " 96% 8028/8340 [1:59:58<04:16,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:39,673 >> Initializing global attention on CLS token...\n",
            " 96% 8029/8340 [1:59:58<04:15,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:40,494 >> Initializing global attention on CLS token...\n",
            " 96% 8030/8340 [1:59:59<04:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:41,322 >> Initializing global attention on CLS token...\n",
            " 96% 8031/8340 [2:00:00<04:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:42,146 >> Initializing global attention on CLS token...\n",
            " 96% 8032/8340 [2:00:01<04:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:42,972 >> Initializing global attention on CLS token...\n",
            " 96% 8033/8340 [2:00:02<04:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:43,803 >> Initializing global attention on CLS token...\n",
            " 96% 8034/8340 [2:00:02<04:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:44,626 >> Initializing global attention on CLS token...\n",
            " 96% 8035/8340 [2:00:03<04:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:45,451 >> Initializing global attention on CLS token...\n",
            " 96% 8036/8340 [2:00:04<04:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:46,276 >> Initializing global attention on CLS token...\n",
            " 96% 8037/8340 [2:00:05<04:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:47,100 >> Initializing global attention on CLS token...\n",
            " 96% 8038/8340 [2:00:06<04:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:47,925 >> Initializing global attention on CLS token...\n",
            " 96% 8039/8340 [2:00:07<04:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:48,755 >> Initializing global attention on CLS token...\n",
            " 96% 8040/8340 [2:00:07<04:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:49,583 >> Initializing global attention on CLS token...\n",
            " 96% 8041/8340 [2:00:08<04:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:50,408 >> Initializing global attention on CLS token...\n",
            " 96% 8042/8340 [2:00:09<04:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:51,233 >> Initializing global attention on CLS token...\n",
            " 96% 8043/8340 [2:00:10<04:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:52,056 >> Initializing global attention on CLS token...\n",
            " 96% 8044/8340 [2:00:11<04:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:52,880 >> Initializing global attention on CLS token...\n",
            " 96% 8045/8340 [2:00:12<04:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:53,707 >> Initializing global attention on CLS token...\n",
            " 96% 8046/8340 [2:00:12<04:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:54,533 >> Initializing global attention on CLS token...\n",
            " 96% 8047/8340 [2:00:13<04:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:55,356 >> Initializing global attention on CLS token...\n",
            " 96% 8048/8340 [2:00:14<04:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:56,188 >> Initializing global attention on CLS token...\n",
            " 97% 8049/8340 [2:00:15<04:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:57,013 >> Initializing global attention on CLS token...\n",
            " 97% 8050/8340 [2:00:16<03:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:57,839 >> Initializing global attention on CLS token...\n",
            " 97% 8051/8340 [2:00:17<03:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:58,662 >> Initializing global attention on CLS token...\n",
            " 97% 8052/8340 [2:00:17<03:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:00:59,486 >> Initializing global attention on CLS token...\n",
            " 97% 8053/8340 [2:00:18<03:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:00,315 >> Initializing global attention on CLS token...\n",
            " 97% 8054/8340 [2:00:19<03:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:01,138 >> Initializing global attention on CLS token...\n",
            " 97% 8055/8340 [2:00:20<03:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:01,964 >> Initializing global attention on CLS token...\n",
            " 97% 8056/8340 [2:00:21<03:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:02,794 >> Initializing global attention on CLS token...\n",
            " 97% 8057/8340 [2:00:21<03:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:03,624 >> Initializing global attention on CLS token...\n",
            " 97% 8058/8340 [2:00:22<03:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:04,452 >> Initializing global attention on CLS token...\n",
            " 97% 8059/8340 [2:00:23<03:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:05,276 >> Initializing global attention on CLS token...\n",
            " 97% 8060/8340 [2:00:24<03:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:06,103 >> Initializing global attention on CLS token...\n",
            " 97% 8061/8340 [2:00:25<03:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:06,929 >> Initializing global attention on CLS token...\n",
            " 97% 8062/8340 [2:00:26<03:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:07,754 >> Initializing global attention on CLS token...\n",
            " 97% 8063/8340 [2:00:26<03:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:08,594 >> Initializing global attention on CLS token...\n",
            " 97% 8064/8340 [2:00:27<03:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:09,418 >> Initializing global attention on CLS token...\n",
            " 97% 8065/8340 [2:00:28<03:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:10,243 >> Initializing global attention on CLS token...\n",
            " 97% 8066/8340 [2:00:29<03:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:11,073 >> Initializing global attention on CLS token...\n",
            " 97% 8067/8340 [2:00:30<03:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:11,896 >> Initializing global attention on CLS token...\n",
            " 97% 8068/8340 [2:00:31<03:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:12,721 >> Initializing global attention on CLS token...\n",
            " 97% 8069/8340 [2:00:31<03:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:13,549 >> Initializing global attention on CLS token...\n",
            " 97% 8070/8340 [2:00:32<03:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:14,378 >> Initializing global attention on CLS token...\n",
            " 97% 8071/8340 [2:00:33<03:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:15,203 >> Initializing global attention on CLS token...\n",
            " 97% 8072/8340 [2:00:34<03:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:16,028 >> Initializing global attention on CLS token...\n",
            " 97% 8073/8340 [2:00:35<03:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:16,856 >> Initializing global attention on CLS token...\n",
            " 97% 8074/8340 [2:00:36<03:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:17,680 >> Initializing global attention on CLS token...\n",
            " 97% 8075/8340 [2:00:36<03:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:18,508 >> Initializing global attention on CLS token...\n",
            " 97% 8076/8340 [2:00:37<03:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:19,333 >> Initializing global attention on CLS token...\n",
            " 97% 8077/8340 [2:00:38<03:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:20,161 >> Initializing global attention on CLS token...\n",
            " 97% 8078/8340 [2:00:39<03:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:20,987 >> Initializing global attention on CLS token...\n",
            " 97% 8079/8340 [2:00:40<03:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:21,813 >> Initializing global attention on CLS token...\n",
            " 97% 8080/8340 [2:00:40<03:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:22,638 >> Initializing global attention on CLS token...\n",
            " 97% 8081/8340 [2:00:41<03:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:23,461 >> Initializing global attention on CLS token...\n",
            " 97% 8082/8340 [2:00:42<03:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:24,284 >> Initializing global attention on CLS token...\n",
            " 97% 8083/8340 [2:00:43<03:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:25,107 >> Initializing global attention on CLS token...\n",
            " 97% 8084/8340 [2:00:44<03:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:25,934 >> Initializing global attention on CLS token...\n",
            " 97% 8085/8340 [2:00:45<03:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:26,757 >> Initializing global attention on CLS token...\n",
            " 97% 8086/8340 [2:00:45<03:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:27,583 >> Initializing global attention on CLS token...\n",
            " 97% 8087/8340 [2:00:46<03:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:28,414 >> Initializing global attention on CLS token...\n",
            " 97% 8088/8340 [2:00:47<03:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:29,240 >> Initializing global attention on CLS token...\n",
            " 97% 8089/8340 [2:00:48<03:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:30,065 >> Initializing global attention on CLS token...\n",
            " 97% 8090/8340 [2:00:49<03:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:30,891 >> Initializing global attention on CLS token...\n",
            " 97% 8091/8340 [2:00:50<03:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:31,719 >> Initializing global attention on CLS token...\n",
            " 97% 8092/8340 [2:00:50<03:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:32,547 >> Initializing global attention on CLS token...\n",
            " 97% 8093/8340 [2:00:51<03:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:33,375 >> Initializing global attention on CLS token...\n",
            " 97% 8094/8340 [2:00:52<03:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:34,201 >> Initializing global attention on CLS token...\n",
            " 97% 8095/8340 [2:00:53<03:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:35,030 >> Initializing global attention on CLS token...\n",
            " 97% 8096/8340 [2:00:54<03:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:35,857 >> Initializing global attention on CLS token...\n",
            " 97% 8097/8340 [2:00:55<03:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:36,682 >> Initializing global attention on CLS token...\n",
            " 97% 8098/8340 [2:00:55<03:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:37,505 >> Initializing global attention on CLS token...\n",
            " 97% 8099/8340 [2:00:56<03:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:38,330 >> Initializing global attention on CLS token...\n",
            " 97% 8100/8340 [2:00:57<03:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:39,155 >> Initializing global attention on CLS token...\n",
            " 97% 8101/8340 [2:00:58<03:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:39,986 >> Initializing global attention on CLS token...\n",
            " 97% 8102/8340 [2:00:59<03:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:40,811 >> Initializing global attention on CLS token...\n",
            " 97% 8103/8340 [2:00:59<03:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:41,637 >> Initializing global attention on CLS token...\n",
            " 97% 8104/8340 [2:01:00<03:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:42,464 >> Initializing global attention on CLS token...\n",
            " 97% 8105/8340 [2:01:01<03:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:43,286 >> Initializing global attention on CLS token...\n",
            " 97% 8106/8340 [2:01:02<03:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:44,114 >> Initializing global attention on CLS token...\n",
            " 97% 8107/8340 [2:01:03<03:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:44,940 >> Initializing global attention on CLS token...\n",
            " 97% 8108/8340 [2:01:04<03:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:45,770 >> Initializing global attention on CLS token...\n",
            " 97% 8109/8340 [2:01:04<03:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:46,597 >> Initializing global attention on CLS token...\n",
            " 97% 8110/8340 [2:01:05<03:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:47,424 >> Initializing global attention on CLS token...\n",
            " 97% 8111/8340 [2:01:06<03:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:48,251 >> Initializing global attention on CLS token...\n",
            " 97% 8112/8340 [2:01:07<03:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:49,081 >> Initializing global attention on CLS token...\n",
            " 97% 8113/8340 [2:01:08<03:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:49,931 >> Initializing global attention on CLS token...\n",
            " 97% 8114/8340 [2:01:09<03:09,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:50,776 >> Initializing global attention on CLS token...\n",
            " 97% 8115/8340 [2:01:09<03:08,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:51,605 >> Initializing global attention on CLS token...\n",
            " 97% 8116/8340 [2:01:10<03:06,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:52,430 >> Initializing global attention on CLS token...\n",
            " 97% 8117/8340 [2:01:11<03:05,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:53,259 >> Initializing global attention on CLS token...\n",
            " 97% 8118/8340 [2:01:12<03:04,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:54,087 >> Initializing global attention on CLS token...\n",
            " 97% 8119/8340 [2:01:13<03:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:54,914 >> Initializing global attention on CLS token...\n",
            " 97% 8120/8340 [2:01:14<03:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:55,739 >> Initializing global attention on CLS token...\n",
            " 97% 8121/8340 [2:01:14<03:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:56,562 >> Initializing global attention on CLS token...\n",
            " 97% 8122/8340 [2:01:15<03:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:57,387 >> Initializing global attention on CLS token...\n",
            " 97% 8123/8340 [2:01:16<02:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:58,214 >> Initializing global attention on CLS token...\n",
            " 97% 8124/8340 [2:01:17<02:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:59,038 >> Initializing global attention on CLS token...\n",
            " 97% 8125/8340 [2:01:18<02:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:01:59,864 >> Initializing global attention on CLS token...\n",
            " 97% 8126/8340 [2:01:19<02:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:00,690 >> Initializing global attention on CLS token...\n",
            " 97% 8127/8340 [2:01:19<02:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:01,516 >> Initializing global attention on CLS token...\n",
            " 97% 8128/8340 [2:01:20<02:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:02,343 >> Initializing global attention on CLS token...\n",
            " 97% 8129/8340 [2:01:21<02:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:03,167 >> Initializing global attention on CLS token...\n",
            " 97% 8130/8340 [2:01:22<02:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:03,992 >> Initializing global attention on CLS token...\n",
            " 97% 8131/8340 [2:01:23<02:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:04,818 >> Initializing global attention on CLS token...\n",
            " 98% 8132/8340 [2:01:23<02:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:05,643 >> Initializing global attention on CLS token...\n",
            " 98% 8133/8340 [2:01:24<02:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:06,469 >> Initializing global attention on CLS token...\n",
            " 98% 8134/8340 [2:01:25<02:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:07,294 >> Initializing global attention on CLS token...\n",
            " 98% 8135/8340 [2:01:26<02:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:08,118 >> Initializing global attention on CLS token...\n",
            " 98% 8136/8340 [2:01:27<02:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:08,943 >> Initializing global attention on CLS token...\n",
            " 98% 8137/8340 [2:01:28<02:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:09,769 >> Initializing global attention on CLS token...\n",
            " 98% 8138/8340 [2:01:28<02:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:10,593 >> Initializing global attention on CLS token...\n",
            " 98% 8139/8340 [2:01:29<02:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:11,420 >> Initializing global attention on CLS token...\n",
            " 98% 8140/8340 [2:01:30<02:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:12,247 >> Initializing global attention on CLS token...\n",
            " 98% 8141/8340 [2:01:31<02:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:13,068 >> Initializing global attention on CLS token...\n",
            " 98% 8142/8340 [2:01:32<02:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:13,893 >> Initializing global attention on CLS token...\n",
            " 98% 8143/8340 [2:01:33<02:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:14,718 >> Initializing global attention on CLS token...\n",
            " 98% 8144/8340 [2:01:33<02:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:15,545 >> Initializing global attention on CLS token...\n",
            " 98% 8145/8340 [2:01:34<02:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:16,367 >> Initializing global attention on CLS token...\n",
            " 98% 8146/8340 [2:01:35<02:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:17,192 >> Initializing global attention on CLS token...\n",
            " 98% 8147/8340 [2:01:36<02:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:18,015 >> Initializing global attention on CLS token...\n",
            " 98% 8148/8340 [2:01:37<02:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:18,842 >> Initializing global attention on CLS token...\n",
            " 98% 8149/8340 [2:01:38<02:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:19,666 >> Initializing global attention on CLS token...\n",
            " 98% 8150/8340 [2:01:38<02:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:20,496 >> Initializing global attention on CLS token...\n",
            " 98% 8151/8340 [2:01:39<02:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:21,322 >> Initializing global attention on CLS token...\n",
            " 98% 8152/8340 [2:01:40<02:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:22,147 >> Initializing global attention on CLS token...\n",
            " 98% 8153/8340 [2:01:41<02:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:22,973 >> Initializing global attention on CLS token...\n",
            " 98% 8154/8340 [2:01:42<02:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:23,795 >> Initializing global attention on CLS token...\n",
            " 98% 8155/8340 [2:01:42<02:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:24,619 >> Initializing global attention on CLS token...\n",
            " 98% 8156/8340 [2:01:43<02:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:25,447 >> Initializing global attention on CLS token...\n",
            " 98% 8157/8340 [2:01:44<02:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:26,268 >> Initializing global attention on CLS token...\n",
            " 98% 8158/8340 [2:01:45<02:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:27,097 >> Initializing global attention on CLS token...\n",
            " 98% 8159/8340 [2:01:46<02:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:27,920 >> Initializing global attention on CLS token...\n",
            " 98% 8160/8340 [2:01:47<02:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:28,747 >> Initializing global attention on CLS token...\n",
            " 98% 8161/8340 [2:01:47<02:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:29,569 >> Initializing global attention on CLS token...\n",
            " 98% 8162/8340 [2:01:48<02:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:30,394 >> Initializing global attention on CLS token...\n",
            " 98% 8163/8340 [2:01:49<02:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:31,217 >> Initializing global attention on CLS token...\n",
            " 98% 8164/8340 [2:01:50<02:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:32,042 >> Initializing global attention on CLS token...\n",
            " 98% 8165/8340 [2:01:51<02:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:32,865 >> Initializing global attention on CLS token...\n",
            " 98% 8166/8340 [2:01:52<02:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:33,690 >> Initializing global attention on CLS token...\n",
            " 98% 8167/8340 [2:01:52<02:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:34,515 >> Initializing global attention on CLS token...\n",
            " 98% 8168/8340 [2:01:53<02:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:35,336 >> Initializing global attention on CLS token...\n",
            " 98% 8169/8340 [2:01:54<02:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:36,159 >> Initializing global attention on CLS token...\n",
            " 98% 8170/8340 [2:01:55<02:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:36,982 >> Initializing global attention on CLS token...\n",
            " 98% 8171/8340 [2:01:56<02:19,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:37,809 >> Initializing global attention on CLS token...\n",
            " 98% 8172/8340 [2:01:56<02:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:38,634 >> Initializing global attention on CLS token...\n",
            " 98% 8173/8340 [2:01:57<02:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:39,461 >> Initializing global attention on CLS token...\n",
            " 98% 8174/8340 [2:01:58<02:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:40,285 >> Initializing global attention on CLS token...\n",
            " 98% 8175/8340 [2:01:59<02:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:41,106 >> Initializing global attention on CLS token...\n",
            " 98% 8176/8340 [2:02:00<02:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:41,932 >> Initializing global attention on CLS token...\n",
            " 98% 8177/8340 [2:02:01<02:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:42,760 >> Initializing global attention on CLS token...\n",
            " 98% 8178/8340 [2:02:01<02:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:43,582 >> Initializing global attention on CLS token...\n",
            " 98% 8179/8340 [2:02:02<02:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:44,404 >> Initializing global attention on CLS token...\n",
            " 98% 8180/8340 [2:02:03<02:11,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:45,224 >> Initializing global attention on CLS token...\n",
            " 98% 8181/8340 [2:02:04<02:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:46,051 >> Initializing global attention on CLS token...\n",
            " 98% 8182/8340 [2:02:05<02:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:46,875 >> Initializing global attention on CLS token...\n",
            " 98% 8183/8340 [2:02:06<02:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:47,700 >> Initializing global attention on CLS token...\n",
            " 98% 8184/8340 [2:02:06<02:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:48,524 >> Initializing global attention on CLS token...\n",
            " 98% 8185/8340 [2:02:07<02:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:49,351 >> Initializing global attention on CLS token...\n",
            " 98% 8186/8340 [2:02:08<02:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:50,174 >> Initializing global attention on CLS token...\n",
            " 98% 8187/8340 [2:02:09<02:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:50,999 >> Initializing global attention on CLS token...\n",
            " 98% 8188/8340 [2:02:10<02:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:51,827 >> Initializing global attention on CLS token...\n",
            " 98% 8189/8340 [2:02:10<02:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:52,650 >> Initializing global attention on CLS token...\n",
            " 98% 8190/8340 [2:02:11<02:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:53,481 >> Initializing global attention on CLS token...\n",
            " 98% 8191/8340 [2:02:12<02:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:54,305 >> Initializing global attention on CLS token...\n",
            " 98% 8192/8340 [2:02:13<02:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:55,129 >> Initializing global attention on CLS token...\n",
            " 98% 8193/8340 [2:02:14<02:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:55,957 >> Initializing global attention on CLS token...\n",
            " 98% 8194/8340 [2:02:15<02:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:56,784 >> Initializing global attention on CLS token...\n",
            " 98% 8195/8340 [2:02:15<01:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:57,610 >> Initializing global attention on CLS token...\n",
            " 98% 8196/8340 [2:02:16<01:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:58,441 >> Initializing global attention on CLS token...\n",
            " 98% 8197/8340 [2:02:17<01:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:02:59,265 >> Initializing global attention on CLS token...\n",
            " 98% 8198/8340 [2:02:18<01:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:00,089 >> Initializing global attention on CLS token...\n",
            " 98% 8199/8340 [2:02:19<01:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:00,933 >> Initializing global attention on CLS token...\n",
            " 98% 8200/8340 [2:02:20<01:56,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:01,764 >> Initializing global attention on CLS token...\n",
            " 98% 8201/8340 [2:02:20<01:55,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:02,621 >> Initializing global attention on CLS token...\n",
            " 98% 8202/8340 [2:02:21<01:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:03,469 >> Initializing global attention on CLS token...\n",
            " 98% 8203/8340 [2:02:22<01:55,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:04,313 >> Initializing global attention on CLS token...\n",
            " 98% 8204/8340 [2:02:23<01:54,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:05,149 >> Initializing global attention on CLS token...\n",
            " 98% 8205/8340 [2:02:24<01:53,  1.19it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:05,974 >> Initializing global attention on CLS token...\n",
            " 98% 8206/8340 [2:02:25<01:51,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:06,797 >> Initializing global attention on CLS token...\n",
            " 98% 8207/8340 [2:02:25<01:50,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:07,626 >> Initializing global attention on CLS token...\n",
            " 98% 8208/8340 [2:02:26<01:49,  1.20it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:08,449 >> Initializing global attention on CLS token...\n",
            " 98% 8209/8340 [2:02:27<01:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:09,275 >> Initializing global attention on CLS token...\n",
            " 98% 8210/8340 [2:02:28<01:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:10,100 >> Initializing global attention on CLS token...\n",
            " 98% 8211/8340 [2:02:29<01:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:10,923 >> Initializing global attention on CLS token...\n",
            " 98% 8212/8340 [2:02:30<01:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:11,747 >> Initializing global attention on CLS token...\n",
            " 98% 8213/8340 [2:02:30<01:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:12,568 >> Initializing global attention on CLS token...\n",
            " 98% 8214/8340 [2:02:31<01:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:13,392 >> Initializing global attention on CLS token...\n",
            " 99% 8215/8340 [2:02:32<01:42,  1.22it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:14,212 >> Initializing global attention on CLS token...\n",
            " 99% 8216/8340 [2:02:33<01:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:15,036 >> Initializing global attention on CLS token...\n",
            " 99% 8217/8340 [2:02:34<01:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:15,867 >> Initializing global attention on CLS token...\n",
            " 99% 8218/8340 [2:02:35<01:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:16,691 >> Initializing global attention on CLS token...\n",
            " 99% 8219/8340 [2:02:35<01:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:17,518 >> Initializing global attention on CLS token...\n",
            " 99% 8220/8340 [2:02:36<01:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:18,342 >> Initializing global attention on CLS token...\n",
            " 99% 8221/8340 [2:02:37<01:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:19,169 >> Initializing global attention on CLS token...\n",
            " 99% 8222/8340 [2:02:38<01:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:19,994 >> Initializing global attention on CLS token...\n",
            " 99% 8223/8340 [2:02:39<01:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:20,816 >> Initializing global attention on CLS token...\n",
            " 99% 8224/8340 [2:02:39<01:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:21,647 >> Initializing global attention on CLS token...\n",
            " 99% 8225/8340 [2:02:40<01:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:22,466 >> Initializing global attention on CLS token...\n",
            " 99% 8226/8340 [2:02:41<01:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:23,289 >> Initializing global attention on CLS token...\n",
            " 99% 8227/8340 [2:02:42<01:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:24,121 >> Initializing global attention on CLS token...\n",
            " 99% 8228/8340 [2:02:43<01:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:24,945 >> Initializing global attention on CLS token...\n",
            " 99% 8229/8340 [2:02:44<01:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:25,769 >> Initializing global attention on CLS token...\n",
            " 99% 8230/8340 [2:02:44<01:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:26,591 >> Initializing global attention on CLS token...\n",
            " 99% 8231/8340 [2:02:45<01:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:27,413 >> Initializing global attention on CLS token...\n",
            " 99% 8232/8340 [2:02:46<01:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:28,239 >> Initializing global attention on CLS token...\n",
            " 99% 8233/8340 [2:02:47<01:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:29,066 >> Initializing global attention on CLS token...\n",
            " 99% 8234/8340 [2:02:48<01:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:29,889 >> Initializing global attention on CLS token...\n",
            " 99% 8235/8340 [2:02:49<01:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:30,713 >> Initializing global attention on CLS token...\n",
            " 99% 8236/8340 [2:02:49<01:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:31,537 >> Initializing global attention on CLS token...\n",
            " 99% 8237/8340 [2:02:50<01:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:32,363 >> Initializing global attention on CLS token...\n",
            " 99% 8238/8340 [2:02:51<01:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:33,190 >> Initializing global attention on CLS token...\n",
            " 99% 8239/8340 [2:02:52<01:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:34,018 >> Initializing global attention on CLS token...\n",
            " 99% 8240/8340 [2:02:53<01:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:34,843 >> Initializing global attention on CLS token...\n",
            " 99% 8241/8340 [2:02:54<01:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:35,665 >> Initializing global attention on CLS token...\n",
            " 99% 8242/8340 [2:02:54<01:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:36,494 >> Initializing global attention on CLS token...\n",
            " 99% 8243/8340 [2:02:55<01:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:37,319 >> Initializing global attention on CLS token...\n",
            " 99% 8244/8340 [2:02:56<01:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:38,142 >> Initializing global attention on CLS token...\n",
            " 99% 8245/8340 [2:02:57<01:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:38,965 >> Initializing global attention on CLS token...\n",
            " 99% 8246/8340 [2:02:58<01:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:39,789 >> Initializing global attention on CLS token...\n",
            " 99% 8247/8340 [2:02:58<01:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:40,611 >> Initializing global attention on CLS token...\n",
            " 99% 8248/8340 [2:02:59<01:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:41,441 >> Initializing global attention on CLS token...\n",
            " 99% 8249/8340 [2:03:00<01:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:42,266 >> Initializing global attention on CLS token...\n",
            " 99% 8250/8340 [2:03:01<01:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:43,090 >> Initializing global attention on CLS token...\n",
            " 99% 8251/8340 [2:03:02<01:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:43,916 >> Initializing global attention on CLS token...\n",
            " 99% 8252/8340 [2:03:03<01:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:44,739 >> Initializing global attention on CLS token...\n",
            " 99% 8253/8340 [2:03:03<01:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:45,569 >> Initializing global attention on CLS token...\n",
            " 99% 8254/8340 [2:03:04<01:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:46,393 >> Initializing global attention on CLS token...\n",
            " 99% 8255/8340 [2:03:05<01:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:47,217 >> Initializing global attention on CLS token...\n",
            " 99% 8256/8340 [2:03:06<01:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:48,043 >> Initializing global attention on CLS token...\n",
            " 99% 8257/8340 [2:03:07<01:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:48,870 >> Initializing global attention on CLS token...\n",
            " 99% 8258/8340 [2:03:08<01:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:49,694 >> Initializing global attention on CLS token...\n",
            " 99% 8259/8340 [2:03:08<01:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:50,519 >> Initializing global attention on CLS token...\n",
            " 99% 8260/8340 [2:03:09<01:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:51,339 >> Initializing global attention on CLS token...\n",
            " 99% 8261/8340 [2:03:10<01:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:52,165 >> Initializing global attention on CLS token...\n",
            " 99% 8262/8340 [2:03:11<01:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:52,987 >> Initializing global attention on CLS token...\n",
            " 99% 8263/8340 [2:03:12<01:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:53,812 >> Initializing global attention on CLS token...\n",
            " 99% 8264/8340 [2:03:12<01:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:54,634 >> Initializing global attention on CLS token...\n",
            " 99% 8265/8340 [2:03:13<01:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:55,464 >> Initializing global attention on CLS token...\n",
            " 99% 8266/8340 [2:03:14<01:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:56,288 >> Initializing global attention on CLS token...\n",
            " 99% 8267/8340 [2:03:15<01:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:57,115 >> Initializing global attention on CLS token...\n",
            " 99% 8268/8340 [2:03:16<00:59,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:57,942 >> Initializing global attention on CLS token...\n",
            " 99% 8269/8340 [2:03:17<00:58,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:58,766 >> Initializing global attention on CLS token...\n",
            " 99% 8270/8340 [2:03:17<00:57,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:03:59,591 >> Initializing global attention on CLS token...\n",
            " 99% 8271/8340 [2:03:18<00:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:00,416 >> Initializing global attention on CLS token...\n",
            " 99% 8272/8340 [2:03:19<00:56,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:01,237 >> Initializing global attention on CLS token...\n",
            " 99% 8273/8340 [2:03:20<00:55,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:02,062 >> Initializing global attention on CLS token...\n",
            " 99% 8274/8340 [2:03:21<00:54,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:02,886 >> Initializing global attention on CLS token...\n",
            " 99% 8275/8340 [2:03:22<00:53,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:03,711 >> Initializing global attention on CLS token...\n",
            " 99% 8276/8340 [2:03:22<00:52,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:04,534 >> Initializing global attention on CLS token...\n",
            " 99% 8277/8340 [2:03:23<00:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:05,365 >> Initializing global attention on CLS token...\n",
            " 99% 8278/8340 [2:03:24<00:51,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:06,190 >> Initializing global attention on CLS token...\n",
            " 99% 8279/8340 [2:03:25<00:50,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:07,015 >> Initializing global attention on CLS token...\n",
            " 99% 8280/8340 [2:03:26<00:49,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:07,852 >> Initializing global attention on CLS token...\n",
            " 99% 8281/8340 [2:03:27<00:48,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:08,672 >> Initializing global attention on CLS token...\n",
            " 99% 8282/8340 [2:03:27<00:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:09,493 >> Initializing global attention on CLS token...\n",
            " 99% 8283/8340 [2:03:28<00:47,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:10,320 >> Initializing global attention on CLS token...\n",
            " 99% 8284/8340 [2:03:29<00:46,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:11,145 >> Initializing global attention on CLS token...\n",
            " 99% 8285/8340 [2:03:30<00:45,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:11,974 >> Initializing global attention on CLS token...\n",
            " 99% 8286/8340 [2:03:31<00:44,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:12,798 >> Initializing global attention on CLS token...\n",
            " 99% 8287/8340 [2:03:31<00:43,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:13,624 >> Initializing global attention on CLS token...\n",
            " 99% 8288/8340 [2:03:32<00:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:14,448 >> Initializing global attention on CLS token...\n",
            " 99% 8289/8340 [2:03:33<00:42,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:15,271 >> Initializing global attention on CLS token...\n",
            " 99% 8290/8340 [2:03:34<00:41,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:16,097 >> Initializing global attention on CLS token...\n",
            " 99% 8291/8340 [2:03:35<00:40,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:16,924 >> Initializing global attention on CLS token...\n",
            " 99% 8292/8340 [2:03:36<00:39,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:17,752 >> Initializing global attention on CLS token...\n",
            " 99% 8293/8340 [2:03:36<00:38,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:18,578 >> Initializing global attention on CLS token...\n",
            " 99% 8294/8340 [2:03:37<00:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:19,400 >> Initializing global attention on CLS token...\n",
            " 99% 8295/8340 [2:03:38<00:37,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:20,225 >> Initializing global attention on CLS token...\n",
            " 99% 8296/8340 [2:03:39<00:36,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:21,052 >> Initializing global attention on CLS token...\n",
            " 99% 8297/8340 [2:03:40<00:35,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:21,877 >> Initializing global attention on CLS token...\n",
            " 99% 8298/8340 [2:03:41<00:34,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:22,705 >> Initializing global attention on CLS token...\n",
            "100% 8299/8340 [2:03:41<00:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:23,529 >> Initializing global attention on CLS token...\n",
            "100% 8300/8340 [2:03:42<00:33,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:24,356 >> Initializing global attention on CLS token...\n",
            "100% 8301/8340 [2:03:43<00:32,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:25,181 >> Initializing global attention on CLS token...\n",
            "100% 8302/8340 [2:03:44<00:31,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:26,008 >> Initializing global attention on CLS token...\n",
            "100% 8303/8340 [2:03:45<00:30,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:26,834 >> Initializing global attention on CLS token...\n",
            "100% 8304/8340 [2:03:45<00:29,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:27,656 >> Initializing global attention on CLS token...\n",
            "100% 8305/8340 [2:03:46<00:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:28,486 >> Initializing global attention on CLS token...\n",
            "100% 8306/8340 [2:03:47<00:28,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:29,310 >> Initializing global attention on CLS token...\n",
            "100% 8307/8340 [2:03:48<00:27,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:30,140 >> Initializing global attention on CLS token...\n",
            "100% 8308/8340 [2:03:49<00:26,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:30,966 >> Initializing global attention on CLS token...\n",
            "100% 8309/8340 [2:03:50<00:25,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:31,791 >> Initializing global attention on CLS token...\n",
            "100% 8310/8340 [2:03:50<00:24,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:32,619 >> Initializing global attention on CLS token...\n",
            "100% 8311/8340 [2:03:51<00:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:33,446 >> Initializing global attention on CLS token...\n",
            "100% 8312/8340 [2:03:52<00:23,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:34,272 >> Initializing global attention on CLS token...\n",
            "100% 8313/8340 [2:03:53<00:22,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:35,100 >> Initializing global attention on CLS token...\n",
            "100% 8314/8340 [2:03:54<00:21,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:35,925 >> Initializing global attention on CLS token...\n",
            "100% 8315/8340 [2:03:55<00:20,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:36,756 >> Initializing global attention on CLS token...\n",
            "100% 8316/8340 [2:03:55<00:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:37,582 >> Initializing global attention on CLS token...\n",
            "100% 8317/8340 [2:03:56<00:19,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:38,406 >> Initializing global attention on CLS token...\n",
            "100% 8318/8340 [2:03:57<00:18,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:39,232 >> Initializing global attention on CLS token...\n",
            "100% 8319/8340 [2:03:58<00:17,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:40,053 >> Initializing global attention on CLS token...\n",
            "100% 8320/8340 [2:03:59<00:16,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:40,878 >> Initializing global attention on CLS token...\n",
            "100% 8321/8340 [2:04:00<00:15,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:41,701 >> Initializing global attention on CLS token...\n",
            "100% 8322/8340 [2:04:00<00:14,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:42,528 >> Initializing global attention on CLS token...\n",
            "100% 8323/8340 [2:04:01<00:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:43,349 >> Initializing global attention on CLS token...\n",
            "100% 8324/8340 [2:04:02<00:13,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:44,176 >> Initializing global attention on CLS token...\n",
            "100% 8325/8340 [2:04:03<00:12,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:45,002 >> Initializing global attention on CLS token...\n",
            "100% 8326/8340 [2:04:04<00:11,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:45,830 >> Initializing global attention on CLS token...\n",
            "100% 8327/8340 [2:04:04<00:10,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:46,657 >> Initializing global attention on CLS token...\n",
            "100% 8328/8340 [2:04:05<00:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:47,484 >> Initializing global attention on CLS token...\n",
            "100% 8329/8340 [2:04:06<00:09,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:48,312 >> Initializing global attention on CLS token...\n",
            "100% 8330/8340 [2:04:07<00:08,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:49,138 >> Initializing global attention on CLS token...\n",
            "100% 8331/8340 [2:04:08<00:07,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:49,961 >> Initializing global attention on CLS token...\n",
            "100% 8332/8340 [2:04:09<00:06,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:50,786 >> Initializing global attention on CLS token...\n",
            "100% 8333/8340 [2:04:09<00:05,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:51,613 >> Initializing global attention on CLS token...\n",
            "100% 8334/8340 [2:04:10<00:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:52,439 >> Initializing global attention on CLS token...\n",
            "100% 8335/8340 [2:04:11<00:04,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:53,265 >> Initializing global attention on CLS token...\n",
            "100% 8336/8340 [2:04:12<00:03,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:54,087 >> Initializing global attention on CLS token...\n",
            "100% 8337/8340 [2:04:13<00:02,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:54,910 >> Initializing global attention on CLS token...\n",
            "100% 8338/8340 [2:04:14<00:01,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:55,739 >> Initializing global attention on CLS token...\n",
            "100% 8339/8340 [2:04:14<00:00,  1.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:04:56,547 >> Initializing global attention on CLS token...\n",
            "100% 8340/8340 [2:04:15<00:00,  1.49it/s][INFO|trainer.py:725] 2022-12-10 17:04:56,839 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 17:04:56,841 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 17:04:56,841 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 17:04:56,841 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:56,871 >> Initializing global attention on CLS token...\n",
            "\n",
            "  0% 0/234 [00:00<?, ?it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:57,118 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 2/234 [00:00<00:28,  8.14it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:57,364 >> Initializing global attention on CLS token...\n",
            "\n",
            "  1% 3/234 [00:00<00:40,  5.71it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:57,621 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 4/234 [00:00<00:47,  4.88it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:57,867 >> Initializing global attention on CLS token...\n",
            "\n",
            "  2% 5/234 [00:00<00:50,  4.56it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:58,114 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 6/234 [00:01<00:52,  4.38it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:58,360 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 7/234 [00:01<00:53,  4.26it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:58,614 >> Initializing global attention on CLS token...\n",
            "\n",
            "  3% 8/234 [00:01<00:54,  4.16it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:58,860 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 9/234 [00:01<00:54,  4.13it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:59,110 >> Initializing global attention on CLS token...\n",
            "\n",
            "  4% 10/234 [00:02<00:54,  4.11it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:59,354 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 11/234 [00:02<00:54,  4.09it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:59,600 >> Initializing global attention on CLS token...\n",
            "\n",
            "  5% 12/234 [00:02<00:54,  4.07it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:04:59,848 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 13/234 [00:02<00:54,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:00,097 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 14/234 [00:03<00:54,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:00,345 >> Initializing global attention on CLS token...\n",
            "\n",
            "  6% 15/234 [00:03<00:54,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:00,594 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 16/234 [00:03<00:53,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:00,845 >> Initializing global attention on CLS token...\n",
            "\n",
            "  7% 17/234 [00:03<00:53,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:01,091 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 18/234 [00:04<00:53,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:01,343 >> Initializing global attention on CLS token...\n",
            "\n",
            "  8% 19/234 [00:04<00:53,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:01,591 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 20/234 [00:04<00:53,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:01,839 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 21/234 [00:04<00:52,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:02,086 >> Initializing global attention on CLS token...\n",
            "\n",
            "  9% 22/234 [00:05<00:52,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:02,335 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 23/234 [00:05<00:52,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:02,580 >> Initializing global attention on CLS token...\n",
            "\n",
            " 10% 24/234 [00:05<00:51,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:02,836 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 25/234 [00:05<00:52,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:03,083 >> Initializing global attention on CLS token...\n",
            "\n",
            " 11% 26/234 [00:06<00:51,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:03,335 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 27/234 [00:06<00:51,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:03,581 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 28/234 [00:06<00:51,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:03,831 >> Initializing global attention on CLS token...\n",
            "\n",
            " 12% 29/234 [00:06<00:51,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:04,078 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 30/234 [00:07<00:50,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:04,324 >> Initializing global attention on CLS token...\n",
            "\n",
            " 13% 31/234 [00:07<00:50,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:04,576 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 32/234 [00:07<00:50,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:04,824 >> Initializing global attention on CLS token...\n",
            "\n",
            " 14% 33/234 [00:07<00:50,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:05,078 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 34/234 [00:08<00:50,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:05,324 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 35/234 [00:08<00:49,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:05,575 >> Initializing global attention on CLS token...\n",
            "\n",
            " 15% 36/234 [00:08<00:49,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:05,821 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 37/234 [00:08<00:48,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:06,070 >> Initializing global attention on CLS token...\n",
            "\n",
            " 16% 38/234 [00:09<00:48,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:06,313 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 39/234 [00:09<00:48,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:06,560 >> Initializing global attention on CLS token...\n",
            "\n",
            " 17% 40/234 [00:09<00:47,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:06,807 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 41/234 [00:09<00:47,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:07,055 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 42/234 [00:10<00:47,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:07,304 >> Initializing global attention on CLS token...\n",
            "\n",
            " 18% 43/234 [00:10<00:47,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:07,551 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 44/234 [00:10<00:47,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:07,818 >> Initializing global attention on CLS token...\n",
            "\n",
            " 19% 45/234 [00:10<00:47,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:08,066 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 46/234 [00:11<00:47,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:08,313 >> Initializing global attention on CLS token...\n",
            "\n",
            " 20% 47/234 [00:11<00:46,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:08,559 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 48/234 [00:11<00:46,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:08,810 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 49/234 [00:11<00:46,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:09,056 >> Initializing global attention on CLS token...\n",
            "\n",
            " 21% 50/234 [00:12<00:45,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:09,304 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 51/234 [00:12<00:45,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:09,551 >> Initializing global attention on CLS token...\n",
            "\n",
            " 22% 52/234 [00:12<00:45,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:09,799 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 53/234 [00:12<00:44,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:10,045 >> Initializing global attention on CLS token...\n",
            "\n",
            " 23% 54/234 [00:13<00:44,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:10,293 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 55/234 [00:13<00:44,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:10,545 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 56/234 [00:13<00:44,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:10,792 >> Initializing global attention on CLS token...\n",
            "\n",
            " 24% 57/234 [00:13<00:44,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:11,040 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 58/234 [00:14<00:43,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:11,289 >> Initializing global attention on CLS token...\n",
            "\n",
            " 25% 59/234 [00:14<00:43,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:11,542 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 60/234 [00:14<00:43,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:11,790 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 61/234 [00:14<00:43,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:12,038 >> Initializing global attention on CLS token...\n",
            "\n",
            " 26% 62/234 [00:15<00:42,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:12,285 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 63/234 [00:15<00:42,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:12,531 >> Initializing global attention on CLS token...\n",
            "\n",
            " 27% 64/234 [00:15<00:41,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:12,777 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 65/234 [00:15<00:41,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:13,028 >> Initializing global attention on CLS token...\n",
            "\n",
            " 28% 66/234 [00:16<00:41,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:13,271 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 67/234 [00:16<00:41,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:13,518 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 68/234 [00:16<00:41,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:13,765 >> Initializing global attention on CLS token...\n",
            "\n",
            " 29% 69/234 [00:16<00:40,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:14,012 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 70/234 [00:17<00:40,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:14,264 >> Initializing global attention on CLS token...\n",
            "\n",
            " 30% 71/234 [00:17<00:40,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:14,510 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 72/234 [00:17<00:40,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:14,761 >> Initializing global attention on CLS token...\n",
            "\n",
            " 31% 73/234 [00:17<00:40,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:15,007 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 74/234 [00:18<00:39,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:15,259 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 75/234 [00:18<00:39,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:15,505 >> Initializing global attention on CLS token...\n",
            "\n",
            " 32% 76/234 [00:18<00:39,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:15,756 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 77/234 [00:18<00:39,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:16,004 >> Initializing global attention on CLS token...\n",
            "\n",
            " 33% 78/234 [00:19<00:38,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:16,251 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 79/234 [00:19<00:38,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:16,502 >> Initializing global attention on CLS token...\n",
            "\n",
            " 34% 80/234 [00:19<00:38,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:16,756 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 81/234 [00:19<00:38,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:17,003 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 82/234 [00:20<00:37,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:17,250 >> Initializing global attention on CLS token...\n",
            "\n",
            " 35% 83/234 [00:20<00:37,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:17,497 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 84/234 [00:20<00:37,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:17,747 >> Initializing global attention on CLS token...\n",
            "\n",
            " 36% 85/234 [00:20<00:37,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:17,995 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 86/234 [00:21<00:36,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:18,240 >> Initializing global attention on CLS token...\n",
            "\n",
            " 37% 87/234 [00:21<00:36,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:18,487 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 88/234 [00:21<00:36,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:18,736 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 89/234 [00:21<00:35,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:18,984 >> Initializing global attention on CLS token...\n",
            "\n",
            " 38% 90/234 [00:22<00:35,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:19,231 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 91/234 [00:22<00:35,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:19,493 >> Initializing global attention on CLS token...\n",
            "\n",
            " 39% 92/234 [00:22<00:35,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:19,737 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 93/234 [00:22<00:35,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:19,985 >> Initializing global attention on CLS token...\n",
            "\n",
            " 40% 94/234 [00:23<00:34,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:20,240 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 95/234 [00:23<00:34,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:20,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 96/234 [00:23<00:34,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:20,735 >> Initializing global attention on CLS token...\n",
            "\n",
            " 41% 97/234 [00:23<00:34,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:20,984 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 98/234 [00:24<00:33,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:21,230 >> Initializing global attention on CLS token...\n",
            "\n",
            " 42% 99/234 [00:24<00:33,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:21,479 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 100/234 [00:24<00:33,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:21,729 >> Initializing global attention on CLS token...\n",
            "\n",
            " 43% 101/234 [00:24<00:33,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:21,975 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 102/234 [00:25<00:32,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:22,222 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 103/234 [00:25<00:32,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:22,468 >> Initializing global attention on CLS token...\n",
            "\n",
            " 44% 104/234 [00:25<00:32,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:22,714 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 105/234 [00:25<00:31,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:22,968 >> Initializing global attention on CLS token...\n",
            "\n",
            " 45% 106/234 [00:26<00:31,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:23,225 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 107/234 [00:26<00:31,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:23,472 >> Initializing global attention on CLS token...\n",
            "\n",
            " 46% 108/234 [00:26<00:31,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:23,721 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 109/234 [00:26<00:31,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:23,970 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 110/234 [00:27<00:30,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:24,220 >> Initializing global attention on CLS token...\n",
            "\n",
            " 47% 111/234 [00:27<00:30,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:24,468 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 112/234 [00:27<00:30,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:24,718 >> Initializing global attention on CLS token...\n",
            "\n",
            " 48% 113/234 [00:27<00:30,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:24,969 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 114/234 [00:28<00:29,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:25,217 >> Initializing global attention on CLS token...\n",
            "\n",
            " 49% 115/234 [00:28<00:29,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:25,466 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 116/234 [00:28<00:29,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:25,712 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 117/234 [00:28<00:29,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:25,974 >> Initializing global attention on CLS token...\n",
            "\n",
            " 50% 118/234 [00:29<00:29,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:26,217 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 119/234 [00:29<00:28,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:26,469 >> Initializing global attention on CLS token...\n",
            "\n",
            " 51% 120/234 [00:29<00:28,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:26,718 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 121/234 [00:29<00:28,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:26,974 >> Initializing global attention on CLS token...\n",
            "\n",
            " 52% 122/234 [00:30<00:28,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:27,220 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 123/234 [00:30<00:27,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:27,475 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 124/234 [00:30<00:27,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:27,721 >> Initializing global attention on CLS token...\n",
            "\n",
            " 53% 125/234 [00:30<00:27,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:27,970 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 126/234 [00:31<00:26,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:28,215 >> Initializing global attention on CLS token...\n",
            "\n",
            " 54% 127/234 [00:31<00:26,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:28,465 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 128/234 [00:31<00:26,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:28,716 >> Initializing global attention on CLS token...\n",
            "\n",
            " 55% 129/234 [00:31<00:26,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:28,963 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 130/234 [00:32<00:25,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:29,212 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 131/234 [00:32<00:25,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:29,464 >> Initializing global attention on CLS token...\n",
            "\n",
            " 56% 132/234 [00:32<00:25,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:29,712 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 133/234 [00:32<00:25,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:29,960 >> Initializing global attention on CLS token...\n",
            "\n",
            " 57% 134/234 [00:33<00:24,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:30,207 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 135/234 [00:33<00:24,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:30,455 >> Initializing global attention on CLS token...\n",
            "\n",
            " 58% 136/234 [00:33<00:24,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:30,702 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 137/234 [00:33<00:23,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:30,946 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 138/234 [00:34<00:23,  4.05it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:31,203 >> Initializing global attention on CLS token...\n",
            "\n",
            " 59% 139/234 [00:34<00:23,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:31,451 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 140/234 [00:34<00:23,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:31,698 >> Initializing global attention on CLS token...\n",
            "\n",
            " 60% 141/234 [00:34<00:23,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:31,946 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 142/234 [00:35<00:22,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:32,198 >> Initializing global attention on CLS token...\n",
            "\n",
            " 61% 143/234 [00:35<00:22,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:32,446 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 144/234 [00:35<00:22,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:32,697 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 145/234 [00:35<00:22,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:32,961 >> Initializing global attention on CLS token...\n",
            "\n",
            " 62% 146/234 [00:36<00:22,  3.93it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:33,212 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 147/234 [00:36<00:22,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:33,459 >> Initializing global attention on CLS token...\n",
            "\n",
            " 63% 148/234 [00:36<00:21,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:33,722 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 149/234 [00:36<00:21,  3.92it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:33,971 >> Initializing global attention on CLS token...\n",
            "\n",
            " 64% 150/234 [00:37<00:21,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:34,222 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 151/234 [00:37<00:20,  3.96it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:34,486 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 152/234 [00:37<00:21,  3.90it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:34,755 >> Initializing global attention on CLS token...\n",
            "\n",
            " 65% 153/234 [00:37<00:21,  3.85it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:35,005 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 154/234 [00:38<00:20,  3.89it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:35,274 >> Initializing global attention on CLS token...\n",
            "\n",
            " 66% 155/234 [00:38<00:20,  3.84it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:35,535 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 156/234 [00:38<00:20,  3.83it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:35,789 >> Initializing global attention on CLS token...\n",
            "\n",
            " 67% 157/234 [00:38<00:19,  3.87it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:36,040 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 158/234 [00:39<00:19,  3.91it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:36,287 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 159/234 [00:39<00:18,  3.95it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:36,534 >> Initializing global attention on CLS token...\n",
            "\n",
            " 68% 160/234 [00:39<00:18,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:36,783 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 161/234 [00:39<00:18,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:37,030 >> Initializing global attention on CLS token...\n",
            "\n",
            " 69% 162/234 [00:40<00:17,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:37,279 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 163/234 [00:40<00:17,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:37,523 >> Initializing global attention on CLS token...\n",
            "\n",
            " 70% 164/234 [00:40<00:17,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:37,772 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 165/234 [00:40<00:17,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:38,018 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 166/234 [00:41<00:16,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:38,266 >> Initializing global attention on CLS token...\n",
            "\n",
            " 71% 167/234 [00:41<00:16,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:38,513 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 168/234 [00:41<00:16,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:38,762 >> Initializing global attention on CLS token...\n",
            "\n",
            " 72% 169/234 [00:41<00:16,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:39,012 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 170/234 [00:42<00:15,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:39,259 >> Initializing global attention on CLS token...\n",
            "\n",
            " 73% 171/234 [00:42<00:15,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:39,507 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 172/234 [00:42<00:15,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:39,755 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 173/234 [00:42<00:15,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:40,003 >> Initializing global attention on CLS token...\n",
            "\n",
            " 74% 174/234 [00:43<00:14,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:40,249 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 175/234 [00:43<00:14,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:40,508 >> Initializing global attention on CLS token...\n",
            "\n",
            " 75% 176/234 [00:43<00:14,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:40,754 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 177/234 [00:43<00:14,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:41,007 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 178/234 [00:44<00:14,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:41,252 >> Initializing global attention on CLS token...\n",
            "\n",
            " 76% 179/234 [00:44<00:13,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:41,499 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 180/234 [00:44<00:13,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:41,747 >> Initializing global attention on CLS token...\n",
            "\n",
            " 77% 181/234 [00:44<00:13,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:41,998 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 182/234 [00:45<00:12,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:42,246 >> Initializing global attention on CLS token...\n",
            "\n",
            " 78% 183/234 [00:45<00:12,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:42,493 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 184/234 [00:45<00:12,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:42,743 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 185/234 [00:45<00:12,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:43,000 >> Initializing global attention on CLS token...\n",
            "\n",
            " 79% 186/234 [00:46<00:12,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:43,249 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 187/234 [00:46<00:11,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:43,498 >> Initializing global attention on CLS token...\n",
            "\n",
            " 80% 188/234 [00:46<00:11,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:43,745 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 189/234 [00:46<00:11,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:43,993 >> Initializing global attention on CLS token...\n",
            "\n",
            " 81% 190/234 [00:47<00:10,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:44,245 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 191/234 [00:47<00:10,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:44,491 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 192/234 [00:47<00:10,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:44,740 >> Initializing global attention on CLS token...\n",
            "\n",
            " 82% 193/234 [00:47<00:10,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:44,988 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 194/234 [00:48<00:09,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:45,234 >> Initializing global attention on CLS token...\n",
            "\n",
            " 83% 195/234 [00:48<00:09,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:45,484 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 196/234 [00:48<00:09,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:45,740 >> Initializing global attention on CLS token...\n",
            "\n",
            " 84% 197/234 [00:48<00:09,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:45,987 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 198/234 [00:49<00:08,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:46,243 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 199/234 [00:49<00:08,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:46,492 >> Initializing global attention on CLS token...\n",
            "\n",
            " 85% 200/234 [00:49<00:08,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:46,738 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 201/234 [00:49<00:08,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:46,987 >> Initializing global attention on CLS token...\n",
            "\n",
            " 86% 202/234 [00:50<00:07,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:47,241 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 203/234 [00:50<00:07,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:47,488 >> Initializing global attention on CLS token...\n",
            "\n",
            " 87% 204/234 [00:50<00:07,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:47,736 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 205/234 [00:50<00:07,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:47,982 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 206/234 [00:51<00:06,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:48,229 >> Initializing global attention on CLS token...\n",
            "\n",
            " 88% 207/234 [00:51<00:06,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:48,479 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 208/234 [00:51<00:06,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:48,723 >> Initializing global attention on CLS token...\n",
            "\n",
            " 89% 209/234 [00:51<00:06,  4.06it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:48,967 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 210/234 [00:52<00:05,  4.07it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:49,211 >> Initializing global attention on CLS token...\n",
            "\n",
            " 90% 211/234 [00:52<00:05,  4.07it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:49,472 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 212/234 [00:52<00:05,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:49,718 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 213/234 [00:52<00:05,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:49,964 >> Initializing global attention on CLS token...\n",
            "\n",
            " 91% 214/234 [00:53<00:04,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:50,210 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 215/234 [00:53<00:04,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:50,461 >> Initializing global attention on CLS token...\n",
            "\n",
            " 92% 216/234 [00:53<00:04,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:50,708 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 217/234 [00:53<00:04,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:50,954 >> Initializing global attention on CLS token...\n",
            "\n",
            " 93% 218/234 [00:54<00:03,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:51,201 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 219/234 [00:54<00:03,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:51,451 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 220/234 [00:54<00:03,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:51,698 >> Initializing global attention on CLS token...\n",
            "\n",
            " 94% 221/234 [00:54<00:03,  4.03it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:51,946 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 222/234 [00:55<00:02,  4.04it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:52,197 >> Initializing global attention on CLS token...\n",
            "\n",
            " 95% 223/234 [00:55<00:02,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:52,447 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 224/234 [00:55<00:02,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:52,702 >> Initializing global attention on CLS token...\n",
            "\n",
            " 96% 225/234 [00:55<00:02,  3.99it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:52,955 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 226/234 [00:56<00:02,  3.97it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:53,205 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 227/234 [00:56<00:01,  3.98it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:53,452 >> Initializing global attention on CLS token...\n",
            "\n",
            " 97% 228/234 [00:56<00:01,  4.00it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:53,700 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 229/234 [00:56<00:01,  4.01it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:53,947 >> Initializing global attention on CLS token...\n",
            "\n",
            " 98% 230/234 [00:57<00:00,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:54,197 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 231/234 [00:57<00:00,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:54,446 >> Initializing global attention on CLS token...\n",
            "\n",
            " 99% 232/234 [00:57<00:00,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:54,694 >> Initializing global attention on CLS token...\n",
            "\n",
            "100% 233/234 [00:57<00:00,  4.02it/s]\u001b[A[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:54,923 >> Initializing global attention on CLS token...\n",
            "                                         \n",
            "\u001b[A{'eval_loss': 1.5590816736221313, 'eval_f1-micro': 0.7699999999999999, 'eval_f1-macro': 0.6929630678416155, 'eval_runtime': 59.3562, 'eval_samples_per_second': 23.586, 'eval_steps_per_second': 3.942, 'epoch': 10.0}\n",
            "100% 8340/8340 [2:05:14<00:00,  1.49it/s]\n",
            "100% 234/234 [00:59<00:00,  4.02it/s]\u001b[A\n",
            "                                     \u001b[A[INFO|trainer.py:2656] 2022-12-10 17:05:56,200 >> Saving model checkpoint to logs/output_1/checkpoint-8340\n",
            "[INFO|configuration_utils.py:447] 2022-12-10 17:05:56,201 >> Configuration saved in logs/output_1/checkpoint-8340/config.json\n",
            "[INFO|modeling_utils.py:1624] 2022-12-10 17:05:56,462 >> Model weights saved in logs/output_1/checkpoint-8340/pytorch_model.bin\n",
            "[INFO|tokenization_utils_base.py:2123] 2022-12-10 17:05:56,463 >> tokenizer config file saved in logs/output_1/checkpoint-8340/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2130] 2022-12-10 17:05:56,463 >> Special tokens file saved in logs/output_1/checkpoint-8340/special_tokens_map.json\n",
            "[INFO|trainer.py:1852] 2022-12-10 17:05:57,055 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "[INFO|trainer.py:1946] 2022-12-10 17:05:57,056 >> Loading best model from logs/output_1/checkpoint-7506 (score: 0.7721428571428571).\n",
            "{'train_runtime': 7515.5563, 'train_samples_per_second': 6.653, 'train_steps_per_second': 1.11, 'train_loss': 0.3217689167681358, 'epoch': 10.0}\n",
            "100% 8340/8340 [2:05:15<00:00,  1.11it/s]\n",
            "[INFO|trainer.py:725] 2022-12-10 17:05:57,242 >> The following columns in the evaluation set don't have a corresponding argument in `LongformerForSequenceClassification.forward` and have been ignored: text. If text are not expected by `LongformerForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "[INFO|trainer.py:2907] 2022-12-10 17:05:57,245 >> ***** Running Evaluation *****\n",
            "[INFO|trainer.py:2909] 2022-12-10 17:05:57,245 >>   Num examples = 1400\n",
            "[INFO|trainer.py:2912] 2022-12-10 17:05:57,245 >>   Batch size = 6\n",
            "[INFO|modeling_longformer.py:1932] 2022-12-10 17:05:57,278 >> Initializing global attention on CLS token...\n",
            "  0% 0/234 [00:00<?, ?it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:57,610 >> Initializing global attention on CLS token...\n",
            "  1% 2/234 [00:00<00:28,  8.09it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:57,856 >> Initializing global attention on CLS token...\n",
            "  1% 3/234 [00:00<00:40,  5.73it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:58,102 >> Initializing global attention on CLS token...\n",
            "  2% 4/234 [00:00<00:46,  4.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:58,348 >> Initializing global attention on CLS token...\n",
            "  2% 5/234 [00:00<00:49,  4.62it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:58,592 >> Initializing global attention on CLS token...\n",
            "  3% 6/234 [00:01<00:51,  4.44it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:58,839 >> Initializing global attention on CLS token...\n",
            "  3% 7/234 [00:01<00:52,  4.30it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:59,086 >> Initializing global attention on CLS token...\n",
            "  3% 8/234 [00:01<00:53,  4.21it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:59,334 >> Initializing global attention on CLS token...\n",
            "  4% 9/234 [00:01<00:54,  4.15it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:59,585 >> Initializing global attention on CLS token...\n",
            "  4% 10/234 [00:02<00:54,  4.11it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:05:59,834 >> Initializing global attention on CLS token...\n",
            "  5% 11/234 [00:02<00:54,  4.07it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:00,081 >> Initializing global attention on CLS token...\n",
            "  5% 12/234 [00:02<00:54,  4.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:00,328 >> Initializing global attention on CLS token...\n",
            "  6% 13/234 [00:02<00:54,  4.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:00,575 >> Initializing global attention on CLS token...\n",
            "  6% 14/234 [00:03<00:54,  4.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:00,821 >> Initializing global attention on CLS token...\n",
            "  6% 15/234 [00:03<00:53,  4.07it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:01,074 >> Initializing global attention on CLS token...\n",
            "  7% 16/234 [00:03<00:53,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:01,317 >> Initializing global attention on CLS token...\n",
            "  7% 17/234 [00:03<00:53,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:01,566 >> Initializing global attention on CLS token...\n",
            "  8% 18/234 [00:04<00:53,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:01,813 >> Initializing global attention on CLS token...\n",
            "  8% 19/234 [00:04<00:53,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:02,060 >> Initializing global attention on CLS token...\n",
            "  9% 20/234 [00:04<00:52,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:02,309 >> Initializing global attention on CLS token...\n",
            "  9% 21/234 [00:04<00:52,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:02,561 >> Initializing global attention on CLS token...\n",
            "  9% 22/234 [00:05<00:52,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:02,811 >> Initializing global attention on CLS token...\n",
            " 10% 23/234 [00:05<00:52,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:03,054 >> Initializing global attention on CLS token...\n",
            " 10% 24/234 [00:05<00:52,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:03,301 >> Initializing global attention on CLS token...\n",
            " 11% 25/234 [00:05<00:51,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:03,549 >> Initializing global attention on CLS token...\n",
            " 11% 26/234 [00:06<00:51,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:03,797 >> Initializing global attention on CLS token...\n",
            " 12% 27/234 [00:06<00:51,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:04,041 >> Initializing global attention on CLS token...\n",
            " 12% 28/234 [00:06<00:50,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:04,295 >> Initializing global attention on CLS token...\n",
            " 12% 29/234 [00:06<00:51,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:04,545 >> Initializing global attention on CLS token...\n",
            " 13% 30/234 [00:07<00:50,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:04,795 >> Initializing global attention on CLS token...\n",
            " 13% 31/234 [00:07<00:50,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:05,043 >> Initializing global attention on CLS token...\n",
            " 14% 32/234 [00:07<00:50,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:05,297 >> Initializing global attention on CLS token...\n",
            " 14% 33/234 [00:07<00:50,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:05,550 >> Initializing global attention on CLS token...\n",
            " 15% 34/234 [00:08<00:50,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:05,797 >> Initializing global attention on CLS token...\n",
            " 15% 35/234 [00:08<00:49,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:06,044 >> Initializing global attention on CLS token...\n",
            " 15% 36/234 [00:08<00:49,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:06,287 >> Initializing global attention on CLS token...\n",
            " 16% 37/234 [00:08<00:48,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:06,536 >> Initializing global attention on CLS token...\n",
            " 16% 38/234 [00:09<00:48,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:06,782 >> Initializing global attention on CLS token...\n",
            " 17% 39/234 [00:09<00:48,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:07,031 >> Initializing global attention on CLS token...\n",
            " 17% 40/234 [00:09<00:48,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:07,277 >> Initializing global attention on CLS token...\n",
            " 18% 41/234 [00:09<00:47,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:07,522 >> Initializing global attention on CLS token...\n",
            " 18% 42/234 [00:10<00:47,  4.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:07,767 >> Initializing global attention on CLS token...\n",
            " 18% 43/234 [00:10<00:47,  4.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:08,018 >> Initializing global attention on CLS token...\n",
            " 19% 44/234 [00:10<00:47,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:08,267 >> Initializing global attention on CLS token...\n",
            " 19% 45/234 [00:10<00:46,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:08,518 >> Initializing global attention on CLS token...\n",
            " 20% 46/234 [00:11<00:46,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:08,768 >> Initializing global attention on CLS token...\n",
            " 20% 47/234 [00:11<00:46,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:09,020 >> Initializing global attention on CLS token...\n",
            " 21% 48/234 [00:11<00:46,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:09,268 >> Initializing global attention on CLS token...\n",
            " 21% 49/234 [00:11<00:46,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:09,515 >> Initializing global attention on CLS token...\n",
            " 21% 50/234 [00:12<00:45,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:09,766 >> Initializing global attention on CLS token...\n",
            " 22% 51/234 [00:12<00:45,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:10,011 >> Initializing global attention on CLS token...\n",
            " 22% 52/234 [00:12<00:45,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:10,259 >> Initializing global attention on CLS token...\n",
            " 23% 53/234 [00:12<00:44,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:10,504 >> Initializing global attention on CLS token...\n",
            " 23% 54/234 [00:13<00:44,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:10,754 >> Initializing global attention on CLS token...\n",
            " 24% 55/234 [00:13<00:44,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:11,001 >> Initializing global attention on CLS token...\n",
            " 24% 56/234 [00:13<00:44,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:11,249 >> Initializing global attention on CLS token...\n",
            " 24% 57/234 [00:13<00:43,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:11,497 >> Initializing global attention on CLS token...\n",
            " 25% 58/234 [00:14<00:43,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:11,747 >> Initializing global attention on CLS token...\n",
            " 25% 59/234 [00:14<00:43,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:11,998 >> Initializing global attention on CLS token...\n",
            " 26% 60/234 [00:14<00:43,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:12,245 >> Initializing global attention on CLS token...\n",
            " 26% 61/234 [00:14<00:43,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:12,508 >> Initializing global attention on CLS token...\n",
            " 26% 62/234 [00:15<00:43,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:12,754 >> Initializing global attention on CLS token...\n",
            " 27% 63/234 [00:15<00:42,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:13,004 >> Initializing global attention on CLS token...\n",
            " 27% 64/234 [00:15<00:42,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:13,250 >> Initializing global attention on CLS token...\n",
            " 28% 65/234 [00:15<00:42,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:13,496 >> Initializing global attention on CLS token...\n",
            " 28% 66/234 [00:16<00:41,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:13,740 >> Initializing global attention on CLS token...\n",
            " 29% 67/234 [00:16<00:41,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:13,988 >> Initializing global attention on CLS token...\n",
            " 29% 68/234 [00:16<00:41,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:14,235 >> Initializing global attention on CLS token...\n",
            " 29% 69/234 [00:16<00:40,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:14,482 >> Initializing global attention on CLS token...\n",
            " 30% 70/234 [00:17<00:40,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:14,730 >> Initializing global attention on CLS token...\n",
            " 30% 71/234 [00:17<00:40,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:14,982 >> Initializing global attention on CLS token...\n",
            " 31% 72/234 [00:17<00:40,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:15,233 >> Initializing global attention on CLS token...\n",
            " 31% 73/234 [00:17<00:40,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:15,483 >> Initializing global attention on CLS token...\n",
            " 32% 74/234 [00:18<00:39,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:15,730 >> Initializing global attention on CLS token...\n",
            " 32% 75/234 [00:18<00:39,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:15,976 >> Initializing global attention on CLS token...\n",
            " 32% 76/234 [00:18<00:39,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:16,224 >> Initializing global attention on CLS token...\n",
            " 33% 77/234 [00:18<00:38,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:16,466 >> Initializing global attention on CLS token...\n",
            " 33% 78/234 [00:19<00:38,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:16,733 >> Initializing global attention on CLS token...\n",
            " 34% 79/234 [00:19<00:39,  3.97it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:16,978 >> Initializing global attention on CLS token...\n",
            " 34% 80/234 [00:19<00:38,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:17,224 >> Initializing global attention on CLS token...\n",
            " 35% 81/234 [00:19<00:38,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:17,470 >> Initializing global attention on CLS token...\n",
            " 35% 82/234 [00:20<00:37,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:17,736 >> Initializing global attention on CLS token...\n",
            " 35% 83/234 [00:20<00:38,  3.94it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:17,982 >> Initializing global attention on CLS token...\n",
            " 36% 84/234 [00:20<00:37,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:18,233 >> Initializing global attention on CLS token...\n",
            " 36% 85/234 [00:20<00:37,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:18,479 >> Initializing global attention on CLS token...\n",
            " 37% 86/234 [00:21<00:37,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:18,729 >> Initializing global attention on CLS token...\n",
            " 37% 87/234 [00:21<00:36,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:18,980 >> Initializing global attention on CLS token...\n",
            " 38% 88/234 [00:21<00:36,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:19,229 >> Initializing global attention on CLS token...\n",
            " 38% 89/234 [00:21<00:36,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:19,476 >> Initializing global attention on CLS token...\n",
            " 38% 90/234 [00:22<00:35,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:19,726 >> Initializing global attention on CLS token...\n",
            " 39% 91/234 [00:22<00:35,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:19,978 >> Initializing global attention on CLS token...\n",
            " 39% 92/234 [00:22<00:35,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:20,228 >> Initializing global attention on CLS token...\n",
            " 40% 93/234 [00:22<00:35,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:20,476 >> Initializing global attention on CLS token...\n",
            " 40% 94/234 [00:23<00:34,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:20,722 >> Initializing global attention on CLS token...\n",
            " 41% 95/234 [00:23<00:34,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:20,973 >> Initializing global attention on CLS token...\n",
            " 41% 96/234 [00:23<00:34,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:21,219 >> Initializing global attention on CLS token...\n",
            " 41% 97/234 [00:23<00:33,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:21,463 >> Initializing global attention on CLS token...\n",
            " 42% 98/234 [00:24<00:33,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:21,709 >> Initializing global attention on CLS token...\n",
            " 42% 99/234 [00:24<00:33,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:21,966 >> Initializing global attention on CLS token...\n",
            " 43% 100/234 [00:24<00:33,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:22,211 >> Initializing global attention on CLS token...\n",
            " 43% 101/234 [00:24<00:33,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:22,459 >> Initializing global attention on CLS token...\n",
            " 44% 102/234 [00:25<00:32,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:22,710 >> Initializing global attention on CLS token...\n",
            " 44% 103/234 [00:25<00:32,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:22,958 >> Initializing global attention on CLS token...\n",
            " 44% 104/234 [00:25<00:32,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:23,208 >> Initializing global attention on CLS token...\n",
            " 45% 105/234 [00:25<00:32,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:23,455 >> Initializing global attention on CLS token...\n",
            " 45% 106/234 [00:26<00:31,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:23,710 >> Initializing global attention on CLS token...\n",
            " 46% 107/234 [00:26<00:31,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:23,957 >> Initializing global attention on CLS token...\n",
            " 46% 108/234 [00:26<00:31,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:24,207 >> Initializing global attention on CLS token...\n",
            " 47% 109/234 [00:26<00:31,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:24,453 >> Initializing global attention on CLS token...\n",
            " 47% 110/234 [00:27<00:30,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:24,705 >> Initializing global attention on CLS token...\n",
            " 47% 111/234 [00:27<00:30,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:24,951 >> Initializing global attention on CLS token...\n",
            " 48% 112/234 [00:27<00:30,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:25,197 >> Initializing global attention on CLS token...\n",
            " 48% 113/234 [00:27<00:29,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:25,443 >> Initializing global attention on CLS token...\n",
            " 49% 114/234 [00:28<00:29,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:25,694 >> Initializing global attention on CLS token...\n",
            " 49% 115/234 [00:28<00:29,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:25,941 >> Initializing global attention on CLS token...\n",
            " 50% 116/234 [00:28<00:29,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:26,189 >> Initializing global attention on CLS token...\n",
            " 50% 117/234 [00:28<00:29,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:26,445 >> Initializing global attention on CLS token...\n",
            " 50% 118/234 [00:29<00:29,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:26,698 >> Initializing global attention on CLS token...\n",
            " 51% 119/234 [00:29<00:28,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:26,947 >> Initializing global attention on CLS token...\n",
            " 51% 120/234 [00:29<00:28,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:27,200 >> Initializing global attention on CLS token...\n",
            " 52% 121/234 [00:29<00:28,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:27,453 >> Initializing global attention on CLS token...\n",
            " 52% 122/234 [00:30<00:28,  3.97it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:27,703 >> Initializing global attention on CLS token...\n",
            " 53% 123/234 [00:30<00:27,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:27,949 >> Initializing global attention on CLS token...\n",
            " 53% 124/234 [00:30<00:27,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:28,197 >> Initializing global attention on CLS token...\n",
            " 53% 125/234 [00:30<00:27,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:28,444 >> Initializing global attention on CLS token...\n",
            " 54% 126/234 [00:31<00:26,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:28,691 >> Initializing global attention on CLS token...\n",
            " 54% 127/234 [00:31<00:26,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:28,949 >> Initializing global attention on CLS token...\n",
            " 55% 128/234 [00:31<00:26,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:29,194 >> Initializing global attention on CLS token...\n",
            " 55% 129/234 [00:31<00:26,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:29,443 >> Initializing global attention on CLS token...\n",
            " 56% 130/234 [00:32<00:25,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:29,687 >> Initializing global attention on CLS token...\n",
            " 56% 131/234 [00:32<00:25,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:29,942 >> Initializing global attention on CLS token...\n",
            " 56% 132/234 [00:32<00:25,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:30,187 >> Initializing global attention on CLS token...\n",
            " 57% 133/234 [00:32<00:25,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:30,434 >> Initializing global attention on CLS token...\n",
            " 57% 134/234 [00:33<00:24,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:30,681 >> Initializing global attention on CLS token...\n",
            " 58% 135/234 [00:33<00:24,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:30,931 >> Initializing global attention on CLS token...\n",
            " 58% 136/234 [00:33<00:24,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:31,179 >> Initializing global attention on CLS token...\n",
            " 59% 137/234 [00:33<00:24,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:31,434 >> Initializing global attention on CLS token...\n",
            " 59% 138/234 [00:34<00:23,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:31,685 >> Initializing global attention on CLS token...\n",
            " 59% 139/234 [00:34<00:23,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:31,933 >> Initializing global attention on CLS token...\n",
            " 60% 140/234 [00:34<00:23,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:32,181 >> Initializing global attention on CLS token...\n",
            " 60% 141/234 [00:34<00:23,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:32,430 >> Initializing global attention on CLS token...\n",
            " 61% 142/234 [00:35<00:22,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:32,676 >> Initializing global attention on CLS token...\n",
            " 61% 143/234 [00:35<00:22,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:32,923 >> Initializing global attention on CLS token...\n",
            " 62% 144/234 [00:35<00:22,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:33,172 >> Initializing global attention on CLS token...\n",
            " 62% 145/234 [00:35<00:22,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:33,419 >> Initializing global attention on CLS token...\n",
            " 62% 146/234 [00:36<00:21,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:33,666 >> Initializing global attention on CLS token...\n",
            " 63% 147/234 [00:36<00:21,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:33,913 >> Initializing global attention on CLS token...\n",
            " 63% 148/234 [00:36<00:21,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:34,163 >> Initializing global attention on CLS token...\n",
            " 64% 149/234 [00:36<00:21,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:34,412 >> Initializing global attention on CLS token...\n",
            " 64% 150/234 [00:37<00:20,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:34,660 >> Initializing global attention on CLS token...\n",
            " 65% 151/234 [00:37<00:20,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:34,907 >> Initializing global attention on CLS token...\n",
            " 65% 152/234 [00:37<00:20,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:35,160 >> Initializing global attention on CLS token...\n",
            " 65% 153/234 [00:37<00:20,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:35,409 >> Initializing global attention on CLS token...\n",
            " 66% 154/234 [00:38<00:19,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:35,654 >> Initializing global attention on CLS token...\n",
            " 66% 155/234 [00:38<00:19,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:35,902 >> Initializing global attention on CLS token...\n",
            " 67% 156/234 [00:38<00:19,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:36,150 >> Initializing global attention on CLS token...\n",
            " 67% 157/234 [00:38<00:19,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:36,399 >> Initializing global attention on CLS token...\n",
            " 68% 158/234 [00:39<00:18,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:36,646 >> Initializing global attention on CLS token...\n",
            " 68% 159/234 [00:39<00:18,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:36,893 >> Initializing global attention on CLS token...\n",
            " 68% 160/234 [00:39<00:18,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:37,138 >> Initializing global attention on CLS token...\n",
            " 69% 161/234 [00:39<00:18,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:37,388 >> Initializing global attention on CLS token...\n",
            " 69% 162/234 [00:40<00:17,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:37,638 >> Initializing global attention on CLS token...\n",
            " 70% 163/234 [00:40<00:17,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:37,889 >> Initializing global attention on CLS token...\n",
            " 70% 164/234 [00:40<00:17,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:38,136 >> Initializing global attention on CLS token...\n",
            " 71% 165/234 [00:40<00:17,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:38,384 >> Initializing global attention on CLS token...\n",
            " 71% 166/234 [00:41<00:16,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:38,631 >> Initializing global attention on CLS token...\n",
            " 71% 167/234 [00:41<00:16,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:38,879 >> Initializing global attention on CLS token...\n",
            " 72% 168/234 [00:41<00:16,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:39,134 >> Initializing global attention on CLS token...\n",
            " 72% 169/234 [00:41<00:16,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:39,380 >> Initializing global attention on CLS token...\n",
            " 73% 170/234 [00:42<00:15,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:39,625 >> Initializing global attention on CLS token...\n",
            " 73% 171/234 [00:42<00:15,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:39,872 >> Initializing global attention on CLS token...\n",
            " 74% 172/234 [00:42<00:15,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:40,126 >> Initializing global attention on CLS token...\n",
            " 74% 173/234 [00:42<00:15,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:40,371 >> Initializing global attention on CLS token...\n",
            " 74% 174/234 [00:43<00:14,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:40,624 >> Initializing global attention on CLS token...\n",
            " 75% 175/234 [00:43<00:14,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:40,870 >> Initializing global attention on CLS token...\n",
            " 75% 176/234 [00:43<00:14,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:41,117 >> Initializing global attention on CLS token...\n",
            " 76% 177/234 [00:43<00:14,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:41,364 >> Initializing global attention on CLS token...\n",
            " 76% 178/234 [00:44<00:13,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:41,612 >> Initializing global attention on CLS token...\n",
            " 76% 179/234 [00:44<00:13,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:41,861 >> Initializing global attention on CLS token...\n",
            " 77% 180/234 [00:44<00:13,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:42,111 >> Initializing global attention on CLS token...\n",
            " 77% 181/234 [00:44<00:13,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:42,365 >> Initializing global attention on CLS token...\n",
            " 78% 182/234 [00:45<00:13,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:42,611 >> Initializing global attention on CLS token...\n",
            " 78% 183/234 [00:45<00:12,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:42,863 >> Initializing global attention on CLS token...\n",
            " 79% 184/234 [00:45<00:12,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:43,112 >> Initializing global attention on CLS token...\n",
            " 79% 185/234 [00:45<00:12,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:43,359 >> Initializing global attention on CLS token...\n",
            " 79% 186/234 [00:45<00:11,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:43,606 >> Initializing global attention on CLS token...\n",
            " 80% 187/234 [00:46<00:11,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:43,855 >> Initializing global attention on CLS token...\n",
            " 80% 188/234 [00:46<00:11,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:44,101 >> Initializing global attention on CLS token...\n",
            " 81% 189/234 [00:46<00:11,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:44,364 >> Initializing global attention on CLS token...\n",
            " 81% 190/234 [00:47<00:11,  3.97it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:44,610 >> Initializing global attention on CLS token...\n",
            " 82% 191/234 [00:47<00:10,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:44,864 >> Initializing global attention on CLS token...\n",
            " 82% 192/234 [00:47<00:10,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:45,109 >> Initializing global attention on CLS token...\n",
            " 82% 193/234 [00:47<00:10,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:45,357 >> Initializing global attention on CLS token...\n",
            " 83% 194/234 [00:47<00:09,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:45,613 >> Initializing global attention on CLS token...\n",
            " 83% 195/234 [00:48<00:09,  3.99it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:45,857 >> Initializing global attention on CLS token...\n",
            " 84% 196/234 [00:48<00:09,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:46,109 >> Initializing global attention on CLS token...\n",
            " 84% 197/234 [00:48<00:09,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:46,355 >> Initializing global attention on CLS token...\n",
            " 85% 198/234 [00:48<00:08,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:46,602 >> Initializing global attention on CLS token...\n",
            " 85% 199/234 [00:49<00:08,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:46,849 >> Initializing global attention on CLS token...\n",
            " 85% 200/234 [00:49<00:08,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:47,096 >> Initializing global attention on CLS token...\n",
            " 86% 201/234 [00:49<00:08,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:47,344 >> Initializing global attention on CLS token...\n",
            " 86% 202/234 [00:49<00:07,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:47,591 >> Initializing global attention on CLS token...\n",
            " 87% 203/234 [00:50<00:07,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:47,837 >> Initializing global attention on CLS token...\n",
            " 87% 204/234 [00:50<00:07,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:48,091 >> Initializing global attention on CLS token...\n",
            " 88% 205/234 [00:50<00:07,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:48,339 >> Initializing global attention on CLS token...\n",
            " 88% 206/234 [00:50<00:06,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:48,601 >> Initializing global attention on CLS token...\n",
            " 88% 207/234 [00:51<00:06,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:48,855 >> Initializing global attention on CLS token...\n",
            " 89% 208/234 [00:51<00:06,  3.96it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:49,108 >> Initializing global attention on CLS token...\n",
            " 89% 209/234 [00:51<00:06,  3.95it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:49,354 >> Initializing global attention on CLS token...\n",
            " 90% 210/234 [00:51<00:06,  3.98it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:49,603 >> Initializing global attention on CLS token...\n",
            " 90% 211/234 [00:52<00:05,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:49,852 >> Initializing global attention on CLS token...\n",
            " 91% 212/234 [00:52<00:05,  4.00it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:50,100 >> Initializing global attention on CLS token...\n",
            " 91% 213/234 [00:52<00:05,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:50,347 >> Initializing global attention on CLS token...\n",
            " 91% 214/234 [00:52<00:04,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:50,594 >> Initializing global attention on CLS token...\n",
            " 92% 215/234 [00:53<00:04,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:50,843 >> Initializing global attention on CLS token...\n",
            " 92% 216/234 [00:53<00:04,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:51,090 >> Initializing global attention on CLS token...\n",
            " 93% 217/234 [00:53<00:04,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:51,341 >> Initializing global attention on CLS token...\n",
            " 93% 218/234 [00:53<00:03,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:51,586 >> Initializing global attention on CLS token...\n",
            " 94% 219/234 [00:54<00:03,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:51,839 >> Initializing global attention on CLS token...\n",
            " 94% 220/234 [00:54<00:03,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:52,083 >> Initializing global attention on CLS token...\n",
            " 94% 221/234 [00:54<00:03,  4.03it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:52,338 >> Initializing global attention on CLS token...\n",
            " 95% 222/234 [00:54<00:02,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:52,586 >> Initializing global attention on CLS token...\n",
            " 95% 223/234 [00:55<00:02,  4.01it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:52,834 >> Initializing global attention on CLS token...\n",
            " 96% 224/234 [00:55<00:02,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:53,083 >> Initializing global attention on CLS token...\n",
            " 96% 225/234 [00:55<00:02,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:53,331 >> Initializing global attention on CLS token...\n",
            " 97% 226/234 [00:55<00:01,  4.02it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:53,576 >> Initializing global attention on CLS token...\n",
            " 97% 227/234 [00:56<00:01,  4.04it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:53,824 >> Initializing global attention on CLS token...\n",
            " 97% 228/234 [00:56<00:01,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:54,068 >> Initializing global attention on CLS token...\n",
            " 98% 229/234 [00:56<00:01,  4.05it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:54,315 >> Initializing global attention on CLS token...\n",
            " 98% 230/234 [00:56<00:00,  4.06it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:54,559 >> Initializing global attention on CLS token...\n",
            " 99% 231/234 [00:57<00:00,  4.07it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:54,803 >> Initializing global attention on CLS token...\n",
            " 99% 232/234 [00:57<00:00,  4.09it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:55,047 >> Initializing global attention on CLS token...\n",
            "100% 233/234 [00:57<00:00,  4.09it/s][INFO|modeling_longformer.py:1932] 2022-12-10 17:06:55,271 >> Initializing global attention on CLS token...\n",
            "100% 234/234 [00:58<00:00,  3.99it/s]\n",
            "***** eval metrics *****\n",
            "  epoch                   =       10.0\n",
            "  eval_f1-macro           =     0.6319\n",
            "  eval_f1-micro           =     0.7521\n",
            "  eval_loss               =     1.7822\n",
            "  eval_runtime            = 0:00:58.96\n",
            "  eval_samples_per_second =     23.745\n",
            "  eval_steps_per_second   =      3.969\n"
          ]
        }
      ],
      "source": [
        "!python /content/IR_LDC/model/SCOTUS/bregman_scotus_classification.py \\\n",
        "    --output_dir logs/output_1 \\\n",
        "    --model_name 'danielsaggau/legal_long_bert' \\\n",
        "    --model_type 'mean' \\\n",
        "    --load_best_model_at_end \\\n",
        "    --overwrite_output_dir \\\n",
        "    --evaluation_strategy epoch \\\n",
        "    --save_strategy epoch \\\n",
        "    --learning_rate 3e-5 \\\n",
        "    --per_device_train_batch_size 6 \\\n",
        "    --per_device_eval_batch_size 6 \\\n",
        "    --num_train_epochs 10 \\\n",
        "    --weight_decay 0.01 \\\n",
        "    --fp16 \\\n",
        "    --gradient_accumulation_steps 1 \\\n",
        "    --metric_for_best_model \"f1-micro\" \\\n",
        "    --greater_is_better 1 \\\n",
        "    --report_to 'wandb'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z2d0yLc_allP"
      },
      "outputs": [],
      "source": [
        "re"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s98bKNICA_lc"
      },
      "source": [
        "```function ClickConnect(){\n",
        "    console.log(\"Clicked on connect button\"); \n",
        "    document.querySelector(\"colab-connect-button\").click()\n",
        "}\n",
        "setInterval(ClickConnect,60000)```"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "authorship_tag": "ABX9TyMDNc7T2m9JGuUOvHGYJTCh",
      "include_colab_link": true,
      "machine_shape": "hm",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
