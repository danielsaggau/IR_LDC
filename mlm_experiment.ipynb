{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mlm_experiment.ipynb",
      "provenance": [],
      "mount_file_id": "1n5Tjz763vGClxdXuuUg3aM02MevWlUnw",
      "authorship_tag": "ABX9TyNujzjqU0Tg3bh2ubKBSKZF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/mlm_experiment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TrN5wvHTkxqY"
      },
      "outputs": [],
      "source": [
        "!pip install sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/UKPLab/sentence-transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7av4u5vmB37",
        "outputId": "08d4aff3-fe4f-46e1-9dcd-a8bf16c99b1b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'sentence-transformers'...\n",
            "remote: Enumerating objects: 6798, done.\u001b[K\n",
            "remote: Counting objects: 100% (220/220), done.\u001b[K\n",
            "remote: Compressing objects: 100% (122/122), done.\u001b[K\n",
            "remote: Total 6798 (delta 127), reused 160 (delta 97), pack-reused 6578\u001b[K\n",
            "Receiving objects: 100% (6798/6798), 19.63 MiB | 21.66 MiB/s, done.\n",
            "Resolving deltas: 100% (4645/4645), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/sentence-transformers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4MqjW4OzmFPG",
        "outputId": "1f0f5529-03bb-4cd5-df2c-8d4e232043ed"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/sentence-transformers\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install datasets\n",
        "from datasets import load_dataset\n",
        "dataset = load_dataset(\"ecthr_cases\")"
      ],
      "metadata": {
        "id": "cIF9yeDhn-Cy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset['test']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "94cnkFy6oA6s",
        "outputId": "c06f71a4-27d7-48ca-f752-0e9ce11f9a2c"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['facts', 'labels', 'silver_rationales', 'gold_rationales'],\n",
              "    num_rows: 1000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with open('your_file.txt', 'w') as f:\n",
        "    for line in dataset['test']['facts']:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "zDV-Qa-woaov"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python /content/sentence-transformers/examples/unsupervised_learning/MLM/train_mlm.py distilbert-base-uncased /content/sentence-transformers/your_file.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RtQHZw_ylOUo",
        "outputId": "48798f23-40ec-4568-b265-4b65c2d8e8f3"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Save checkpoints to: output/distilbert-base-uncased-2022-08-25_15-44-10\n",
            "Train sentences: 1000\n",
            "Dev sentences: 0\n",
            "Save tokenizer to: output/distilbert-base-uncased-2022-08-25_15-44-10\n",
            "tokenizer config file saved in output/distilbert-base-uncased-2022-08-25_15-44-10/tokenizer_config.json\n",
            "Special tokens file saved in output/distilbert-base-uncased-2022-08-25_15-44-10/special_tokens_map.json\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:310: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 1000\n",
            "  Num Epochs = 3\n",
            "  Instantaneous batch size per device = 64\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 48\n",
            "100% 48/48 [30:49<00:00, 35.12s/it]\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 1849.1386, 'train_samples_per_second': 1.622, 'train_steps_per_second': 0.026, 'train_loss': 1.8406602541605632, 'epoch': 3.0}\n",
            "100% 48/48 [30:49<00:00, 38.52s/it]\n",
            "Save model to: output/distilbert-base-uncased-2022-08-25_15-44-10\n",
            "Configuration saved in output/distilbert-base-uncased-2022-08-25_15-44-10/config.json\n",
            "Model weights saved in output/distilbert-base-uncased-2022-08-25_15-44-10/pytorch_model.bin\n",
            "Training done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-myeg1l6pQXH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}