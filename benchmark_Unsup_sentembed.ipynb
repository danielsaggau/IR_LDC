{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOSTgA2GnS1wkYHxegoR5YB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/danielsaggau/IR_LDC/blob/main/benchmark_Unsup_sentembed.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a4lC6VDnYiFe"
      },
      "outputs": [],
      "source": [
        "!git clone https://github.com/princeton-nlp/SimCSE.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.7.1+cu110 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "id": "bqBcypHKYkRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch==1.7.1"
      ],
      "metadata": {
        "id": "32popNEWYoCM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SimCSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MEqyqBgKYqa9",
        "outputId": "23faff90-e268-4371-faac-908fa6a86c83"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SimCSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "id": "CFDfL-cxmtn7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd SentEval/data/downstream/\n",
        "!bash download_dataset.sh"
      ],
      "metadata": {
        "id": "fZqYuuQam5mb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/SimCSE"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-fwZAuCnHEC",
        "outputId": "18616ba3-ac0d-4ed8-fa71-bdb3884c3c6c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/SimCSE\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluation.py \\\n",
        "    --model_name_or_path princeton-nlp/sup-simcse-bert-base-uncased \\\n",
        "    --pooler cls \\\n",
        "    --task_set sts \\\n",
        "    --mode test"
      ],
      "metadata": {
        "id": "-xOCoMy1nGbN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python evaluation.py \\\n",
        "    --model_name_or_path princeton-nlp/sup-simcse-bert-base-uncased \\\n",
        "    --pooler cls \\\n",
        "    --task_set full \\\n",
        "    --mode test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fWcORKUGrC5O",
        "outputId": "0669d086-e553-4b3c-9a54-b3ff648117d3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2022-10-19 14:39:09,782 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:10,711 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "2022-10-19 14:39:10,714 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:11,627 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/pytorch_model.bin HTTP/1.1\" 302 0\n",
            "2022-10-19 14:39:13,980 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:14,927 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
            "2022-10-19 14:39:14,931 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:15,867 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
            "2022-10-19 14:39:15,871 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:16,801 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 404 0\n",
            "2022-10-19 14:39:16,804 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:17,713 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
            "2022-10-19 14:39:17,716 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:18,624 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/special_tokens_map.json HTTP/1.1\" 200 0\n",
            "2022-10-19 14:39:18,627 : Starting new HTTPS connection (1): huggingface.co:443\n",
            "2022-10-19 14:39:19,578 : https://huggingface.co:443 \"HEAD /princeton-nlp/sup-simcse-bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
            "2022-10-19 14:39:22,943 : ***** Transfer task : STS12 *****\n",
            "\n",
            "\n",
            "./SentEval/senteval/sts.py:42: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  sent1 = np.array([s.split() for s in sent1])[not_empty_idx]\n",
            "./SentEval/senteval/sts.py:43: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  sent2 = np.array([s.split() for s in sent2])[not_empty_idx]\n",
            "2022-10-19 14:39:26,273 : MSRpar : pearson = 0.6199, spearman = 0.6253\n",
            "2022-10-19 14:39:27,522 : MSRvid : pearson = 0.9261, spearman = 0.9293\n",
            "2022-10-19 14:39:28,623 : SMTeuroparl : pearson = 0.4987, spearman = 0.5878\n",
            "2022-10-19 14:39:30,845 : surprise.OnWN : pearson = 0.7662, spearman = 0.6992\n",
            "2022-10-19 14:39:31,977 : surprise.SMTnews : pearson = 0.7292, spearman = 0.6098\n",
            "2022-10-19 14:39:31,979 : ALL : Pearson = 0.8438,             Spearman = 0.7530\n",
            "2022-10-19 14:39:31,979 : ALL (weighted average) : Pearson = 0.7252,             Spearman = 0.7090\n",
            "2022-10-19 14:39:31,979 : ALL (average) : Pearson = 0.7080,             Spearman = 0.6903\n",
            "\n",
            "2022-10-19 14:39:31,982 : ***** Transfer task : STS13 (-SMT) *****\n",
            "\n",
            "\n",
            "2022-10-19 14:39:33,108 : FNWN : pearson = 0.6293, spearman = 0.6379\n",
            "2022-10-19 14:39:34,639 : headlines : pearson = 0.8011, spearman = 0.8231\n",
            "2022-10-19 14:39:35,821 : OnWN : pearson = 0.8772, spearman = 0.8635\n",
            "2022-10-19 14:39:35,823 : ALL : Pearson = 0.8306,             Spearman = 0.8467\n",
            "2022-10-19 14:39:35,823 : ALL (weighted average) : Pearson = 0.8079,             Spearman = 0.8149\n",
            "2022-10-19 14:39:35,823 : ALL (average) : Pearson = 0.7692,             Spearman = 0.7748\n",
            "\n",
            "2022-10-19 14:39:35,825 : ***** Transfer task : STS14 *****\n",
            "\n",
            "\n",
            "2022-10-19 14:39:37,016 : deft-forum : pearson = 0.6477, spearman = 0.6436\n",
            "2022-10-19 14:39:38,408 : deft-news : pearson = 0.8242, spearman = 0.8096\n",
            "2022-10-19 14:39:40,218 : headlines : pearson = 0.7931, spearman = 0.7909\n",
            "2022-10-19 14:39:41,916 : images : pearson = 0.8937, spearman = 0.8658\n",
            "2022-10-19 14:39:43,754 : OnWN : pearson = 0.8949, spearman = 0.8752\n",
            "2022-10-19 14:39:46,233 : tweet-news : pearson = 0.8357, spearman = 0.7677\n",
            "2022-10-19 14:39:46,236 : ALL : Pearson = 0.8251,             Spearman = 0.8019\n",
            "2022-10-19 14:39:46,236 : ALL (weighted average) : Pearson = 0.8271,             Spearman = 0.8019\n",
            "2022-10-19 14:39:46,236 : ALL (average) : Pearson = 0.8149,             Spearman = 0.7921\n",
            "\n",
            "2022-10-19 14:39:46,239 : ***** Transfer task : STS15 *****\n",
            "\n",
            "\n",
            "2022-10-19 14:39:48,021 : answers-forums : pearson = 0.7454, spearman = 0.7464\n",
            "2022-10-19 14:39:49,742 : answers-students : pearson = 0.7442, spearman = 0.7512\n",
            "2022-10-19 14:39:51,578 : belief : pearson = 0.8519, spearman = 0.8722\n",
            "2022-10-19 14:39:53,491 : headlines : pearson = 0.8209, spearman = 0.8539\n",
            "2022-10-19 14:39:55,334 : images : pearson = 0.9273, spearman = 0.9372\n",
            "2022-10-19 14:39:55,336 : ALL : Pearson = 0.8428,             Spearman = 0.8540\n",
            "2022-10-19 14:39:55,336 : ALL (weighted average) : Pearson = 0.8227,             Spearman = 0.8379\n",
            "2022-10-19 14:39:55,336 : ALL (average) : Pearson = 0.8179,             Spearman = 0.8322\n",
            "\n",
            "2022-10-19 14:39:55,339 : ***** Transfer task : STS16 *****\n",
            "\n",
            "\n",
            "2022-10-19 14:39:56,095 : answer-answer : pearson = 0.7629, spearman = 0.7651\n",
            "2022-10-19 14:39:56,683 : headlines : pearson = 0.7947, spearman = 0.8354\n",
            "2022-10-19 14:39:57,479 : plagiarism : pearson = 0.8431, spearman = 0.8652\n",
            "2022-10-19 14:39:58,806 : postediting : pearson = 0.8448, spearman = 0.8863\n",
            "2022-10-19 14:39:59,341 : question-question : pearson = 0.7289, spearman = 0.7348\n",
            "2022-10-19 14:39:59,343 : ALL : Pearson = 0.7821,             Spearman = 0.8082\n",
            "2022-10-19 14:39:59,343 : ALL (weighted average) : Pearson = 0.7960,             Spearman = 0.8189\n",
            "2022-10-19 14:39:59,343 : ALL (average) : Pearson = 0.7949,             Spearman = 0.8174\n",
            "\n",
            "2022-10-19 14:39:59,344 : \n",
            "\n",
            "***** Transfer task : STSBenchmark*****\n",
            "\n",
            "\n",
            "2022-10-19 14:40:20,744 : train : pearson = 0.8365, spearman = 0.8330\n",
            "2022-10-19 14:40:27,248 : dev : pearson = 0.8569, spearman = 0.8619\n",
            "2022-10-19 14:40:32,561 : test : pearson = 0.8328, spearman = 0.8426\n",
            "2022-10-19 14:40:32,566 : ALL : Pearson = 0.8401,             Spearman = 0.8413\n",
            "2022-10-19 14:40:32,566 : ALL (weighted average) : Pearson = 0.8394,             Spearman = 0.8396\n",
            "2022-10-19 14:40:32,566 : ALL (average) : Pearson = 0.8421,             Spearman = 0.8458\n",
            "\n",
            "2022-10-19 14:40:32,572 : \n",
            "\n",
            "***** Transfer task : SICKRelatedness*****\n",
            "\n",
            "\n",
            "2022-10-19 14:40:45,415 : train : pearson = 0.8583, spearman = 0.8099\n",
            "2022-10-19 14:40:47,061 : dev : pearson = 0.8519, spearman = 0.8256\n",
            "2022-10-19 14:41:00,817 : test : pearson = 0.8512, spearman = 0.8039\n",
            "2022-10-19 14:41:00,822 : ALL : Pearson = 0.8546,             Spearman = 0.8077\n",
            "2022-10-19 14:41:00,822 : ALL (weighted average) : Pearson = 0.8545,             Spearman = 0.8077\n",
            "2022-10-19 14:41:00,822 : ALL (average) : Pearson = 0.8538,             Spearman = 0.8131\n",
            "\n",
            "2022-10-19 14:41:00,828 : ***** Transfer task : MR *****\n",
            "\n",
            "\n",
            "2022-10-19 14:41:00,915 : Generating sentence embeddings\n",
            "2022-10-19 14:41:28,957 : Generated sentence embeddings\n",
            "2022-10-19 14:41:28,958 : Training pytorch-MLP-nhid0-adam-bs64 with (inner) 10-fold cross-validation\n",
            "2022-10-19 14:45:07,231 : Best param found at split 1: l2reg = 0.0001                 with score 83.78\n",
            "2022-10-19 14:48:43,100 : Best param found at split 2: l2reg = 0.0001                 with score 83.94\n",
            "2022-10-19 14:52:16,761 : Best param found at split 3: l2reg = 1e-05                 with score 83.3\n",
            "2022-10-19 14:55:48,583 : Best param found at split 4: l2reg = 0.0001                 with score 83.53\n",
            "2022-10-19 14:59:14,618 : Best param found at split 5: l2reg = 0.001                 with score 83.45\n",
            "2022-10-19 15:02:46,523 : Best param found at split 6: l2reg = 0.001                 with score 83.51\n",
            "2022-10-19 15:06:13,582 : Best param found at split 7: l2reg = 1e-05                 with score 83.64\n",
            "2022-10-19 15:09:48,157 : Best param found at split 8: l2reg = 0.0001                 with score 83.31\n",
            "2022-10-19 15:13:08,241 : Best param found at split 9: l2reg = 1e-05                 with score 83.56\n",
            "2022-10-19 15:16:27,587 : Best param found at split 10: l2reg = 0.0001                 with score 83.31\n",
            "2022-10-19 15:16:32,400 : Dev acc : 83.53 Test acc : 82.88\n",
            "\n",
            "2022-10-19 15:16:32,405 : ***** Transfer task : CR *****\n",
            "\n",
            "\n",
            "2022-10-19 15:16:32,414 : Generating sentence embeddings\n",
            "2022-10-19 15:16:40,038 : Generated sentence embeddings\n",
            "2022-10-19 15:16:40,039 : Training pytorch-MLP-nhid0-adam-bs64 with (inner) 10-fold cross-validation\n",
            "2022-10-19 15:17:45,306 : Best param found at split 1: l2reg = 0.01                 with score 90.14\n",
            "2022-10-19 15:18:51,411 : Best param found at split 2: l2reg = 1e-05                 with score 90.29\n",
            "2022-10-19 15:19:54,871 : Best param found at split 3: l2reg = 0.01                 with score 89.99\n",
            "2022-10-19 15:21:01,250 : Best param found at split 4: l2reg = 0.001                 with score 90.17\n",
            "2022-10-19 15:22:07,870 : Best param found at split 5: l2reg = 0.001                 with score 90.26\n",
            "2022-10-19 15:23:12,006 : Best param found at split 6: l2reg = 1e-05                 with score 89.82\n",
            "2022-10-19 15:24:17,197 : Best param found at split 7: l2reg = 1e-05                 with score 89.73\n",
            "2022-10-19 15:25:20,821 : Best param found at split 8: l2reg = 0.001                 with score 90.05\n",
            "2022-10-19 15:26:24,587 : Best param found at split 9: l2reg = 0.001                 with score 89.82\n",
            "2022-10-19 15:27:26,669 : Best param found at split 10: l2reg = 0.001                 with score 89.7\n",
            "2022-10-19 15:27:28,577 : Dev acc : 90.0 Test acc : 89.2\n",
            "\n",
            "2022-10-19 15:27:28,579 : ***** Transfer task : MPQA *****\n",
            "\n",
            "\n",
            "2022-10-19 15:27:28,590 : Generating sentence embeddings\n",
            "2022-10-19 15:27:35,219 : Generated sentence embeddings\n",
            "2022-10-19 15:27:35,220 : Training pytorch-MLP-nhid0-adam-bs64 with (inner) 10-fold cross-validation\n",
            "2022-10-19 15:30:53,491 : Best param found at split 1: l2reg = 1e-05                 with score 90.19\n",
            "2022-10-19 15:34:23,254 : Best param found at split 2: l2reg = 1e-05                 with score 90.12\n",
            "2022-10-19 15:37:52,515 : Best param found at split 3: l2reg = 1e-05                 with score 89.89\n",
            "2022-10-19 15:41:22,309 : Best param found at split 4: l2reg = 1e-05                 with score 90.04\n",
            "2022-10-19 15:44:50,076 : Best param found at split 5: l2reg = 1e-05                 with score 90.18\n",
            "2022-10-19 15:48:13,057 : Best param found at split 6: l2reg = 1e-05                 with score 90.06\n",
            "2022-10-19 15:51:31,918 : Best param found at split 7: l2reg = 0.001                 with score 90.18\n",
            "2022-10-19 15:54:55,978 : Best param found at split 8: l2reg = 0.0001                 with score 90.18\n",
            "2022-10-19 15:58:10,672 : Best param found at split 9: l2reg = 1e-05                 with score 90.02\n",
            "2022-10-19 16:01:36,050 : Best param found at split 10: l2reg = 1e-05                 with score 90.19\n",
            "2022-10-19 16:01:41,353 : Dev acc : 90.1 Test acc : 89.67\n",
            "\n",
            "2022-10-19 16:01:41,356 : ***** Transfer task : SUBJ *****\n",
            "\n",
            "\n",
            "2022-10-19 16:01:41,448 : Generating sentence embeddings\n",
            "2022-10-19 16:02:11,068 : Generated sentence embeddings\n",
            "2022-10-19 16:02:11,069 : Training pytorch-MLP-nhid0-adam-bs64 with (inner) 10-fold cross-validation\n",
            "2022-10-19 16:05:48,116 : Best param found at split 1: l2reg = 0.0001                 with score 95.17\n",
            "2022-10-19 16:09:34,720 : Best param found at split 2: l2reg = 1e-05                 with score 95.29\n",
            "2022-10-19 16:13:12,772 : Best param found at split 3: l2reg = 1e-05                 with score 95.28\n",
            "2022-10-19 16:16:50,534 : Best param found at split 4: l2reg = 1e-05                 with score 95.12\n",
            "2022-10-19 16:20:29,109 : Best param found at split 5: l2reg = 0.0001                 with score 95.01\n",
            "2022-10-19 16:24:09,554 : Best param found at split 6: l2reg = 0.0001                 with score 95.17\n",
            "2022-10-19 16:27:56,444 : Best param found at split 7: l2reg = 0.0001                 with score 95.3\n",
            "2022-10-19 16:31:38,236 : Best param found at split 8: l2reg = 1e-05                 with score 95.26\n",
            "2022-10-19 16:35:26,571 : Best param found at split 9: l2reg = 1e-05                 with score 95.24\n",
            "2022-10-19 16:39:10,184 : Best param found at split 10: l2reg = 1e-05                 with score 95.11\n",
            "2022-10-19 16:39:16,715 : Dev acc : 95.2 Test acc : 94.81\n",
            "\n",
            "2022-10-19 16:39:16,721 : ***** Transfer task : SST Binary classification *****\n",
            "\n",
            "\n",
            "2022-10-19 16:39:16,908 : Computing embedding for train\n",
            "2022-10-19 16:40:46,474 : Computed train embeddings\n",
            "2022-10-19 16:40:46,474 : Computing embedding for dev\n",
            "2022-10-19 16:40:48,396 : Computed dev embeddings\n",
            "2022-10-19 16:40:48,396 : Computing embedding for test\n",
            "2022-10-19 16:40:52,571 : Computed test embeddings\n",
            "2022-10-19 16:40:52,571 : Training pytorch-MLP-nhid0-adam-bs64 with standard validation..\n",
            "2022-10-19 16:43:19,640 : [('reg:1e-05', 88.07), ('reg:0.0001', 87.84), ('reg:0.001', 87.61), ('reg:0.01', 86.93)]\n",
            "2022-10-19 16:43:19,640 : Validation : best param found is reg = 1e-05 with score             88.07\n",
            "2022-10-19 16:43:19,641 : Evaluating...\n",
            "2022-10-19 16:43:58,779 : \n",
            "Dev acc : 88.07 Test acc : 87.31 for             SST Binary classification\n",
            "\n",
            "2022-10-19 16:43:58,816 : ***** Transfer task : TREC *****\n",
            "\n",
            "\n",
            "2022-10-19 16:44:05,645 : Computed train embeddings\n",
            "2022-10-19 16:44:06,191 : Computed test embeddings\n",
            "2022-10-19 16:44:06,192 : Training pytorch-MLP-nhid0-adam-bs64 with 10-fold cross-validation\n",
            "2022-10-19 16:46:56,711 : [('reg:1e-05', 83.22), ('reg:0.0001', 83.16), ('reg:0.001', 82.23), ('reg:0.01', 78.08)]\n",
            "2022-10-19 16:46:56,711 : Cross-validation : best param found is reg = 1e-05             with score 83.22\n",
            "2022-10-19 16:46:56,711 : Evaluating...\n",
            "2022-10-19 16:47:00,955 : \n",
            "Dev acc : 83.22 Test acc : 88.4             for TREC\n",
            "\n",
            "2022-10-19 16:47:00,958 : ***** Transfer task : MRPC *****\n",
            "\n",
            "\n",
            "2022-10-19 16:47:00,982 : Computing embedding for train\n",
            "2022-10-19 16:47:22,497 : Computed train embeddings\n",
            "2022-10-19 16:47:22,497 : Computing embedding for test\n",
            "2022-10-19 16:47:31,549 : Computed test embeddings\n",
            "2022-10-19 16:47:31,573 : Training pytorch-MLP-nhid0-adam-bs64 with 10-fold cross-validation\n",
            "2022-10-19 16:48:48,878 : [('reg:1e-05', 76.62), ('reg:0.0001', 76.59), ('reg:0.001', 76.52), ('reg:0.01', 76.42)]\n",
            "2022-10-19 16:48:48,879 : Cross-validation : best param found is reg = 1e-05             with score 76.62\n",
            "2022-10-19 16:48:48,879 : Evaluating...\n",
            "2022-10-19 16:48:51,438 : Dev acc : 76.62 Test acc 73.51; Test F1 80.93 for MRPC.\n",
            "\n",
            "------ test ------\n",
            "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
            "| STS12 | STS13 | STS14 | STS15 | STS16 | STSBenchmark | SICKRelatedness |  Avg. |\n",
            "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
            "| 75.30 | 84.67 | 80.19 | 85.40 | 80.82 |    84.26     |      80.39      | 81.58 |\n",
            "+-------+-------+-------+-------+-------+--------------+-----------------+-------+\n",
            "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "|   MR  |   CR  |  SUBJ |  MPQA |  SST2 |  TREC |  MRPC |  Avg. |\n",
            "+-------+-------+-------+-------+-------+-------+-------+-------+\n",
            "| 82.88 | 89.20 | 94.81 | 89.67 | 87.31 | 88.40 | 73.51 | 86.54 |\n",
            "+-------+-------+-------+-------+-------+-------+-------+-------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# unsupervised method with NLI \n",
        "!bash data/download_wiki.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nSq6OUmTsWqw",
        "outputId": "12fe5306-8069-459c-ce7b-47e3b8c55146"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2022-10-19 16:53:57--  https://huggingface.co/datasets/princeton-nlp/datasets-for-simcse/resolve/main/wiki1m_for_simcse.txt\n",
            "Resolving huggingface.co (huggingface.co)... 52.204.9.116, 52.5.54.249, 54.210.225.113, ...\n",
            "Connecting to huggingface.co (huggingface.co)|52.204.9.116|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/datasets/princeton-nlp/datasets-for-simcse/7b1825863a99aa76479b0456f7c210539dfaeeb69598b41fb4de4f524dd5a706?response-content-disposition=attachment%3B%20filename%3D%22wiki1m_for_simcse.txt%22&Expires=1666457592&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2RhdGFzZXRzL3ByaW5jZXRvbi1ubHAvZGF0YXNldHMtZm9yLXNpbWNzZS83YjE4MjU4NjNhOTlhYTc2NDc5YjA0NTZmN2MyMTA1MzlkZmFlZWI2OTU5OGI0MWZiNGRlNGY1MjRkZDVhNzA2P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249YXR0YWNobWVudCUzQiUyMGZpbGVuYW1lJTNEJTIyd2lraTFtX2Zvcl9zaW1jc2UudHh0JTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY2NDU3NTkyfX19XX0_&Signature=w-~6iSTuSPywLRiTR271qMm2SU2DMX4Wf85kcW-XBaj3Ro3l6FUaiH59IZMoSH7JDYzzo3kOfIFXPPrL4Z5xx0xspdHiPLWrCOUG~0NgtEFBsRkao-geYGBl6aIlo5oGYKc2gfHGwTV4iC2Gkv3gVPAg2IFxw4~a0JlvskTa72GtF-~KjU0dKO4FFDyIiLNn49bKi7Rw5srTc7lOxnzTeKALHNYe5zn2g-hWWiDsqsmLrCFXmkDV8RgY22oFESrWJENRRZCnY5WFrEiDYP32d8OvcW7gFjn9V3WYQ0iHKB5UHnQn9jWUFSZkollcKCajPGApf8nxEqyTmsPwUHKZZw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2022-10-19 16:53:58--  https://cdn-lfs.huggingface.co/datasets/princeton-nlp/datasets-for-simcse/7b1825863a99aa76479b0456f7c210539dfaeeb69598b41fb4de4f524dd5a706?response-content-disposition=attachment%3B%20filename%3D%22wiki1m_for_simcse.txt%22&Expires=1666457592&Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jZG4tbGZzLmh1Z2dpbmdmYWNlLmNvL2RhdGFzZXRzL3ByaW5jZXRvbi1ubHAvZGF0YXNldHMtZm9yLXNpbWNzZS83YjE4MjU4NjNhOTlhYTc2NDc5YjA0NTZmN2MyMTA1MzlkZmFlZWI2OTU5OGI0MWZiNGRlNGY1MjRkZDVhNzA2P3Jlc3BvbnNlLWNvbnRlbnQtZGlzcG9zaXRpb249YXR0YWNobWVudCUzQiUyMGZpbGVuYW1lJTNEJTIyd2lraTFtX2Zvcl9zaW1jc2UudHh0JTIyIiwiQ29uZGl0aW9uIjp7IkRhdGVMZXNzVGhhbiI6eyJBV1M6RXBvY2hUaW1lIjoxNjY2NDU3NTkyfX19XX0_&Signature=w-~6iSTuSPywLRiTR271qMm2SU2DMX4Wf85kcW-XBaj3Ro3l6FUaiH59IZMoSH7JDYzzo3kOfIFXPPrL4Z5xx0xspdHiPLWrCOUG~0NgtEFBsRkao-geYGBl6aIlo5oGYKc2gfHGwTV4iC2Gkv3gVPAg2IFxw4~a0JlvskTa72GtF-~KjU0dKO4FFDyIiLNn49bKi7Rw5srTc7lOxnzTeKALHNYe5zn2g-hWWiDsqsmLrCFXmkDV8RgY22oFESrWJENRRZCnY5WFrEiDYP32d8OvcW7gFjn9V3WYQ0iHKB5UHnQn9jWUFSZkollcKCajPGApf8nxEqyTmsPwUHKZZw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 13.227.254.123, 13.227.254.33, 13.227.254.47, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|13.227.254.123|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 120038621 (114M) [text/plain]\n",
            "Saving to: ‘wiki1m_for_simcse.txt.1’\n",
            "\n",
            "wiki1m_for_simcse.t 100%[===================>] 114.48M   277MB/s    in 0.4s    \n",
            "\n",
            "2022-10-19 16:53:59 (277 MB/s) - ‘wiki1m_for_simcse.txt.1’ saved [120038621/120038621]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!bash run_unsup_example.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D4xN67x8tKIh",
        "outputId": "9c99db83-76ef-4697-b61f-034269edd296"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:__main__:Process rank: -1, device: cuda:0, n_gpu: 1 distributed training: False, 16-bits training: True\n",
            "WARNING:datasets.builder:Using custom data configuration default-6a5f262011017c5e\n",
            "Downloading and preparing dataset text/default to /content/SimCSE/./data/text/default-6a5f262011017c5e/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad...\n",
            "Downloading data files: 100% 1/1 [00:00<00:00, 7345.54it/s]\n",
            "Extracting data files: 100% 1/1 [00:00<00:00, 557.98it/s]\n",
            "Dataset text downloaded and prepared to /content/SimCSE/./data/text/default-6a5f262011017c5e/0.0.0/21a506d1b2b34316b1e82d0bd79066905d846e5d7e619823c0dd338d6f1fa6ad. Subsequent calls will reuse this data.\n",
            "100% 1/1 [00:00<00:00, 344.05it/s]\n",
            "[INFO|file_utils.py:1272] 2022-10-19 16:54:21,621 >> https://huggingface.co/bert-base-uncased/resolve/main/config.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpce8dyu0j\n",
            "Downloading: 100% 570/570 [00:00<00:00, 511kB/s]\n",
            "[INFO|file_utils.py:1276] 2022-10-19 16:54:22,551 >> storing https://huggingface.co/bert-base-uncased/resolve/main/config.json in cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "[INFO|file_utils.py:1279] 2022-10-19 16:54:22,551 >> creating metadata file for /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "[INFO|configuration_utils.py:445] 2022-10-19 16:54:22,552 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "[INFO|configuration_utils.py:481] 2022-10-19 16:54:22,552 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.2.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|configuration_utils.py:445] 2022-10-19 16:54:23,466 >> loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
            "[INFO|configuration_utils.py:481] 2022-10-19 16:54:23,467 >> Model config BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.2.1\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "[INFO|file_utils.py:1272] 2022-10-19 16:54:24,411 >> https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmp7hekgkf8\n",
            "Downloading: 100% 232k/232k [00:00<00:00, 255kB/s]\n",
            "[INFO|file_utils.py:1276] 2022-10-19 16:54:26,249 >> storing https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt in cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|file_utils.py:1279] 2022-10-19 16:54:26,249 >> creating metadata file for /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|file_utils.py:1272] 2022-10-19 16:54:27,180 >> https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpy7py3sl4\n",
            "Downloading: 100% 466k/466k [00:01<00:00, 412kB/s]\n",
            "[INFO|file_utils.py:1276] 2022-10-19 16:54:29,245 >> storing https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json in cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "[INFO|file_utils.py:1279] 2022-10-19 16:54:29,246 >> creating metadata file for /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-10-19 16:54:29,246 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
            "[INFO|tokenization_utils_base.py:1766] 2022-10-19 16:54:29,246 >> loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
            "[INFO|file_utils.py:1272] 2022-10-19 16:54:30,203 >> https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/huggingface/transformers/tmpjxitwpaq\n",
            "Downloading: 100% 440M/440M [00:06<00:00, 73.3MB/s]\n",
            "[INFO|file_utils.py:1276] 2022-10-19 16:54:36,230 >> storing https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin in cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "[INFO|file_utils.py:1279] 2022-10-19 16:54:36,231 >> creating metadata file for /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "[INFO|modeling_utils.py:1027] 2022-10-19 16:54:36,231 >> loading weights file https://huggingface.co/bert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f\n",
            "[WARNING|modeling_utils.py:1135] 2022-10-19 16:54:39,662 >> Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForCL: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForCL from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForCL from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "[WARNING|modeling_utils.py:1146] 2022-10-19 16:54:39,662 >> Some weights of BertForCL were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['mlp.dense.weight', 'mlp.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "100% 999/1000 [02:47<00:00,  5.97ba/s]\n",
            "[INFO|trainer.py:442] 2022-10-19 16:57:32,749 >> The following columns in the training set don't have a corresponding argument in `BertForCL.forward` and have been ignored: .\n",
            "[INFO|trainer.py:358] 2022-10-19 16:57:32,750 >> Using amp fp16 backend\n",
            "  0% 0/15625 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/optim/lr_scheduler.py:136: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
            "  \"https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\", UserWarning)\n",
            "{'eval_stsb_spearman': 0.6421115350839484, 'eval_sickr_spearman': 0.6019637558236653, 'eval_avg_sts': 0.6220376454538068, 'epoch': 0.01}\n",
            "  1% 125/15625 [01:29<1:05:09,  3.97it/s][INFO|trainer.py:1344] 2022-10-19 16:59:02,645 >> Saving model checkpoint to result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2022-10-19 16:59:02,647 >> Configuration saved in result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2022-10-19 16:59:03,954 >> Model weights saved in result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "{'eval_stsb_spearman': 0.729741373709072, 'eval_sickr_spearman': 0.6785767728256571, 'eval_avg_sts': 0.7041590732673646, 'epoch': 0.02}\n",
            "  2% 250/15625 [03:08<1:09:08,  3.71it/s][INFO|trainer.py:1344] 2022-10-19 17:00:41,663 >> Saving model checkpoint to result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2022-10-19 17:00:41,665 >> Configuration saved in result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2022-10-19 17:00:43,049 >> Model weights saved in result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "{'eval_stsb_spearman': 0.7527492625834318, 'eval_sickr_spearman': 0.6877809727942427, 'eval_avg_sts': 0.7202651176888373, 'epoch': 0.02}\n",
            "  2% 375/15625 [04:48<1:09:13,  3.67it/s][INFO|trainer.py:1344] 2022-10-19 17:02:21,172 >> Saving model checkpoint to result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2022-10-19 17:02:21,173 >> Configuration saved in result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2022-10-19 17:02:22,570 >> Model weights saved in result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "{'loss': 0.0118, 'learning_rate': 2.904e-05, 'epoch': 0.03}\n",
            "{'eval_stsb_spearman': 0.741668788754357, 'eval_sickr_spearman': 0.6824211341536622, 'eval_avg_sts': 0.7120449614540096, 'epoch': 0.03}\n",
            "{'eval_stsb_spearman': 0.7429090974383863, 'eval_sickr_spearman': 0.6817717056311176, 'eval_avg_sts': 0.7123404015347519, 'epoch': 0.04}\n",
            "{'eval_stsb_spearman': 0.7597268339041375, 'eval_sickr_spearman': 0.6972679798880959, 'eval_avg_sts': 0.7284974068961168, 'epoch': 0.05}\n",
            "  5% 750/15625 [09:36<1:06:51,  3.71it/s][INFO|trainer.py:1344] 2022-10-19 17:07:09,758 >> Saving model checkpoint to result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2022-10-19 17:07:09,760 >> Configuration saved in result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2022-10-19 17:07:11,088 >> Model weights saved in result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "{'eval_stsb_spearman': 0.7772175461526007, 'eval_sickr_spearman': 0.7052118126489952, 'eval_avg_sts': 0.741214679400798, 'epoch': 0.06}\n",
            "  6% 875/15625 [11:17<1:07:46,  3.63it/s][INFO|trainer.py:1344] 2022-10-19 17:08:49,994 >> Saving model checkpoint to result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2022-10-19 17:08:49,996 >> Configuration saved in result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2022-10-19 17:08:51,492 >> Model weights saved in result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "{'loss': 0.0002, 'learning_rate': 2.8080000000000002e-05, 'epoch': 0.06}\n",
            "{'eval_stsb_spearman': 0.7937373388760115, 'eval_sickr_spearman': 0.7118902321922047, 'eval_avg_sts': 0.7528137855341082, 'epoch': 0.06}\n",
            "  6% 1000/15625 [13:00<1:08:42,  3.55it/s][INFO|trainer.py:1344] 2022-10-19 17:10:33,335 >> Saving model checkpoint to result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2022-10-19 17:10:33,336 >> Configuration saved in result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2022-10-19 17:10:34,775 >> Model weights saved in result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "{'eval_stsb_spearman': 0.7925443433918514, 'eval_sickr_spearman': 0.7050203437535115, 'eval_avg_sts': 0.7487823435726815, 'epoch': 0.07}\n",
            "{'eval_stsb_spearman': 0.7961862985669826, 'eval_sickr_spearman': 0.7084001962995086, 'eval_avg_sts': 0.7522932474332455, 'epoch': 0.08}\n",
            "  8% 1250/15625 [16:15<1:04:24,  3.72it/s][INFO|trainer.py:1344] 2022-10-19 17:13:48,435 >> Saving model checkpoint to result/my-unsup-simcse-bert-base-uncased\n",
            "[INFO|configuration_utils.py:300] 2022-10-19 17:13:48,437 >> Configuration saved in result/my-unsup-simcse-bert-base-uncased/config.json\n",
            "[INFO|modeling_utils.py:817] 2022-10-19 17:13:50,230 >> Model weights saved in result/my-unsup-simcse-bert-base-uncased/pytorch_model.bin\n",
            "{'eval_stsb_spearman': 0.7942476228518577, 'eval_sickr_spearman': 0.7091388666085253, 'eval_avg_sts': 0.7516932447301915, 'epoch': 0.09}\n",
            "{'loss': 0.0001, 'learning_rate': 2.712e-05, 'epoch': 0.1}\n",
            "{'eval_stsb_spearman': 0.7877131272391296, 'eval_sickr_spearman': 0.7111094386072269, 'eval_avg_sts': 0.7494112829231783, 'epoch': 0.1}\n",
            "{'eval_stsb_spearman': 0.7587555609918589, 'eval_sickr_spearman': 0.6725029038310978, 'eval_avg_sts': 0.7156292324114784, 'epoch': 0.1}\n",
            "{'eval_stsb_spearman': 0.7656960046026939, 'eval_sickr_spearman': 0.6798159272116591, 'eval_avg_sts': 0.7227559659071765, 'epoch': 0.11}\n",
            "{'eval_stsb_spearman': 0.7319923497008028, 'eval_sickr_spearman': 0.6465032363427345, 'eval_avg_sts': 0.6892477930217686, 'epoch': 0.12}\n",
            "{'loss': 0.0002, 'learning_rate': 2.616e-05, 'epoch': 0.13}\n",
            "{'eval_stsb_spearman': 0.7576662381760485, 'eval_sickr_spearman': 0.6730706314500963, 'eval_avg_sts': 0.7153684348130724, 'epoch': 0.13}\n",
            "{'eval_stsb_spearman': 0.762843606517689, 'eval_sickr_spearman': 0.6764458249792539, 'eval_avg_sts': 0.7196447157484714, 'epoch': 0.14}\n",
            "{'eval_stsb_spearman': 0.7694719340457052, 'eval_sickr_spearman': 0.7006714637360005, 'eval_avg_sts': 0.7350716988908529, 'epoch': 0.14}\n",
            "{'eval_stsb_spearman': 0.7695292997436569, 'eval_sickr_spearman': 0.6991267835137508, 'eval_avg_sts': 0.7343280416287039, 'epoch': 0.15}\n",
            " 16% 2463/15625 [30:57<59:03,  3.71it/s]"
          ]
        }
      ]
    }
  ]
}